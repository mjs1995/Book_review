# 서평
- 이 책을 읽기 전까지 엔지니어가 결국 기업의 의사결정을 효율적으로 지원하는 역할을 해야 한다고 생각했습니다. 이에 따라 백엔드부터 비즈니스 인텔리전스, 인공지능, 머신러닝, 그리고 MLOps까지 다양한 분야를 고려해야 한다고 생각했습니다. 그러나 이 책을 통해 데이터 엔지니어의 궁극적인 목적과 역할에 대해 새롭게 조명을 받게 되었습니다.
- 데이터 엔지니어링의 생명주기는 데이터의 생성부터 저장, 수집, 변환, 그리고 서빙까지 이르며, 이 전 과정에 걸쳐 보안, 데이터 관리, DevOps, 아키텍처, 그리고 오케스트레이션, 소프트웨어 엔지니어링까지 다양한 요소들이 복합적으로 작용합니다. 결국, 데이터 엔지니어는 이러한 수명주기 전반에 걸쳐 기업의 투자수익률(ROI)을 극대화하고, 재무적, 기회적 비용을 최소화하며, 다양한 리스크(보안과 데이터 품질 등)를 효과적으로 관리하는 것이 최상위 목표라 할 수 있습니다.
- 이 책은 "어떻게 하면 비즈니스에 진정한 가치를 더하는 데이터 엔지니어가 될 수 있을까?" 그리고 "데이터 엔지니어로서 고려해야 할 핵심 요소들은 무엇인가?" 등의 본질적인 질문에 대한 깊이 있는 통찰을 제공합니다. 이 책에서 탐구하는 데이터 엔지니어의 역할은 더욱 정확하게는 '데이터 수명주기 엔지니어'라고 칭할 수 있을 만큼 전반적이고 종합적인 관점을 제시합니다.

# 데이터 엔지니어링 기반 구축하기
## 데이터 엔지니어링 상세 
- 데이터 엔지니어링이란?
  - 알텍스소프트의 데이터 엔지니어링의 개념, 프로세스 및 도구
    - 데이터 엔지니어링은 데이터 과학자, 데이터 분석가, 비즈니스 인텔리전스 개발자, 그리고 조직 내의 다른 전문가가 데이터를 사용할 수 있도록 만드는 일련의 작업이다. 대규모의 데이터를 수집 및 저장하면서 추가 분석을 수행할 수 있는 데이터를 준비하기 위한 시스템을 설계하고 구축하려면 데이터 엔지니어와 같은 전담 전문가가 필요하다. 간단히 말해서, 데이터 엔지니어는 조직의 데이터 인프라를 구축하고 운영해 데이터 분석가와 데이터 과학자가 추가 분석을 수행할 수 있도록 준비한다.
  - 데이터 엔지니어링 정의
    - 데이터 엔지니어링은 원시 데이터(raw data)를 가져와 분석 및 머신러닝과 같은 다운스트림 사용 사례를 지원하는, 고품질의 일관된 정보를 시스템과 프로세스의 개발, 구현 및 유지 관리이다. 데이터 엔지니어링은 보안, 데이터 관리, 데이터 운영, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링의 교차점이다.
    - 데이터 엔지니어는 원천 시스템에서 데이터를 가져오는 것부터 시작해 분석 또는 머신러닝과 같은 사용 사례에 데이터를 제공하는 것으로 끝나는 데이터 엔지니어링 수명 주기를 관리한다.
  - 데이터 엔지니어링 수명 주기
    - 단계
      - 데이터 생성(generation)
      - 데이터 저장(Storage)
      - 데이터 수집(Ingestion)
      - 데이터 변환(Transformation)
      - 데이터 서빙(Serving)
    - 데이터 엔지니어링 수명 주기는 전체 수명 주기에 걸쳐 중요한 아이디어인 드러나지 않는 요소(undercurrent)라는 개념을 포함함. 여기에는 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링이 포함됨
  - 데이터 엔지니어의 진화
    - 1980년부터 2000년까지: 데이터 웨어하우징에서 웹으로
      - 1980년대에 비즈니스 데이터 웨어하우스라는 용어가 형성되었으며 1989년 빌 인먼이 데이터 웨어하우스라는 용어를 공식적으로 만들었음.
      - IBM의 엔지니어들이 관계형 데이터 베이스와 구조적 질의 언어(SQL, Structured Query Language)를 개발한 이후 오라클은 이 기술을 대중화함
      - BI를 위한 전용  툴과 데이터 파이프라인이 필요해졌으며 랄프 킴벌과 빌 인먼은 데이터 모델링 기법과 접근 방식을 개발 했음
      - 데이터 웨어하우징은 대량의 데이터를 처리하고 전례 없는 막대한 양의 데이터를 지원하고자, 다수의 프로세서를 사용하는 새로운 대규모 병렬 처리(MPP) 데이터베이스로 확장성 있는 분석의 첫 시대를 열음. 이로 인해 BI 엔지니어, ETL 개발자, 데이터 웨어하우스 엔지니어와 같은 역할은 데이터 웨어하우스의 다양한 요구 사항을 해결함 
      - 인터넷은 1990년대 중반에 주류를 이루었고 AOL, 야후, 아마존과 같은 세대의 웹 우선(web-first) 기업을 탄생함. 닷컴 열풍은 웹 애플리케이션과 이를 지원하는 백엔드 시스템(서버, 데이터베이스 ,스토리지)에서 엄청난 활동을 만듬. 대부분의 인프라는 비용이 많이 들고, 거대했으며, 라이선스의 부담이 매우 컸음 
    - 2000년대 초: 현대 데이터 엔지니어링의 탄생
      - 닷컴 열풍이 무너지고 생존자 중 일부인 야후, 구글, 아마존 같은 기업들은 강력한 기술 기업으로 성장함. 1990년대의 전통적인 모놀리식 관계형 데이터베이스와 데이터 웨어하우스에 계속 의존하면서 시스템을 한계까지 몰아붙임.
      - 데이터의 폭발적 증가와 함께 서버, RAM, 디스크, 플래시 드라이브와 같은 범용 하드웨어도 저렴해지고 어디서나 사용할 수 있게 됐으며 몇 가지 혁신은 대규모 컴퓨팅 클러스터에서의 분산 연산 및 저장을 실현함. 이러한 혁신은 전통적인 모놀리식 서비스를 분산하고 분리하기 시작함.(빅데이터시대, 3V)
      - 2003년 구글은 구글 파일 시스템에 관한 논문을 발표했고, 그 직후인 2004년에는 초확장 데이터 처리 패러다임인 맵리듀스에 대한 논문을 발표했음.
      - 구글의 논문들은 야후의 엔지니어들이 2006년 아파치 하둡을 개발하고 나중에 오픈소스하는 데 영감을 주었음. 모든 규모와 유형의 기업들이 다루는 데이터가 테라바이트, 심지어 페타바이트 규모로 증가하면서 빅데이터 엔지니어 시대가 탄생함
      - 비슷한 시기에 아마존은 폭발적으로 증가하는 데이터 요구에 대응해야 했으며 EC2, S3, 다이나모DB를 비롯한 데이터 빌딩 블록을 구축했음. AWS가 아마존의 높은 수익성을 책임지는 성장 엔진이 되면서 구글 클라우드, 마이크로소프트 애저, 디지털오션과 같은 다른 퍼블릭 클라우드가 잇따라 등장하기 시작함.퍼블릭 클라우드는 소프트웨어와 데이터 애플리케이션의 개발 및 배포 방식에 혁명을 일으킴  
    - 2000년대와 2010년대: 빅데이터 엔지니어링
      - 하둡 생태계의 오픈 소스 빅데이터 도구는 빠르게 성숙했고, 배치 컴퓨팅에서 이벤트 스트리밍으로의 전환과 함께 또 다른 혁명이 발생했고 실시간 빅데이터의 새로운 시대를 열었음.
      - 엔지니어는 하둡, 피그, 하이브, 드레멜, HBase, 스톰, 카산드라, 스파크, 프레스토 등 최신 기술을 선택할 수 있었고 기존의 엔터프라이즈 지향적이고 GUI 기반인 데이터 도구는 갑자기 구식으로 느껴지며 맵리듀스의 출현으로 코드 우선(code-first) 엔지니어링이 유행했음
      - 데이터 도구가 폭발적으로 증가하면서 빅데이터 엔지니어가 탄생했으며 하둡,얀,HDFS,맵리듀스를 포함하는 하둡 생태계 같은 도구와 기술을 효과적으로 사용하려면 빅데이터 엔지니어가 소프트웨어 개발 및 저수준의 인프라 해키에 능숙해야 했지만, 강조점이 바뀌었음. 빅데이터 엔지니어는 보통 대규모 데이터를 제공하고자 상용 하드웨어의 대규모 클러스터를 유지 관리했고 핵심 기술 개발에서 데이터 전달로 초점이 옮겨짐.
    - 2020년대: 데이터 수명 주기를 위한 엔지니어링
      - 데이터 엔지니어는 역사적으로 하둡, 스파크 또는 인포매티카와 같은 모놀리식 프레임워크의 저수준의 세부 정보를 사용하는 경향이 있었음. 하지만 이제는 그 트렌드가 분산되고 모듈화되고, 관리되고, 고도로 추상화된 도구로 이동중임
      - 데이터 엔지니어링은 점차 궁극적인 비즈니스 목표를 달성하고자 다양한 기술을 마치 레고 블록처럼 연결하고 상호 운용하는 분야가 되고 있음
      - 데이터 엔지니어는 여전히 저수준의 데이터 프로그래밍 기술을 유지하고 필요에 따라 이를 사용합니다. 하지만 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션 및 일반 데이터 수명 주기 관리와 같은 가치 사슬의 상위 영역에 자신의 역할이 점점 더 집중되고 있음을 발견함
      - 이제 CCPA와 GDPR 같은 약어에 정통하며 파이프라인을 설계할때는 개인정보보호, 익명화, 데이터 가비지 수집 및 규정 준수에 관심을 가지고 고민함
- 데이터 엔지니어링 기술과 활동
  - 데이터 엔지니어의 기술 역량에는 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처 및 소프트웨어 엔지니어링과 같은 데이터 엔지니어링의 드러나지 않는 요소가 포함됨
  - 데이터 엔지니어는 수많은 복잡한 가변적 요소를 처리하고 비용, 민첩성, 확장성, 단순성, 재사용성, 상호 운용성의 축에 따라 지속해서 최적화를 수행해야 함
  - 데이터 성숙도와 데이터 엔지니어
    - 데이터 성숙도(data maturity)는 조직 전체어 걸쳐 더 높은 데이터 활용률(utilization), 기능(capability), 통합(ingegration)을 향해 나아가는 과정
    - 단순화된 기업용 데이터 성숙도 모델
      - 데이터로 시작하기
        - 데이터로 시작하는 조직의 데이터 엔지니어는 다음과 같은 사항에 중점을 두어야 함
          - 데이터 엔지니어는 기업의 목표를 지원하는 데이터 아키텍처를 설계하고 구축하는 중요한 계획에 대한 스폰서를 확보하는 것이 이상적
          - 적절한 데이터 아키텍처를 정의한다(데이터 아키텍트가 없을 가능성이 높으므로 보통 홀로 진행함). 이는 데이터 이니셔티브를  통해 달성하려는 경영 목표와 경쟁 우위를 결정한다는 의미로, 이러한 목표를 지원하는 데이터 아키텍처를 구축함 
      - 데이터로 확장하기
        - 해당 조직에서 데이터 엔지니어의 목표
          - 공식적인 데이터 관행 수립
          - 확장성 있고 견고한 데이터 아키텍처 구축
          - 데브옵스 및 데이터옵스 관행 채택
          - ML을 지원하는 시스템 구축
          - 차별화되지 않은 과중한 업무를 피하고, 경쟁 우위를 확보할 때만 커스터마이징 
      - 데이터로 선도하기
        - 이전 단계를 계속 구축함과 동시에 다음 작업을 수행함
          - 새로운 데이터의 매끄러운 배포와 사용을 위한 자동화를 구축함
          - 경쟁 우위로서 데이터를 활용하는 사용자 정의 도구와 시스템 구축에 주력함
          - 데이터 관리(데이터 거버넌스와 품질을 포함) 및 데이터옵스와 같은 데이터의 기업적 측면에 집중함
          - 데이터 카탈로그, 데이터 계보 도구, 메타데이터 관리 시스템을 포함해 데이터를 조직 전체에 노출하고 전파하는 도구를 배포함
          - 소프트웨어 엔지니어, ML 엔지니어, 분석가 등과 효율적으로 협업함
          - 역할이나 직책과 관계없이 사람들이 협업하고 공개적으로 토론할 수 있는 커뮤니티와 환경을 구축함
  - 데이터 엔지니어의 배경과 기술
    - 데이터 엔지니어는 정의상 데이터와 기술을 모두 이해해야 함.
      - 데이터 측면에서는 데이터 관리의 다양한 모범 사례를 알아야 함
      - 기술 측면에서는 데이터 엔지니어가 도구들의 다양한 옵션, 상호 작용 및 상충 관계를 알아야 함. 그러려면 소프트웨어 엔지니어링, 데이터옵스 및 데이터 아키텍처를 이해해야 함 
  - 기술 책임
    - 최근 들어 완전 관리형 서비스는 과거 엔지니어들에게 요구되는 수많은 저수준 프로그래밍 작업을 상당 부분 대체하게 됐음. 이제 엔지니어는 관리형 오픈 소스와 단순한 플러그 앤 플레이 SaaS 제품을 사용함
    - 예를 들어 데이터 엔지니어는 이제 고수준의 추상화에 주력하거나 오케스트레이션 프레임워크 내에서 파이프라인을 코드로 작성하는 작업에 더 집중함
    - 데이터 엔지니어링의 주요 언어
      - SQL
        - 스파크 SQL, 구글 빅쿼리, 스노우플레이크, 하이브 및 기타 여러 데이터 도구는 선언적이고 집합론적인 SQL 시맨틱을 사용해 대량의 데이터를 처리할 수 있음.
        - SQL은 아파치 플링크, 빔, 카프카와 같은 많은 스트리밍 프레임워크에서도 지원됨 
      - Python, Java, Scalar
      - 자바 가상 머신
        - 스파크, 하이브, 드루이드와 같은 아파치 오픈 소스 프로젝트에 널리 쓰임
        - JVM은 보통 파이썬보다 성능이 우수하며,(스파크와 빔등의 경우) 파이썬 API보다 저수준의 특성에 접근할 수 있음.
        - 널리 쓰이는 오픈 소스 데이터 프레임워크를 사용한다면 자바 또는 스칼라와 같은 언어를 이해하는 것이 유용함 
      - bash
    - 보저직인 프로그래밍 언어
      - R, 자바스크립트, Go, Rust, C/C++, C#, Julia 등
  - A에서 B로 이어지는 데이터 엔지니어링 역할의 연속성
    - A형 데이터 엔지니어
      - A는 추상화(abstraction)을 의미함. 이 경우 데이터 엔지니어는 차별화되지 않은 과중한 작업을 피하고, 데이터 아키텍처를 가능한 한 추상적이고 단순하게 유지함으로써 시간 낭비를 피함
      - A형 데이터 엔지니어는 주로 시판되는 기성 제품, 관리형 서비스와 도구들을 사용해 데이터 엔지니어링 수명 주기를 관리함.
      - A형 데이터 엔지니어는 데이터 성숙도 수준에 상관없이 산업계 전반에 걸쳐 다양한 회사에서 근무함
    - B형 데이터 엔지니어
      - B는 구축을(build)를 의미함
      - B형 데이터 엔지니어는 기업의 핵심 역량과 경쟁 우위를 확장하고 활용할 데이터 도구와 시스템을 구축함
      - B형 데이터 엔지니어는 데이터 성숙도 범위에서 (데이터로 확장하고 선도하는) 2단계 및 3단계에 해당하거나, 초기 데이터 사용 사례가 매우 독특하고 중요해서 작업을 시작하려면 맞춤형 데이터 도구가 필요한 회사에서 더 많이 찾아볼 수 있음 
- 조직 내 데이터 엔지니어
  - 내부 vs 외부 대면 데이터 엔지니어
    - 외부 대면(external-facing) 데이터 엔지니어는 일반적으로 소셜 미디어 앱, 사물 인터넷 장치, 전자 상거래 플랫폼과 같은 외부용 애플리케이션의 사용자와 연계함. 이 데이터 엔지니어는 이러한 애플리케이션에서 발생하는 트랜잭션 및 이벤트 데이터를 수집, 저장, 처리하는 시스템을 설계, 구축, 관리함
    - 내부 대면(internal-facing) 데이터 엔지니어는 일반적으로 비즈니스 및 내부 이해관계자의 요구 사항에 중요한 활동에 집중함. 예를 들면 BI 대시보드, 보고서, 비즈니스 프로세스, 데이터 과학, ML 모델용 데이터 파이프라인과 데이터 웨어하우스의 생성 및 유지 보수 등이 포함됨 
  - 데이터 엔지니어와 기타 기술 역할
    - 데이터 엔지니어는 소프트웨어 엔지니어, 데이터 아키텍트, 데브옵스 엔지니어 또는 사이트 신뢰성 엔지니어(SRE) 같은 데이터 생산자(data producer)와 데이터 분석가, 데이터 과학자, ML 엔지니어 등과 같은 데이터 소비자(data consumer)사이에서 허브 역할을 함. 또한 데이터 엔지니어는 데브옵스 엔지니어와 같이 운영 역할을 하는 사람들과 소통함
    - 업스트림 이해 관계자
      - 데이터 아키텍트
        - 데이터 아키텍트는 조직 내 데이터 관리를 위한 청사진을 설계하고, 프로세스와 전체 데이터 아키텍처 및 시스템을 매핑함. 또한 조직의 기술적 측면과 비기술적 측면을 연결하는 가교 역할을 수행함
        - 데이터 아키텍트는 사일로 및 사업부 전체에 걸쳐 데이터를 관리하는 정책을 구현하고, 데이터 관리 및 데이터 거버넌스와 같은 글로벌 전략을 조율하며, 중요한 이니셔티브를 안내함.
        - 데이터 아키텍트는 클라우드 마이그레이션과 신규 클라우드 설계에서 중심적인 역할을 수행하는 경우가 많음
      - 소프트웨어 엔지니어
        - 소프트웨어 엔지니어는 비즈니스를 운영하는 소프트웨어와 시스템을 구축함. 이들은 데이터 엔지니어가 소비하고 처리하는 내부 데이터(internal data)의 생성 업무에 큰 책임이 있음.
        - 소프트웨어 엔지니어가 구축한 시스템은 보통 애플리케이션 이벤트 데이터와 로그를 생성하는데 이는 그 자체로 중요한 자산임. 이러한 내부 데이터는 SaaS 플랫폼 또는 파트너 비즈니스에서 가져온 외부 데이터(external data)와 대조됨
      - 데브옵스 엔지니어와 사이트 신뢰성 엔지니어
        - 데브옵스 엔지니어와 사이트 신뢰성 엔지니어(SRE)는 종종 운영 모니터링을 통해 데이터를 생성함
    - 다운스트림 이해관계자
      - 데이터 과학자
        - 데이터 과학자는 예측과 추천을 위한 미래 지향적인 모델을 구축함. 그런 다음 이러한 모델을 라이브 데이터로 평가해 다양한 방식으로 가치를 제공함
        - 특히 널리 사용되는 수많은 데이터 과학 프레임워크는 적절히 확장되지 않으면 병목 현상이 발생할 수 있음. 단일 워크스테이션에서만 작업하는 데이터 과학자는 데이터 다운샘플링을 강요당해 데이터 준비가 상당히 복잡해지고 만들어낸 모델의 품질이 저하될 가능성이 있음. 게다가 로컬에서 개발된 코드와 환경은 실제 운영 환경에서 배포하기 어렵고, 자동화가 부족하면 데이터 과학 워크플로에 크게 방해가 됨
      - 데이터 분석가
        - 데이터 분석가(또는 비즈니스 분석가)는 비즈니스 성과와 동향을 파악하고자 함. 데이터 과학자가 미래지향적이라면 데이터 분석가는 보통 과거 또는 현재에 초점을 맞춤
        - 데이터 분석가는 일반적으로 데이터 웨어하우스 또는 데이터 레이크에서 SQL 쿼리를 실행함. 또한 계산 및 분석을 위해 스프레드시트를 활용하며 마이크로소프트 파워 BI, 루커, 태블로 등의 다양한 BI 도구를 사용할 수도 있음
        - 데이터 분석가는 자주 사용하는 데이터의 도메인 전문가로서 데이터 정의, 특징 및 품질 문제에 정통함. 데이터 분석가의 일반적인 다운스트림 고객은 비즈니스 사용자, 경영진 및 임원
      - 머신러닝 엔지니어와 인공지능 연구원
        - ML 엔지니어는 고급 ML 기술을 개발하고, 모델을 훈련하며, 확장된 운영 환경에서 ML 프로세스를 실행하는 인프라를 설계하고 유지 관리함
        - ML 엔지니어는 종종 ML과 파이토치 또는 텐서플로와 같은 딥러닝 기술 및 프레임워크에 대한 고급 실무 지식을 갖추고 잇음
        - ML 엔지니어는 운영 환경에서의 모델 훈련과 모델 배포를 위해 이러한 프레임워크를 실행하는 데 필요한 하드웨어와 서비스 및 시스템을 이해함
        - ML 워크플로는 보통 ML 엔지니어가 온디맨드 방식으로 인프라 자원을 스핀업하고 확장하거나 관리형 서비스에 의존할 수 있는 클라우드 환경에서 실행됨 

## 데이터 엔지니어링 수명 주기 
- 데이터 엔지니어링 수명 주기란?
  - 데이터 엔지니어링 수명 주기는 원시 데이터의 요소를 분석가, 데이터 과학자, ML 엔지니어 등이 사용할 수 있는 유용한 최종 제품으로 전환하는 단계로 구성됨
  - 데이터 생성
    - 원천 시스템(source system)은 데이터 엔지니어링 수명 주기에서 사용되는 데이터의 원본. 예를 들어 원천 시스템은 IoT 장치, 애플리케이션 메시지 대기열 또는 트랜잭션 데이터베이스일 수 있음
    - 데이터 엔지니어는 원천 시스템의 작동 방식, 데이터 생성 방식, 데이터의 빈도 및 속도, 생성되는 데이터의 다양성을 실무적으로 이해해야 함
    - 원천 시스템 평가: 주요 엔지니어링 고려 사항
      - 데이터 엔지니어가 고려할 원천 시스템의 평가 질문 스타터킷(starter kit)
        - 데이터 원천의 본질적인 특징은 무엇인가? 데이터 원천은 애플리케이션인가? IoT 장치의 스웜인가?
        - 원천 시스템에서 데이터는 어떻게 유지되는가? 데이터는 장기간 보존되는가? 아니면 일시적이고 빠르게 삭제되는가?
        - 데이터는 어느 정도의 속도로 생성되는가? 초당 몇 개의 이벤트가 발생할까? 시간당 몇 기가바이트인가?
        - 데이터 엔지니어는 출력 데이터에서 어느 정도의 일관성을 기대할 수 있는가? 출력 데이터에 대해 데이터 품질 검사를 실행할 때, 예상치 못한 출력값(예를 들면 null값)이나 잘못된 데이터 포맷과 같은 데이터 불일치 사례는 얼마나 자주 발생할까?
        - 에러는 얼마나 자주 발생하는가?
        - 데이터에 중복이 포함되지는 않는가? 
        - 일부 데이터값이 동시에 생성되는 다른 메시지보다 훨씬 늦게 도착할 수 있는가?
        - 수집된 데이터의 스키마는 무엇인가? 데이터 엔지니어가 데이터를 완전히 파악하려면 여러 테이블 또는 여러 시스템에 걸쳐 조인을 수행해야 하는가?
        - 스키마가 변경되면(예를 들어 새로운 열이 추가되었을 때) 어떻게 대처하고 다운스트림 이해관계자에게 전달할 수 있는가?
        - 원천 시스템에서 데이터를 얼마나 자주 가져와야 하는가?
        - (고객 계정 정보를 추적하는 데이터베이스 등) 상태가 있는 시스템(stateful system)의 경우, 데이터는 정기적인 스냅숏으로 제공되는가? 아니면 변경 데이터 캡처(CDC)로부터 갱신 이벤트로 제공되는가? 변경은 어떻게 수행되며, 원천 데이터베이스에서 이러한 변경을 어떻게 추적하는가?
        - 다운스트림 사용을 위한 데이터를 전송하는 데이터 제공업체는 누구(무엇)인가?
        - 데이터 원천에서의 데이터 조회가 성능에 영향을 미치는가?
        - 원천 시스템에 업스트림 데이터 의존 관계가 있는가? 이러한 업스트림 시스템의 특징은 무엇인가?
        - 늦거나 누락된 데이터 확인용으로 데이터 품질 검사가 실시되고 있는가?
      - 스키마리스 방식은 스키마가 없다는 뜻은 아님. 애플리케이션은 메시지 대기열, 플랫 파일(Flat file), BLOB 또는 몽고DB와 같은 도큐먼트 데이터베이스에 데이터가 기록될 때 스키마를 정의함.
      - 관계형 데이터베이스 스토리지를 기반으로 구축된 더 전통적인 모델은 데이터베이스에 적용된 고정 스키마(fixed schema) 방식을 사용하는데, 애플리케이션 쓰기는 이 스키마를 준수해야 함
  - 데이터 저장
    - 스토리지 시스템 평가: 주요 엔지니어링 고려 사항
      - 데이터 웨어하우스, 데이터 레이크하우스, 데이터베이스 또는 객체 스토리지를 위한 스토리지 시스템을 선택할 때 확인할 몇 가지 핵심 엔지니어링 질문
        - 이 스토리지 설루션은 아키텍처에서 요구하는 쓰기 및 읽기 속도와 잘 맞는가?
        - 스토리지가 다운스트림 프로세스의 병목 현상을 초래하지는 않는가?
        - 이 스토리지 기술이 작동하는 방식을 인지하고 있는가? 스토리지 시스템을 최적으로 활용하는가? 아니면 부자연스러운 행동을 하는가? 예를 들어 객체 스토리지 시스템에 높은 비율의 임의 접근(random access) 갱신을 적용하고 있지는 않은가?(이것은 성능 오버헤드가 큰 안티패턴)
        - 이 스토리지 시스템은 향후 예상되는 확장을 처리할 수 있는가? 사용 가능한 총 스토리지, 읽기 작업 속도, 쓰기 볼륨 등 스토리지 시스템의 모든 용량 제한을 고려해야 함
        - 다운스트림 사용자와 프로세스가 필요한 서비스 수준 협약(SLA)에 따라 데이터를 취득할 수 있는가?
        - 스키마 진화, 데이터 흐름, 데이터 계보 등에 대한 메타데이터를 캡처하고 있는가? 메타데이터는 데이터 활용성에 큰 영향을 미친다. 메타데이터는 미래에 대한 투자로, 검색 가능성과 제도적 지식을 획기적으로 향상시켜 미래의 프로젝트 및 아키텍처 변경을 간소화함
        - 순수 스토리지 설루션(객체 스토리지)인가? 아니면 복잡한 쿼리 패턴(예 클라우드 데이터 웨어하우스)을 지원하는가?
        - 스토리지 시스템이 스키마에 구애받지는 않는가(객체 스토리지)? 유연한 스키마(카산드라)인가? 강제 적용된 스키마(클라우드 데이터 웨어하우스)인가?
        - 데이터 거버넌스를 위해 마스터 데이터, 골든 레코드 데이터 품질 및 데이터 계보를 어떻게 추적하고 있는가?
        - 법령 준수 및 데이터 주권에 어떻게 대처하고 있는가? 예를 들어 특정 지리적 위치에는 데이터를 저장하고 다른 위치에는 저장하지 않을 수 있는가?
    - 데이터 접근 빈도 이해
      - 데이터의 온도 : 데이터 접근 빈도에 따라 데이터 온도가 결정됨
        - 핫 데이터 : 가장 자주 액세스 되는 데이터
          - 일반적으로 하루에 여러번 검색됨. 이러한 데이터는 빠른 검색용으로 저장되어야 하는데, 여기서 빠른은 사용 사례에 따라 달라짐
        - 미온적 데이터(lukewarm data): 가끔(매주 또는 매월) 액세스 되는 데이터
        - 콜드 데이터 : 거의 쿼리되지 앟ㄴ으며 아카이브 시스템에 저장하는 데 적합함
          - 콜드 데이터는 규정 준수의 목적으로 보관되거나, 다른 시스템에 심각한 장애가 발생했을 때 보관되는 경우가 많음
  - 데이터 수집
    - 수집 단계에서의 주요 엔지니어링 고려 사항
      - 시스템 설계 또는 구축을 준비할 때 수집 단계에 대한 몇 가지 주요 질문 
        - 수집 중인 데이터의 사용 사례는 무엇인가? 같은 데이터셋의 여러 버전을 생성하는 대신 이 데이터를 재사용할 수 있는가?
        - 시스템이 이 데이터를 안정적으로 생성하고 수집하고 있는가? 필요할 때 해당 데이터를 사용할 수 있는가?
        - 수집 후 데이터 목적지는 어디인가?
        - 데이터는 얼마나 자주 접근해야 하는가?
        - 데이터는 보통 어느 정도의 용량으로 도착하는가?
        - 데이터 형식은 무엇인가? 다운스트림 스토리지 및 변환 시스템에서 이 형식을 처리할 수 있는가?
        - 원천 데이터는 다운스트림에서 즉시 사용할 수 있는 양호한 상태인가? 그렇다면 얼마나 오래 사용할 수 있으며, 사용할 수 없게 되는 요인은 무엇인가?
        - 데이터가 스트리밍 소스에서 전송된 경우, 목적지에 도달하기 전에 데이터를 변환해야 하는가? 데이터가 스트림 자체 내에서 변환되는 형태의 변환이 적절할까?
    - 배치 vs 스트리밍
      - 우리가 다루는 대부분의 데이터는 본질적으로 스트리밍임. 스트리밍 수집을 사용하면 다른 애플리케이션이나 데이터베이스 또는 분석 시스템 등의 다운 스트림 시스템에 데이터를 실시간으로 연속해 제공할 수 있음
        - 많은 시스템에서 스토리지와 컴퓨팅 자원이 분리되고 이벤트 스트리밍과 처리 플랫폼이 보편화됨에 따라, 데이터 스트림의 지속적인 처리에 대한 접근성과 인기가 더욱 높아지고 있음 
      - 데이터는 거의 항상 원천에서 지속해 생성되고 갱신됨. 배치 수집은 이 스트림을 큰 청크로 처리하는 전문적이고 편리한 방법(예를 들어 하루 분량의 데이터를 단일 배치 방식으로 처리함)
        - 배치 데이터는 미리 설정된 시간 간격에 따라, 또는 데이터가 미리 설정된 크기 임계값에 도달하면 수집됨. 배치 수집은 한 방향으로만 이루어지며, 데이터가 배치로 분할되면 다운스트림 소비자의 지연 시간이 본질적으로 제한됨
        - 레거시 시스템의 제약 때문에 오랫동안 배치가 기본적인 데이터 수집 방식이었음. 배치 처리는 특히 분석 및 머신러닝(ML)에서 다운스트림을 사용할 때 데이터를 수집하는 매우 인기 있는 방법
    - 배치와 스트림 수집의 주료 고려 사항
      - 스트리밍 수집이 배치 수집보다 적절한 선택인지 여부를 판단할 때 자문해봐야 할 몇 가지 질문
        - 데이터를 실시간으로 수집하면 다운스트림 스토리지 시스템이 데이터 흐름 속도를 처리할 수 있는가?
        - 밀리초 단위의 실시간 데이터 수집이 필요할까? 아니면 매분마다 데이터를 축적하고 수집하는 마이크로 배치 접근 방식이 효과가 있을까?
        - 스트리밍 수집의 사용 사례로는 무엇이 있을까? 스트리밍을 구현하면 구체적으로 어떤 이점을 얻을 수 있을까? 데이터를 실시간으로 가져올 수 있다면, 배치 방식에 비해 개선될 수 있는 데이터에 대해 어떤 조치를 취할 수 있을까?
        - 스트리밍 우선 접근 방식은 단순 배치 방식보다 시간, 비용, 유지 보수, 다운타임 및 기회비용 측면에서 더 많은 비용을 소비할까?
        - 인프라에 장애가 발생했을 때 스트리밍 파이프라인과 시스템이 안정적이고 다중화되어 있는가?
        - 사용 사례에 가장 적합한 도구는 무엇인가? 관리형 서비스(아마존 키네시스, 구글 클라우드 Pub/Sub, 구글 클라우드 데이터플로)를 사용해야 하는가? 아니면 카프카, 플링크, 스파크, 펄사 등의 인스턴스를 구축해야 할까? 후자를 선택한다면 누가 관리의 역할을 맡을 것인가? 비용과 트레이드오프는 무엇일까?
        - ML 모델을 배포했을 때 온라인 예측 및 지속적인 훈련으로 얻을 수 있는 이점은 무엇일까?
        - 실제 운영 인스턴스에서 데이터를 가져오는가? 그렇다면 이 원천 시스템에 대한 수집 프로세스의 영향도는 얼마나 될까?
    - 푸시 vs 풀
      - 데이터 수집의 푸시 몯레에서 원천 시스템은 데이터베이스, 객체 저장소 또는 파일 시스템과 관계없이 타깃에 데이터를 씀
      - 풀 모델에서는 원천 시스템에서 데이터를 검색함
      - 배치 지향 수집 워크플로에서 일반적으로 사용되는 추출-변환-적재(ETL) 프로세스를 생각해보면 ETL의 추출 부분은 풀 수집 모델을 다루고 있음을 명확히 보여줌. 기존 ETL에서는 수집 시스템이 정해진 일정에 따라 현재 소스 테이블의 스냅숏을 쿼리함
      - 연속적인 CDC
        - 원천 데이터베이스에서 행이 변경될 대마다 메시지를 트리거하는 것. 이 메시지는 큐에 푸시되며, 수집 시스템이 해당 메시지를 가져감.
        - 다른 CDC 방식은 데이터베이스에 대한 모든 커밋을 기록하는 바이너리 로그를 사용하는 것인데, 데이터베이스가 로그를 푸시함. 수집 시스템은 로그를 읽지만, 그 외에는 데이터베이스와 직접 상호 작용하지 않음. 그에 따라 원천 데이터베이스에 대한 추가 부하는 거의 없거나 또는 전혀 추가되지 않음.
        - 배치 CDC의 일부 버전에서는 풀 패턴을 사용함. 예를 들어 타임스탬프 기반 CDC에서는 수집 시스템이 원천 데이터베이스를 쿼리하고 이전 갱신 이후에 변경된 행을 가져옴
  - 데이터 변환
    - 변환 단계에서의 주요 고려 사항
      - 데이터 엔지니어링 수명 주기 내에서 데이터를 변환할 때는 다음 사항을 고려해야 함
        - 변환에 드는 비용과 투자수익률(ROI)은 얼마인가? 관련된 비즈니스 가치는 무엇인가?
        - 변환은 가능한 한 단순하고 독립적인가?
        - 변환이 지원하는 비즈니스 규칙은 무엇인가? 
  - 데이터 서빙
    - 데이터를 수집하고 저장한 뒤에 일관성 있고 유용한 구조로 변환했으니, 이제 데이터로부터 가치를 창출 할 때
    - 데이터 허영(data vanity) 프로젝트는 기업의 주요 리스크. 많은 기업이 빅데이터 시대에 불필요한 프로젝트를 추진해, 어떤 유용한 방법으로도 소비되지 않는 데이터 레이크에서 대규모 데이터셋을 수집했음
    - 분석
      - 데이터가 저장되고 변환되면 보고서 또는 대시보드를 생성하고 데이터에 대한 임시 분석을 수행할 수 있음
      - 비즈니스 인텔리전스(BI)
        - BI는 기업 경영의 과거와 현재 상태를 설명하기 위해 데이터를 수집함. BI는 비즈니스 로직을 사용해 원시 데이터를 처리해야 함
        - 기업의 데이터 성숙도가 높아짐에 따라 기업은 애드혹 데이터 분석에서 셀프서비스 분석으로 전환해 IT 부서의 개입 없이도 비즈니스 사용자가 데이터에 접근할 수 있게 됨. 이때 셀프서비스 분석을 수행하는 기능은 조직의 전체 인원이 데이터에 직접 접근하고, 원하는 방식으로 데이터를 분석하고, 즉각적인 통찰력을 얻을 수 있을 만큼 충분히 양호한 데이터라고 가정함
        - 셀프서비스 분석은 이론상으로는 간단하지만, 실제로 성공하기는 어려움. 주된 이유는 데이터 품질 저하, 조직 사일로 현상, 적절한 데이터 기술 부족 등의 문제가 광범위한 분석에 방해되기 때문
      - 운영 분석
        - 운영의 상세 사항에 중점을 두고 보고서 사용자가 즉시 수행할 수 있는 작업을 촉진함. 운영 분석은 재고 물품에 대한 실시간 뷰 또는 웹사이트나 애플리케이션 상태에 대한 실시간 대시보드가 될 수 있음
      - 임베디드 분석
        - 임베디드 분석(고객 대면 분석)을 사용하면 보고서 요청 비율과 그에 따른 분석 시스템의 부담이 매우 커지며, 접근 제어 역시 훨씬 더 복잡해지고 중요해짐. 기업은 수천 명 이상의 고객에게 별도의 분석 및 데이터를 제공할 수 있음.이때 각 고객은 자신의 데이터만 확인할 수 있어야 함 
        - 기업 내부의 데이터 접근 오류는 절차적 검토로 이루어질 수 있음. 고객 간 데이터 유출은 중대한 신뢰 위반으로 간주되어 언론의 주목을 받고 고객 감소로 이어질 수 있음. 따라서 데이터 유출 및 보안 취약성과 관련한 피해 범위를 최소화하자. 스토리지를 비롯해 데이터 유출 가능성이 있는 모든 장소에서 테넌트 또는 데이터 수준의 보안을 적용함
    - 머신 러닝
      - ML 관련 데이터 서빙 단계에서 고려할 사항
        - 신뢰할 수 있는 특성 엔지니어링을 수행하기에 충분한 품질의 데이터인가? 품질 요구 사항 및 평가는 데이터를 사용하는 팀과 긴밀히 협력해 개발됨
        - 데이터를 검색할 수 있는가? 데이터 과학자와 ML 엔지니어는 가치 있는 데이터를 쉽게 찾을 수 있는가?
        - 데이터 엔지니어링과 ML 엔지니어링 간의 기술적 및 조직적 경계는 어디인가? 이러한 조직 차원의 질문은 아키텍처에 큰 영향을 미침
        - 데이터셋이 실제 상황을 제대로 나타내고 있는가? 불공평하게 편향되어 있지는 않은가?
    - 역 ETL
      - 데이터 엔지니어링 수명 주기의 출력 측에서 처리한 데이터를 가져와 원천 시스템이 다시 공급함
      - 역 ETL을 사용하면 분석, 평가 모델 등을 가져와 운영 시스템 또는 SaaS 플랫폼에 다시 제공할 수 있음
      - 기업이 SaaS 및 외부 플랫폼에 점점 더 많이 의존하게 되면서 역 ETL은 특히 중요해지고 있음.
        - 예를 들어 기업은 데이터 웨어하우스에서 고객 데이터 플랫폼 또는 CRM 시스템으로 특정한 측정 지표를 푸시할 수 있음.
        - 또 다른 일상적인 사용 사례로는 구글 애즈와 같은 광고 플랫폼이 있음
      - 핵심은 변환된 데이터가 원천 시스템과 관련한 올바른 계통과 비즈니스 프로세스를 통해 어떤 방식으로든 원천 시스템에 반화되어야 한다는 것 
- 데이터 엔지니어링 수명 주기의 드러나지 않는 주요 요소
  - 보안
    - 접근 제어
      - 데이터
      - 시스템
    - 상세설명
      - 데이터 엔지니어는 데이터와 접근 보안을 모두 이해하고 최소 권한 원칙을 실행해야 함
      - 최소 권한 원칙이란 사용자 또는 시스템이 의도된 기능을 수행하는 데 필수적인 데이터와 자원에만 접근할 수 있는 것을 의미함
      - 암호화(encryption), 토큰화(tokenization), 데이터 마스킹, 난독화(obfuscation) 및 단순하고 견고한 접근 제어(access control)를 사용해 이동 중인 데이터와 저장된 데이터 모두 원치 않는 가시성으로 부터 보호해야 함
      - 사용자 및 ID 접근 관리(IAM)의 역할, 정책, 그룹, 네트워크 보안, 암호 정책, 암호화 등은 보안 관련 지식을 쌓기에 좋은 출발점
  - 데이터 관리
    - 데이터 거버넌스
      - 발견 가능성
      - 정의
      - 책임
    - 데이터 모델링
    - 데이터 무결성
    - 상세 설명
      - 데이터 관리는 수명 주기 전체에 걸쳐 데이터와 정보 자산의 가치를 제공, 제어, 보호 및 향상할 계획, 정책, 프로그램과 사례를 개발, 실행 및 감독한는 것
      - 데이터 관리의 여러 측면
        - 발전 가능성(discoverability) 및 책임(accountability)을 포함한 데이터 거버넌스
        - 데이터 모델링 및 설계
        - 데이터 계보
        - 저장 및 운영
        - 데이터 통합 및 상호 운용성
        - 데이터 수명 주기 관리
        - 고급 분석 및 ML을 위한 데이터 시스템
        - 윤리 및 개인정보보호
      - 데이터 거버넌스
        - 에브렌 에리우렉의 저서에 따르면 데이터 거버넌스는 무엇보다도 조직이 수집한 데이터의 품질, 무결성(integrity), 보안 및 사용성(usability)을 보장하기 위한 데이터 관리 기능
        - 데이터 거버넌스는 적절한 보안 제어로 데이터를 보호하면서, 조직 전체의 데이터 가치를 극대화하기 위해 인력, 프로세스 및 기술을 활용함
        - 데이터 거버넌스의 핵심 범주는 발견 가능성, 보안, 책임. 이러한 핵심 범주에는 데이터 품질, 메타데이터 및 개인정보보호와 같은 하위 범주가 있음
        - 발견 가능성
          - 데이터 발견 가능성의 주요 분야로는 메타데이터 관리 및 마스터 데이터 관리 등이 있음
        - 메타 데이터
          - 메타데이터는 데이터에 관한 데이터로 데이터 엔지니어링 수명 주기의 모든 부분을 뒷받침함. 메타데이터는 데이터를 검색하고 제어하는 데 필요한 데이터
          - 메타데이터는 크게 자동 생성 데이터와 인간 생성 데이터의 두 가지 범주로 나뉨
          - DMBOK는 데이터 엔지니어에게 유용한 메타데이터의 네 가지 주요 범주를 다음과 같이 식별함
            - 비즈니스 메타데이터
              - 비즈니스와 데이터 정의, 데이터 규칙과 로직, 데이터 사용 방법과 장소, 데이터 소유자 등 비즈니스에서 데이터가 사용되는 방식과 관련이 있음 
            - 기술 메타데이터
              - 데이터 엔지니어링 수명 주기 전반에 걸쳐 시스템이 생성하고 사용하는 데이터를 의미함. 여기에는 데이터 모델과 스키마, 데이터 계보, 필드 매핑 및 파이프라인 워크플로우가 포함됨
              - 일반적인 유형의 기술 메타데이터
                - 파이프라인 메타데이터(종종 오케스트레이션 시스템에서 생성됨)
                  - 오케스트레이션은 다양한 시스템에서 워크플로를 조정하는 중앙 허브. 오케스트레이션 시스템에서 캡처된 파이프라인 메타데이터는 워크플로 일정, 시스템과 데이터 종속성, 구성, 연결 세부 정보 등을 제공함 
                - 데이터 계보 메타데이터
                  - 데이터 원본과 변경 사항, 데이터 종속성을 시간에 따라 추적함. 데이터는 데이터 엔지니어링 수명 주기를 통과하면서 변환되거나 다른 데이터와 결합되며 진화함
                  - 데이터 계보는 데이터가 다양한 시스템과 워크플로를 거치는 동안 데이터의 진화에 대한 감사 추적(audit trail)을 제공함 
                - 스키마 메타데이터
                  - 데이터베이스, 데이터 웨어하우스, 데이터 레이크 또는 파일 시스템과 같은 시스템에 저장된 데이터 구조를 설명함. 이 구조는 다양한 스토리지 시스템의 주요 차별화 요소 중 하나
                  - 예를 들어 객체 저장소는 스키마 메타데이터를 관리하지 않으며 대신 메타스토어에 관리해야 함. 반면 클라우드 데이터 웨어하우스는 스키마 메타데이터를 내부적으로 관리함 
            - 운영 메타데이터
              - 다양한 시스템의 운영 결과를 설명하는 프로세스, 작업 ID, 애플리케이션 런타임 로그, 프로세스에서 사용되는 데이터 및 오류 로그에 대한 통계를 포함함. 데이터 엔지니어는 운영 메타데이터를 사용해서 프로세스의 성공 또는 실패 여부와 그 프로세스에 관련된 데이터를 판단함 
            - 참조 메타데이터
              - 다른 데이터를 분류하는 데 필요한 데이터로, 조회 데이터(lookup data)라고도 함.
              - 참조 데이터의 표준 사례로는 내부 코드 ,지리적 코드 ,측정 단위 및 내부 달력 표준 등이 있음. 대부분의 참조 데이터는 내부적으로 완벽하게 관리되지만, 지리 코드와 같은 항목은 표준 외부 참조에서 가져올 수 있음.
              - 참조 데이터는 기본적으로 다른 데이터를 해석하기 위한 표준이므로 데이터가 변경되면 시간이 지남에 따라 서서히 변경됨
          - 데이터 책임(data accountability) : 데이터의 일부를 관리할 개인을 지정하는 것을 의미함. 그런 다음 책임자는 다른 이해관계자의 거버넌스 활동을 조정함
          - 데이터 품질 
            - 데이터 품질 테스트를 수행하고, 스키마 기대치 ,데이터 완전성 및 정밀도에 대한 데이터 준수를 보장하는 것이 포함됨
            - 데이터 품질의 3가지 주요 특징
              - 정확도(accuracy) : 수집된 데이터가 실제로 정확한가? 중복된 값이 있는가? 수치가 정확한가?
              - 완전성(completeness) : 기록은 완전한가? 모든 필수 필드에 유횻값이 포함되는가?
              - 적시성(timeliness) : 기록을 시기 적절하게 이용할 수 있는가?
            - 마스터 데이터 관리
              - 마스터 데이터는 직원, 고객, 제품 및 위치와 같은 비즈니스 엔티티에 대한 데이터
              - 마스터 데이터 관리(master data management(MDM))는 골든 레코드(golden record)로 알려진 일관된 엔티티 정의를 구축하는 관행. 골든 레코드는 조직 전체 및 파트너 간에 엔티티 데이터를 조화시킴. MDM은 기술 도구를 구축하고 배포함으로써 촉진되는 비즈니스 운영 프로세스 
      - 데이터 모델링 및 설계 : 데이터를 사용 가능한 형태로 변환하는 프로세스를 데이터 모델링 및 설계
      - 데이터 계보
        - 데이터를 처리하는 시스템과 데이터가 의존하는 업스트림 데이터를 모두 추적해 수명 주기 전체에 걸쳐 데이터의 감사 추적을 기록하는 것
        - 데이터 계보는 데이터 및 데이터를 처리하는 시스템의 오류 추적, 설명 및 디버깅에 도움이 됨. 데이터 수명 주기에 대한 감사 추적을 제공한다는 명백한 이점이 있으며 컴플라이언스(규정 준수)에도 도움이 됨
        - 예를 들어 사용자가 시스템에서 데이터를 삭제하려는 경우 해당 데이터에 대한 계보가 있으면 데이터가 저장된 위치와 종속성을 알 수 있음
      - 데이터 통합과 상호 운용성
        - 여러 도구와 프로세스 전반에 걸쳐 데이터를 통합하는 프로세스. 분석에 대한 단일 스택(single-stack) 접근 방식에 벗어나, 다양한 도구가 온디맨드로 데이터를 처리하는 이기종 클라우드 환경으로 전환함에 따라 통합 및 상호 운용성은 데이터 엔지니어의 작업 범위를 더욱 넓히고 있음
        - 데이터 통합은 맞춤형 데이터베이스 연결이 아닌 범용 API를 통해 이루어지는 경우가 늘고 있음. 예를 들어 데이터 파이프라인은 세일즈포스의 API에서 데이터를 가져와 아마존 S3에 저장하고 스노우플레이크의 API를 호출해 테이블에 적재한 다음, API를 다시 호출해 쿼리를 실행한 뒤 그 결과를 S3로 내보내 스파크가 데이터를 소비할 수 있음
        - 이 모든 작업은 데이터를 직접 처리하는 대신 데이터 시스템과 통신하는 비교적 단순한 파이썬 코드로 관리할 수 있음. 데이터 시스템과 상호 작용의 복잡성은 감소했지만, 시스템 수와 파이프라인의 복잡성은 극적으로 증가 했음
      - 데이터 수명 주기 관리
        - 데이터 레이크의 등장으로 조직은 데이터 보관(archival) 및 파기(destruction)를 무시하게 됐음
        - 클라우드에 점점 더 많은 데이터가 저장되고 있음. 즉, 사내 데이터 레이크에 대한 대규모 초기 자본 지출 대신 종량제 스토리지 비용이 발생하게 됐음
        - GPR과 CCPA 같은 개인정보보호 및 데이터 보존법에 따라 데이터 엔지니어는 사용자의 잊혀질 권리를 존중하기 위해 데이터 파기를 적극적으로 관리해야 함
        - 데이터 파기는 한 번 쓰고 여러 번 읽기(WORM, write once read many)가 기본 스토리지 패턴인 데이터 레이크에서 더 어려웠음
      - 윤리와 개인정보보호
        - 데이터 엔지니어는 데이터셋이 개인식별정보(PII) 및 기타 중요한 정보를 마스킹 처리하는지를 확인해야 함. 그러면 데이터셋이 변환될 때 편향을 식별하고 추적할 수 있음 
  - 데이터옵스
    - 데이터 거버넌스
    - 관찰 가능성과 모니터링
    - 사건 보고
    - 상세 설명
      - 데이터옵스는 애자일 방법론, 데브옵스, 통계적 공정 관리(SPC, statistical process control)의 모범사례를 데이터에 매핑함.
      - 데브옵스의 목표는 소프트웨어 제품의 릴리스와 품질을 개선하는 것이지만 데이터옵스는 데이터 제품에 대해서도 같은 작업을 수행함
      - 소프트웨어 제품은 최종 사용자에게 특정 기능과 기술적 기능을 제공함. 한편, 데이터 제품은 사용자가 의사결정을 내리거나 자동화된 작업을 수행하는 모델을 구축하는 건전한 비즈니스 로직과 측정 지표를 기반으로 구축됨.
      - 데이터 엔지니어는 소프트웨어 제품 구축의 기술적 측면과, 우수한 데이터 제품을 만드는 비즈니스 로직, 품질 및 측정 지표를 모두 이해해야 함
      - 데이터 옵스는 다음 사항들을 실현하는 기술 관행, 워크플로, 문화적 규범, 아키텍처 패턴의 집합
        - 신속한 혁신과 실험으로 고객에게 새로운 통찰력을 빠르게 제공
        - 매우 높은 데이터 품질과 매우 낮은 오류율
        - 인력, 기술, 환경의 복잡한 집합 전반에 걸친 협업
        - 명확한 측정, 모니터링 및 결과의 투명성
        - 데이터 옵스를 통해 데이터 엔지니어는 모든 업무에서 데이터옵스 작업의 우선순위를 높게 지정하는 것이 좋음. 선행 작업에서는 제품의 신속한 제공, 데이터의 신뢰성 및 정확성 향상, 비즈니스 전체적인 가치 향상을 통해 장기적으로 상당한 성과를 거둘 수 있음 
      - 데이터 옵스에는 자동화, 모니터링 및 관찰 가능성, 사고 대응이라는 세 가지 핵심 기술 요소가 있음
        - 자동화(automation)
          - 데이터옵스 프로세스의 신뢰성과 일관성을 보장할 수 있으며, 데이터 엔지니어가 새로운 제품 기능과 개선 사항을 기존 워크플로에 신속하게 구현할 수 있음.
          - 데이터옵스 자동화는 변경 관리(환경, 코드 및 데이터 버전 제어), 지속적 통합 배포(CI/CD), 코드로 구성된 데브옵스와 유사한 프레임워크 및 워크플로를 가짐
          - 데브옵스와 마찬가지로 데이터옵스 관행은 데이터 품질, 데이터/모델 드리프트, 메타데이터 무결성 등을 확인하는 차원을 추가해 기술과 시스템(데이터 파이프라인, 오케스트레이션 등)의 신뢰성을 모니터링하고 유지함
          - 가상의 조직을 이용해 데이터옵스 자동화의 진화를 간략히 설명
            - 데이터옵스 성숙도가 낮은 조직에서는 크론 잡을 사용해 데이터 변환 프로세스의 여러 단계를 에약하려고 시도하는 경우가 많으며, 실제로 한동안은 잘 작동함. 하지만 데이터 파이프라인이 복잡해짐에 따라 여러 가지 일이 발생할 수 있음
            - 크론 잡이 클라우드 인스턴스에서 호스팅되는 경우, 인스턴스에 작동 문제가 발생해 작업 실행이 예기치 않게 중지될 수 있음. 작업 간의 간격이 더 좁아지면 결국 작업이 오래 실행되어 후속 작업이 실패하거나 오래된 데이터가 생성됨. 엔지니어는 분석가로부터 보고서가 오래됐다는 이야기를 듣기 전까지는 작업 실패를 인식하지 못할 수 있음
            - 조직의 데이터 성숙도가 높아짐에 따라, 데이터 엔지니어는 일반적으로 에어플로 또는 대그스터와 같은 오케스트레이션 프레임워크를 채택함
              - 데이터 엔지니어들은 에어플로가 운영상의 부담을 초래한다는 것을 알지만, 결국 오케스트레이션의 이점이 복잡성을 능가함
              - 엔지니어는 크론 잡을 에어플로 잡으로 단계적으로 이행함. 이제 작업이 실행되기 전에 종속성을 확인함. 각 작업은 미리 정해진 시간이 아닌, 업스트림 데이터가 준비되는 즉시 시작할 수 있으므로 주어진 시간에 더 많은 변환 작업을 패킹(packing)할 수 있음
        - 관찰 가능성과 모니터링
          - 페트렐라의 DODD 방법론은 데이터 관찰 가능성을 고려할 수 있는 훌륭한 프레임워크를 제공함. DODD는 소프트웨어 엔지니어링의 TDD(test-driven developmnet) 매우 유사함
            - DODD의 목적은 데이터 가치 사슬(data value chain)에 관련된 모든 데이터 사용자가 데이터 및 데이터 애플리케이션에 대한 가시성을 확보하고 그 변경 사항을 수집에서 변환, 분석까지 모든 단계에서 식별할 수 있도록 함으로써, 데이터 문제를 해결하거나 예방하는 것.
            - DODD는 데이터 엔지니어링 수명 주기에서 데이터 관찰 가능성을 최우선 고려 사항으로 삼는 데 중점을 둠 
        - 사고 대응(incident response)
          - 자동화 및 관찰 가능성 기능을 사용해 이러한 사고의 근본 원인을 신속하게 특정하고 가능한 한 확실하고 빠르게 해결하는 것 
  - 데이터 아키텍처
    - 데이터 분석 트레이드오프
    - 디자인과 민첩성
    - 비즈니스에 가치 더하기
    - 상세 설명
      - 원천 시스템, 수집, 저장, 변환 및 데이터 서빙에 있어 설계 패턴, 기술 및 도구의 트레이드오프를 파악해야 함
      - 데이터 엔지니어가 데이터 아키텍트와 함께 작업할 경우 데이터 엔지니어는 데이터 아키텍트의 설계를 이행하고 아키텍처 피드백을 제공할 수 있어야 함 
  - 오케스트레이션
    - 워크플로 조정
    - 작업 스케줄링
    - 작업 관리
    - 상세 설명
      - 오케스트레이션은 많은 작업이 예약된 순서대로 최대한 빠르고 효율적으로 실행되도록 조정하는 프로세스
      - 오케스트레이션 엔진은 일반적으로 유향 비순환 그래프(DAG)의 형태로 작업 종속성에 따라 메타데이터를 구축함. DAG는 한 번만 실행되거나 매일, 매주, 매시간, 5분 등 일정한 간격으로 실행되도록 스케줄링할 수 있음
      - 오케스트레이션 시스템은 관리하는 작업을 모니터링하고 내부 DAG 종속성이 완료되면 새 작업(task)를 시작함. 또한 외부 시스템과 도구를 모니터링해 데이터가 도착하고 기준을 충족하는지 확인할 수 있음. 특정 조건이 범위를 벗어나면 시스템은 오류 조건을 설정하고 이메일 또는 다른 채널을 통해 경고를 보냄
      - 오케스트레이션 시스템은 또한 작업 기록 기능, 시각화 및 경고 기능을 구축함. 고급 오케스트레이션 엔진은 새로운 DAG 또는 개별 작업이 DAG에 추가될 때 백필 작업을 수행할 수 있음. 또한 시간 범위에 따른 종속성(의존 관계)도 지원함
      - 몇몇 초기 오픈 소스 프로젝트의 목표는 에어플로 핵심 설계의 가장 좋은 요소를 모방함과 동시에 주요 영역에서 이를 개선하는 것.
        - 가장 흥미로운 예로는 프리팩트(prefect)와 대그스터(Dagster)가 있는데, 그 목적은 DAG의 이식성(portability)과 테스트 가능성을 개선해 엔지니어가 로컬 개발에서 운영 환경(porduction)으로 더 쉽게 이동하도록 돕는 것.
        - 아르고(Argo)는 쿠버네티스 프리미티브(플랫폼에서 애플리케이션ㅇ르 만들고 운영하기 위해 쿠버네티스 아키텍처에 고정된 기본 구성 요소)를 기반으로 구축된 오케스트레이션 엔진.
        - 메타플로(Metaflow)는 넷플릭스의 오픈 소스 프로젝트로, 데이터 과학 오케스트레이션의 개선이 목표 
  - 소프트웨어 엔지니어링
    - 프로그래밍과 코딩 기술
    - 소프트웨어 디자인 패턴
    - 테스트와 디버깅
    - 상세 설명
      - 2000년 부터 2010년 까지의 현대 데이터 엔지니어링 초기에 데이터 엔지니어는 저수준 프레임워크에서 작업했으며 C, C++ 및 자바에서 맵 리듀스 잡을 작성했음. 2010년대 중반 빅데이터 시대의 정점에 이르자 엔지니어들은 이러한 저수준의 세부 사항을 추상화한 프레임워크를 사용하기 시작했음
      - 코어 데이터 처리 코드
        - 데이터 엔지니어는 수집, 변환, 데이터 서빙과 관계없이 스파크, SQL, 빔 등의 프레임워크와 언어에 매우 능숙하고 생산성이 뛰어나야 함
        - 데이터 엔지니어는 단위(unit), 회귀, 통합, 엔드투엔드, 스모크(smoke) 등의 적절한 코드 테스트 방법론을 이해하는 것이 중요함
      - 오픈소스 프레임워크 개발
        - 데이터 엔지니어는 새로운 내부 도구를 엔지니어링하기 전에 공개적으로 사용할 수 있는 도구의 환경을 조사하는 것이 좋음. 도구 구현에 수반되는 총소유비용(TCO,total cost of ownership)과 기회비용에 주목하자. 해결해야 할 문제를 해결해주는 오픈 소스 프로젝트가 이미 존재할 가능성이 높음
      - 스트리밍
        - 윈도잉을 사용하면 실시간 시스템에서 추적 통계와 같은 중요한 측정 지표를 계산할 수 있음. 엔지니어는 개별 이벤트를 처리하는 다양한 함수 플랫폼(OpenFaaS, AWS 람다, 구글 클라우드 함수 또는 스트림을 분석해 보고 실시간 작업을 지원하는 전용 스트림 프로세서(스파크, 빔, 플링크 또는 펄사) 등 다양한 프레임워크 중에서 선택할 수 있음
      - 코드형 인프라(IaC)
        - 빅데이터 시대의 인프라 관리 부담은 기업들이 데이터브릭스나 아마존 EMR 같은 관리형 빅데이터 시스템과 클라우드 데이터 웨어하우스로 이전함에 따라 감소하고 있음.
        - 데이터 엔지니어가 클라우드 환경에서 인프라를 관리해야할 경우, 인스턴스를 수동으로 스핀업하고 소프트웨어를 설치하는 대신 IaC 프레임워크로 대응하는 사례가 늘고 있음. 여러 범용 클라우드 플랫폼별 프레임워크를 통해 일련의 사양에 따라 인프라를 자동 배포할 수 있음. 이러한 프레임워크는 대부분 인프라뿐만 아니라 클라우드 서비스도 관리할 수 있음. 또한 헬름(Helm) 등의 도구를 써서 컨테이너와 쿠버네티스를 사용하는 IaC의 개념도 있음
        - 이러한 사례뜰은 데브옵스의 중요한 부분으로, 버전 제어와 배포 반복성을 실현함
      - 코드형 파이프라인
        - 데이터 엔지니어는 코드(일반적으로 파이썬)를 사용해 데이터 작업과 데이터 간의 종속성을 선언함
      - 범용 문제 해결
        - 데이터 엔지니어는 파이브트랜(Fivetran), 에어바이트(Airbyte) 또는 마틸리언(Matillion)과 같은 프레임워크를 사용할 때 기존 커넥터가 없는 데이터 원천에 직면하게 되고 사용자 정의 코드를 작성해야 함
        - 그들은 API를 이해하고, 데이터 풀링 및 변환을 수행하고, 예외를 처리하는 등 필요한 소프트웨어 엔지니어링에 능숙해야 함 

## 우수한 데이터 아키텍처 설계
- 클라우드 기능을 활용해 확장성(scalability), 가용성(availability), 신뢰성(reliability)을 제공할 것을 강조함
- 데이터 아키텍처란?
  - 엔터프라이즈 아키텍처 정의(enterprise architecture, EA)
    - 비즈니스, 기술, 애플리케이션 및 데이터를 포함한 많은 하위집합이 있음
    - TOGAF(The Open Group Architecture Framework)의 정의
      - 오픈 그룹의 표준이며 오늘날 가장 널리 사용되는 아키텍처 프레임워크
      - 엔터프라이즈 아키텍처의 맥라겡서 엔터프라이즈라는 용어는 모든 정보 및 기술 서비스, 프로세스, 인프라를 포함하는 전체 기업 또는 기업 내 특정 도메인을 의미할 수 있음. 어느 경우든 아키텍처는 기업 내 여러 시스템과 기능 그룹을 너남듬
    - 가트너의 정의
      - 가트너는 기업 관련 동향에 관한 연구 기사와 보고서를 작성하는 글로벌 리서치 및 자문 기업
      - 엔터프라이즈 아키텍처는 바람직한 비즈니스 비전과 결과를 향한 변화의 실행을 식별하고 분석함으로써 기업이 파괴적인 힘에 능동적이고 전체적으로 대응하도록 주도하는 분야. EA는 비즈니스 리더와 IT 리더에게 관련 사업의 중단을 기회로 삼아 목표한 사업 결과를 달성하기 위해 정책 및 프로젝트를 조정할 수 있는 서명 가능한 권장 사항을 제시함으로써 가치를 제공함
    - EABOK(Enterprise Architecture Book of Knowledge)의 정의
      - 미국의 비영리 조직인 마이터 코퍼레이션(MITRE Corporation)이 작성한 엔터프라이즈 아키텍처 참조 자료를 의미함
      - 엔터프라이즈 아키텍처는 전략, 운용 및 기술을 조정해 성공 로드맵을 만드는 추상적인 표현이자 조직 모델
    - 우리의 정의
      - 엔터프라이즈 아키텍처는 기업의 변화를 지원하는 시스템 설계로, 신중한 트레이드오프 평가를 통해 도달한 유연하고 되돌릴 수 있는 의사결정으로 달성됨
      - 가역적 의사결정
        - 필수 요소 
          - 세상은 끊임없이 변화하며 미래를 예측하기란 불가능함. 이때 가역적 의사결정은 세상의 변화와 새로운 정보 수집에 따라서 프로세스를 조정할 수 있게 해줌
          - 조직이 성장함에 따라 자연스럽게 기업의 경직화(ossification)가 발생하는 경향이 있음. 이때 되돌릴 수 있는 결정 문화를 채택하면 각종 의사결정에 수반되는 위험을 줄임으로써 이러한 경직화 경향을 극복하는 데 도움이 됨
          - 단반향 의사결정(one-way door)은 되돌릴 수 없는 결정
          - 양방향 의사결정(two-way door)은 쉽게 되돌릴 수 있는 결정
      - 변경 관리
        - 되돌릴 수 있는 의삭결정에 중점을 두더라도, 기업은 종종 대규모 이니셔티브를 수행해야 함
        - 아키텍트는 현재 상태의 문제(낮은 데이터 품질, 확장성 제한, 비용 손실)를 식별하고, 바람직한 미래 상태(민첩한 데이터 품질 개선, 확장성 있는 클라우드 데이터 설루션, 비즈니스 프로세스 개선)를 정의하며, 소규모의 구체적인 단계를 실행함으로써 이니셔티브를 실현함. 반복을 감내할 수 있어야 가능한 일
          - 기술적 설루션은 그 자체를 위한 것이 아니라 비즈니스 목표를 지원하기 위해 존재함
      - 트레이드오프 평가
        - 데이터 엔지니어가 최적의 시스템을 설계하려면 모든 단계에서 트레이드오프를 고려해야 하며 동시에 값비싼 기술 부채를 최소화해야 함 
  - 데이터 아키텍처 정의 
    - 데이터 아키텍처는 엔터프라이즈 아키텍처의 하위집합으로 프로세스, 전략, 변경 관리, 트레이드오프 평가 등의 속성을 상속함
    - TOGAF의 정의
      - 기업의 주요 데이터 유형과 원천, 논리적 데이터 자산, 물리적 데이터 자산, 데이터 관리 자원의 구조와 상호 작용에 관한 설명
    - DAMA의 정의
      - (구조와 관계없이) 기업의 데이터 요구 사항을 파악하고, 이러한 요구를 충족시킬 마스터 청사진을 설계 및 유지 관리함. 마스터 청사진을 사용해 데이터 통합을 안내하고, 데이터 자산을 제어하며, 데이터 투자를 비즈니스 전략에 맞게 조정함
    - 우리의 정의
      - 데이터 아키텍처는 기업의 진화하는 데이터 요구 사항을 지원하는 시스템 설계로, 트레이드오프에 대한 신중한 평가를 통해 유연하고 되돌릴 수 있는 결정을 내림으로써 실현됨 
