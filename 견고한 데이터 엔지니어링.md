# 서평
- 이 책을 읽기 전까지 엔지니어가 결국 기업의 의사결정을 효율적으로 지원하는 역할을 해야 한다고 생각했습니다. 이에 따라 백엔드부터 비즈니스 인텔리전스, 인공지능, 머신러닝, 그리고 MLOps까지 다양한 분야를 고려해야 한다고 생각했습니다. 그러나 이 책을 통해 데이터 엔지니어의 궁극적인 목적과 역할에 대해 새롭게 조명을 받게 되었습니다.
- 데이터 엔지니어링의 생명주기는 데이터의 생성부터 저장, 수집, 변환, 그리고 서빙까지 이르며, 이 전 과정에 걸쳐 보안, 데이터 관리, DevOps, 아키텍처, 그리고 오케스트레이션, 소프트웨어 엔지니어링까지 다양한 요소들이 복합적으로 작용합니다. 결국, 데이터 엔지니어는 이러한 수명주기 전반에 걸쳐 기업의 투자수익률(ROI)을 극대화하고, 재무적, 기회적 비용을 최소화하며, 다양한 리스크(보안과 데이터 품질 등)를 효과적으로 관리하는 것이 최상위 목표라 할 수 있습니다.
- 이 책은 "어떻게 하면 비즈니스에 진정한 가치를 더하는 데이터 엔지니어가 될 수 있을까?" 그리고 "데이터 엔지니어로서 고려해야 할 핵심 요소들은 무엇인가?" 등의 본질적인 질문에 대한 깊이 있는 통찰을 제공합니다. 이 책에서 탐구하는 데이터 엔지니어의 역할은 더욱 정확하게는 '데이터 수명주기 엔지니어'라고 칭할 수 있을 만큼 전반적이고 종합적인 관점을 제시합니다.

# 데이터 엔지니어링 기반 구축하기
## 데이터 엔지니어링 상세 
- 데이터 엔지니어링이란?
  - 알텍스소프트의 데이터 엔지니어링의 개념, 프로세스 및 도구
    - 데이터 엔지니어링은 데이터 과학자, 데이터 분석가, 비즈니스 인텔리전스 개발자, 그리고 조직 내의 다른 전문가가 데이터를 사용할 수 있도록 만드는 일련의 작업이다. 대규모의 데이터를 수집 및 저장하면서 추가 분석을 수행할 수 있는 데이터를 준비하기 위한 시스템을 설계하고 구축하려면 데이터 엔지니어와 같은 전담 전문가가 필요하다. 간단히 말해서, 데이터 엔지니어는 조직의 데이터 인프라를 구축하고 운영해 데이터 분석가와 데이터 과학자가 추가 분석을 수행할 수 있도록 준비한다.
  - 데이터 엔지니어링 정의
    - 데이터 엔지니어링은 원시 데이터(raw data)를 가져와 분석 및 머신러닝과 같은 다운스트림 사용 사례를 지원하는, 고품질의 일관된 정보를 시스템과 프로세스의 개발, 구현 및 유지 관리이다. 데이터 엔지니어링은 보안, 데이터 관리, 데이터 운영, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링의 교차점이다.
    - 데이터 엔지니어는 원천 시스템에서 데이터를 가져오는 것부터 시작해 분석 또는 머신러닝과 같은 사용 사례에 데이터를 제공하는 것으로 끝나는 데이터 엔지니어링 수명 주기를 관리한다.
  - 데이터 엔지니어링 수명 주기
    - 단계
      - 데이터 생성(generation)
      - 데이터 저장(Storage)
      - 데이터 수집(Ingestion)
      - 데이터 변환(Transformation)
      - 데이터 서빙(Serving)
    - 데이터 엔지니어링 수명 주기는 전체 수명 주기에 걸쳐 중요한 아이디어인 드러나지 않는 요소(undercurrent)라는 개념을 포함함. 여기에는 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링이 포함됨
  - 데이터 엔지니어의 진화
    - 1980년부터 2000년까지: 데이터 웨어하우징에서 웹으로
      - 1980년대에 비즈니스 데이터 웨어하우스라는 용어가 형성되었으며 1989년 빌 인먼이 데이터 웨어하우스라는 용어를 공식적으로 만들었음.
      - IBM의 엔지니어들이 관계형 데이터 베이스와 구조적 질의 언어(SQL, Structured Query Language)를 개발한 이후 오라클은 이 기술을 대중화함
      - BI를 위한 전용  툴과 데이터 파이프라인이 필요해졌으며 랄프 킴벌과 빌 인먼은 데이터 모델링 기법과 접근 방식을 개발 했음
      - 데이터 웨어하우징은 대량의 데이터를 처리하고 전례 없는 막대한 양의 데이터를 지원하고자, 다수의 프로세서를 사용하는 새로운 대규모 병렬 처리(MPP) 데이터베이스로 확장성 있는 분석의 첫 시대를 열음. 이로 인해 BI 엔지니어, ETL 개발자, 데이터 웨어하우스 엔지니어와 같은 역할은 데이터 웨어하우스의 다양한 요구 사항을 해결함 
      - 인터넷은 1990년대 중반에 주류를 이루었고 AOL, 야후, 아마존과 같은 세대의 웹 우선(web-first) 기업을 탄생함. 닷컴 열풍은 웹 애플리케이션과 이를 지원하는 백엔드 시스템(서버, 데이터베이스 ,스토리지)에서 엄청난 활동을 만듬. 대부분의 인프라는 비용이 많이 들고, 거대했으며, 라이선스의 부담이 매우 컸음 
    - 2000년대 초: 현대 데이터 엔지니어링의 탄생
      - 닷컴 열풍이 무너지고 생존자 중 일부인 야후, 구글, 아마존 같은 기업들은 강력한 기술 기업으로 성장함. 1990년대의 전통적인 모놀리식 관계형 데이터베이스와 데이터 웨어하우스에 계속 의존하면서 시스템을 한계까지 몰아붙임.
      - 데이터의 폭발적 증가와 함께 서버, RAM, 디스크, 플래시 드라이브와 같은 범용 하드웨어도 저렴해지고 어디서나 사용할 수 있게 됐으며 몇 가지 혁신은 대규모 컴퓨팅 클러스터에서의 분산 연산 및 저장을 실현함. 이러한 혁신은 전통적인 모놀리식 서비스를 분산하고 분리하기 시작함.(빅데이터시대, 3V)
      - 2003년 구글은 구글 파일 시스템에 관한 논문을 발표했고, 그 직후인 2004년에는 초확장 데이터 처리 패러다임인 맵리듀스에 대한 논문을 발표했음.
      - 구글의 논문들은 야후의 엔지니어들이 2006년 아파치 하둡을 개발하고 나중에 오픈소스하는 데 영감을 주었음. 모든 규모와 유형의 기업들이 다루는 데이터가 테라바이트, 심지어 페타바이트 규모로 증가하면서 빅데이터 엔지니어 시대가 탄생함
      - 비슷한 시기에 아마존은 폭발적으로 증가하는 데이터 요구에 대응해야 했으며 EC2, S3, 다이나모DB를 비롯한 데이터 빌딩 블록을 구축했음. AWS가 아마존의 높은 수익성을 책임지는 성장 엔진이 되면서 구글 클라우드, 마이크로소프트 애저, 디지털오션과 같은 다른 퍼블릭 클라우드가 잇따라 등장하기 시작함.퍼블릭 클라우드는 소프트웨어와 데이터 애플리케이션의 개발 및 배포 방식에 혁명을 일으킴  
    - 2000년대와 2010년대: 빅데이터 엔지니어링
      - 하둡 생태계의 오픈 소스 빅데이터 도구는 빠르게 성숙했고, 배치 컴퓨팅에서 이벤트 스트리밍으로의 전환과 함께 또 다른 혁명이 발생했고 실시간 빅데이터의 새로운 시대를 열었음.
      - 엔지니어는 하둡, 피그, 하이브, 드레멜, HBase, 스톰, 카산드라, 스파크, 프레스토 등 최신 기술을 선택할 수 있었고 기존의 엔터프라이즈 지향적이고 GUI 기반인 데이터 도구는 갑자기 구식으로 느껴지며 맵리듀스의 출현으로 코드 우선(code-first) 엔지니어링이 유행했음
      - 데이터 도구가 폭발적으로 증가하면서 빅데이터 엔지니어가 탄생했으며 하둡,얀,HDFS,맵리듀스를 포함하는 하둡 생태계 같은 도구와 기술을 효과적으로 사용하려면 빅데이터 엔지니어가 소프트웨어 개발 및 저수준의 인프라 해키에 능숙해야 했지만, 강조점이 바뀌었음. 빅데이터 엔지니어는 보통 대규모 데이터를 제공하고자 상용 하드웨어의 대규모 클러스터를 유지 관리했고 핵심 기술 개발에서 데이터 전달로 초점이 옮겨짐.
    - 2020년대: 데이터 수명 주기를 위한 엔지니어링
      - 데이터 엔지니어는 역사적으로 하둡, 스파크 또는 인포매티카와 같은 모놀리식 프레임워크의 저수준의 세부 정보를 사용하는 경향이 있었음. 하지만 이제는 그 트렌드가 분산되고 모듈화되고, 관리되고, 고도로 추상화된 도구로 이동중임
      - 데이터 엔지니어링은 점차 궁극적인 비즈니스 목표를 달성하고자 다양한 기술을 마치 레고 블록처럼 연결하고 상호 운용하는 분야가 되고 있음
      - 데이터 엔지니어는 여전히 저수준의 데이터 프로그래밍 기술을 유지하고 필요에 따라 이를 사용합니다. 하지만 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션 및 일반 데이터 수명 주기 관리와 같은 가치 사슬의 상위 영역에 자신의 역할이 점점 더 집중되고 있음을 발견함
      - 이제 CCPA와 GDPR 같은 약어에 정통하며 파이프라인을 설계할때는 개인정보보호, 익명화, 데이터 가비지 수집 및 규정 준수에 관심을 가지고 고민함
- 데이터 엔지니어링 기술과 활동
  - 데이터 엔지니어의 기술 역량에는 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처 및 소프트웨어 엔지니어링과 같은 데이터 엔지니어링의 드러나지 않는 요소가 포함됨
  - 데이터 엔지니어는 수많은 복잡한 가변적 요소를 처리하고 비용, 민첩성, 확장성, 단순성, 재사용성, 상호 운용성의 축에 따라 지속해서 최적화를 수행해야 함
  - 데이터 성숙도와 데이터 엔지니어
    - 데이터 성숙도(data maturity)는 조직 전체어 걸쳐 더 높은 데이터 활용률(utilization), 기능(capability), 통합(ingegration)을 향해 나아가는 과정
    - 단순화된 기업용 데이터 성숙도 모델
      - 데이터로 시작하기
        - 데이터로 시작하는 조직의 데이터 엔지니어는 다음과 같은 사항에 중점을 두어야 함
          - 데이터 엔지니어는 기업의 목표를 지원하는 데이터 아키텍처를 설계하고 구축하는 중요한 계획에 대한 스폰서를 확보하는 것이 이상적
          - 적절한 데이터 아키텍처를 정의한다(데이터 아키텍트가 없을 가능성이 높으므로 보통 홀로 진행함). 이는 데이터 이니셔티브를  통해 달성하려는 경영 목표와 경쟁 우위를 결정한다는 의미로, 이러한 목표를 지원하는 데이터 아키텍처를 구축함 
      - 데이터로 확장하기
        - 해당 조직에서 데이터 엔지니어의 목표
          - 공식적인 데이터 관행 수립
          - 확장성 있고 견고한 데이터 아키텍처 구축
          - 데브옵스 및 데이터옵스 관행 채택
          - ML을 지원하는 시스템 구축
          - 차별화되지 않은 과중한 업무를 피하고, 경쟁 우위를 확보할 때만 커스터마이징 
      - 데이터로 선도하기
        - 이전 단계를 계속 구축함과 동시에 다음 작업을 수행함
          - 새로운 데이터의 매끄러운 배포와 사용을 위한 자동화를 구축함
          - 경쟁 우위로서 데이터를 활용하는 사용자 정의 도구와 시스템 구축에 주력함
          - 데이터 관리(데이터 거버넌스와 품질을 포함) 및 데이터옵스와 같은 데이터의 기업적 측면에 집중함
          - 데이터 카탈로그, 데이터 계보 도구, 메타데이터 관리 시스템을 포함해 데이터를 조직 전체에 노출하고 전파하는 도구를 배포함
          - 소프트웨어 엔지니어, ML 엔지니어, 분석가 등과 효율적으로 협업함
          - 역할이나 직책과 관계없이 사람들이 협업하고 공개적으로 토론할 수 있는 커뮤니티와 환경을 구축함
  - 데이터 엔지니어의 배경과 기술
    - 데이터 엔지니어는 정의상 데이터와 기술을 모두 이해해야 함.
      - 데이터 측면에서는 데이터 관리의 다양한 모범 사례를 알아야 함
      - 기술 측면에서는 데이터 엔지니어가 도구들의 다양한 옵션, 상호 작용 및 상충 관계를 알아야 함. 그러려면 소프트웨어 엔지니어링, 데이터옵스 및 데이터 아키텍처를 이해해야 함 
  - 기술 책임
    - 최근 들어 완전 관리형 서비스는 과거 엔지니어들에게 요구되는 수많은 저수준 프로그래밍 작업을 상당 부분 대체하게 됐음. 이제 엔지니어는 관리형 오픈 소스와 단순한 플러그 앤 플레이 SaaS 제품을 사용함
    - 예를 들어 데이터 엔지니어는 이제 고수준의 추상화에 주력하거나 오케스트레이션 프레임워크 내에서 파이프라인을 코드로 작성하는 작업에 더 집중함
    - 데이터 엔지니어링의 주요 언어
      - SQL
        - 스파크 SQL, 구글 빅쿼리, 스노우플레이크, 하이브 및 기타 여러 데이터 도구는 선언적이고 집합론적인 SQL 시맨틱을 사용해 대량의 데이터를 처리할 수 있음.
        - SQL은 아파치 플링크, 빔, 카프카와 같은 많은 스트리밍 프레임워크에서도 지원됨 
      - Python, Java, Scalar
      - 자바 가상 머신
        - 스파크, 하이브, 드루이드와 같은 아파치 오픈 소스 프로젝트에 널리 쓰임
        - JVM은 보통 파이썬보다 성능이 우수하며,(스파크와 빔등의 경우) 파이썬 API보다 저수준의 특성에 접근할 수 있음.
        - 널리 쓰이는 오픈 소스 데이터 프레임워크를 사용한다면 자바 또는 스칼라와 같은 언어를 이해하는 것이 유용함 
      - bash
    - 보저직인 프로그래밍 언어
      - R, 자바스크립트, Go, Rust, C/C++, C#, Julia 등
  - A에서 B로 이어지는 데이터 엔지니어링 역할의 연속성
    - A형 데이터 엔지니어
      - A는 추상화(abstraction)을 의미함. 이 경우 데이터 엔지니어는 차별화되지 않은 과중한 작업을 피하고, 데이터 아키텍처를 가능한 한 추상적이고 단순하게 유지함으로써 시간 낭비를 피함
      - A형 데이터 엔지니어는 주로 시판되는 기성 제품, 관리형 서비스와 도구들을 사용해 데이터 엔지니어링 수명 주기를 관리함.
      - A형 데이터 엔지니어는 데이터 성숙도 수준에 상관없이 산업계 전반에 걸쳐 다양한 회사에서 근무함
    - B형 데이터 엔지니어
      - B는 구축을(build)를 의미함
      - B형 데이터 엔지니어는 기업의 핵심 역량과 경쟁 우위를 확장하고 활용할 데이터 도구와 시스템을 구축함
      - B형 데이터 엔지니어는 데이터 성숙도 범위에서 (데이터로 확장하고 선도하는) 2단계 및 3단계에 해당하거나, 초기 데이터 사용 사례가 매우 독특하고 중요해서 작업을 시작하려면 맞춤형 데이터 도구가 필요한 회사에서 더 많이 찾아볼 수 있음 
- 조직 내 데이터 엔지니어
  - 내부 vs 외부 대면 데이터 엔지니어
    - 외부 대면(external-facing) 데이터 엔지니어는 일반적으로 소셜 미디어 앱, 사물 인터넷 장치, 전자 상거래 플랫폼과 같은 외부용 애플리케이션의 사용자와 연계함. 이 데이터 엔지니어는 이러한 애플리케이션에서 발생하는 트랜잭션 및 이벤트 데이터를 수집, 저장, 처리하는 시스템을 설계, 구축, 관리함
    - 내부 대면(internal-facing) 데이터 엔지니어는 일반적으로 비즈니스 및 내부 이해관계자의 요구 사항에 중요한 활동에 집중함. 예를 들면 BI 대시보드, 보고서, 비즈니스 프로세스, 데이터 과학, ML 모델용 데이터 파이프라인과 데이터 웨어하우스의 생성 및 유지 보수 등이 포함됨 
  - 데이터 엔지니어와 기타 기술 역할
    - 데이터 엔지니어는 소프트웨어 엔지니어, 데이터 아키텍트, 데브옵스 엔지니어 또는 사이트 신뢰성 엔지니어(SRE) 같은 데이터 생산자(data producer)와 데이터 분석가, 데이터 과학자, ML 엔지니어 등과 같은 데이터 소비자(data consumer)사이에서 허브 역할을 함. 또한 데이터 엔지니어는 데브옵스 엔지니어와 같이 운영 역할을 하는 사람들과 소통함
    - 업스트림 이해 관계자
      - 데이터 아키텍트
        - 데이터 아키텍트는 조직 내 데이터 관리를 위한 청사진을 설계하고, 프로세스와 전체 데이터 아키텍처 및 시스템을 매핑함. 또한 조직의 기술적 측면과 비기술적 측면을 연결하는 가교 역할을 수행함
        - 데이터 아키텍트는 사일로 및 사업부 전체에 걸쳐 데이터를 관리하는 정책을 구현하고, 데이터 관리 및 데이터 거버넌스와 같은 글로벌 전략을 조율하며, 중요한 이니셔티브를 안내함.
        - 데이터 아키텍트는 클라우드 마이그레이션과 신규 클라우드 설계에서 중심적인 역할을 수행하는 경우가 많음
      - 소프트웨어 엔지니어
        - 소프트웨어 엔지니어는 비즈니스를 운영하는 소프트웨어와 시스템을 구축함. 이들은 데이터 엔지니어가 소비하고 처리하는 내부 데이터(internal data)의 생성 업무에 큰 책임이 있음.
        - 소프트웨어 엔지니어가 구축한 시스템은 보통 애플리케이션 이벤트 데이터와 로그를 생성하는데 이는 그 자체로 중요한 자산임. 이러한 내부 데이터는 SaaS 플랫폼 또는 파트너 비즈니스에서 가져온 외부 데이터(external data)와 대조됨
      - 데브옵스 엔지니어와 사이트 신뢰성 엔지니어
        - 데브옵스 엔지니어와 사이트 신뢰성 엔지니어(SRE)는 종종 운영 모니터링을 통해 데이터를 생성함
    - 다운스트림 이해관계자
      - 데이터 과학자
        - 데이터 과학자는 예측과 추천을 위한 미래 지향적인 모델을 구축함. 그런 다음 이러한 모델을 라이브 데이터로 평가해 다양한 방식으로 가치를 제공함
        - 특히 널리 사용되는 수많은 데이터 과학 프레임워크는 적절히 확장되지 않으면 병목 현상이 발생할 수 있음. 단일 워크스테이션에서만 작업하는 데이터 과학자는 데이터 다운샘플링을 강요당해 데이터 준비가 상당히 복잡해지고 만들어낸 모델의 품질이 저하될 가능성이 있음. 게다가 로컬에서 개발된 코드와 환경은 실제 운영 환경에서 배포하기 어렵고, 자동화가 부족하면 데이터 과학 워크플로에 크게 방해가 됨
      - 데이터 분석가
        - 데이터 분석가(또는 비즈니스 분석가)는 비즈니스 성과와 동향을 파악하고자 함. 데이터 과학자가 미래지향적이라면 데이터 분석가는 보통 과거 또는 현재에 초점을 맞춤
        - 데이터 분석가는 일반적으로 데이터 웨어하우스 또는 데이터 레이크에서 SQL 쿼리를 실행함. 또한 계산 및 분석을 위해 스프레드시트를 활용하며 마이크로소프트 파워 BI, 루커, 태블로 등의 다양한 BI 도구를 사용할 수도 있음
        - 데이터 분석가는 자주 사용하는 데이터의 도메인 전문가로서 데이터 정의, 특징 및 품질 문제에 정통함. 데이터 분석가의 일반적인 다운스트림 고객은 비즈니스 사용자, 경영진 및 임원
      - 머신러닝 엔지니어와 인공지능 연구원
        - ML 엔지니어는 고급 ML 기술을 개발하고, 모델을 훈련하며, 확장된 운영 환경에서 ML 프로세스를 실행하는 인프라를 설계하고 유지 관리함
        - ML 엔지니어는 종종 ML과 파이토치 또는 텐서플로와 같은 딥러닝 기술 및 프레임워크에 대한 고급 실무 지식을 갖추고 잇음
        - ML 엔지니어는 운영 환경에서의 모델 훈련과 모델 배포를 위해 이러한 프레임워크를 실행하는 데 필요한 하드웨어와 서비스 및 시스템을 이해함
        - ML 워크플로는 보통 ML 엔지니어가 온디맨드 방식으로 인프라 자원을 스핀업하고 확장하거나 관리형 서비스에 의존할 수 있는 클라우드 환경에서 실행됨 

## 데이터 엔지니어링 수명 주기 
- 데이터 엔지니어링 수명 주기란?
  - 데이터 엔지니어링 수명 주기는 원시 데이터의 요소를 분석가, 데이터 과학자, ML 엔지니어 등이 사용할 수 있는 유용한 최종 제품으로 전환하는 단계로 구성됨
  - 데이터 생성
    - 원천 시스템(source system)은 데이터 엔지니어링 수명 주기에서 사용되는 데이터의 원본. 예를 들어 원천 시스템은 IoT 장치, 애플리케이션 메시지 대기열 또는 트랜잭션 데이터베이스일 수 있음
    - 데이터 엔지니어는 원천 시스템의 작동 방식, 데이터 생성 방식, 데이터의 빈도 및 속도, 생성되는 데이터의 다양성을 실무적으로 이해해야 함
    - 원천 시스템 평가: 주요 엔지니어링 고려 사항
      - 데이터 엔지니어가 고려할 원천 시스템의 평가 질문 스타터킷(starter kit)
        - 데이터 원천의 본질적인 특징은 무엇인가? 데이터 원천은 애플리케이션인가? IoT 장치의 스웜인가?
        - 원천 시스템에서 데이터는 어떻게 유지되는가? 데이터는 장기간 보존되는가? 아니면 일시적이고 빠르게 삭제되는가?
        - 데이터는 어느 정도의 속도로 생성되는가? 초당 몇 개의 이벤트가 발생할까? 시간당 몇 기가바이트인가?
        - 데이터 엔지니어는 출력 데이터에서 어느 정도의 일관성을 기대할 수 있는가? 출력 데이터에 대해 데이터 품질 검사를 실행할 때, 예상치 못한 출력값(예를 들면 null값)이나 잘못된 데이터 포맷과 같은 데이터 불일치 사례는 얼마나 자주 발생할까?
        - 에러는 얼마나 자주 발생하는가?
        - 데이터에 중복이 포함되지는 않는가? 
        - 일부 데이터값이 동시에 생성되는 다른 메시지보다 훨씬 늦게 도착할 수 있는가?
        - 수집된 데이터의 스키마는 무엇인가? 데이터 엔지니어가 데이터를 완전히 파악하려면 여러 테이블 또는 여러 시스템에 걸쳐 조인을 수행해야 하는가?
        - 스키마가 변경되면(예를 들어 새로운 열이 추가되었을 때) 어떻게 대처하고 다운스트림 이해관계자에게 전달할 수 있는가?
        - 원천 시스템에서 데이터를 얼마나 자주 가져와야 하는가?
        - (고객 계정 정보를 추적하는 데이터베이스 등) 상태가 있는 시스템(stateful system)의 경우, 데이터는 정기적인 스냅숏으로 제공되는가? 아니면 변경 데이터 캡처(CDC)로부터 갱신 이벤트로 제공되는가? 변경은 어떻게 수행되며, 원천 데이터베이스에서 이러한 변경을 어떻게 추적하는가?
        - 다운스트림 사용을 위한 데이터를 전송하는 데이터 제공업체는 누구(무엇)인가?
        - 데이터 원천에서의 데이터 조회가 성능에 영향을 미치는가?
        - 원천 시스템에 업스트림 데이터 의존 관계가 있는가? 이러한 업스트림 시스템의 특징은 무엇인가?
        - 늦거나 누락된 데이터 확인용으로 데이터 품질 검사가 실시되고 있는가?
      - 스키마리스 방식은 스키마가 없다는 뜻은 아님. 애플리케이션은 메시지 대기열, 플랫 파일(Flat file), BLOB 또는 몽고DB와 같은 도큐먼트 데이터베이스에 데이터가 기록될 때 스키마를 정의함.
      - 관계형 데이터베이스 스토리지를 기반으로 구축된 더 전통적인 모델은 데이터베이스에 적용된 고정 스키마(fixed schema) 방식을 사용하는데, 애플리케이션 쓰기는 이 스키마를 준수해야 함
  - 데이터 저장
    - 스토리지 시스템 평가: 주요 엔지니어링 고려 사항
      - 데이터 웨어하우스, 데이터 레이크하우스, 데이터베이스 또는 객체 스토리지를 위한 스토리지 시스템을 선택할 때 확인할 몇 가지 핵심 엔지니어링 질문
        - 이 스토리지 설루션은 아키텍처에서 요구하는 쓰기 및 읽기 속도와 잘 맞는가?
        - 스토리지가 다운스트림 프로세스의 병목 현상을 초래하지는 않는가?
        - 이 스토리지 기술이 작동하는 방식을 인지하고 있는가? 스토리지 시스템을 최적으로 활용하는가? 아니면 부자연스러운 행동을 하는가? 예를 들어 객체 스토리지 시스템에 높은 비율의 임의 접근(random access) 갱신을 적용하고 있지는 않은가?(이것은 성능 오버헤드가 큰 안티패턴)
        - 이 스토리지 시스템은 향후 예상되는 확장을 처리할 수 있는가? 사용 가능한 총 스토리지, 읽기 작업 속도, 쓰기 볼륨 등 스토리지 시스템의 모든 용량 제한을 고려해야 함
        - 다운스트림 사용자와 프로세스가 필요한 서비스 수준 협약(SLA)에 따라 데이터를 취득할 수 있는가?
        - 스키마 진화, 데이터 흐름, 데이터 계보 등에 대한 메타데이터를 캡처하고 있는가? 메타데이터는 데이터 활용성에 큰 영향을 미친다. 메타데이터는 미래에 대한 투자로, 검색 가능성과 제도적 지식을 획기적으로 향상시켜 미래의 프로젝트 및 아키텍처 변경을 간소화함
        - 순수 스토리지 설루션(객체 스토리지)인가? 아니면 복잡한 쿼리 패턴(예 클라우드 데이터 웨어하우스)을 지원하는가?
        - 스토리지 시스템이 스키마에 구애받지는 않는가(객체 스토리지)? 유연한 스키마(카산드라)인가? 강제 적용된 스키마(클라우드 데이터 웨어하우스)인가?
        - 데이터 거버넌스를 위해 마스터 데이터, 골든 레코드 데이터 품질 및 데이터 계보를 어떻게 추적하고 있는가?
        - 법령 준수 및 데이터 주권에 어떻게 대처하고 있는가? 예를 들어 특정 지리적 위치에는 데이터를 저장하고 다른 위치에는 저장하지 않을 수 있는가?
    - 데이터 접근 빈도 이해
      - 데이터의 온도 : 데이터 접근 빈도에 따라 데이터 온도가 결정됨
        - 핫 데이터 : 가장 자주 액세스 되는 데이터
          - 일반적으로 하루에 여러번 검색됨. 이러한 데이터는 빠른 검색용으로 저장되어야 하는데, 여기서 빠른은 사용 사례에 따라 달라짐
        - 미온적 데이터(lukewarm data): 가끔(매주 또는 매월) 액세스 되는 데이터
        - 콜드 데이터 : 거의 쿼리되지 앟ㄴ으며 아카이브 시스템에 저장하는 데 적합함
          - 콜드 데이터는 규정 준수의 목적으로 보관되거나, 다른 시스템에 심각한 장애가 발생했을 때 보관되는 경우가 많음
  - 데이터 수집
    - 수집 단계에서의 주요 엔지니어링 고려 사항
      - 시스템 설계 또는 구축을 준비할 때 수집 단계에 대한 몇 가지 주요 질문 
        - 수집 중인 데이터의 사용 사례는 무엇인가? 같은 데이터셋의 여러 버전을 생성하는 대신 이 데이터를 재사용할 수 있는가?
        - 시스템이 이 데이터를 안정적으로 생성하고 수집하고 있는가? 필요할 때 해당 데이터를 사용할 수 있는가?
        - 수집 후 데이터 목적지는 어디인가?
        - 데이터는 얼마나 자주 접근해야 하는가?
        - 데이터는 보통 어느 정도의 용량으로 도착하는가?
        - 데이터 형식은 무엇인가? 다운스트림 스토리지 및 변환 시스템에서 이 형식을 처리할 수 있는가?
        - 원천 데이터는 다운스트림에서 즉시 사용할 수 있는 양호한 상태인가? 그렇다면 얼마나 오래 사용할 수 있으며, 사용할 수 없게 되는 요인은 무엇인가?
        - 데이터가 스트리밍 소스에서 전송된 경우, 목적지에 도달하기 전에 데이터를 변환해야 하는가? 데이터가 스트림 자체 내에서 변환되는 형태의 변환이 적절할까?
    - 배치 vs 스트리밍
      - 우리가 다루는 대부분의 데이터는 본질적으로 스트리밍임. 스트리밍 수집을 사용하면 다른 애플리케이션이나 데이터베이스 또는 분석 시스템 등의 다운 스트림 시스템에 데이터를 실시간으로 연속해 제공할 수 있음
        - 많은 시스템에서 스토리지와 컴퓨팅 자원이 분리되고 이벤트 스트리밍과 처리 플랫폼이 보편화됨에 따라, 데이터 스트림의 지속적인 처리에 대한 접근성과 인기가 더욱 높아지고 있음 
      - 데이터는 거의 항상 원천에서 지속해 생성되고 갱신됨. 배치 수집은 이 스트림을 큰 청크로 처리하는 전문적이고 편리한 방법(예를 들어 하루 분량의 데이터를 단일 배치 방식으로 처리함)
        - 배치 데이터는 미리 설정된 시간 간격에 따라, 또는 데이터가 미리 설정된 크기 임계값에 도달하면 수집됨. 배치 수집은 한 방향으로만 이루어지며, 데이터가 배치로 분할되면 다운스트림 소비자의 지연 시간이 본질적으로 제한됨
        - 레거시 시스템의 제약 때문에 오랫동안 배치가 기본적인 데이터 수집 방식이었음. 배치 처리는 특히 분석 및 머신러닝(ML)에서 다운스트림을 사용할 때 데이터를 수집하는 매우 인기 있는 방법
    - 배치와 스트림 수집의 주료 고려 사항
      - 스트리밍 수집이 배치 수집보다 적절한 선택인지 여부를 판단할 때 자문해봐야 할 몇 가지 질문
        - 데이터를 실시간으로 수집하면 다운스트림 스토리지 시스템이 데이터 흐름 속도를 처리할 수 있는가?
        - 밀리초 단위의 실시간 데이터 수집이 필요할까? 아니면 매분마다 데이터를 축적하고 수집하는 마이크로 배치 접근 방식이 효과가 있을까?
        - 스트리밍 수집의 사용 사례로는 무엇이 있을까? 스트리밍을 구현하면 구체적으로 어떤 이점을 얻을 수 있을까? 데이터를 실시간으로 가져올 수 있다면, 배치 방식에 비해 개선될 수 있는 데이터에 대해 어떤 조치를 취할 수 있을까?
        - 스트리밍 우선 접근 방식은 단순 배치 방식보다 시간, 비용, 유지 보수, 다운타임 및 기회비용 측면에서 더 많은 비용을 소비할까?
        - 인프라에 장애가 발생했을 때 스트리밍 파이프라인과 시스템이 안정적이고 다중화되어 있는가?
        - 사용 사례에 가장 적합한 도구는 무엇인가? 관리형 서비스(아마존 키네시스, 구글 클라우드 Pub/Sub, 구글 클라우드 데이터플로)를 사용해야 하는가? 아니면 카프카, 플링크, 스파크, 펄사 등의 인스턴스를 구축해야 할까? 후자를 선택한다면 누가 관리의 역할을 맡을 것인가? 비용과 트레이드오프는 무엇일까?
        - ML 모델을 배포했을 때 온라인 예측 및 지속적인 훈련으로 얻을 수 있는 이점은 무엇일까?
        - 실제 운영 인스턴스에서 데이터를 가져오는가? 그렇다면 이 원천 시스템에 대한 수집 프로세스의 영향도는 얼마나 될까?
    - 푸시 vs 풀
      - 데이터 수집의 푸시 몯레에서 원천 시스템은 데이터베이스, 객체 저장소 또는 파일 시스템과 관계없이 타깃에 데이터를 씀
      - 풀 모델에서는 원천 시스템에서 데이터를 검색함
      - 배치 지향 수집 워크플로에서 일반적으로 사용되는 추출-변환-적재(ETL) 프로세스를 생각해보면 ETL의 추출 부분은 풀 수집 모델을 다루고 있음을 명확히 보여줌. 기존 ETL에서는 수집 시스템이 정해진 일정에 따라 현재 소스 테이블의 스냅숏을 쿼리함
      - 연속적인 CDC
        - 원천 데이터베이스에서 행이 변경될 대마다 메시지를 트리거하는 것. 이 메시지는 큐에 푸시되며, 수집 시스템이 해당 메시지를 가져감.
        - 다른 CDC 방식은 데이터베이스에 대한 모든 커밋을 기록하는 바이너리 로그를 사용하는 것인데, 데이터베이스가 로그를 푸시함. 수집 시스템은 로그를 읽지만, 그 외에는 데이터베이스와 직접 상호 작용하지 않음. 그에 따라 원천 데이터베이스에 대한 추가 부하는 거의 없거나 또는 전혀 추가되지 않음.
        - 배치 CDC의 일부 버전에서는 풀 패턴을 사용함. 예를 들어 타임스탬프 기반 CDC에서는 수집 시스템이 원천 데이터베이스를 쿼리하고 이전 갱신 이후에 변경된 행을 가져옴
  - 데이터 변환
    - 변환 단계에서의 주요 고려 사항
      - 데이터 엔지니어링 수명 주기 내에서 데이터를 변환할 때는 다음 사항을 고려해야 함
        - 변환에 드는 비용과 투자수익률(ROI)은 얼마인가? 관련된 비즈니스 가치는 무엇인가?
        - 변환은 가능한 한 단순하고 독립적인가?
        - 변환이 지원하는 비즈니스 규칙은 무엇인가? 
  - 데이터 서빙
    - 데이터를 수집하고 저장한 뒤에 일관성 있고 유용한 구조로 변환했으니, 이제 데이터로부터 가치를 창출 할 때
    - 데이터 허영(data vanity) 프로젝트는 기업의 주요 리스크. 많은 기업이 빅데이터 시대에 불필요한 프로젝트를 추진해, 어떤 유용한 방법으로도 소비되지 않는 데이터 레이크에서 대규모 데이터셋을 수집했음
    - 분석
      - 데이터가 저장되고 변환되면 보고서 또는 대시보드를 생성하고 데이터에 대한 임시 분석을 수행할 수 있음
      - 비즈니스 인텔리전스(BI)
        - BI는 기업 경영의 과거와 현재 상태를 설명하기 위해 데이터를 수집함. BI는 비즈니스 로직을 사용해 원시 데이터를 처리해야 함
        - 기업의 데이터 성숙도가 높아짐에 따라 기업은 애드혹 데이터 분석에서 셀프서비스 분석으로 전환해 IT 부서의 개입 없이도 비즈니스 사용자가 데이터에 접근할 수 있게 됨. 이때 셀프서비스 분석을 수행하는 기능은 조직의 전체 인원이 데이터에 직접 접근하고, 원하는 방식으로 데이터를 분석하고, 즉각적인 통찰력을 얻을 수 있을 만큼 충분히 양호한 데이터라고 가정함
        - 셀프서비스 분석은 이론상으로는 간단하지만, 실제로 성공하기는 어려움. 주된 이유는 데이터 품질 저하, 조직 사일로 현상, 적절한 데이터 기술 부족 등의 문제가 광범위한 분석에 방해되기 때문
      - 운영 분석
        - 운영의 상세 사항에 중점을 두고 보고서 사용자가 즉시 수행할 수 있는 작업을 촉진함. 운영 분석은 재고 물품에 대한 실시간 뷰 또는 웹사이트나 애플리케이션 상태에 대한 실시간 대시보드가 될 수 있음
      - 임베디드 분석
        - 임베디드 분석(고객 대면 분석)을 사용하면 보고서 요청 비율과 그에 따른 분석 시스템의 부담이 매우 커지며, 접근 제어 역시 훨씬 더 복잡해지고 중요해짐. 기업은 수천 명 이상의 고객에게 별도의 분석 및 데이터를 제공할 수 있음.이때 각 고객은 자신의 데이터만 확인할 수 있어야 함 
        - 기업 내부의 데이터 접근 오류는 절차적 검토로 이루어질 수 있음. 고객 간 데이터 유출은 중대한 신뢰 위반으로 간주되어 언론의 주목을 받고 고객 감소로 이어질 수 있음. 따라서 데이터 유출 및 보안 취약성과 관련한 피해 범위를 최소화하자. 스토리지를 비롯해 데이터 유출 가능성이 있는 모든 장소에서 테넌트 또는 데이터 수준의 보안을 적용함
    - 머신 러닝
      - ML 관련 데이터 서빙 단계에서 고려할 사항
        - 신뢰할 수 있는 특성 엔지니어링을 수행하기에 충분한 품질의 데이터인가? 품질 요구 사항 및 평가는 데이터를 사용하는 팀과 긴밀히 협력해 개발됨
        - 데이터를 검색할 수 있는가? 데이터 과학자와 ML 엔지니어는 가치 있는 데이터를 쉽게 찾을 수 있는가?
        - 데이터 엔지니어링과 ML 엔지니어링 간의 기술적 및 조직적 경계는 어디인가? 이러한 조직 차원의 질문은 아키텍처에 큰 영향을 미침
        - 데이터셋이 실제 상황을 제대로 나타내고 있는가? 불공평하게 편향되어 있지는 않은가?
    - 역 ETL
      - 데이터 엔지니어링 수명 주기의 출력 측에서 처리한 데이터를 가져와 원천 시스템이 다시 공급함
      - 역 ETL을 사용하면 분석, 평가 모델 등을 가져와 운영 시스템 또는 SaaS 플랫폼에 다시 제공할 수 있음
      - 기업이 SaaS 및 외부 플랫폼에 점점 더 많이 의존하게 되면서 역 ETL은 특히 중요해지고 있음.
        - 예를 들어 기업은 데이터 웨어하우스에서 고객 데이터 플랫폼 또는 CRM 시스템으로 특정한 측정 지표를 푸시할 수 있음.
        - 또 다른 일상적인 사용 사례로는 구글 애즈와 같은 광고 플랫폼이 있음
      - 핵심은 변환된 데이터가 원천 시스템과 관련한 올바른 계통과 비즈니스 프로세스를 통해 어떤 방식으로든 원천 시스템에 반화되어야 한다는 것 
- 데이터 엔지니어링 수명 주기의 드러나지 않는 주요 요소
  - 보안
    - 접근 제어
      - 데이터
      - 시스템
    - 상세설명
      - 데이터 엔지니어는 데이터와 접근 보안을 모두 이해하고 최소 권한 원칙을 실행해야 함
      - 최소 권한 원칙이란 사용자 또는 시스템이 의도된 기능을 수행하는 데 필수적인 데이터와 자원에만 접근할 수 있는 것을 의미함
      - 암호화(encryption), 토큰화(tokenization), 데이터 마스킹, 난독화(obfuscation) 및 단순하고 견고한 접근 제어(access control)를 사용해 이동 중인 데이터와 저장된 데이터 모두 원치 않는 가시성으로 부터 보호해야 함
      - 사용자 및 ID 접근 관리(IAM)의 역할, 정책, 그룹, 네트워크 보안, 암호 정책, 암호화 등은 보안 관련 지식을 쌓기에 좋은 출발점
  - 데이터 관리
    - 데이터 거버넌스
      - 발견 가능성
      - 정의
      - 책임
    - 데이터 모델링
    - 데이터 무결성
    - 상세 설명
      - 데이터 관리는 수명 주기 전체에 걸쳐 데이터와 정보 자산의 가치를 제공, 제어, 보호 및 향상할 계획, 정책, 프로그램과 사례를 개발, 실행 및 감독한는 것
      - 데이터 관리의 여러 측면
        - 발전 가능성(discoverability) 및 책임(accountability)을 포함한 데이터 거버넌스
        - 데이터 모델링 및 설계
        - 데이터 계보
        - 저장 및 운영
        - 데이터 통합 및 상호 운용성
        - 데이터 수명 주기 관리
        - 고급 분석 및 ML을 위한 데이터 시스템
        - 윤리 및 개인정보보호
      - 데이터 거버넌스
        - 에브렌 에리우렉의 저서에 따르면 데이터 거버넌스는 무엇보다도 조직이 수집한 데이터의 품질, 무결성(integrity), 보안 및 사용성(usability)을 보장하기 위한 데이터 관리 기능
        - 데이터 거버넌스는 적절한 보안 제어로 데이터를 보호하면서, 조직 전체의 데이터 가치를 극대화하기 위해 인력, 프로세스 및 기술을 활용함
        - 데이터 거버넌스의 핵심 범주는 발견 가능성, 보안, 책임. 이러한 핵심 범주에는 데이터 품질, 메타데이터 및 개인정보보호와 같은 하위 범주가 있음
        - 발견 가능성
          - 데이터 발견 가능성의 주요 분야로는 메타데이터 관리 및 마스터 데이터 관리 등이 있음
        - 메타 데이터
          - 메타데이터는 데이터에 관한 데이터로 데이터 엔지니어링 수명 주기의 모든 부분을 뒷받침함. 메타데이터는 데이터를 검색하고 제어하는 데 필요한 데이터
          - 메타데이터는 크게 자동 생성 데이터와 인간 생성 데이터의 두 가지 범주로 나뉨
          - DMBOK는 데이터 엔지니어에게 유용한 메타데이터의 네 가지 주요 범주를 다음과 같이 식별함
            - 비즈니스 메타데이터
              - 비즈니스와 데이터 정의, 데이터 규칙과 로직, 데이터 사용 방법과 장소, 데이터 소유자 등 비즈니스에서 데이터가 사용되는 방식과 관련이 있음 
            - 기술 메타데이터
              - 데이터 엔지니어링 수명 주기 전반에 걸쳐 시스템이 생성하고 사용하는 데이터를 의미함. 여기에는 데이터 모델과 스키마, 데이터 계보, 필드 매핑 및 파이프라인 워크플로우가 포함됨
              - 일반적인 유형의 기술 메타데이터
                - 파이프라인 메타데이터(종종 오케스트레이션 시스템에서 생성됨)
                  - 오케스트레이션은 다양한 시스템에서 워크플로를 조정하는 중앙 허브. 오케스트레이션 시스템에서 캡처된 파이프라인 메타데이터는 워크플로 일정, 시스템과 데이터 종속성, 구성, 연결 세부 정보 등을 제공함 
                - 데이터 계보 메타데이터
                  - 데이터 원본과 변경 사항, 데이터 종속성을 시간에 따라 추적함. 데이터는 데이터 엔지니어링 수명 주기를 통과하면서 변환되거나 다른 데이터와 결합되며 진화함
                  - 데이터 계보는 데이터가 다양한 시스템과 워크플로를 거치는 동안 데이터의 진화에 대한 감사 추적(audit trail)을 제공함 
                - 스키마 메타데이터
                  - 데이터베이스, 데이터 웨어하우스, 데이터 레이크 또는 파일 시스템과 같은 시스템에 저장된 데이터 구조를 설명함. 이 구조는 다양한 스토리지 시스템의 주요 차별화 요소 중 하나
                  - 예를 들어 객체 저장소는 스키마 메타데이터를 관리하지 않으며 대신 메타스토어에 관리해야 함. 반면 클라우드 데이터 웨어하우스는 스키마 메타데이터를 내부적으로 관리함 
            - 운영 메타데이터
              - 다양한 시스템의 운영 결과를 설명하는 프로세스, 작업 ID, 애플리케이션 런타임 로그, 프로세스에서 사용되는 데이터 및 오류 로그에 대한 통계를 포함함. 데이터 엔지니어는 운영 메타데이터를 사용해서 프로세스의 성공 또는 실패 여부와 그 프로세스에 관련된 데이터를 판단함 
            - 참조 메타데이터
              - 다른 데이터를 분류하는 데 필요한 데이터로, 조회 데이터(lookup data)라고도 함.
              - 참조 데이터의 표준 사례로는 내부 코드 ,지리적 코드 ,측정 단위 및 내부 달력 표준 등이 있음. 대부분의 참조 데이터는 내부적으로 완벽하게 관리되지만, 지리 코드와 같은 항목은 표준 외부 참조에서 가져올 수 있음.
              - 참조 데이터는 기본적으로 다른 데이터를 해석하기 위한 표준이므로 데이터가 변경되면 시간이 지남에 따라 서서히 변경됨
          - 데이터 책임(data accountability) : 데이터의 일부를 관리할 개인을 지정하는 것을 의미함. 그런 다음 책임자는 다른 이해관계자의 거버넌스 활동을 조정함
          - 데이터 품질 
            - 데이터 품질 테스트를 수행하고, 스키마 기대치 ,데이터 완전성 및 정밀도에 대한 데이터 준수를 보장하는 것이 포함됨
            - 데이터 품질의 3가지 주요 특징
              - 정확도(accuracy) : 수집된 데이터가 실제로 정확한가? 중복된 값이 있는가? 수치가 정확한가?
              - 완전성(completeness) : 기록은 완전한가? 모든 필수 필드에 유횻값이 포함되는가?
              - 적시성(timeliness) : 기록을 시기 적절하게 이용할 수 있는가?
            - 마스터 데이터 관리
              - 마스터 데이터는 직원, 고객, 제품 및 위치와 같은 비즈니스 엔티티에 대한 데이터
              - 마스터 데이터 관리(master data management(MDM))는 골든 레코드(golden record)로 알려진 일관된 엔티티 정의를 구축하는 관행. 골든 레코드는 조직 전체 및 파트너 간에 엔티티 데이터를 조화시킴. MDM은 기술 도구를 구축하고 배포함으로써 촉진되는 비즈니스 운영 프로세스 
      - 데이터 모델링 및 설계 : 데이터를 사용 가능한 형태로 변환하는 프로세스를 데이터 모델링 및 설계
      - 데이터 계보
        - 데이터를 처리하는 시스템과 데이터가 의존하는 업스트림 데이터를 모두 추적해 수명 주기 전체에 걸쳐 데이터의 감사 추적을 기록하는 것
        - 데이터 계보는 데이터 및 데이터를 처리하는 시스템의 오류 추적, 설명 및 디버깅에 도움이 됨. 데이터 수명 주기에 대한 감사 추적을 제공한다는 명백한 이점이 있으며 컴플라이언스(규정 준수)에도 도움이 됨
        - 예를 들어 사용자가 시스템에서 데이터를 삭제하려는 경우 해당 데이터에 대한 계보가 있으면 데이터가 저장된 위치와 종속성을 알 수 있음
      - 데이터 통합과 상호 운용성
        - 여러 도구와 프로세스 전반에 걸쳐 데이터를 통합하는 프로세스. 분석에 대한 단일 스택(single-stack) 접근 방식에 벗어나, 다양한 도구가 온디맨드로 데이터를 처리하는 이기종 클라우드 환경으로 전환함에 따라 통합 및 상호 운용성은 데이터 엔지니어의 작업 범위를 더욱 넓히고 있음
        - 데이터 통합은 맞춤형 데이터베이스 연결이 아닌 범용 API를 통해 이루어지는 경우가 늘고 있음. 예를 들어 데이터 파이프라인은 세일즈포스의 API에서 데이터를 가져와 아마존 S3에 저장하고 스노우플레이크의 API를 호출해 테이블에 적재한 다음, API를 다시 호출해 쿼리를 실행한 뒤 그 결과를 S3로 내보내 스파크가 데이터를 소비할 수 있음
        - 이 모든 작업은 데이터를 직접 처리하는 대신 데이터 시스템과 통신하는 비교적 단순한 파이썬 코드로 관리할 수 있음. 데이터 시스템과 상호 작용의 복잡성은 감소했지만, 시스템 수와 파이프라인의 복잡성은 극적으로 증가 했음
      - 데이터 수명 주기 관리
        - 데이터 레이크의 등장으로 조직은 데이터 보관(archival) 및 파기(destruction)를 무시하게 됐음
        - 클라우드에 점점 더 많은 데이터가 저장되고 있음. 즉, 사내 데이터 레이크에 대한 대규모 초기 자본 지출 대신 종량제 스토리지 비용이 발생하게 됐음
        - GPR과 CCPA 같은 개인정보보호 및 데이터 보존법에 따라 데이터 엔지니어는 사용자의 잊혀질 권리를 존중하기 위해 데이터 파기를 적극적으로 관리해야 함
        - 데이터 파기는 한 번 쓰고 여러 번 읽기(WORM, write once read many)가 기본 스토리지 패턴인 데이터 레이크에서 더 어려웠음
      - 윤리와 개인정보보호
        - 데이터 엔지니어는 데이터셋이 개인식별정보(PII) 및 기타 중요한 정보를 마스킹 처리하는지를 확인해야 함. 그러면 데이터셋이 변환될 때 편향을 식별하고 추적할 수 있음 
  - 데이터옵스
    - 데이터 거버넌스
    - 관찰 가능성과 모니터링
    - 사건 보고
    - 상세 설명
      - 데이터옵스는 애자일 방법론, 데브옵스, 통계적 공정 관리(SPC, statistical process control)의 모범사례를 데이터에 매핑함.
      - 데브옵스의 목표는 소프트웨어 제품의 릴리스와 품질을 개선하는 것이지만 데이터옵스는 데이터 제품에 대해서도 같은 작업을 수행함
      - 소프트웨어 제품은 최종 사용자에게 특정 기능과 기술적 기능을 제공함. 한편, 데이터 제품은 사용자가 의사결정을 내리거나 자동화된 작업을 수행하는 모델을 구축하는 건전한 비즈니스 로직과 측정 지표를 기반으로 구축됨.
      - 데이터 엔지니어는 소프트웨어 제품 구축의 기술적 측면과, 우수한 데이터 제품을 만드는 비즈니스 로직, 품질 및 측정 지표를 모두 이해해야 함
      - 데이터 옵스는 다음 사항들을 실현하는 기술 관행, 워크플로, 문화적 규범, 아키텍처 패턴의 집합
        - 신속한 혁신과 실험으로 고객에게 새로운 통찰력을 빠르게 제공
        - 매우 높은 데이터 품질과 매우 낮은 오류율
        - 인력, 기술, 환경의 복잡한 집합 전반에 걸친 협업
        - 명확한 측정, 모니터링 및 결과의 투명성
        - 데이터 옵스를 통해 데이터 엔지니어는 모든 업무에서 데이터옵스 작업의 우선순위를 높게 지정하는 것이 좋음. 선행 작업에서는 제품의 신속한 제공, 데이터의 신뢰성 및 정확성 향상, 비즈니스 전체적인 가치 향상을 통해 장기적으로 상당한 성과를 거둘 수 있음 
      - 데이터 옵스에는 자동화, 모니터링 및 관찰 가능성, 사고 대응이라는 세 가지 핵심 기술 요소가 있음
        - 자동화(automation)
          - 데이터옵스 프로세스의 신뢰성과 일관성을 보장할 수 있으며, 데이터 엔지니어가 새로운 제품 기능과 개선 사항을 기존 워크플로에 신속하게 구현할 수 있음.
          - 데이터옵스 자동화는 변경 관리(환경, 코드 및 데이터 버전 제어), 지속적 통합 배포(CI/CD), 코드로 구성된 데브옵스와 유사한 프레임워크 및 워크플로를 가짐
          - 데브옵스와 마찬가지로 데이터옵스 관행은 데이터 품질, 데이터/모델 드리프트, 메타데이터 무결성 등을 확인하는 차원을 추가해 기술과 시스템(데이터 파이프라인, 오케스트레이션 등)의 신뢰성을 모니터링하고 유지함
          - 가상의 조직을 이용해 데이터옵스 자동화의 진화를 간략히 설명
            - 데이터옵스 성숙도가 낮은 조직에서는 크론 잡을 사용해 데이터 변환 프로세스의 여러 단계를 에약하려고 시도하는 경우가 많으며, 실제로 한동안은 잘 작동함. 하지만 데이터 파이프라인이 복잡해짐에 따라 여러 가지 일이 발생할 수 있음
            - 크론 잡이 클라우드 인스턴스에서 호스팅되는 경우, 인스턴스에 작동 문제가 발생해 작업 실행이 예기치 않게 중지될 수 있음. 작업 간의 간격이 더 좁아지면 결국 작업이 오래 실행되어 후속 작업이 실패하거나 오래된 데이터가 생성됨. 엔지니어는 분석가로부터 보고서가 오래됐다는 이야기를 듣기 전까지는 작업 실패를 인식하지 못할 수 있음
            - 조직의 데이터 성숙도가 높아짐에 따라, 데이터 엔지니어는 일반적으로 에어플로 또는 대그스터와 같은 오케스트레이션 프레임워크를 채택함
              - 데이터 엔지니어들은 에어플로가 운영상의 부담을 초래한다는 것을 알지만, 결국 오케스트레이션의 이점이 복잡성을 능가함
              - 엔지니어는 크론 잡을 에어플로 잡으로 단계적으로 이행함. 이제 작업이 실행되기 전에 종속성을 확인함. 각 작업은 미리 정해진 시간이 아닌, 업스트림 데이터가 준비되는 즉시 시작할 수 있으므로 주어진 시간에 더 많은 변환 작업을 패킹(packing)할 수 있음
        - 관찰 가능성과 모니터링
          - 페트렐라의 DODD 방법론은 데이터 관찰 가능성을 고려할 수 있는 훌륭한 프레임워크를 제공함. DODD는 소프트웨어 엔지니어링의 TDD(test-driven developmnet) 매우 유사함
            - DODD의 목적은 데이터 가치 사슬(data value chain)에 관련된 모든 데이터 사용자가 데이터 및 데이터 애플리케이션에 대한 가시성을 확보하고 그 변경 사항을 수집에서 변환, 분석까지 모든 단계에서 식별할 수 있도록 함으로써, 데이터 문제를 해결하거나 예방하는 것.
            - DODD는 데이터 엔지니어링 수명 주기에서 데이터 관찰 가능성을 최우선 고려 사항으로 삼는 데 중점을 둠 
        - 사고 대응(incident response)
          - 자동화 및 관찰 가능성 기능을 사용해 이러한 사고의 근본 원인을 신속하게 특정하고 가능한 한 확실하고 빠르게 해결하는 것 
  - 데이터 아키텍처
    - 데이터 분석 트레이드오프
    - 디자인과 민첩성
    - 비즈니스에 가치 더하기
    - 상세 설명
      - 원천 시스템, 수집, 저장, 변환 및 데이터 서빙에 있어 설계 패턴, 기술 및 도구의 트레이드오프를 파악해야 함
      - 데이터 엔지니어가 데이터 아키텍트와 함께 작업할 경우 데이터 엔지니어는 데이터 아키텍트의 설계를 이행하고 아키텍처 피드백을 제공할 수 있어야 함 
  - 오케스트레이션
    - 워크플로 조정
    - 작업 스케줄링
    - 작업 관리
    - 상세 설명
      - 오케스트레이션은 많은 작업이 예약된 순서대로 최대한 빠르고 효율적으로 실행되도록 조정하는 프로세스
      - 오케스트레이션 엔진은 일반적으로 유향 비순환 그래프(DAG)의 형태로 작업 종속성에 따라 메타데이터를 구축함. DAG는 한 번만 실행되거나 매일, 매주, 매시간, 5분 등 일정한 간격으로 실행되도록 스케줄링할 수 있음
      - 오케스트레이션 시스템은 관리하는 작업을 모니터링하고 내부 DAG 종속성이 완료되면 새 작업(task)를 시작함. 또한 외부 시스템과 도구를 모니터링해 데이터가 도착하고 기준을 충족하는지 확인할 수 있음. 특정 조건이 범위를 벗어나면 시스템은 오류 조건을 설정하고 이메일 또는 다른 채널을 통해 경고를 보냄
      - 오케스트레이션 시스템은 또한 작업 기록 기능, 시각화 및 경고 기능을 구축함. 고급 오케스트레이션 엔진은 새로운 DAG 또는 개별 작업이 DAG에 추가될 때 백필 작업을 수행할 수 있음. 또한 시간 범위에 따른 종속성(의존 관계)도 지원함
      - 몇몇 초기 오픈 소스 프로젝트의 목표는 에어플로 핵심 설계의 가장 좋은 요소를 모방함과 동시에 주요 영역에서 이를 개선하는 것.
        - 가장 흥미로운 예로는 프리팩트(prefect)와 대그스터(Dagster)가 있는데, 그 목적은 DAG의 이식성(portability)과 테스트 가능성을 개선해 엔지니어가 로컬 개발에서 운영 환경(porduction)으로 더 쉽게 이동하도록 돕는 것.
        - 아르고(Argo)는 쿠버네티스 프리미티브(플랫폼에서 애플리케이션ㅇ르 만들고 운영하기 위해 쿠버네티스 아키텍처에 고정된 기본 구성 요소)를 기반으로 구축된 오케스트레이션 엔진.
        - 메타플로(Metaflow)는 넷플릭스의 오픈 소스 프로젝트로, 데이터 과학 오케스트레이션의 개선이 목표 
  - 소프트웨어 엔지니어링
    - 프로그래밍과 코딩 기술
    - 소프트웨어 디자인 패턴
    - 테스트와 디버깅
    - 상세 설명
      - 2000년 부터 2010년 까지의 현대 데이터 엔지니어링 초기에 데이터 엔지니어는 저수준 프레임워크에서 작업했으며 C, C++ 및 자바에서 맵 리듀스 잡을 작성했음. 2010년대 중반 빅데이터 시대의 정점에 이르자 엔지니어들은 이러한 저수준의 세부 사항을 추상화한 프레임워크를 사용하기 시작했음
      - 코어 데이터 처리 코드
        - 데이터 엔지니어는 수집, 변환, 데이터 서빙과 관계없이 스파크, SQL, 빔 등의 프레임워크와 언어에 매우 능숙하고 생산성이 뛰어나야 함
        - 데이터 엔지니어는 단위(unit), 회귀, 통합, 엔드투엔드, 스모크(smoke) 등의 적절한 코드 테스트 방법론을 이해하는 것이 중요함
      - 오픈소스 프레임워크 개발
        - 데이터 엔지니어는 새로운 내부 도구를 엔지니어링하기 전에 공개적으로 사용할 수 있는 도구의 환경을 조사하는 것이 좋음. 도구 구현에 수반되는 총소유비용(TCO,total cost of ownership)과 기회비용에 주목하자. 해결해야 할 문제를 해결해주는 오픈 소스 프로젝트가 이미 존재할 가능성이 높음
      - 스트리밍
        - 윈도잉을 사용하면 실시간 시스템에서 추적 통계와 같은 중요한 측정 지표를 계산할 수 있음. 엔지니어는 개별 이벤트를 처리하는 다양한 함수 플랫폼(OpenFaaS, AWS 람다, 구글 클라우드 함수 또는 스트림을 분석해 보고 실시간 작업을 지원하는 전용 스트림 프로세서(스파크, 빔, 플링크 또는 펄사) 등 다양한 프레임워크 중에서 선택할 수 있음
      - 코드형 인프라(IaC)
        - 빅데이터 시대의 인프라 관리 부담은 기업들이 데이터브릭스나 아마존 EMR 같은 관리형 빅데이터 시스템과 클라우드 데이터 웨어하우스로 이전함에 따라 감소하고 있음.
        - 데이터 엔지니어가 클라우드 환경에서 인프라를 관리해야할 경우, 인스턴스를 수동으로 스핀업하고 소프트웨어를 설치하는 대신 IaC 프레임워크로 대응하는 사례가 늘고 있음. 여러 범용 클라우드 플랫폼별 프레임워크를 통해 일련의 사양에 따라 인프라를 자동 배포할 수 있음. 이러한 프레임워크는 대부분 인프라뿐만 아니라 클라우드 서비스도 관리할 수 있음. 또한 헬름(Helm) 등의 도구를 써서 컨테이너와 쿠버네티스를 사용하는 IaC의 개념도 있음
        - 이러한 사례뜰은 데브옵스의 중요한 부분으로, 버전 제어와 배포 반복성을 실현함
      - 코드형 파이프라인
        - 데이터 엔지니어는 코드(일반적으로 파이썬)를 사용해 데이터 작업과 데이터 간의 종속성을 선언함
      - 범용 문제 해결
        - 데이터 엔지니어는 파이브트랜(Fivetran), 에어바이트(Airbyte) 또는 마틸리언(Matillion)과 같은 프레임워크를 사용할 때 기존 커넥터가 없는 데이터 원천에 직면하게 되고 사용자 정의 코드를 작성해야 함
        - 그들은 API를 이해하고, 데이터 풀링 및 변환을 수행하고, 예외를 처리하는 등 필요한 소프트웨어 엔지니어링에 능숙해야 함 

## 우수한 데이터 아키텍처 설계
- 클라우드 기능을 활용해 확장성(scalability), 가용성(availability), 신뢰성(reliability)을 제공할 것을 강조함
- 데이터 아키텍처란?
  - 엔터프라이즈 아키텍처 정의(enterprise architecture, EA)
    - 비즈니스, 기술, 애플리케이션 및 데이터를 포함한 많은 하위집합이 있음
    - TOGAF(The Open Group Architecture Framework)의 정의
      - 오픈 그룹의 표준이며 오늘날 가장 널리 사용되는 아키텍처 프레임워크
      - 엔터프라이즈 아키텍처의 맥라겡서 엔터프라이즈라는 용어는 모든 정보 및 기술 서비스, 프로세스, 인프라를 포함하는 전체 기업 또는 기업 내 특정 도메인을 의미할 수 있음. 어느 경우든 아키텍처는 기업 내 여러 시스템과 기능 그룹을 너남듬
    - 가트너의 정의
      - 가트너는 기업 관련 동향에 관한 연구 기사와 보고서를 작성하는 글로벌 리서치 및 자문 기업
      - 엔터프라이즈 아키텍처는 바람직한 비즈니스 비전과 결과를 향한 변화의 실행을 식별하고 분석함으로써 기업이 파괴적인 힘에 능동적이고 전체적으로 대응하도록 주도하는 분야. EA는 비즈니스 리더와 IT 리더에게 관련 사업의 중단을 기회로 삼아 목표한 사업 결과를 달성하기 위해 정책 및 프로젝트를 조정할 수 있는 서명 가능한 권장 사항을 제시함으로써 가치를 제공함
    - EABOK(Enterprise Architecture Book of Knowledge)의 정의
      - 미국의 비영리 조직인 마이터 코퍼레이션(MITRE Corporation)이 작성한 엔터프라이즈 아키텍처 참조 자료를 의미함
      - 엔터프라이즈 아키텍처는 전략, 운용 및 기술을 조정해 성공 로드맵을 만드는 추상적인 표현이자 조직 모델
    - 우리의 정의
      - 엔터프라이즈 아키텍처는 기업의 변화를 지원하는 시스템 설계로, 신중한 트레이드오프 평가를 통해 도달한 유연하고 되돌릴 수 있는 의사결정으로 달성됨
      - 가역적 의사결정
        - 필수 요소 
          - 세상은 끊임없이 변화하며 미래를 예측하기란 불가능함. 이때 가역적 의사결정은 세상의 변화와 새로운 정보 수집에 따라서 프로세스를 조정할 수 있게 해줌
          - 조직이 성장함에 따라 자연스럽게 기업의 경직화(ossification)가 발생하는 경향이 있음. 이때 되돌릴 수 있는 결정 문화를 채택하면 각종 의사결정에 수반되는 위험을 줄임으로써 이러한 경직화 경향을 극복하는 데 도움이 됨
          - 단반향 의사결정(one-way door)은 되돌릴 수 없는 결정
          - 양방향 의사결정(two-way door)은 쉽게 되돌릴 수 있는 결정
      - 변경 관리
        - 되돌릴 수 있는 의삭결정에 중점을 두더라도, 기업은 종종 대규모 이니셔티브를 수행해야 함
        - 아키텍트는 현재 상태의 문제(낮은 데이터 품질, 확장성 제한, 비용 손실)를 식별하고, 바람직한 미래 상태(민첩한 데이터 품질 개선, 확장성 있는 클라우드 데이터 설루션, 비즈니스 프로세스 개선)를 정의하며, 소규모의 구체적인 단계를 실행함으로써 이니셔티브를 실현함. 반복을 감내할 수 있어야 가능한 일
          - 기술적 설루션은 그 자체를 위한 것이 아니라 비즈니스 목표를 지원하기 위해 존재함
      - 트레이드오프 평가
        - 데이터 엔지니어가 최적의 시스템을 설계하려면 모든 단계에서 트레이드오프를 고려해야 하며 동시에 값비싼 기술 부채를 최소화해야 함 
  - 데이터 아키텍처 정의 
    - 데이터 아키텍처는 엔터프라이즈 아키텍처의 하위집합으로 프로세스, 전략, 변경 관리, 트레이드오프 평가 등의 속성을 상속함
    - TOGAF의 정의
      - 기업의 주요 데이터 유형과 원천, 논리적 데이터 자산, 물리적 데이터 자산, 데이터 관리 자원의 구조와 상호 작용에 관한 설명
    - DAMA의 정의
      - (구조와 관계없이) 기업의 데이터 요구 사항을 파악하고, 이러한 요구를 충족시킬 마스터 청사진을 설계 및 유지 관리함. 마스터 청사진을 사용해 데이터 통합을 안내하고, 데이터 자산을 제어하며, 데이터 투자를 비즈니스 전략에 맞게 조정함
    - 우리의 정의
      - 데이터 아키텍처는 기업의 진화하는 데이터 요구 사항을 지원하는 시스템 설계로, 트레이드오프에 대한 신중한 평가를 통해 유연하고 되돌릴 수 있는 결정을 내림으로써 실현됨 
      - 데이터 엔지니어링 아키텍처는 데이터 엔지니어링 수명주기의 핵심 부분을 구성하는 시스템 프레임워크 
      - 운영 아키텍처(opertaional architecture)는 인력, 프로세스 및 기술과 관련한 필요 기능의 요건을 포괄함. 
        - 예를 들어 데이터는 어떤 비즈니스 프로세스를 지원하는가? 
        - 조직은 데이터 품질을 어떻게 관리하는가? 
        - 데이터가 생성되는 시점부터 쿼리 가능한 시점까지의 지연 시간 요구 사항은 무엇인가? 
      - 기술 아키텍처(technical architecture) 
        - 데이터 엔지니어링 수명 주기를 통해 데이터를 수집, 저장, 변환 및 제공하는 방법을 개략적으로 설명함. 
        - 예를 들어 시간당 10 TB 의 데이터를 원천 데이버테이스에서 데이터 레이크로 옮기려면 어떻게 해야 할까?
      - 요컨대, 운영 아키텍처는 무엇을 해야하는지 설명하고, 기술 아키텍처는 어떻게 해야하는지를 자세히 설명함 
  - 우수한 데이터 아키텍처
    - 우수한 데이터 아키텍처는 유연하고 유지 관리하기 쉬움 
    - 유연성을 유지하고 적절한 트레이드오프를 실현하는 동시에, 광범위하게 재사용 가능한 공통 구성 요소를 사용해 비즈니스 요건을 충족함
    - 나쁜 아키텍처는 권위주의적이며, 두루 적용되는 획일적인 결정들을 아물허게나 쑤셔 넣어 비즈니스와 시스템을 엉망진창으로 만듬 
      - 나쁜 아키텍처는 서로 긴밀하게 결합되었거나, 경직되었거나, 지나치게 중앙 집중화된 상태이거나, 업무에 맞지 않는 잘못된 도구를 사용해 개발 및 변경 관리를 방해함. 
    - 이상적으로는 원래 상태로 되돌릴 수 있는 가역성을 염두에 두고 아키텍처를 설계함으로써 변경 비용을 절감할 수 있음 
- 우수한 데이터 아키텍처의 원칙 
  - AWS Well-Architected 프레임워크의 6가지 요소 
    - 운영 우수성
    - 보안
    - 신뢰성
    - 성능 효율성
    - 비용 최적화
    - 지속가능성
  - 구글 클라우드의 클라우드 네이티브 아키텍처를 위한 5대 원칙
    - 자동화를 위한 설계하기
    - 상태를 스마트하게 관리하기
    - 관리형 서비스를 선호하기
    - 심층 방어 연습하기
    - 항상 아키텍처를 설계하기 
  - 9가지의 원칙
    - 공통 컴포넌트를 현명하게 선택하라
      - 데이터 엔지니어의 주요 업무 중 하나는 조직 전체에서 널리 쓸 수 있는 컴포넌트와 관행을 선택하는 것 
      - 공통 컴포넌트는 조직 내에 폭넓게 적용할 수 있는 그 어떤 구성 요소라도 될 수 있음. 여기에는 객체 스토리지, 버전 제어 시스템, 관찰 가능성, 모니터링 및 오케스트레이션 시스템, 처리엔진이 포함됨. 공통 컴포넌트는 적절한 사용 사례를 통해 누구나 접근할 수 있어야 하며, 팀은 처음부터 다시 개발해 시간을 낭비하기보다는 이미 사용 중인 공통 컴포넌트에 의존하는 게 좋음. 
      - 공통 컴포넌트는 강력한 권한과 보안을 지원해 팀 간 자산을 공유하면서도 부정 접근을 방지해야 함 
    - 장애에 대비하라
      - 장애 시나리오를 평가하는 몇 가지 핵심 용어
        - 가용성 : IT 서비스 또는 컴포넌트가 작동 가능한 상태에 있는 시간의 비율 
        - 신뢰성 : 지정된 간격 동안 의도된 기능을 수행할 때 시스템이 정의된 표준을 충족할 확률
        - 복구 시간 목표(RTO, recovery time objective) : 서비스 또는 시스템 장애의 최대 허용 시간. 복구 시간 목표는 일반적으로 운영 중단이 비즈니스에 미치는 영향을 판단해 설정됨
        - 복구 시점 목표(RPO) : 복구 후 허용 가능한 상태. 데이터 시스템에서 운영 중단 시 데이터가 손실되는 경우가 많음. 이 설정에서 복구 시점 목표는 허용 가능한 최대 데이터 손실을 나타냄 
    - 확장성을 위한 아키텍처를 설계하라
      - 확장 가능한 시스템은 상당한 양의 데이터를 처리할 수 있도록 스케일 업 할 수 있음. 대규모 클러스터를 스핀업(spin-up)해서 페타바이트 규모의 고객 데이터에 대한 모델을 학습하거나, 스트리밍 수집 시스템을 스케일 아웃해서 일시적인 부하 급증을  처리할 수 있음
      - 확장 가능한 시스템 규모를 스케일 다운할 수 있음. 로드 스파이크가 줄어들면 용량을 자동으로 제거해 비용을 절감해야 함.
      - 탄력적 시스템(elastic system)은 부하에 따라 동적으로 확장할 수 있으며, 이상적으로는 자동화된 방식으로 확장할 수 있음 
      - 일부 확장 가능한 시스템은 사용하지 않을 때 완전히 종료되는 0으로 확장(sclae to zero)할 수도 있음. 대규모 모델 학습 작업이 완료되면 클러스터를 삭제할 수 있음. 많은 서버리스 시스템(예: 서버리스 함수, 서버리스 온라인 분석 처리 또는 OLAP, 데이터베이스)은 자동으로 0으로 확장할 수 있음 
      - 현재 부하와 대략적인 로드 스파이크를 측정하고 향후 몇 년간의 부하를 예측해 데이터베이스 아키텍처가 적절한지를 판단하자 
    - 아키텍처는 리더십이다
      - 이상적인 데이터 아키텍터의 유사한 특징 
        - 현재 데이터 엔지니어를 지도하고, 조직과 협의해 신중하게 기술을 선택하고, 교육과 리더십을 통해 전문 지식을 전파함. 이들은 엔지니어에게 모범 사례를 교육하고 회사의 엔지니어링 자원을 통합해 기술과 비즈니스 모두에서 공통의 목표를 추구함
    - 항상 아키텍처에 충실하라
      - 기본 아키텍처(현재 상태, baseline architecture)에 대한 깊은 지식을 개발하고, 목표 아키텍처(target architecture)를 개발하며, 아키텍처 변경의 우선순위와 순서를 결정하는 시퀀싱 계획(sequencing plan)을 수립하는 것 
    - 느슨하게 결합된 시스템을 구축하라
      - 구글 데브옵스 기술 아키텍처 가이드
        - 한 팀이 다른 팀에 의존하지 않고도 시스템을 테스트, 배포, 변경할 수 있도록 시스템 아키텍처가 설계되면, 해당 팀은 작업을 수행할 때 의사소통이 거의 필요하지 않음. 즉, 아키텍처와 팀 모두 느슨하게 결합되어 있음 
        - 소프트웨어 아키텍처의 경우 느슨하게 결합된 시스템은 다음과 같은 속성을 갖음 
          - 시스템은 많은 수의 작업 컴포넌트로 나뉨
          - 이러한 시스템은 메시징 버스나 API와 같은 추상화 계층을 통해 다른 서비스와 상호 작용함. 이러한 추상화 계층은 데이터베이스 백엔드 또는 내부 클래스 및 메서드 호출과 같은 서비스의 내부적인 세부 정보를 숨기고 보호함
          - 속성 2의 결과, 시스템 컴포넌트에 대한 내부 변경은 다른 부분에 대한 변경을 요구하지 않음. 코드 갱신의 자세한 내용은 안정적인 API 뒤에 숨겨져 있음. 각 조각은 개별적으로 발전하고 개선될 수 있음
          - 속성 3의 결과, 시스템 전체에 대한 폭포수식 글로벌 배포 주기는 없음. 대신 각 컴포넌트는 변경 및 개선이 이루어짐에 따라 개별적으로 갱신됨 
    - 되돌릴 수 있는 의사결정을 하라 
      - 아키텍처를 단순화하고 민첩성을 유지하려면 돌이킬 수 있는 의사결정을 목표로 삼아야함
      - 데이터 아키텍처 전반에 걸친 기술의 분리/모듈화 등의 변화 속도를 고려할 때, 항상 현재에 적합한 최고의 설루션을 선택하도록 노력해야 함. 또한 환경의 진화에 따라 업그레이드 하거나 더 나은 방법을 채택할 수 있도록 준비하자 
    - 보안 우선순위를 지정하라
      - 아래 모델은 클라우드 네이티브 아키텍처와 밀접하게 연계됨 
      - 강화된 경계 보안 모델과 제로 트러스트 보안 모델(zero-trust security)
        - 직원들은 매우 안전한 기업용 네트워크에서 작업하는 그 순간에도 이메일과 모바일 장치를 통해 외부와 연결된 상태를 유지함. 외부 위협은 사실상 내부 위협이 됨 
      - 공동 책임 모델
        - AWS 사용자는 클라우드 내 보안에 대한 책임이 있음 
          - 사용자의 책임은 사용하는 AWS 서비스에 따라 결정됨. 또한 데이터 민감도, 조직의 요구 사항, 적용 가능한 관련 법률 및 규정 등 기타 요인에 관해서도 책임져야 함 
    - 핀옵스를 수용하라 
      - 핀옵스 재단(FinOps Foundation) 정의 
        - 핀옵스는 진화하는 클라우드 재무 관리 분야이자 문화적 관행으로 엔지니어링, 재무, 기술 및 비즈니스 팀이 데이터 기반 지출 결정을 위해 협업할 수 있도록 지원함으로써 조직이 비즈니스 가치를 극대화할 수 있게 해줌 
      - J.R 스토먼트와 마이크 풀러 클라우드 핀옵스
        - 핀옵스라는 용어는 일반적으로 데브옵스와 재무(팀)간의 협력적인 업무 관계를 지지하는 새로운 전문적인 움직임을 의미함. 이는 인프라 지출을 반복해서 데이터 중심으로 관리하는(즉,클라우드 단위 경제성을 낮추는) 동시에 비용 효율성을 높이고 궁극적으로는 클라우드 환경의 수익성을 높임 
      - 클라우드 시대에는 대부분의 데이터 시스템이 종량제 방식이며 쉽게 확장할 수 있음. 시스템은 쿼리당 비용 모델, 처리당 비용 모델 또는 종량제 모델의 다른 변종 모델에서 실행될 수 있음. 이 접근법은 자본 지출 접근법보다 훨씬 더 효과적일 수 있음 
      - 데이터 리더의 새로운 과제는 예산, 우선순위, 효율성을 관리하는 것 
      - 엔지니어는 핀옵스를 통해 클라우드 시스템의 비용 구조를 생각하는 방법을 배워야 함. 예를 들어 분산 클러스터를 실행할 때 AWS 스팟 인스턴스의 적절한 조합은 무엇일까? 비용 효율성과 성능 측면에서 대규모의 일일 작업을 수행하는 데 가장 적합한 접근 방식은 무엇일까? 회사는 언제 유료 모델에서 예약 용량으로 전환해야 할까?
- 주요 아키텍처 개념
  - 도메인과 서비스
    - 도메인: 지식, 영향력 또는 활동이 영역을 가리킴. 사용자가 프로그램을 적용하는 주체영역은 소프트웨어의 도메인(에릭 에반스))
    - 도메인은 실제 설계를 하는 주제 영역, 서비스는 작업 달성이 목적인 기능 집합
  - 분산 시스템, 확장성, 장애에 대비한 설계
    - 데이터 시스템의 밀접하게 관련된 네 가지 특징
      - 확장성 : 시스템의 용량을 늘려 성능을 개선하고 수요를 처리할 수 있음 
      - 탄력성 : 확장성이 뛰어난 시스템을 동적으로 확장할 수 있음. 탄력성이 뛰어난 시스템은 현재 워크로드에 따라 자동으로 스케일 업과 스케일 다운을 수행할 수 있음 
      - 가용성 : IT 서비스 또는 컴포넌트가 작동 가능한 상태에 있는 시간의 비율
      - 신뢰성 : 시스템이 지정된 간격 동안 의도한 기능을 수행할 때 정의된 표준을 충족할 가능성(확률)
    - 시스템이 지정된 시간 동안 성능 요건을 충족하지 못하면 응답하지 않을 수 있음. 따라서 신뢰성이 낮으면 가용성이 저하될 수 있음. 한편 동적 확장은 엔지니어의 수동 개입 없이도 적절한 성능을 보장하는 데 도움이 되며, 탄력성은 신뢰성을 향상시킴 
    - 수평 확장 시스템
      - 워크로드 인스턴스화, 진행 및 완료를 위한 주요 창구 역할을 하는 리더 노드가 있음 
      - 워크로드가 시작되면 리더 노드는 작업을 시스템 내 워커 노드에 분산해 완료하고 그 결과를 리더 노드로 변환함. 일반적인 최신 분산 아키텍처도 중복성을 갖추고 있음 
      - 머신이 정지했을 경우 다른 머신이 서버가 중단된 부분을 이어받을 수 있도록 데이터가 복제됨. 클러스터는 용량을 복원하기 위해 더 많은 머신을 추가할 수 있음 
  - 강한 결합 vs 느슨한 결합: 모놀리스, 마이크로 서비스 
    - 강한 결합(tight coupling)
      - 데이터 아키텍처를 설계할 때는 다양한 도메인, 서비스 및 자원에 얼마나 많은 상호의존성을 포함할지 선택함. 스펙트럼의 한쪽 끝에서는 극도로 중앙 집중화된 종속성과 워크플로를 선택할 수도 있음.
      - 도메인과 서비스의 모든 부분은 다른 모든 도메인과 서비스에 필수적으로 의존함. 이처럼 긴밀하게 결합된 패턴 
    - 느슨한 결합(loose coupling)
      - 스펙트럼의 반대편에는 서로 온전히 의존하지 않는 분산형 도메인과 서비스가 있으며 이를 뜻함
      - 느슨한 결합 시나리오에서는 분산된 팀에서 그들의 동료가 데이터를 사용할 수 없는 시스템을 구축하기 쉬움. 반드시 각각의 도메인과 서비스를 소유하는 팀에게 공통의 표준, 소유권, 책임, 의무를 부여하자
      - 우수한 데이터 아키텍처를 설계하려면 도메인과 서비스의 강한 결합과 느슨한 결합 사이의 트레이드오프에 의존해야 함 
    - 아키텍처 계층 
      - 단일 계층(single-tier) 아키텍처
        - 데이터베이스와 애플리케이션이 밀접하게 연결되어 단일 서버에 상주함. 
        - 강한 결합의 본질은 서버, 데이터베이스 또는 애플리케이션에 장애가 발생하면 전체 아키텍처에 장애가 발생한다는 의미. 
        - 단일 계층 아키텍처는 프로토타이핑 및 개발에는 좋지만, 명백한 장애 위험 때문에 운영 환경에서는 권장되지 않음 
        - 단일 계층 아키텍처는 로컬 머신에서 시스템을 테스트하는 데는 적합하지만, 운영 환경에서는 사용하지 않는 것이 좋음 
      - 다중 계층
        - 강하게 결합된 단일 계층 아키텍처의 문제점은 데이터와 애플리케이션을 분리함으로써 해결할 수 있음 
        - (n-tier라고도 하는) 다중 계층 아키텍처(multi-tier architecture)는 데이터, 애플리케이션, 비즈니스 로직, 프레젠테이션 등의 개별 계층으로 구성됨. 
          - 이러한 계층들은 상향식(bottom-up)이고 계층적(hierarchical)인 구조로, 하위 계층이 반드시 상위 계층에 의존하지 않음. 
          - 반면 상위 계층은 하위 계층에 의존함. 이 개념은 애플리케이션에서 데이터를 분리하고 프레젠테이션에서 애플리케이션을 분리하는 것 
        - 3계층 아키텍처(three-tier architecture)
          - 데이터, 애플리케이션 로직 및 프레젠테이션 계층으로 구성됨
          - 각 계층은 다른 계층과 서로 격리되어 리스크를 분리할 수 있음. 이러한 3계층 아키텍처에서는 모놀리식에 집중할 필요 없이 각 계층에서 원하는 모든 기술을 자유롭게 사용할 수 있음 
          - 다중 계층 아키텍처에서는 분산 시스템으로 작업할 때 계층을 분리하고 계층 내에서 자원을 공유하는 방식을 고려해야 함 
          - 노드와 자원 경합을 원하는지를 생각해보자. 그렇지 않다면 비공유 아키텍처(shared-nothing architecture)를 사용하자. 즉, 단일 노드가 각 요청을 처리하며, 이는 다른 노드들이 해당 노드 또는 서로 간에 메모리, 디스크, CPU 등의 자원을 공유하지 않음을 의미함. 데이터와 자원은 노드로 격리됨. 그 대신 다양한 노드가 여러 요청을 처리하고 자원을 공유할 수 있지만, 자원 경합이 발생할 위험이 있음 
          - 공유 디스크 아키텍처(shared disk architecture)
            - 노드들이 모든 노드에서 접근할 수 있는 동일한 디스크와 메모리를 공유해야 하는지 여부 
            - 보통 임의의 노드에 장애가 발생할 경우 공유 자원이 필요할 때 사용됨 
      - 모놀리스
        - 모놀리스의 일반적인 개념은 가능한 한 많은 것을 한 지붕 아래에 포함하는 것 
        - 기술 결합(technical coupling)은 아키텍처 계층이, 도메인 결합(domain coupling)은 도메인이 서로 결합하는 방식을 말함 
      - 마이크로 서비스 
        - 복잡하게 뒤얽힌 서비스, 중앙 집중화, 서비스 간의 강한 결합과 같은 모놀리스 속성과 비교하면 마이크로서비스는 정반대. 마이크로서비스 아키텍처(microservice architecture)는 개별적이고 분산되어 있으며 느슨한게 결합된 서비스로 구성됨 
        - 각 서비스는 특정 기능이 있으며 도메인 내에서 운영되는 다른 서비스와 분리됨. 한 서비스가 일시적으로 중단되더라도 계속 작동 중인 다른 서비스의 기능에는 영향을 주지 않음 
        - 여러분의 모놀리스를 분리할 수 없을 때는 마이크로서비스친화적인 방식으로 서비스를 분리하는 새로운 병렬 아키텍처를 구축해야 함. 이때 전체적인 리팩터링보다는 서비스 분리를 제안함 
    - 데이터 아키텍처에 관한 고려 사항
      - 중앙 집중화. 즉, 단일팀이 모든 도메인에서 데이터를 수집하고 조직 전체에서 사용할 수 있도록 조정함. 이는 기존에 데이터 웨어하우징의 일반적인 접근 방식
      - 데이터 메시. 데이터 메시를 사용하면 각 소프트웨어 팀은 나머지 조직 전체에서 사용할 데이터를 준비할 책임이 있음 
- 사용자 접근: 싱글 vs 멀티테넌트
  - 멀티테넌시에서는 성능과 보안이라는 두 가지 요소를 고려해야 함. 클라우드 시스템 내에 대규모 테넌트가 여러 개 있을 때 시스템이 모든 테넌트에 대해 일관된 성능을 지원하는가? 아니면 시끄러운 이웃 문제가 발생하는가?(즉, 한 테넌트의 사용량이 많으면 다른 테넌트의 성능이 저하되는가?) 보안과 관련해서는 서로 다른 테넌트의 데이터를 적절히 분리해야 함 
- 이벤트 기반 아키텍처
  - 비즈니스에서는 새로운 고객 확보, 고객의 신규 주문, 제품 또는 서비스 주문과 같은 다양한 상황이 발생함. 이 모든 상황은 일반적으로 어떤 상태(state)의 변화와 같이 광범위하게 정의되는 이벤트들의 사례
  - 이벤트는 생산자, 이벤트 라우터, 소비자 간에 강하게 결합된 종속성 없이 생성되고, 이를 소비하는 대상으로 라우팅되어야 함 
  - 이벤트 기반 아키텍처 
    - 이벤트 기반 워크플로우에서는 이벤트가 생성,라우팅, 소비됨(생산자 - (이벤트) -> 이벤트 라우터 - (이벤트) -> 소비자)
    - 이벤트 기반 아키텍처는 이벤트 중심 워크플로를 수용하고 이를 사용해 다양한 서비스 간에 통신함. 이벤트 기반 아키텍처의 장점은 이벤트 상태를 여러 서비스에 분산시킨다는 점. 이는 서비스가 오프라인 상태가 되거나, 분산 시스템에서 노드에 장애가 발생하거나, 여러 소비자 또는 서비스가 동일한 이벤트에 접근하도록 할 때 유용함 
- 브라운필드 vs 그린필드 프로젝트
  - 데이터 아키텍처 프로젝트를 설계하기 전에 백지상태를 처음부터 시작하는지, 아니면 기존 아키텍처를 재설계하는지 알아야함 
  - 브라운필드 프로젝트(brownfield project)
    - 기존 아키텍처를 리팩터링하고 재구성하는 경우가 많아 현재와 과거의 선택에 따른 제약을 받음. 아키텍처의 핵심 부분은 변경 관리인 만큼, 이러한 한계를 극복하고 새로운 비즈니스 및 기술 목표를 달성할 경로를 설계해야 함 
    - 브라운필드 프로젝트에서는 레거시 아키텍처에 대한 철저한 이해와 다양한 신/구 기술의 상호작용이 필요함 
    - 스트랭글러 패턴(strangler pattern)
      - 새로운 시스템은 레거시 아키텍처의 컴포넌트를 천천히 그리고 점진적으로 대체함 
      - 스트랭글러 패턴의 매력 포인트는 시스템의 한 부분을 한 번에 하나씩 폐기하는 표적 방식과 외과적 접근 방식. 이를 통해 종속 시스템이 미치는 영향을 평가하면서 유연하고 되돌릴 수 있는 결정을 내릴 수 있음 
  - 그린필드 프로젝트(greenfield project)
    - 스펙트럼의 반대쪽 끝이 있는 그린필드 프로젝트를 사용하면 이전 아키텍처의 역사나 레거시에 얽매이지 않고 새롭게 출발할 수 있음 
    - 브라운필드 프로젝트는 그린필드 프로젝트든 항상 우수한 데이터 아키텍처의 원칙에 초점을 맞추자. 트레이드오프를 평가하고, 유연하고 되돌릴 수 있는 결정을 내리고, 긍정적인 ROI를 실현하도록 노력하자 
- 데이터 아키텍처의 사례 및 유형
  - 데이터 웨어하우스
    - 보고 및 분석에 사용되는 중앙 데이터 허브로, 가장 오래되고 잘 확립된 데이터 아키텍처의 하나. 데이터 웨어하우스의 데이터는 일반적으로 분석 활용 사례에 맞게 고도로 포맷되고 구조화되어 있음 
    - 1989년 빌 인먼은 데이터 웨어하우스의 개념을 고안했음. 그는 경영진의 의사결정을 지원하는 주제 지향적이고 통합적이며 비휘발성이고 시간 변형적인 데이터 모임이라 설명함 
      - 조직 데이터 웨어하우스 아키텍처(organizational data warehouse architecture)는 특정 비즈니스 팀의 구조 및 프로세스와 관련된 데이터를 구성함 
        - 운영 데이터베이스(온라인 트랜잭션 처리(OLTP))에서 온라인 분석 처리(OLAP)를 분리 : 이러한 분리는 비즈니스가 성장함에 따라 매우 중요함. 데이터를 별도의 물리적 시스템으로 옮기면 운영 시스템의 부하가 줄어들고 분석 성능이 향상됨 
        - 데이터 중앙 집중화 및 구성 : 전통적으로 데이터 웨어하우스는 ETL을 사용해 애플리케이션 시스템에서 데이터를 가져옴 
      - 기술 데이터 웨어하우스 아키텍처(technical data warehouse architecture)는 MPP와 같은 데이터 웨어하우스의 기술적 본질을 반영함 
      - MPP
        - 기본적으로 관계형 애플리케이션 데이터베이스에서 쓰이는 것과 동일한 SQL 시맨틱을 지원함. 하지만 대량의 데이터를 병렬 스캔하도록 최적화되어 있어 고성능 집계 및 통계 계산을 수행할 수 있음 
        - 최근 들어 MPP 시스템은 특히 클라우드 데이터 웨어하우스에서 더 큰 데이터와 쿼리를 지원할 수 있도록 행 기반 아키텍처에서 열 기반 아키텍처로 점점 더 많이 전환되고 있음. 
        - MPP는 데이터 및 보고 업무의 니즈가 증가함에 따라 대기업의 고성능 쿼리를 실행하는 데 필수 요소 
      - ELT
        - ELT 데이터 웨어하우스 아키텍처에서는 데이터를 운영 시스템에서 데이터 웨어하우스 스테이징 영역으로 어느 정도 직접 이동할 수 있음. 이 설정에서의 스테이징은 데이터가 원시 형식(raw form)임을 나타냄
        - 변환은 외부 시스템을 사용하는 대신 데이터 웨어하우스에서 직접 처리됨. 이는 클라우드 데이터 웨어하우스와 데이터 처리 도구의 방대한 계산 능력을 활용하려는 것. 
        - 데이터는 일괄 처리되며, 변환된 출력은 분석을 위해 테이블 및 뷰에 기록됨 
        - ELT는 CDC 프로세스에서 이벤트를 스트리밍해 스테이징 영역에 저장한 후 데이터 웨어하우스 내에서 변환하므로 스트리밍 배치에서도 인기가 있음 
    - 클라우드 데이터 웨어하우스 
      - 기업은 향후 몇 년간 MPP 시스템의 크기를 적절히 조정하고 시스템을 조달하기 위해 수백만 달러 규모의 계약을 체결하는 대신, 레드시프트 클러스터를 온디맨드로 스핀업해 데이터 및 분석 수요의 증가에 따라 단계적으로 확장할 수 있는 옵션을 선택할 수 있게 됐음. 필요에 따라 새로운 레드시프트 클러스터를 스핀업해 특정 워크로드를 처리하고, 더는 필요하지 않은 클러스터를 신속하게 삭제할 수도 있음 
      - 구글 빅쿼리, 스노우플레이크 및 기타 경쟁업체는 컴퓨팅과 스토리지를 분리하는 아이디어를 대중화했음. 이 아키텍처에서는 데이터가 객체 스토리지에 저장되므로 사실상 무제한 스토리지를 사용할 수 있음. 이를 통해 사용자는 컴퓨팅 파워를 온디맨드 방식으로 스핀업할 수 있으며 수천 개의 노드에 대한 장기적인 비용 없이 애드혹 빅데이터 기능을 제공함 
      - 클라우드 데이터 웨어하우스는 단일 쿼리로 페타바이트 단위의 데이터를 쉽게 처리할 수 있음. 일반적으로 행당 수십 MB의 원시 텍스트 데이터 또는 매우 풍부하고 복잡한 JSON 문서를 저장할 수 있는 데이터 구조를 지원함 
      - 클라우드 데이터 웨어하우스(및 데이터 레이크)가 성숙해짐에 따라 데이터 웨어하우스와 데이터 레이크 간의 경계는 계속 모호해질 것 
    - 데이터 마트
      - 단일 하위 조직이나 부서 또는 비즈니스 라인(LOB, line of Business)에 초점을 맞춰 분석 및 보고서를 제공하도록 설계된 웨어하우스의 한층 더 정교한 하위집합. 
      - 각 부서에는 필요에 따라 고유한 데이터 마트가 있음. 이는 더 광범위한 조직 또는 비즈니스에 서비스를 제공하는 전체 데이터 웨어하우스와는 대조적 
      - 데이터 마트가 필요한 이유 
        - 데이터 마트는 분석가와 보고서 개발자가 데이터에 더 쉽게 접근할 수 있도록 함 
        - 데이터 마트는 초기 ETL 또는 ELT 파이프라인이 제공하는 것보다 더 많은 변환 단계를 제공함. 따라서 보고서 또는 분석 쿼리에 복잡한 데이터 조인 및 집계가 필요한 경우, 특히 원시 데이터가 큰 경우 성능이 크게 향상 될 수 있음.
        - 변환 프로세스는 라이브 쿼리(live query)의 성능을 개선하기 위해 조인 및 집계된 데이터로 데이터 마트를 채울 수 있음 
  - 데이터 레이크
    - 데이터 레이크 1.0은 HDFS에서 시작 됐음. 클라우드의 인기가 높아지면서 이러한 데이터 레이크는 매우 저렴한 스토리지 비용과 사실상 무제한 스토리지 용량을 갖춘 클라우드 기반 객체 스토리지로 옮겨갔음. 
    - 데이터 레이크는 스토리지와 컴퓨팅이 긴밀하게 연결된 단일 데이터 웨어하우스에 의존하는 대신, 모든 크기와 유형의 방대한 데이터를 저장할 수 있음. 이러한 데이터를 쿼리하거나 변환해야 할 때는 클러스터를 온디맨드로 스핀업해 거의 무제한에 가까운 컴퓨팅 성능을 이용할 수 있음
    - 맵리듀스, 스파크, 레이, 프레스토, 하이브 등 원하는 데이터 처리 기술을 선택해 작업을 할 수 있음 
    - 단점 
      - 데이터 레이크는 쓰레기 매립장이 되어버렸음. 한때 유망했던 데이터 프로젝트가 실패하면서 데이터 늪(data swamp), 다크 데이터(dark data), WORN 같은 용어가 생겨났음.
      - 데이터는 스키마 관리, 데이터 카탈로그 작성 및 검색 도구가 거의 없는 상태에서 관리 불가능한 크기로 증가했음. 또한 원래의 데이터 레이크 개념은 본질적으로 쓰기 전용이었기 때문에, 사용자가 레코드를 지정 삭제해야 하는 GDPR과 같은 규제가 도입되면서 큰 골칫거리가 됨 
      - 데이터 처리도 어려웠음. 조인과 같은 비교적 평범한 데이터 변환은 맵리듀스 작업으로 코딩할 때 큰 골칫거리. 이후에 피그 및 하이브와 같은 프레임워크는 데이터 처리 상황을 다소 개선했지만, 데이터 관리의 기본적인 문제를 해결하는 데는 거의 도움되지 못했음 
      - SQL에서 흔히 볼 수 있는 (행 삭제 또는 갱신 등) 간단한 데이터 조작 언어(DML) 작업은 구현하기 어려웠으며, 일반적으로 완전히 새로운 테이블을 생성함으로써 해결할 수 있었음 
    - 기업들은 원신 원시 아파치 코드베이스를 이해하고 커스터마이징 하는 데 드는 어려움과 수고로움을 피하면서 하둡을 더 쉽게 사용하도록 벤더로부터 라이센스를 받아 맞춤형 버전의 하둡을 구입하기로 결정했음. 클라우드 스토리지를 사용해 하둡 클러스터를 관리하지 않ㄴ는 기업도 맵리듀스 작업을 작성하려면 인력에 많은 비용을 지출해야 했음 
    - 많은 조직에서 데이터 레이크는 낭비와 실망, 치솟는 비용으로 얼룩진 내부의 슈퍼펀드 사이트(superfund site, 유독성 폐기물이 버려져 미국 환경보호청에서 정화하도록 지시한 현장을 의미)로 변모 했음 
  - 융합, 차세대 데이터 레이크, 데이터 플랫폼
    - 데이터 레이크하우스 
      - 데이터 웨어하우스에서 볼 수 있는 제어, 데이터 관리, 데이터 구조를 통합하는 동시에, 객체 스토리지에 데이터를 저장하고 다양한 쿼리 및 변경 엔진을 지원함. 특히 데이터 레이크하우스는 단순히 데이터를 쏟아붓기만 하고 갱신하거나 삭제하지는 않는 본래의 데이터 레이크에서 크게 벗어난 ACID(원자성, 일관성, 독립성, 내구성) 트랜잭션을 지원함. 
      - 데이터 레이크하우스라는 용어는 데이터 레이크와 데이터 웨어하우스의 융합을 암시함 
    - 클라우드 데이터 웨어하우스 
      - 컴퓨팅과 시토리지를 분리하고, 페타바이트 규모의 쿼리를 지원하며, 다양한 비정형 데이터 및 반정형 객체를 저장하고, 스파크 또는 빔과 같은 고급 처리 기술과 통합됨 
    - 데이터 플랫폼 
      - 현재 여러 벤더가 데이터 레이크와 데이터 웨어하우스 기능을 결합한 데이터 플랫폼을 제공함. 
      - AWS, 애저, 구글 클라우드, 스노우 플레이크, 데이터브릭스는 각각 데이터 작업을 위해 강하게 통합된 다양한 도구들을 제공하며, 관계형부터 완전한 비정형 상태에 이르기까지 다양한 기능을 제공함 
      - 미래의 데이터 엔지니어는 데이터 레이크 아키텍처와 데이터 웨어하우스 아키텍처 중 하나를 선택하는 대신에 벤더, 생태계, 상대적 개방성 등 다양한 요소를 기반으로 통합 데이터 플랫폼을 선택할 수 있게 될 것 
  - 모던 데이터 스택(modern data stack)
    - 과거의 데이터는 스택이 비싸고 획일적인 모놀리식 도구집합에 의존했다면, 모던 데이터 스택의 주요 목표는 클라우드 기반의 플러그 인 플레이(PnP,plug-and-play) 방식과 사용하기 쉬운 기성 구성 요소를 써서 모듈식이면서도 비용 효율적인 데이터 아키텍처를 구축하는 것. 
    - 구성 요소에는 데이터 파이프라인, 스토리지, 변환, 데이터 관리/거버넌스, 모니터링, 시각화 및 탐색이 포함됨. 도메인은 여전히 유동적이며 특정 도구들을 빠르게 변화하고 발전하고 있지만, 핵심 목표는 복잡성을 줄이고 모듈화를 늘리는 것 
    - 주요 성과는 셀프 서비스(분석 및 파이프라인), 신속한 변화를 위한 데이터 관리, 명확한 가격 구조를 갖춘 오픈 소스 도구 또는 단순한 독점 도구 사용. 커뮤니티는 모던 데이터 스택의 핵심 요소이기도 함
  - 람다 아키텍처
    - 2010년대 초중반 무렵에 스트리밍/실시간 분석용 스톰 및 삼자와 같은 프레임워크와 확장성이 뛰어난 메시지 큐인 카프카가 등장하면서, 스트리밍 데이터 관련 작업의 인기가 폭발적으로 높아졌음. 이러한 기술을 통해 기업은 대량의 데이터에 대한 사용자 집계 및 순위 지정, 제품 권장 사항에 대한 새로운 유형의 분석 및 모델링 작업을 수행할 수 있었음 
    - 람다 아키텍처에서는 배치, 스트리밍 및 서빙 등의 시스템이 서로 독립적으로 작동함. 원천 시스템은 이상적으로 변경할 수 없고 추가만 가능하며, 데이터를 처리할 때는 스트림과 배치라는 두 목적지로 전송함. 
    - 인스트림(in-stream) 처리는 일반적으로 NoSQL 데이터베이스인 속도 계층에서 가능한 한 가장 낮은 지연 시간으로 데이터를 전달하고자 함. 
    - 배치 계층에서는 데이터가 데이터 웨어하우스와 같은 시스템에서 처리 및 변환되어 데이터의 사전 계산 및 집계 뷰를 생성함.
    - 서빙 계층은 두 계층에서 쿼리 결과를 집계해 결합된 뷰를 제공함 
  - 카파 아키텍처
    - 람다 아키텍처의 단점에 대한 대응책으로 제이 크랩스는 카파 아키텍처(Kappa architecture)라는 대안을 제안했음 
    - 스트림 처리 플랫폼을 데이터 처리, 저장 및 서빙 등 모든 데이터 처리의 백본으로 사용하는 것은 어떨까? 이를 통해 진정한 이벤트 기반 아키텍처를 실현할 수 있음. 실시간 이벤트 스트림을 직접 읽고 대량 데이터 청크를 재생해 일괄 처리함으로써 동일한 데이터에 실시간 및 배치 처리를 매끄럽게 적용할 수 있음 
    - 널리 채택되지 못한 이유
      - 스트리밍 자체는 많은 기업에 여전히 미지의 영역. 스트리밍을 말하기는 쉽지만 실행하기는 예상보다 어려움 
      - 카파 아키텍처는 복잡하고 실제로 비용이 많이 드는 것으로 나타남. 일부 스트리밍 시스템은 대규모 데이터 볼륨으로 확장할 수 있지만, 복잡하고 비용이 많이 듬. 한편 배치 스토리지와 프로세싱은 방대한 데이터셋에 비해 훨씬 효과적이고 비용 효율적임 
  - 데이터 흐름 모델, 통합 배치, 스트리밍
    - 배치 및 스트림 처리 관리의 주요 문제 중 하나는 여러 코드 경로를 통합하는 것. 카파 아키텍처는 통합 큐잉 및 스토리지 계층에 의존하지만, 실시간 통계를 수집하거나 배치 집계 작업을 실행하려면 다른 도구를 사용해야 함 
    - 구글은 데이터 흐름(data flow) 모델과 이 모델을 구현하는 아파치빔 프레임워크를 개발함으로써 두각을 나타냄 
    - 데이터 흐름 
      - 핵심 개념은 다양한 유형의 윈도에서 집계가 수행되므로 모든 데이터를 이벤트로 간주하는 것. 지속적인 실시간 이벤트 스트림은 무한 데이터(unbounded data) 
      - 데이터 배치는 단순히 경계가 있는(유한,bounded)이벤트 스트림이며, 경계는 자연스러운 윈도를 제공함.  
      - 엔지니어는 실시간 집계를 위한 슬라이드나 텀블링 등 다양한 윈도 중에서 선택할 수 있음. 실시간 처리와 배치 처리는 거의 같은 코드를 사용해 같은 시스템에서 이뤄짐 
  - IoT용 아키텍처
    - 사물인터넷은 컴퓨터, 센서, 모바일 장치, 스마트홈 장치 등 인터넷 접속이 가능한 장치들의 분산 컬렉션임 
    - IoT 장치는 저전력이며 저자원/저대역폭 환경에서 작동하는 경우가 많음 
    - 장치(device)
      - 인터넷에 연결된 물리 하드웨어로, 주변 환경을 감지하고 데이터를 수집해 다운스트림 목적지로 전송함(일명 사물(thing)이라고도 함). 이러한 장치는 초인종 카메라, 스마트워치 또는 온도 조절기와 같은 소비자 애플리케이션에 쓰일 수 있음 
      - 장치는 최소한의 데이터 수집 및 전송 능력을 갖춰야 함. 단 데이터를 다운스트림으로 전송하기 전에 크런치(crunch)하거나 수집한 데이터에 대해 ML을 실행할 수도 있음(각각 에지 컴퓨티오가 에지 머신러닝)
      - 데이터 엔지니어는 IoT 장치의 내부를 자세히 알 필요는 없지만 장치의 기능, 수집하는 데이터, 데이터를 전송하기 전에 실행하는 에지 컴퓨팅 또는 ML, 데이터 전송 빈도를 알아야 함. 그 과정에서 장치 또는 인터넷의 장애, 환경적 요인 또는 기타 외부 요인이 데이터 수집에 미치는 영향이 무엇인지, 그리고 이러한 요인이 장치로부터 다운스트림 데이터 수집에 어떤 영향을 미치는지 파악할 수 있음 
    - 장치와 인터페이스
      - IoT 게이트웨이
        - 장치를 연결하고 인터넷상의 적절한 수신처에 안전하게 라우팅하는 허브. 
        - IoT 게이트웨이 없이 장치를 인터넷에 직접 연결할 수도 있지만, 게이트웨이는 매우 적은 전력으로 장치를 연결할 수 있음. 데이터 보존의 중간 기착지 역할을 하며, 최종 데이터 수신처로의 인터넷 접속을 관리함 
      - 수집
        - IoT 게이트 웨이에서 시작됨. 이벤트와 측정은 거기서부터 이벤트 수집 아키텍처로 유입될 수 있음 
      - 서빙
        - 다운스트림 사용 사례를 위한 IoT 서빙 패턴
          - 장치 -> IoT 게이트웨이 -> 스트림 처리 -> 스토리지 -> [머신러닝, 보고]
  - 데이터 메시 
    - 데이터 메시는 중앙 집중식 데이터 레이크 및 데이터 웨어하우스 같은 거대한 모놀리식 데이터 플랫폼과, 운영 데이터와 분석 데이터 사이에서 환경이 구분되는 데이터 격차에 대한 최근의 대응책 
    - 데이터 메시는(소프트웨어 아키텍처에서 주로 사용되는 개념인) 도메인 기반 설계 개념을 채택해 데이터 아키텍처에 적용함으로써 중앙 집중식 데이터 아키텍처의 문제를 뒤집으려 함 
    - 데이터 메시의 큰 부분은 분산, 즉 탈중앙화(decentralization)
      - 모놀리식 데이터 플랫폼을 탈중앙화(분산)하려면 데이터, 데이터의 지역성 및 소유권(ownership)에 대한 사고방식을 바꿔야 함. 도메인에서 중앙 소유의 데이터 레이크 또는 플랫폼으로 데이터를 보내는 대신, 쉽게 소모할 수 있는 방식으로 도메인 데이터셋을 호스팅하고 제공해야 함 
    - 데이터 메시의 핵심 구성 요소
      - 도메인 지향 분산형 데이터 소유권 및 아키텍처
      - 제품으로서의 데이터
      - 플랫폼으로서의 셀프서비스 데이터 인프라
      - 통합 컴퓨팅 거버넌스
  - 기타 데이터 아키텍처 예시
    - 데이터 아키텍처에는 데이터 패브릭, 데이터 허브, 확장 아키텍처, ㅁ메타데이터 우선 아키텍처, 이벤트 기반 아키텍처, 라이브 데이터 스택 등 수많은 종류가 있음 

## 데이터 엔지니어링 수명 주기 전체에 걸친 기술 선택 
- 데이터 엔지니어링의 핵심 목적 : 수명 주기 전체에 걸쳐 데이터를 운반하고, 최종 사용자의 요구에 따라 이를 제공하고 견고하고 신뢰성 높은 시스템 설계
- 아키텍처는 전략적이고 도구는 전술적이다
  - 아키텍처는 비즈니스의 전략적 목표를 충족하는 데이터 시스템의 고수준 설계, 로드맵 및 청사진
    - 아키텍처는 무엇을, 왜, 언제 구축해야 하는지를 결정함. 
    - 그리고 아키텍처를 실현하는 데 쓰이는 도구는 어떻게 구축할지를 결정함 
- 우리는 종종 팀들이 아키텍처를 설계하기 전에 궤도에서 벗어나 기술을 무작정 선택하는 것ㅇ르 볼 수 있음. 그 원인은 샤이니 오브젝트 신드롬(shiny object syndrome)이나 이력서 주도(resume-driven) 개발, 아키텍처에 대한 전문 지식 부족 등 다양함 
- 팀의 규모와 능력
  - 카고-컬트 엔지니어링(cargo-cult engineering) : 종종 소규모 데이터 팀이 대기업의 새로운 최첨단 기술에 관한 블로그 포스팅을 읽고, 그 포스팅의 내용과 같은 매우 복잡한 기술과 사례를 모방하려 시도하는 경우가 있음. 
    - 일반적으로 귀중한 시간과 비용을 많이 소비하지만 그 대가로 얻을 만한 것은 거의 없는 큰 실수라 할 수 있음. 특히 소규모 팀이나 기술력이 약한 팀이라면, 가능한 한 많은 관리형 도구와 SaaS 도구를 사용해서 비즈니스에 직접적으로 가치를 부여하는 복잡한 문제를 해결하는 데 자신들의 제한된 역량을 집중하는 것이 좋음 
  - 팀 기술 목록을 작성해보자. 팀 구성원들은 로우 코드 도구를 선호하는가, 아니면 코드 우선 접근 방식을 선호하는가? 자바, 파이썬, 고 같은 특정 언어에 능숙한 사람이 있는가? 물론 로우 코드부터 코드 중심 영역에 이르기까지 모든 선호도를 충족하는 기술을 사용할 수도 있음. 다시 한번 강조하지만 팀에 이미 익숙한 기술과 워크플로를 계속 사용할 것을 권장함 
- 시장 출시 속도
  - 고품질의 표준과 보안을 유지하면서도 기능과 데이터를 더 신속하게 제공할 수 있는 적절한 기술을 선택해야 함. 이는 또한 출시, 학습, 반복 및 개선의 긴밀한 피드백 루프에서 작업하는 것을 의미함 
- 상호 운용성(interoperability)
  - 다양한 기술 또는 시스템이 어떻게 연결되고, 정보를 교환하며, 상호 작용하는지를 나타냄 
  - 거의 모든 데이터베이스는 자바 데이터베이스 연결(JDBC) 또는 오픈 데이터베이스 연결(ODBC)을 통한 연결을 허용함. 즉, 이러한 표준을 사용하면 데이터베이스에 쉽게 연결할 수 있음.
  - 다른 경우에는 표준이 없을 때 상호 운용성이 발생함. 보통 표현(적인) 상태 전송으로 직역되는 REST(representational state transfer)는 API의 진정한 표준은 아니며, 모든 REST API에는 고유한 특징이 있음. 이때 다른 기술 및 시스템과의 원활한 통합을 보장하는 것은 벤더 또는 오픈 소스 소프트웨어(OSS) 프로젝트에 달려 있음 
- 비용 최적화 및 비즈니스 가치
  - 총소유비용(TCO, total cost of ownership)
    - 활용되는 제품 및 서비스의 직접비용과 간접비용을 포함한 이니셔티브의 전체 추정비용임. 
    - 직접비용(direct cost)은 이니셔티브에 직접 귀속될 수 있음 
    - 간접비용(indirect cost)은 이니셔티브와 무관하며, 어디에 귀속되는지와 관계없이 지불해야 함
    - 구매 방법은 비용을 계산하는 방식에 영향을 미침
    - 설비투자비용(CAPEX, captial expense)에는 성행 투자가 필요함 
      - 클라우드가 존재하기 전에 기업들은 일반적으로 대규모 인수 계약을 통해 하드웨어와 소프트웨어를 선불로 구매했음. 또한 서버실과 데이터 센터, 코로케이션 시설에 하드웨어를 호스팅하려면 상당한 투자가 필요함
      - 이러한 초기 투자는 자산으로 간주되며, 시간이 지남에 따라 서서히 감가상각이 이뤄짐. 예산 측면에서 전체 구매비용을 조달하려면 자본이 필요했음. 이는 투입된 노력과 비용에 관해 긍정적인 ROI를 달성하기 위한, 장기 계획에 따른 상당한 자본 지출인 설비투자임 
    - 운영비용(OPEX, operational expense)
      - 특정 측면에서 이러한 CAPEX과 반대. OPEX는 점진적이며 시간이 지남에 따라 분산됨. CAPEX은 장기적 관점에서 이루어지지만 OPEX은 단기적. OPEX은 종량제와 또는 이와 유사한 방식으로 구성될 수 있으며 많은 유연성을 제공함 
  - 총소유 기회비용(TOCO, total opportunity cost of ownership)
    - 기술, 아키텍처 또는 프로세스를 선택할 때 발생하는 기회상실비용. 이러한 설정에서의 소유는 하드웨어나 라이선스를 장기적으로 구매할 필요가 없음 
  - 핀옵스
    - 일반적인 클라우드 지출을 본질적으로 운영비용임. 즉 기업은 중요한 데이터 프로세스를 실행하는 서비스를 선불로 구입한 뒤 시간이 지남에 따라 가치를 회수하는 것이 아니라, 해당 서비스에 대한 비용을 지불함 
    - 핀옵스의 목표는 시스템을 모니터링하고 동적으로 조정하는 데브옵스와 같은 방식을 적용해 재무적 책임과 비즈니스 가치를 완전히 운용하는 것 
- 현재 vs 미래: 불변의 기술과 일시적 기술 비교
  - 불변의 기술
    - 클라우드 기반이 되는 컴포넌트일 수도 있고 오랜 세월을 견딘 언어와 패러다임일 수 있음. 
    - 클라우드에서 변하지 않을 기술의 사례로는 객체 스토리지, 네트워킹, 서버, 보안 등이 있음 
    - 불변의 기술은 린디 효과(Lindy effect)의 혜택을 받는데, 이는 기술이 확립된 기간이 오래될수록 해당 기술은 더 오래 사용되는 현상을 의미함 
  - 일시적 기술(transitory technology)
    - 등장했다가 곧 사라지는 기술 
    - 예를 들어 2010년대 초에는 분석가와 엔지니어가 복잡한 맵리듀스 잡을 수동으로 코딩하지 않고도 대규모 데이터셋을 쿼리할 수 있게 해주는 하이브가 빠르게 도입됐음. 하이브의 성공에 영감을 얻었지만, 단점을 개선하기 위해 엔지니어들은 프레스토와 다른 기술들을 개발함. 하이브는 이제 주로 레거시 배포 환경에 쓰임. 거의 모든 기술이 이처럼 필연적인 쇠퇴의 길을 걷게 됨
- 장소: 온프레미스, 클라우드, 하이브리드 클라우드, 멀티클라우드
  - 온프레미스
    - 기존 기업들은 여전히 온프레미스 시스템 기반. 이들 기업은 기본적으로 하드웨어를 소유하는데, 하드웨어는 그들이 자체 소유한 데이터 센터 또는 임대 코로케이션 공간에 있음. 어떤 경우든 기업은 하드웨어와 하드웨어에서 실행되는 소프트웨어에 대한 운영상의 책임을 짐. 
    - 하드웨어에 장애가 발생하면 수리하거나 교체해야 함. 또한 새로 갱신된 하드웨어가 출시되고 구형 하드웨어가 노후화되어 신뢰성이 떨어지면 몇 년마다 업그레이드 주기를 관리해야 함 
    - 온프레미스 시스템을 담당하는 데이터 엔지니어라면 과잉 구매나 과소비 없이 최대 부하 및 대규모 잡에 뛰어난 성능을 제공할 수 있는 대용량 시스템을 구입해야 함 
    - 기존 기업들은 하드웨어 실행, 소프트웨어 환경 관리, 개발팀의 코드 배포, 데이터베이스 및 빅데이터 시스템 운영에 필요한 비용과 인건비를 적절히 조정할 수 있었음 
  - 클라우드
    - 클라우드는 온프레미스 모델을 완전히 뒤집음. 하드웨어를 구입하는 대신 AWS, 애저 또는 구글 클라우드와 같은 클라우드 제공업체로부터 하드웨어와 관리형 서비스를 임대하기만 하면 됨. 이러한 자원은 대개 매우 단기간으로 예약할 수 있음. VM은 1분 이내에 스핀업되고 이후 사용량은 초 단위로 청구됨 
    - 초기 클라우드 시대에는 기본적으로 하드웨어 슬라이스를 대여하는 VM 및 가상 디스크와 같은 제품인 서비스형 인프라(IaaS)가 주를 이뤘음. 서비스형 플랫폼(PaaS)으로의 전환은 서서히 이루어지고 있으며, 서비스형 소프트웨어(SaaS)제품은 계속해서 빠른 속도로 성장하고 있음 
    - PaaS 서비스를 사용하면 엔지니어는 개별 머신을 관리하고 분산 시스템 전체에 프레임워크를 배포하는 운영 세부 사항을 무시할 수 있음. 이들은 운영 오버헤드를 최소화하면서 복잡한 자동 계산 시스템에 대한 턴키 접근을 제공함 
    - SaaS는 일반적으로 운영 관리가 거의 필요 없는 완전한 기능을 갖춘 엔터프라이즈 소프트웨어 플랫폼을 제공함. SaaS는 화상 회의, 데이터 관리, 애드테크, 오피스 애플리케이션, CRM 시스템 등 모든 영역의 엔터프라이즈 도메인을 대상으로 함 
    - 서버리스 제품은 일반적으로 0에서 매우 높은 사용률까지 자동 확장됨. 이들은 종량제 방식으로 청구되며, 엔지니어는 기본 서버에 대한 운영 인식 없이 작업을 수행할 수 있어야 함. 실제로 서버리스란 보통 보이지 않는 많은 서버(many invisible servers)를 의미함 
    - 클라우드 경제학에 관한 간단한 우회
      - 온프레미스 서버를 클라우드의 VM으로 하나씩 이동하는(리프트 앤 시프트,lift and shift)방식은 클라우드 마이그레이션의 초기 단계, 특히 기존 하드웨어를 종료하지 않을 경우 상당한 규모의 신규 임대 계약이나 하드웨어 계약을 체결해야 하는 등 재정적인 위기에 처한 기업에는 매우 합리적인 전략. 그러나 클라우드 자산을 초기 상태로 방치하는 기업은 갑작스러운 충격을 받게 되는데, 직접 비교해보면 클라우드에서 장기간 실행되는 서버는 온프레미스 서버보다 훨씬 더 비쌈 
      - 클라우드에서 가치를 발견하는 핵심은 클라우드 가격 모델을 이해하고 최적화하는 것. 최대부하를 처리할 수 있는 일련의 장기 실행 서버를 배포하는 대신, 자동 확장 기능을 사용해 부하가 적을 때는 최소한의 인프라로 워크로드를 축소하고 피크 시간에는 대규모 클러스터까지 워크로드를 확장할 수 있음. 사용 빈도가 높고 내구성이 낮은 워크로드를 통해 비용 절감을 실현하려면 예약 인스턴스 또는 스폿 인스턴스를 사용하거나 서버 대신 서버리스 함수를 사용함 
      - 클라우드의 동적인 특성을 활용해 비즈니스 가치를 높이기 위해 노력해야 함. 데이터 엔지니어는 온프레미스 환경에서는 불가능했던 작업을 달성함으로써 클라우드에 새로운 가치를 창출할 수 있음. 예를 들어 대규모 컴퓨팅 클러스터를 신속하게 스핀업해 온프레미스 하드웨어로는 감당할 수 없는 규모의 복잡한 변환을 실행할 수 있음 
  - 하이브리드 클라우드 
    - 클라우드 환경에서 즉각적인 이점을 얻을 수 있는 특정 워크로드로만 마이그레이션할 수 있음. 예를 들어 온프레미스 스파크 스택을 임시 클라우드 클러스터로 마이그레이션해 데이터 엔지니어링팀의 소프트웨어와 하드웨어 관리에 대한 운영 부담을 줄이고 대규모 데이터 잡을 신속하게 확장할 수 있음 
    - 클라우드에 분석을 배치하는 이러한 패턴은 데이터가 주로 한 방향으로 흐르면서(클라우드에서 온프레미스로 다시 불러오는) 데이터 이그레스 비용을 최소화하므로 매우 유려함.
    - 온프레미스 애플리케이션은 기본적으로 무료로 클라우드에 푸시할 수 있는 이벤트 데이터를 생성함. 대량의 데이터는 클라우드에 남아 분석되며, 소량의 데이터는 애플리케이션에 모델을 배포하거나 역 ETL(reverse ETL)을 위해 온프레미스에 다시 푸시됨 
  - 멀티 클라우드
    - 워크로드를 여러 퍼블릭 클라우드에 배포한는 것을 의미함.
    - 기업이 멀티클라우드를 도입하는 동기는 여러 가지가 있을 수 있음. SaaS 플랫폼은 종종 기존 고객 클라우드 워크로드에 가까운 서비스를 제공하자고 함 
    - 여러 클라우드에서 최고의 서비스를 활용할 수 있다는 것
    - 단점 
      - 데이터 이그레스 비용과 네트워킹 병목 현상은 매우 중요함. 멀티클라우드로의 전환은 상당한 복잡성을 초래할 수 있음 
      - 클라우드 간 통합과 보안은 상당한 문제를 야기할 수 있고, 멀티클라우드 네트워킹은 극도로 복잡해질 수 있음 
      - 차세대 클라우드의 클라우드 서비스는 클라우드 전반에 걸쳐 서비스를 제공하고 클라우드 간에 데이터를 원활하게 복제하거나 단일 창을 통해 여러 클라우드에서 워크로드를 관리함으로써 복잡성을 줄이고 멀티클라우드를 촉지하는 것이 목표 
  - 클라우드 송환 논쟁
    - 클라우드 규모란?
      - 엑사바이트의 데이터를 저장하거나 초당 테라비트 단위의 인터넷 송수신 트랙픽을 처리하는 경우 클라우드 규모에 해당할 수 있음(내부 네트워크 트래픽의 초당 테라비트 단위를 달성하기란 매우 쉬움) 
      - 데이터 이그레스 비용이 비즈니스의 주된 요소일 때는 서버를 소유하는 것도 고려해보자. 클라우드 규모 워크로드의 구체적인 예를 들자면, 애플의 iCloud 스토리지를 자체 서버로 마이그레이션함으로써 상당한 재정적 및 성능적 이점을 얻을 수 있었음 
- 구축과 구매 비교
  - 구축에 대한 논거는 설루션을 엔드투엔드로 제어할 수 있고 벤더나 오픈 소스 커뮤니티에 의해 좌우되지 않는다는 것. 구매를 지지하는 주장은 결국 리소스의 제약과 전문성으로 귀결됨. 즉, 이미 사용 가능한 설루션보다 더 나은 설루션을 구축할 수 있는 전문 지식이 있는가 하는 점. 어느 쪽이든 결정은 TCO, TOCO 및 설루션이 조직에 경쟁 우위를 제공하는지 여부에 달려 있음 
  - 오픈 소스 및 유료 서비스의 수를 고려해 봤을 때 모든 것을 직접 구축하는 것은 어리석은 일 
  - 오픈 소스 소프트웨어(OSS)
    - 특정 라이센스 조건에 따라 소프트웨어 및 기본 코드베이스를 일반적으로 용도롱 이용할 수 있도록 공개하는 소프트웨어 분산 모델(distribution model)
    - 종종 OSS는 분산된 공동 작업자 팀에 의해 생성되고 유지 관리됨. 대부분의 경우 OSS는 사용, 변경 및 배포가 자유롭지만, 몇 가지 주의사항이 있음. 예를 들어 많은 라이선스는 소프트웨어를 배포할 때 오픈소스에서 파생된 소프트웨어의 소스 코드를 포함할 것을 요구함 
    - 커뮤니티 관리 OSS
      - OSS 프로젝트의 가장 일반적인 경로. 커뮤니티를 통해 전 세계 개발자의 높은 기술 혁신과 활발한 기여가 이루어지며, 인기 있는 OSS 프로젝트도 커뮤니티에서 개방됨
      - 인지도
        - 관심을 얻지 못하는 인기 없는 OSS의 채택은 피하자. 깃허브의 스타, 포크, 커밋수를 살펴보고 얼마나 최신화되었는지 확인함. 
        - 또 하나의 주의할 점은 관련 채팅 그룹 및 포럼에서의 커뮤니티 활동 
      - 성숙도
        - 프로젝트가 시작된 지 얼마나 되었는지, 현재 얼마나 활성화되었는지, 얼마나 많은 사람이 해당 프로젝트를 유용하게 사용하는지 알고 있는가?
      - 문제 해결
        - 문제가 발생할 경우 어떻게 대처해야 하는가? 문제는 혼자서 해결할 수 있는가? 아니면 커뮤니티가 문제 해결을 도울 수 있는가?
      - 프로젝트 관리
        - 깃 이슈와 그 대처 방식을 살펴보자. 이슈에 신속하게 대응할 수 있을까? 그렇다면 이슈를 제기하고 해결하는 프로세스는 무엇인가?
      - 팀
        - 기업이 OSS 프로젝트를 후원하는가? 핵심 기여자는 누구인가?
      - 개발자 관계 및 커뮤니티 관리
        - 프로젝트는 도입과 채택을 장려하기 위해 무엇을 하는가? 격려와 지원을 제공하는 활발한 채팅 커뮤니티(슬랙)가 있는가?
      - 기여
        - 프로젝트가 풀 리퀘스트를 장려하고 수용하는가? 풀 리퀘스트를 수락하고 메인 코드베이스에 포함하기 위한 프로세스와 타임라인은 어떻게 되는가?
      - 로드맵
        - 프로젝트 로드맵이 있는가? 있다면 그 로드맵은 명확하고 투명한가?
      - 자체 호스팅 및 유지 보수
        - OSS 설루션을 호스팅하고 유지 보수할 수 있는 리소스가 있는가? 그렇다면 OSS 벤더로부터 관리 서비스를 구입할 경우와 비교해 TCO와 TOC는 얼마나 되는가?
      - 커뮤니티로의 환원
        - 프로젝트가 마음에 들고 적극적으로 사용하고 있다면 그에 기여할 방법을 고려해보자. 커뮤니티 포럼이나 채팅에서 코드베이스에 기여하고 문제를 해결하며 조언을 제공할 수 있음 
    - 상용 OSS
      - OSS의 몇 가지 단점 : 사용자 환경에서 설루션을 호스팅하고 유지 관리해야 함. OSS 애플리케이션에 따라서는 사소할 수도 있지만, 매우 복잡하고 번거로울 수도 있음 
      - 상용 OSS(COSS, commercial OSS) : 비즈니스 벤더는 OSS 설루션(일반적으로 클라우드 SaaS 제품)을 호스팅 및 관리함으로써 이러한 관리 문제를 해결하려고 함. 이러한 벤더의 예로는 데이터브릭스(스파크), 컨플루언스(카프카), DBT 랩스(dbt) 등이 있으며 그 외에도 매우 많으며 이러한 모델을 뜻함 
      - 커뮤니티 관리 OSS 버전을 계속 사용할 수 있지만, 자체적으로 유지 관리하는 작업(갱신, 서버/컨테이너 유지 보수, 버그 수정을 위한 풀 리퀘스트 등)을 계속 수행해야 함. 또는 벤더에 비용을 지불하고 COSS 제품의 관리를 맡길 수도 있음 
      - 상용 OSS 프로젝트에서 고려해야 할 요소
        - 가치
          - 벤더가 OSS 기술을 직접 관리할 때보다 더 나은 가치를 제공하는가? 일부 벤더는 커뮤니티 OSS 버전에서 이용할 수 없는 많은 기능을 관리형 오퍼링에 추가함. 이러한 추가 기능이 여러분에게 매력적으로 작용하는가?
        - 제공 모델
          - 서비스에는 어떻게 접근하는가? 다운로드, API 또는 웹/모바일 UI를 통해 제품을 이용할 수 있는가? 초기 버전 및 후속 릴리스에 쉽게 접근할 수 있는지 확인하자
        - 지원
          - 제품의 지원 모델은 무엇인가? 또한 지원 비용이 추가되는가?
          - 지원 대상과 지원 외 대상이 무엇인지도 파악해야 함. 지원 대상에 포함되지 않은 항목은 고객이 소유하고 관리할 책임이 있음 
        - 릴리스 및 버그 수정
          - 벤더는 출시 일정, 개선 사항 및 버그 수정을 투명하게 파악하고 있는가? 이러한 갱신을 쉽게 이용할 수 있는가?
        - 판매 주기 및 가격 설정
          - 벤더는 특히 SaaS 제품에 대해 온디맨드 가격을 제시하고, 연장 계약을 체결하면 할인을 제공하는 경우가 많음. 사용량에 따른 종량제 지불 방식과 선불 지불 방식의 트레이드오프를 반드시 이해하기 바람.
          - 일시불로 목돈을 지불할 가치가 있는가? 아니면 다른 곳에 돈을 쓰는 것이 더 합리적ㅇ니가?
        - 회사 재정
          - 회사는 존속 가능한가? 회사가 VC 자금을 조달한 적이 있다면 크런치베이스 같은 사이트에서 펀딩 자금을 확인할 수 있음 
          - 해당 회사는 얼마나 많은 비즈니스 영역을 보유하고 있으며, 수년 후에도 계속 운영될 수 있는가? 
        - 로고 vs 수익
          - 회사는 고객 수를 늘리는 로고 성장에(스타트업에서는 고객 수 증가를 로고 성장이라는 용어로 표현하기도 함) 초점을 맞추는가? 아니면 수익 증대를 목표로 하는가? 건전한 재정을 확립할 수 있는 수익 없이 고객 수, 깃허브 스타 수 또는 슬랙 채널 멤버십을 늘리는 데만 주로 신경 쓰는 기업이 얼마나 많은지 안다면 놀랄 것이다
        - 커뮤니티 지원
          - 회사는 OSS 프로젝트의 커뮤니티 버전을 진정으로 지원하는가? 해당 회사는 커뮤니티 OSS 코드베이스에 얼마나 기여하는가? 일부 벤더가 OSS 프로젝트를 공동 선택하고, 그 후 커뮤니티에 거의 가치를 제공하지 않는다는 논란이 제기되고 있음. 회사가 문을 닫는 경우 해당 제품이 커뮤니티 지원 오픈 소스로서 존속할 가능성은 얼마나 되는가?
  - 전용 폐쇄형 네트워크 서비스 
    - 데이터 업계에서 가장 큰 기업 중 일부는 비공개 소스 제품을 판매함. 전용 폐쇄형 네트워크 서비스의 두 가지 주요 유형 
    - 독립 오퍼링
      - 데이터 도구에 대한 새로운 독립형 오퍼링들이 매일 등장하고 있음 
      - 고려해야 할 사항
        - 상호 운용성
          - 대상 도구가 여러분이 선택한 다른 도구(OSS, 기타 독립형 서비스, 클라우드 오퍼링 등)와 상호 운용되는지 확인하자.
        - 인지도와 시장 점유율
          - 설루션이 인기 있는가? 시장에서의 존재감이 있는가? 고객의 호평을 받고 있는가?
        - 문서화와 지원
          - 문제와 질문은 필연적으로 발생함. 문서화 또는 지원을 통해 문제를 해결하는 방법이 명확한가?
        - 가격 책정
          - 가격은 합리적인가? 사용 가능성이 낮은 확률, 중간 정도의 확률 그리고 높은 확률의 시나리오를 각각의 비용과 함께 계획하자. 
          - 할인된 가격으로 계약을 이끌 수 있는가? 그럴 만한 가치가 있는가? 계약에 서명하면 협상 및 새로운 옵션의 시도 측면에서 유연성에 얼마나 많으 제약이 걸리는가? 향후 가격 책정에 관한 계약상 확약을 얻을 수 있는가?
        - 수명
          - 계약할 회사는 당신이 해당 제품으로부터 가치를 얻을 수 있을 만큼 오래 생존할 수 있는가? 
    - 클라우드 플랫폼 전용 서비스 오퍼링
      - 고려해야할 요소
        - 성능 vs 가격
          - 클라우드 오퍼링이 독립형 버전 또는 OSS 버전보다 훨씬 더 우수한가? 클라우드 오퍼링을 선택하는 데 드는 TCO는 얼마인가?
        - 구매 고려 사항
          - 온디맨드 가격은 비쌀 수 있음. 예약된 용량을 구입하거나 장기 약정 계약을 체결해 비용을 절감할 수 있는가? 
  - 조언 
    - 구축과 구매 사이의 비교는 여러분의 경쟁 우위를 파악하고 맞춤화를 위해 자원을 투자하는 것이 합리적인지 파악하는 것으로 귀결됨. 보통은 OSS와 COSS를 선호하므로, 이러한 옵션이 부족한 영역을 개선하는 데 집중할 수 있음 
    - 내부 운영 오버헤드를 매몰 비용으로 처리하지 말자. 온프레미스 서버를 관리하는 대신 관리형 플랫폼상에 정교한 시스템을 구축하도록 기존 데이터 팀의 역량을 강화하는 것은 매우 중요함. 또한 기업이 수익을 올리는 방법을 생각해보자 
- 모놀리식과 모듈식 비교 
  - 모놀리식 시스템은 독립형이며, 단일 시스템에서 여러 기능을 수행하는 경우가 많음. 모놀리스 진영은 모든 것을 한곳에 두는 단순함을 선호함. 단일 엔티티에 대해 추론하기가 더 쉽고 유동적인 구성 요소가 적기 때문에 더 빠르게 이동할 수 있음 
  - 한편 모듈식 진영은 고유한 과제를 훌륭하게 수행하는 동종 최고의 분리형 기술을 선호함. 특히 데이터 환경의 제품 변화 속도를 고려할 때, 끊임없이 변화하는 설루션 집합 간의 상호 운용성을 목표로 해야함 
  - 모놀리스(monolith) 
    - 과거 워터폴 방식 싣새에는 소프트웨어 릴리스가 크고 긴밀하게 결합되어 있으며 느린 리듬으로 이동한다는 것을 의미했음 
    - 모놀리식 데이터 시스템은 인포매티카 같은 오래된 소프트웨어 벤더와 스파크 등의 오픈 소스 프레임워크를 통해 오늘날도 지속되고 있음 
    - 장점
      - 추론하기 쉽고, 모든 구성이 독립적인 만큼 인지적 부담과 컨텍스트 전환이 덜 요구된다는 것 
      - 수십 개의 기술을 다루는 대신 하나의 기술과(일반적으로는) 하나의 주요 프로그래밍 언어를 다룸. 아키텍처와 프로세스에 대한 단순한 추론을 원한다면 모놀리스를 사용하는 것이 좋음 
    - 단점
      - 깨지기 쉽다는 점. 일단 유동적인 구성 요소의 수가 많다 보니 소프트웨어 갱신이나 릴리스가 오래 걸림. 너무 많은 기능을 한 번에 추가하려는 경향이 있기 때문. 시스템에 버그가 있을 때는 시스템 전체에 해를 끼칠 수도 있음 
      - 파이프라인의 어딘가에서 문제가 생기면 전체 프로세스를 다시 시작해야 함 
      - 모놀리식 시스템의 멀티테넌시도 심각한 문제가 될 수 있음. 여러 사용자의 워크로드를 분리하기는 어려울 수 있음. 온프레미스 데이터 웨어하우스에서는 사용자 정의 함수 하나가 다른 사용자들의 시스템 속도를 낮추기에 충분할 만큼의 CPU를 소비할 수 있음. 의존성과 리소스 경합 간의 충돌은 자주 발생하는 골칫거리
      - 벤더 또는 오픈 소스 프로젝트가 중단될 때 새로운 시스템으로 전환하기 어렵다는 것. 모든 프로세스가 모놀리스 안에 포함되므롸, 시스템에서 새로운 플랫폼으로 이동하려면 많은 시간과 비용이 소요됨 
  - 모듈성(modularity)
    - 마이크로서비스 API를 통해 통신할 수 있으므로, 개발자는 자신의 도메인에 집중하면서 다른 마이크로서비스에서 애플리케이션에 접근할 수 있음 
    - 데이터는 데이터 레이크 및 레이크하우스의 파케이 같은 표준 형식으로 객체 스토리지에 저장됨. 해당 형식을 지원하는 모든 처리 도구는 데이터를 읽고 처리된 결과를 다른 도구로 처리하기 위해 데이터 레이크에 다시 쓸 수 있음. 
    - 클라우드 데이터 웨어하우스는 표준 형식 및 외부 테이블을 사용한 임포트 및 익스포트를 통해 객체 스토리지와의 상호 운용을 지원함. 즉 쿼리는 데이터 레이크의 데이터에 대해 직접 실행함 
    - 단점
      - 고려해야 할 사항이 더 많다는 것
      - 관심 있는 단일 시스템을 처리하는 대신, 수많은 시스템을 이해하고 운용해야 할 수 있음. 상호 운용성은 잠재적인 골칫거리. 이러한 시스템이 모두 잘 연계되어 작동하기를 바람 
  - 분산형 모놀리스 패턴
    - 기본 개념은 분산 시스템을 서로 다른 서비스로 실행해 서로 다른 작업을 수행하는 것. 그러나 서비스와 노드는 공통의 의존 관계 또는 공통의 코드베이스를 공유함 
    - 한 가지 표준적인 예로는 전통적인 하둡 클러스터를 들 수 있음.
      - 하둡 클러스터는 하이브, 피그 또는 스파크 같은 여러 프레임워크를 동시에 호스팅 할 수 잇음. 클러스터는 또한 내부 의존성도 포함함. 게다가 클러스터는 하둡 공통 라이브러리, HDFS, WARN, 자바 같은 핵심 하둡 구성 요소를 실행함. 실제로 클러스터에는 각 구성 요소의 버전이 하나씩 설치되는 경우가 많음
      - 표준 온프레미스 하둡 시스템은 모든 사용자와 모든 잡에서 작동하는 공통 환경을를 들 수 있음.
      - 하둡 클러스터는 하이브, 피그 또는 스파크 같은 여러 프레임워크를 동시에 호스팅 할 수 잇음. 클러스터는 또한 내부 의존성도 포함함. 게다가 클러스터는 하둡 공통 라이브러리, HDFS, WARN, 자바 같은 핵심 하둡 구성 요소를 실행함. 실제로 클러스터에는 각 구성 요소의 버전이 하나씩 설치되는 경우가 많음
      - 표준 온프레 관리함. 업그레이드 및 설치 관리는 중요한 과제. 의존성을 업그레이드하기 위해 잡을 강제하면 의존성이 깨질 위험이 있음. 또한 프레임워크의 두 가지 버전을 유지 관리하려면 복잡성이 증가함 
        - 아파치 에어플로 같은 일부 최신 파이썬 기반 오케스트레이션 기술도 이러한 문제를 안고 있음 
        - 이러한 기술은 고도로 분리된 비동기 아키텍처를 사용하지만, 모든 서비스는 동일한 의존성을 가지는 동일한 코드베이스를 실행함. 모든 실행자(executor)가 모든 작업(task)을 실행할 수 있으므로, 하나의 DAG에서 실행되는 단일 작업에 대한 클라이언트 라이브러리가 전체 클러스터에 설치되어 있어야 함. 많은 도구를 오케스트레이션하려면 여러 API 호스트에 대한 클라이언트 라이브러리를 설치해야 함. 의존성 충돌을 항상 발생하는 문제
      - 분산형 모놀리스 문제의 한 가지 해결 방법은 클라우드 환경의 임시 인프라
        - 각 작업에는 의존성이 있는 자체 임시 서버 또는 클러스터를 설치함. 각 클러스터는 고도로 모놀리식한 상태로 유지되지만, 작업을 분리하면 충동이 크게 줄어듬
        - 컨테이너를 사용해 분산된 모놀리스를 여러 소프트웨어 환경으로 적절하게 분배하는 것 
  - 조언 
    - 모놀리스는 이해하기 쉽고 복잡성이 줄어든다는 점에서 매력적이지만 비용이 많이 듬. 이때 비용이란 유연성, 기회비용 및 마찰이 심한 개발 주기의 잠재적 손실 등이다.
    - 모놀리스 옵션과 모듈식 옵션을 비교할 때 고려해야할 몇 가지 사항
      - 상호 운용성 : 공유와 상호 운용성을 위한 설계
      - 곰의 덫 회피 : 빠지기 쉬운 함정은 고통스럽거나 탈출이 불가능할 수 있음
      - 유연성 : 현재 데이터 공간에서는 모든 것이 매우 빠르게 변화하고 있음. 모놀리스에 전념하면 유연성과 되돌릴 수 있는 의사결정이 줄어듬
- 서버리스와 서버 비교
  - 클라우드 제공업체의 큰 트렌드는 서버리스. 이를 통해 개발자와 데이터 엔지니어는 백그라운드에서 서버를 관리하지 않고도 애플리케이션을 실행할 수 있음. 서버리스는 적절한 사용 사례에 대한 가치를 신속하게 제공하지만, 그 외의 사례에는 잘 맞지 않을 수 있음 
  - 서버리스
    - 서버를 관리할 필요 없이 필요에 따라 작은 코드 청크를 실행할 수 있다는 약속 아래 서버리스의 인기는 폭발적으로 증가했음. 그 인기의 주된 이유는 비용과 편리함. 즉, 서버 비용을 지불하는 대신 코드가 호출되었을 때만 비용을 지불하는 방식 
    - 종류
      - 서비스형 함수(FaaS, function as a service)가 널리 보급되었지만, 서버리스 시스템은 AWS 람다가 등장하기 전부터 있었음. 예를 들어 구글 클라우드의 빅쿼리는 데이터 엔지니어가 백엔드 인프라를 관리할 필요가 없었다는 점에서 서버리스. 시스템은 0으로 확장되고 대규모 쿼리를 처리하기 위해 자동으로 확장됨. 시스템에 데이터를 로드하고 쿼리를 시작하기만 하면 됨. 이때 쿼리가 소비하는 데이터의 양과 데이터 저장에 드는 소액의 비용을 지불해야 함. 
      - 데이터 사용량과 저장량에 대한 비용을 지불하는 이러한 결제 모델은 점점 더 보편화되고 잇음 
    - 실제 환경에서의 이벤트당 비용 및 서버리스 실행의 최대 기간을 확인하기 위해 모니터링하고 이 이벤트당 비용을 사용해 이벤트율의 증가에 따른 전체적인 비용을 판단하기 위해 모델을 작성함
  - 컨테이너
    - 컨테이너는 종종 경량 가상 머신이라고도 함. 기존의 VM은 전체 운영 체제를 포괄하는 반면, 컨테이너는 격리된 사용자 공간(파일 시스템 및 일부 프로세스 등)을 패키징함. 이러한 많은 컨테이너는 단일 호스트 운영 체제에서 공존할 수 있음. 이렇게 하면 운영 체제 커널 전체를 지니는 오버헤드를 발생하지 않고, 가상화의 주요 이점(의존성 및 코드 분리)을 누릴 수 있음 
    - 단일 하드웨어 노드는 세분화된 자원 할당을 통해 다수의 컨테이너를 호스트할 수 있음 
    - 컨테이너 클러스터는 전체 VM이 제공하는 것과 동일한 보안 및 격리 기능을 제공하지 않음 
      - 컨테이너 이스케이프(container escape)는 컨테이너 코드가 OS 수준에서 컨테이너 외부의 권한을 얻는 공격코드의 일종으로, 멀티테넌시의 위험으로 간주될 만큼 충분히 일반적임. 
      - 아마존 EC2는 여러 고객이 VM이 동일한 하드웨어에서 호스팅되는 진정한 멀티테넌트 환경이지만, 쿠버네티스 클러스터는 상호 신뢰 환경(예: 단일 회사의 벽 내부) 내에서만 코드를 호스팅해야 함.
      - 코드 리뷰 프로세스와 취약성 검사는 개발자가 보안상 허점을 만들지 않도록 하는 데 매우 중요함 
    - 컨테이너형 함수 플랫폼 
      - 영구 서비스가 아닌, 이벤트에 의해 트리거 되는 임시 단위(사용 후 삭제)로 컨테이너를 실행함. 따라서 사용자는 매우 제한적인 람다 런타임 대신, 컨테이너 환경의 완전한 유연성을 통해 AWS 람다의 단순성을 누릴 수 있음 
      - AWS 파게이트와 구글 앱 엔진 같은 서비스는 쿠버네티스에 필요한 컴퓨팅 클러스터를 관리하지 않고도 컨테이너를 실행함. 이러한 서비스는 컨테이너를 완전히 격리해 멀티테넌시와 관련한 보안 문제를 방지함 
  - 서버 vs 서버리스 평가 방법
    - 서버리스 대신 자체 서버를 사용하려는 이유는 무엇일까? 몇몇 이유 중 가장 큰 요인은 비용임. 서버리스는 사용량과 비용이 서버 실행 및 유지 보수에 드는 지속적인 비용을 초과하면 의미가 사라짐. 특정 규모에서는 서버리스의 경제적 이점이 감소할 수 있으며, 서버를 가동하는 편이 더 매력적으로 느껴질 수 있음
    - 사용자 정의, 성능, 제어 등은 서버리스보다 서버를 선호하는 또 다른 주요 이유. 일부 서버리스 프레임워크는 특정 사용 사례에 따라 성능이 저하되거나 제한될 수 있음. 서버, 특히 서버 리소스가 일시적인 클라우드에서 서버를 사용할 때 고려해야할 사항
      - 서버 장애 예상하기
        - 서버 장애가 발생할 것. 지나치게 커스터마이징되어 부서지기 쉬운, 세상에 하나뿐인 특별한 서버는 아키텍처에 현저한 취약성이 생기므로 사용하지 말자. 대신 서버를 필요에 따라 생성할 수 있는 임시 리소스로 취급하자. 
        - 애플리케이션이 서버에 특정 코드를 설치하도록 요구할 경우에는 부트 스크립트를 사용하거나 이미지를 빌드해야 함. CI/CD 파이프라인을 통해 서버에 코드를 배포하자 
      - 클러스터와 오토스케일링 사용하기
        - 컴퓨팅 자원을 필요에 따라 확장 및 축소할 수 있는 클라우드의 기능을 활용하자. 애플리케이션 사용률이 높아짐에 따라 애플리케이션 서버를 클러스터링하고 오토스케일링 기능을 사용해 수요 증가에 따라 애플리케이션을 자동으로 수평 확장하자 
      - 인프라를 코드로 취급하기
        - 자동화는 서버에만 적용되는 것이 아니므로 가능한 한 인프라롤 확장해야 함. 테라폼, AWS CloudForm 및 Google Cloud Deployment Manager 같은 배포 매니저를 사용해 인프라(서버 또는 기타)를 배포하자 
      - 컨테이너 사용하기
        - 복잡한 의존성이 설치된 더 정교하거나 부하가 높은 워크로드의 경우, 단일 서버 또는 쿠버네티스에 컨테이너를 사용하는 것을 고려해보자
  - 조언 
    - 서버리스에 적합한지 여부를 판단하는 데 도움이 될 몇가지 중요한 고려 사항 
      - 워크로드 규모와 복잡성
        - 서버리스는 단순한 개별 작업과 워크로드에 가장 적합함. 유동적인 요소가 많거나 컴퓨팅 또는 메모리 처리 능력이 많이 필요한 경우에는 적합하지 않음. 이 때는 쿠버네티스와 같은 컨테이너와 컨테이너 워크플로 오케스테이션 프레임워크의 사용을 고려하자 
      - 실행 빈도 및 기간
        - 서버리스 애플리케이션은 초당 몇 건의 요청을 처리하는가? 각 요청을 처리하는 데 시간이 얼만아 걸리는가? 클라우드 서버리스 플랫폼에는 실행 빈도, 동시성 및 기간에 제한이 있음. 애플리케이션이 이러한 제한 내에서 제대로 작동하지 않는다면 컨테이너 중심의 접근 방식을 고려할 때 
      - 요청과 네트워킹 
        - 서버리스 플랫폼은 종종 어떤 형태의 단순한 네트워킹을 활용하지만, VPC나 방화벽 등의 모든 클라우드 가상 네트워킹 기능을 지원하지 않음 
      - 언어
        - 주로 어떤 언어를 사용하는가? 서버리스 플랫폼에서 공식적으로 지원되는 언어가 아닌 경우에는 컨테이너를 고려해야 함 
      - 런타임 제약
        - 서버리스 플랫폼에서는 완전한 운영 체제 추상화를 얻을 수 없음. 대신 특정 런타임 이미지로 제한됨 
      - 비용
        - 서버리스 함수는 매우 편리하지만 잠재적으로 비용이 많이 들 수 있음. 서버리스 함수가 몇 가지 이벤트만 처리할 때는 비용이 절감되고, 이벤트 수가 증가하면 비용이 빠르게 증가함. 이러한 시나리오 때문에 클라우드 비용 지출이 예상치 못하게 급증하는 경우가 많음 
    - 결국 추상화가 우세한 경향이 있음. 서버리스를 먼저 사용한 다음. 서버리스 옵션을 사용할 수 없을 만큼 충분히 성장한 후에는 (가능하다면 컨테이너 및 오케스트레이션과 함께) 서버를 사용하는 것이 좋음 
- 최적화, 성능, 벤치마크 전쟁
  - 1990년대의 빅데이터
    - 페타바이트 규모의 빅데이터를 지원한다고 주장하는 제품은 스마트폰의 저장 공간에 쉽게 들어갈 수 있을 만큼 작은 벤치마크 데이터셋을 사용하는 경우가 많음.
    - 캐싱 계층에 의존해 성능을 제공하는 시스템의 경우, 테스트 데이터셋은 솔리드 스테이트 드라이브(SSD, Solid-State drive) 또는 메모리에 완전히 상주하며 벤치마크에서 동일한 데이터를 반복적으로 쿼리해 최고 성능을 보여줄 수 있음. 
    - 소규모 테스트 데이터셋으로 가격을 비교하면 RAM과 SSD 비용을 최소화할 수 있음 
    - 실제 사용 사례를 벤치마킹하려면 예쌍되는 실제 데이터와 쿼리 크기를 시뮬레이션해야 함. 요구 사항에 대한 상세한 평가를 바탕으로 쿼리 성능 및 자원 비용을 평가하자 
  - 무의미한 비용 비교 
    - 가격 대비 성능 또는 TCO를 분석할 때 일반적으로 사용하는 트릭
    - 예를 들어 많은 MPP 시스템은 클라우드 환경에 상주하는 경우에도 쉽게 생성 및 삭제할 수 없음. 이러한 시스템은 일단 한 번 구성되면 몇 년 동안 계속 실행됨. 다른 데이터베이스는 동적 컴퓨팅 모델을 지원하며 쿼리당 또는 사용 초당 과금됨. 
    - 단기 시스템과 비단기 시스템을 초당 비용으로 비교하는 것은 무의미하지만, 벤치마크에서는 항상 볼 수 있는 현상 
  - 비대칭 최적화
    - 업체는 종종 고도로 정규화된 데이터에 대해 복잡한 조인 쿼리를 실행하는 벤치마크를 사용해 행 기반 MPP 시스템과 열 기반 데이터베이스를 비교함 
    - 정규화된 데이터 모델은 행 기반 시스템에 최적이지만 열 기반 시스템은 일부 스키마를 변경해야 그 잠재력을 최대한 발휘할 수 있음. 설상가상으로 벤더는 경쟁 데이터베이스에 유사한 튜닝(구체화한 뷰에 조인 배치)을 적용하지 않고 조인 최적화(조인의 사전 색인화)를 추가로 수행해 시스템을 가동함 
- 데이터 엔지니어링 수명 주기의 드러나지 않는 요소 
  - 데이터 관리 
    - 질문해야 할 몇가지 예제 사항 
      - 외부와 내부 모두에서 발생하는 침해로부터 데이터를 어떻게 보호하고 있는가?
      - GDPR, CCPA 및 기타 데이터 개인정보보호 규정을 준수하는 제품은 무엇인가?
      - 이러한 규정을 준수하기 위해 데이터를 호스팅할 수 있는가?
      - 어떻게 데이터 품질을 보장하고 설루션에서 올바른 데이터를 표시하는가?
  - 데이터 옵스
    - 새로운 기술을 평가할 때는 새로운 코드 배포를 얼마나 제어할 수 있을까? 문제가 발생했을 때 어떻게 경고를 받고 어떻게 대응할 수 있을가? 그 해답은 주로 고려중인 기술의 유형에 따라 달라짐. 해당 기술이 OSS인 경우에는 모니터링, 호스팅 및 코드 배포의 설정을 담당할 가능성이 있음 
    - 문제를 어떻게 처리할 것인가? 사고 대응은 어떻게 하는가? 관리형 오퍼링을 사용할 경우 대부분의 작업은 사용자가 제어할 수 없음. 벤더의 SLA, 문제를 경고하는 방식, 문제 해결에 대한 ETA 제공 등 벤더가 문제를 해결하는 방법을 투명하게 공개하는지 여부를 고려하자 
  - 오케스트레이션 예제: 에어플로 
    - 에어플로는 오픈 소스 시장에서 지배적인 위치를 차지하는 만큼 많은 이점을 누리고 있음 
      - 에어플로 오픈 소스 프로젝트는 매우 활발하게 운영됨. 높은 커밋률과 버그 및 보안 문제에 대한 빠른 응답 시간을 보이며, 최근에는 코드베이스의 주요 리팩터인 에어플로 2를 출시했음 
      - 에어플로는 높은 수준의 인지도를 누리고 있음. 에어플로는 슬랙, 스택 오버플로, 깃허브 등 많은 커뮤니케이션 플랫폼에서 활발한 커뮤니티를 운영하므로 사용자는 질문과 문제에 대한 답을 쉽게 찾을 수 있음 
      - 에어플로는 GCP, AWS 및 Astronomer.io를 포함한 많은 벤더를 통해 관리형 서비스 또는 소프트웨어 배포로서 상업적으로 이용할 수 있음 
    - 에어플로의 단점 
      - 에어플로는 성능, 확장성 및 신뢰성의 병목 현상이 될 수 있는 몇몇 확장 불가능한 핵심 컴포넌트 (스케줄러 및 백엔드 데이터베이스)에 의존함 
      - 에어플로의 확장 가능한 부분은 여전히 분산형 모놀리스 패턴을 따름. 마지막으로 에어플로는 스키마 관리, 계보, 카탈로그 작성 등 많은 데이터 네이티브 구조를 지원하지 않으며 에어플로 워크플로를 개발하고 테스트하기도 어려움 

# 데이터 엔지니어링 수명 주기 심층 분석
## 원천 시스템에서의 데이터 생성
- 데이터 엔지니어의 역할은 원천 시스템에서 데이터를 가져와 이를 사용해 작업을 수행하고, 다운스트림 사용 사례를 처리하는 데 도움되도록 만드는 것. 그러나 원시 데이터를 얻기 전에 데이터가 어디에 있는지, 어떻게 생성되는지, 데이터의 특징과 특이점은 무엇인지 알아야 함.
- 데이터 원천: 데이터는 어떻게 생성될까?
  - 데이터는 사실(fact)과 수치(figure)의 비조직적이고 맥락 없는 집합. 데이터는 아날로그와 디지털 등 다양한 방법으로 생성될 수 있음 
  - 아날로그 데이터(analog data)는 음성, 수화, 종이에 글쓰기, 악기 연주와 같이 실제 세계에서 생성됨. 이러한 아날로그 데이터는 일시적인 경우가 많음 
  - 디지털 데이터는 아날로그 데이터를 디지털 형식으로 변환해 생성되거나 디지털 시스템의 기본 산물. 아날로그에서 디지털로 변환하는 예로는 아날로그 음성을 디지털 텍스트로 변환하는 모바일 문자 앱을 들 수 있음. 디지털 데이터 생성의 예로는 전자 상거래 플랫폼에서의 신용카드 거래를 들 수 있음 
  - 우리는 IoT 장치, 신용카드 단말기, 망원경 센서, 주식 거래 등에서 데이터를 수집함 
- 원천 시스템: 주요 아이디어
  - 파일과 비정형 데이터
    - 파일은 바이트의 시퀀스로서, 일반적으로 디스크에 저장됨. 애플리케이션은 종종 파일에 데이터를 씀. 파일은 로컬 매개변수, 이벤트, 로그, 이미지 및 오디오를 저장할 수 있음. 또한 파일은 데이터 교환의 보편적인 매개체  
    - 데이터 엔지니어로서 보게 될 주요 소스 파일 형식, 즉 수동으로 생성하거나 원천 시스템 프로세스의 출력으로 생성되는 파일은 엑셀, CSV, TXT, JSON, XML임. 이러한 파일은 고유한 특징이 있으며 정형(엑셀, CSV), 반정형(JSON, XML, CSV), 비정형(TXT,CSV) 등이 있음 
  - API
    - 애플리케이션 프로그래밍 인터페이스(API)는 시스템 간에 데이터를 교환하는 표준 방식. 이론적으로 API는 데이터 엔지니어의 데이터 수집 작업을 단순화함 
  - 애플리케이션 데이터베이스(OLTP 시스템)
    - 애플리케이션 데이터베이스는 애플리케이션의 상태를 저장함. 은행 계좌의 잔액을 저장하는 데이터베이스 등이 일반적인 예 
    - 일반적으로 애플리케이션 데이터베이스는 개별 데이터 레코드를 높은 속도로 읽고 쓰는 온라인 트랜잭션(OLTP) 시스템. OLTP 시스템은 종종 트랜잭션 데이터베이스라고 불리지만, 해당 시스템이 반드시 원자적 트랜잭션을 지원한다는 의미는 아님 
    - OLTP 데이터베이스는 보통 짧은 지연 시간과 높은 동시성을 지원함. RDBMS 데이터베이스는 (네트워크 지연 시간을 고려하지 않고) 1밀리초 이내에 행을 선택하거나 갱신할 수 있으며, 초당 수천 건의 읽기 및 쓰기를 처리할 수 있음. 도큐먼트(document) 기반 데이터베이스 클러스터는 잠재적인 불일치를 감수하고라도 훨씬 더 높은 도큐먼트 커밋률을 관리할 수 있음 . 
    - 일부 그래프 데이터베이스는 트랜잭션 사용 사례도 처리할 수 있음 
    - 기본적으로 OLTP 데이터베이스는 수천 명, 심지어 수백만 명의 사용자가 애플리케이션과 동시에 상호 작용하고 데이터를 갱신하거나 작성할 때 애플리케이션 백엔드로서 잘 작동함. 
    - OLTP 시스템은 단일 쿼리로 방대한 양의 데이털르 검색해야 하는 대규모 분석에 기반한 사용사례에는 적합하지 않음 
    - ACID
      - 일관성(consistency)이란 데이터베이스를 읽을 때 검색된 항목의 마지막으로 기록된 버전이 반환되는 것을 의미함. 
      - 독립성(isolation)은 동일한 항목에 대해 2개의 갱신 작업이 동시에 실행 중일 때, 최종 데이터베이스 상태는 이들 갱신이 제출된 순서대로 순차적으로 실행되는 것과 일치한다는 의미 
      - 내구성(durability)이란 정전 시에도 커밋된 데이터가 손실되지 않음을 의미함 
      - ACID 특성은 데이터베이스가 일관된 형상을 유지하도록 보장하고, 앱 개발자의 작업을 획기적으로 간소화함 
      - 모든 (데이터 또는 기타) 엔지니어는 ACID를 사용할 때와 그렇지 않을 때의 작동 방식을 이해해야 함. 예를 들어 일부 분산형 데이터베이스는 성능을 개선하기 위해 최종 일관성(eventual consistency)과 같은 완화된 일관성 제약 조건을 사용함. 현재 사용중인 일관성 모델을 이해하면 장애를 예방하는 데 도움이 됨 
    - 원자적 트랜직션(atomic transaction)
      - 단위로 커밋되는 여러 변경 사항의 집합 
    - OLTP와 분석
      - 어떤 시점에 OLTP에서 분석 쿼리를 실행하면 OLTP의 구조적 제한이나 경쟁 트랜잭션 워크로드와의 리소스 경합 때문에 성능 문제가 발생할 수 있음. 데이터 엔지니어는 운영 애플리케이션 성능을 저하하지 않으면서 분석 시스템과의 적절한 통합을 설정하기 위해 OLTP와 애플리케이션 백엔드의 내부 작동 방식을 이해해야 함 
      - 트랜잭션 워크로드와 부넉 워크로드를 혼합하는 애플리케이션을 지칭하기 위해 데이터 애플리케이션(data application)이라는 용어를 사용할 것 
  - 온라인 분석 처리(OLAP) 시스템 
    - OLTP 시스템과 달리 온라인 분석 처리 시스템은 대규모 분석 쿼리를 실행하도록 구축되어 있으며 일반적으로 개별 레코드의 조회 처리에는 비효율적. 예를 들어 최신의 열 기반 데이터베이스는 대량의 데이터를 스캔하도록 최적화되어 있으며, 확장성과 스캔 성능을 개선하기 위해 인덱스를 사용하지 않음. 
    - 모든 쿼리에는 일반적으로 크기가 100MB 이상인 최소 데이터 블록을 스캔하는 작업이 포함됨. 이러한 시스템에서 초당 수천 개의 개별 항목을 조회하려고 하면 그 사용 사례에 맞게 설계된 캐싱 계층과 결합되지 않는 한 시스템이 중단될 것 
    - OLAP라는 용어는 대규모 대화형 분석 쿼리를 지원하는 데이터베이스 시스템을 가리키는 데 사용되며, OLAP 큐브(데이터의 다차원 배열)를 지원하는 시스템에만 국한되지 않음. OLAP의 온라인 부분은 시스템이 들어오는 쿼리를 지속해 수신 대기한다는 뜻으로, OLAP 시스템이 대화형 분석에 적합하다는 것을 의미함. 
    - OLAP는 일반적으로 분석을 위한 스토리지 및 쿼리 시스템
  - 변경 데이터 캡처(Change data capture, CDC)
    - 데이터베이스에서 발생하는 각 변경 이벤트(입력, 갱신, 삭제)를 추출하는 방법. CDC는 데이터베이스 간에 거의 실시간으로 복제하거나 다운스트림 처리를 위한 이벤트 스트림을 생성하는 데 자주 사용됨 
    - CDC는 데이터베이스 기술에 따라 다르게 처리됨. 관계형 데이터베이스의 경우 스트림을 생성하기 위해 처리될 수 있는 이벤트 로그를 종종 생성해 데이터베이스 서버에 직접 저장함.
    - 많은 클라우드 NoSQL 데이터베이스는 로그 또는 이벤트 스트림을 목표로하는 스토리지 위치로 전송할 수 있음 
  - 로그 
    - 로그는 시스템에서 발생하는 이벤트에 대한 정보를 수집함. 예를 들어 로그는 웹 서버의 트래픽과 사용 패턴을 수집할 수 있음.
    - 데스크톱 컴퓨터 운영 체제(윈도우, macOS, 리눅스)의 경우 시스템 부팅 시 애플리케이션이 시작되거나 충돌할 때 등의 이벤트를 기록함 
    - 로그는 풍부한 데이터 원천으로서 다운스트림 데이터 분석, ML 및 자동화에 잠재적으로 유용함. 
    - 몇 가지 일반적인 로그 소스
      - 운영 체제
      - 애플리케이션
      - 서버
      - 컨테이너
      - 네트워크
      - IoT 장치
    - 모든 로그는 이벤트와 이벤트 메타데이터를 추적함. 로그는 최소한 누가, 무엇을, 언제 수행했는지를 수집해야 함 
      - 누구인가 : 이벤트와 관련된 사람. 시스템 또는 서비스 계정(예: 웹 브라우저 사용자 에이전트 또는 사용자 ID)
      - 무슨 일이 있었는가 : 이벤트 및 관련 메타데이터
      - 언제 발생했는가 : 이벤트의 타임스탬프 
    - 로그 인코딩
      - 로그는 몇 가지 방법으로 인코딩 됨 
        - 바이너리 인코딩 로그
          - 공간 효율과 빠른 I/O를 위해 데이터를 사용자 정의 압축 형식으로 인코딩함 
        - 반정형 로그
          - 객체 직렬화 형식(주로 JSON)의 텍스트로 인코딩됨. 이러한 로그는 기계가 읽을 수 있고 이식성이 뛰어남. 그러나 바이너리 로그보다 효율성이 훨씬 떨어짐.
          - 명목상으로는 기계 판독이 가능하지만, 가치를 추출하려면 상당한 사용자 정의 코드가 필요한 경우가 많음 
        - 일반 텍스트(비정형) 로그
          - 기본적으로 소프트웨어로부터의 코놋ㄹ 출력을 저장함. 따라서 범용 규격은 존재하지 않음. 이러한 로그는 원시 텍스트 데이터에서 유용한 정보를 추출하는 과정이 다소 복잡할 수 있지만, 데이터 과학자와 ML 엔지니어에게 유용한 정보를 제공할 수 있음 
    - 로그 해상도(log resolution)
      - 로그에 캡처된 이벤트 데이터의 양을 나타냄. 예를 들어 데이터베이스 로그는 데이터베이스 이벤트에서 충분한 정보를 캡처해 특정 시점의 데이터베이스 상태를 언제든지 재구성할 수 있음 
      - 특정 유형의 커밋 이벤트가 발생한 사실만 기록할 수 있음. 로그 레벨(log level)이란 로그 엔트리(entry)를 기록하는 데 필요한 조건, 특히 에러와 디버깅에 관한 조건. 예를 들어 소프트웨어는 모든 이벤트를 기록하거나 에러만 기록하도록 구성할 수 있음 
    - 로그 지연 시간: 배치 또는 실시간
      - 배치 로그는 종종 파일에 연속적으로 기록됨. 개별 로그 엔트리는 실시간 애플리케이션을 위해 카프카나 펄사와 같은 메시징 시스템에 기록할 수 있음 
  - 데이터베이스 로그
    - 로그 선행 기록(write-ahead logging, 일반적으로 특정 데이터베이스 네티이브 형식으로 저장된 바이너리 파일)은 데이터베이스 보장과 복구에 중요한 역할을 수행함.
    - 데이터베이스 서버는 데이터베이스 테이블에 대한 쓰기 및 갱신 요청을 수신하고, 각 작업을 로그에 저장한 후에 요청을 확인응답(acknowledgment)함. 
    - 확인 응답에는 로그 관련 보증이 포함되므로 서버에 장애가 발생해도 로그에서 미완성 작업을 완료함으로써 재부팅 시 상태를 복구할 수 있음
    - 데이터베이스 로그는 데이터 엔지니얼이에 꽤 유용한데, 특히 CDC가 데이터베이스 변경에서 이벤트 스트림을 생성하는 데 매우 유용함 
  - CRUD
    - 생성(create), 조회(read), 갱신(update), 삭제(delete)를 의미하는 CRUD는 프로그래밍에서 일반적으로 사용되는 트랜잭션 패턴으로, 영구 스토리지의 네 가지 기본적인 연산 작업을 나타냄. CRUD는 애플리케이션 상태를 데이터베이스에 저장하는 가장 일반적인 패턴
    - CRUD의 기본 원칙은 데이터를 사용하기 전에 생성해야 한다는 것. 일단 데이터가 생성되면 데이터를 조회하고 갱신할 수 있으며, 마지막에는 데이터를 삭제해야 할 수도 있음. CRUD는 스토리지와 관계없이 데이터에 대한 이러한 네 가지 연산을 수행할 수 있도록 보자앟ㅁ
    - CRUD는 소프트웨어 애플리케이션에서 널리 사용되는 패턴으로, 보통 API와 데이터베이스에서 CRUD가 사용됨 
    - 다른 모든 데이터베이스와 마찬가지로, 스냅숏 기반 추출을 사용해 애플리케이션이 CRUD 연산을 적용하는 데이터베이스로부터 데이터를 가져올 수 있음. 한편 CDC를 사용한 이벤트 추출은 운영의 완전한 연산 이력을 제공하며, 실시간에 가까운 분석을 가능하게 함 
  - 입력 전용(insert-only pattern)
    - 데이터를 포함하는 테이블에서 이력을 직접 유지함. 레코드를 갱신하는 대신, 새로운 레코드가 생성된 시점을 나타내는 타임스탬프와 함께 입력됨 
    - 단점
      - 각 변경 사항이 테이블에 입력되므로 특히 데이터가 자주 변경될 때는 테이블이 상당히 커질 수 있음. 테이블 크기를 적정하게 유지하기 위해 레코드 만료 일자 또는 레코드 버전의 최대 수에 따라 레코드가 삭제되는 경우가 있음 
      - 현재 상태를 조회할 때 MAX(created_timestamp)를 실행하기 때문에 레코드 조회 시 추가 오버헤드가 발생한다는 것 
  - 메시지와 스트림
    - 메시지는 둘 이상의 시스템 간에 전달되는 원시 데이터. 
      - 일반적으로 메시지는 게시자(publisher)에서 소비자(consumer)에게 메시지 큐를 통해 발송되며, 메시지가 전달되면 큐에서 삭제됨 
      - 메시지는 이벤트 기반 시스템에서 불연속적(이산적)이고 단일한 신호
    - 스트림(stream)은 이벤트 레코드의 추가 전용 로그(스트림은 이벤트 스트리밍 플랫폼에서 수집 및 저장됨)
      - 이벤트가 발생하면 순선대로 누적되며, 타임스탬프 또는 ID로 이벤트 순서를 정렬할 수 있음(분산 시스템의 미묘한 차이 때문에 이벤트가 항상 정확한 순서로 전달되지는 않는다는 점에 유의하자)
      - 여러 이벤트에 걸쳐 무슨 일이 일어났는지를 살펴볼 때 스트림을 사용할 수 있음. 스트림의 추가 전용 특성 때문에 레코드는 (수 주 또는 수개월에 이르는) 장기적인 보존 기간에 걸쳐 유지되므로, 여러 레코드의 집계 또는 스트림 내 특정 시점으로 되감기 기능과 같은 레코드의 복잡한 작업을 수행할 수 있음 
      - 스트림을 처리하는 시스템은 메시지를 처리할 수 있으며 스트리밍 플랫폼은 메시지 전달에 자주 사용됨. 메시지 분석을 수행할 때는 메시지를 스트림에 축적하는 경우가 많음 
  - 시간 유형
    - 데이터를 수집할 때 소요되는 주요 시간 유형 
    - 이벤트가 생성되는 시간
      - 이벤트 시간은 원본 시스템 자체의 타임스탬프를 포함해 원천 시스템에서 이벤트가 생성된 시점을 나타냄. 이벤트가 생성될 때는 이벤트가 수집되고 다운스트림으로 처리되기 전까지 미정의 시간 지연이 발생함 
      - 이벤트가 이동하는 각 단계의 타임스탬프를 항상 포함하자. 이벤트가 생성, 수집 및 처리되는 각 시간 단계에서 발생하는 이벤트를 로그에 기록하자. 이러한 타임스탬프 로그를 사용해 데이터 파이프라인을 통한 데이터 이동을 정확하게 추적할 수 있음 
    - 수집되고 처리되는 시간
      - 데이터가 생성된 후에는 어딘가로 수집됨. 수집 시간(ingestion time)은 원천 시스템에서 메시지 대기열, 캐시, 메모리, 객체 스토리지, 데이터베이스 또는 데이터가 저장된 다른 위치로 이벤트가 언제 수집되었는지를 나타냄
      - 수집 이후 데이터는 즉시 처리할 수도 있고 몇 분, 몇 시간 또는 며칠 이내에 처리할 수도 있으며 단순히 무기한 스토리지에 보관할 수도 있음 
    - 처리하는 데 걸리는 시간 
      - 처리 시간(process time)은 수집 시간 이후에 데이터가 처리(일반적으로 변환)될 때 발생함. 처리에 걸린 시간은 데이터를 처리하는 데 걸린 시간으로 초, 분, 시간 등으로 측정됨 
      - 데이터 워크플로를 따라 모니터링 기능을 설정해 이벤트가 언제 발생하는지, 언제 수집 및 처리되는지, 이벤트를 처리하는 데 걸린 시간은 얼마나 되는지 등의 세부 사항을 파악하자 
- 원천 시스템의 실질적인 세부 사항 
  - 데이터베이스 
    - 데이터베이스 기술을 이해하기 위한 주요 고려 사항 
      - 다양한 데이터베이스 기술 전반에 걸쳐 발생하는 주요 아이디어
        - 데이터베이스 관리 시스템
          - 데이터를 저장하고 제공하는 데 사용되는 데이터베이스 시스템으로, 줄여서 DBMS라고도 함 
          - 스토리지 엔진, 쿼리 옵티마이저, 재해 복구 및 데이터베이스 시스템 관리를 위한 기타 주요 컴포넌트로 구성됨 
        - 조회
          - 인덱스는 조회(lookup) 속도를 높이는 데 도움이 되지만, 모든 데이터베이스에 인덱스가 있는 건 아님
          - 만약 인덱스를 사용한다면 인덱스를 설계하고 유지 관리하는 가장 좋은 패턴은 무엇일까? 효율적인 추출을 위해 인덱스를 활용하는 방법을 이해하자. 
          - B-tree와 로그 구조 병합 트리(log-structured merge-tree, LSM)를 포함한 인덱스의 주요 유형에 대한 기본 지식도 있으면 도움이 됨 
        - 쿼리 옵티마이저
          - 데이터베이스는 쿼리 옵티마이저를 사용하는가? 그 특징은 무엇인가?
        - 확장과 분산
          - 수요에 따라 데이터베이스를 확장할 수 있는가? 어떤 확장 전략을 사용하는가? 수평 확장(데이터베이스 노드 증가)인가? 아니면 수직 확장(단일 머신에서 리소스 증가)인가?
        - 모델링 패턴
          - 데이터베이스에 가장 적합한 모델링 패턴(예: 데이터 정규화 또는 와이드 테이블)은 무엇인가?
        - CRUD
          - 데이터베이스에서 데이터를 쿼리, 생성, 갱신 및 삭제하는 방법은 무엇인가? 데이터베이스 유형에 따라 CRUD 작업은 다르게 처리됨 
        - 일관성
          - 데이터베이스가 완전한 일관성을 갖추고 있는가? 아니면 완화된 일관성 모델(예: 최종 일관성)을 지원하는가? 데이터베이스는 읽기 및 쓰기에 대해 선택적인 일관성 모드(예: 강력한 일관된 읽기)를 지원하는가?
    - 관계형 데이터베이스
      - 관계형 데이터베이스 관리 시스템(RDBMS)은 가장 일반적인 애플리케이션 백엔드 중 하나. 
      - 관계형 데이터베이스는 1970년대에 IBM이 개발했고 1980년대에 오라클이 대중화 했음. 인터넷의 성장과 함께 LAMP 스택(리눅스, 아파치 웹 서버, MySQL, PHP)이 등장했고 ,벤더 및 오픈 소스 RDBMS 옵션이 폭발적으로 증가 했음 
      - NoSQL 데이터베이스의 등장에도 불구하고 관계형 데이터베이스는 여전히 큰 인기를 끌고 있음 
      - 데이터는 관계(relation) 테이블(행)에 저장되며, 각 관계에는 여러 필드(field, 열)가 함됨
      - 테이블 내의 각 관계는 동일한 스키마(string, integer 또는 float 등의 정적 유형이 할당된 일련의 열)를 가짐. 행은 일반적으로 연속된 바이트 시퀀스로 디스크에 저장됨 
      - 테이블은 일반적으로 테이블의 각 행에 대한 고유 필드인 기본 키(primary key)에 의해 인덱싱됨. 기본 키에 대한 인덱싱 전략은 디스크에 있는 테이블의 레이아웃과 밀접하게 관련됨 
      - 테이블은 또한 다른 테이블의 기본 키 값과 연결된 값인 있는 필드인 다양한 외래 키를 가질 수도 잇음. 이러한 외래 키는 조인을 용이하게 하고 여러 테이블에 걸쳐 데이터를 분산하는 복잡한 스키마를 사용하게 해줌. 특히 정규화된 스키마를 설계할 수 있음. 정규화는 레코드의 데이터가 여러 곳에 중복되지 않도록 하려는 전략으로, 여러 곳의 상태를 동시에 갱신할 필요가 없으며 불일치를 방지할 수 있음 
      - RDBMS 시스템은 일반적으로 ACID를 준수함. 정규화된 스키마, ACID 컴플라이언스 및 높은 트랜잭션 비율 지원을 결합한 관계형 데이터베이스 시스템은 빠르게 변화하는 애플리케이션 상태를 저장하는 데 이상적 
    - 비관계형 데이터베이스: NoSQL
      - NoSQL은 not only SQL을 줄인 표현으로 ,관계형 패러다임을 포기한 모든 종류의 데이터베이스를 나타냄 
      - 관계형 제약 조건을 해제하면 성능, 확장성, 스키마 유연성을 높일 수 있음. 그러나 아키텍처에는 언제나 그렇듯 트레이드오프가 존재함. 또한 NoSQL 데이터베이스는 일반적으로 강력한 일관성, 조인 또는 고정 스키마와 같은 다양한 RDBMS 특성을 포기함 
      - 2000년대 초반 구글이나 아마존 같은 기술 기업들은 관계형 데이터베이스를 벗어나 자신들의 웹 플랫폼을 확장하기 위해 새로운 분산형 비관계형 데이터베이스를 개척하기 시작했음. NoSQL이라는 용어는 1998년에 처음 등장했지만, 최신 버전은 2000년대에 에릭 에반스가 만들었으며 2009년 블로그에 다음과 같은 글을 포스팅했음 
      - 데이터 엔지니어는 사용상 고려 사항, 저장할 데이터 구조, 데이터 엔지니어링 수명 주기에서 각 데이터베이스를 활용하는 방법 등 이러한 유형의 데이터베이스들을 이해해야 함 
      - 키-값 쌍 저장소
        - 키-값 데이터베이스는 각 레코드를 고유하게 식별하는 키를 사용해 레코드를 검색하는 비관계형 데이터베이스. 많은 프로그래밍 언어로 제공되는 해시 맵이나 사전 데이터 구조와 비슷하지만, 잠재적으로 확장성이 더 뛰어남.
        - 인메모리 키-값 데이터베이스는 초고속 검색과 높은 동시성이 요구되는 웹 및 모바일 애플리케이션의 세션 데이터를 캐싱하는 데 널리 쓰임. 이러한 시스템의 스토리지는 보통 일시적이며, 데이터베이스가 종료되면 데이터는 사라짐. 이러한 캐시는 기본 기본 애플리케이션 데이터베이스에 대한 부담을 줄이고 신속한 응답을 제공할 수 있음 
        - 키-값 저장소는 높은 내구성과 지속성이 요구되는 애플리케이션을 지원할 수도 있음 
      - 도큐먼트 저장소(document store)
        - 특화된 키-값 쌍 저장소. 도큐먼트는 중첩된 객체이며, 일반적으로 각 도큐먼트를 실질적인 목적을 위한 JSON 객체로 간주할 수 있음. 도큐먼트는 컬렉션에 저장되고 키로 검색됨. 컬렉션(collection)은 관계형 데이터베이스 테이블과 거의 동일함 
        - 관계형 데이터베이스와 도큐먼트 저장소의 중요한 차이점
          - 후자가 조인을 지원하지 않는다는 것. 즉, 데이터를 쉽게 정규화할 수 없으며 여러 테이블로 분할할 수 없음(애플리케이션은 여전히 수동으로 조인할 수 있음. 코드에서 도큐먼트를 조회(lookup)하고 속성(property)을 추출한 다음 다른 도큐먼트를 검색할 수 있음). 이상적으로는 모든 관련 데이터를 동일한 도큐먼트에 저장할 수 있음 
          - 대부분의 경우 동일한 데이터를 여러 컬렉션에 분산해 여러 도큐먼트에 저장해야 함. 소프트웨어 엔지니어는 저장소마다 속성을 갱신해야 함(많은 도큐먼트 저장소는 이를 용이하게 하기 위해 트랜잭션 개념을 지원함)
        - 도큐먼트 데이터베이스는 일반적으로 JSON의 모든 유연성을 수용하며 스키마나 유형을 강제하지 않는데, 이는 축복이자 저주로 작용할 수 있음. 한편으로는 스키마가 매우 유연하고 표현력이 풍부해지는데, 이 스키마는 애플리케이션의 성장에 따라 진화할 수도 있음 
        - 개발자가 스키마의 진화를 관리하는 데 주의를 기울이지 않으면 시간이 지남에 따라 데이터가 일관성 없이 비대해질 수 있음. 또한 스키마의 진화는 (배포 전) 적시에 전달되지 않으면, 다운스트림 수집을 중단시켜 데이터 엔지니어의 골칫거리가 될 수도 있음 
        - 대부분의 도큐먼트 데이터 베이스는 특정 속성별로 도큐먼트를 검색할 수 있도록 인덱스와 조회 테이블 생성을 지원함. 이는 종종 다양한 방법으로 도큐먼트를 검색해야 할 때 애플리케이션 개발에서 매우 유용함 
        - 데이터 엔지니어에게 중요한 또 다른 기술 세부 사항은 도큐먼트 저장소가 관계형 데이터베이스와 달리 일반적으로 ACID를 준수하지 않는다는 것. 성능, 튜닝, 구성, 쓰기에 대한 관련 효과, 일관성, 내구성 등을 이해하려면 특정 도큐먼트 저장소에 대한 기술적 전문 지식은 필수 요소.
          - 예를 들어 많은 도큐먼트 저장소는 결과적으로 일관성을 유지함. 클러스터에 걸쳐 데이터를 분산하면 확장성과 성능에 도움이 되지만, 엔지니어와 개발자가 그 의미를 이해하지 못하면 큰 문제로 이어질 수 있음 
        - 도큐먼트 저장소에서 분석을 실행하려면 일반적으로 엔지니어가 풀 스캔을 실행해 컬렉션에서 모든 데이터를 추출하거나 CDC 전략을 사용해 이벤트를 대상 스트림으로 보내야함.
          - 풀 스캔 방식은 성능과 비용 모두에 영향을 미칠 수 있음. 스캔 때문에 데이터베이스가 실행되는 속도가 느려지는 경우가 많으며, 많은 서버리스 클라우드 서비스에서는 풀 스캔마다 상당한 비용이 발생함.
          - 도큐먼트 데이터베이스에서 쿼리 속도를 높이기 위해 인덱스를 생성하는 것은 종종 유용함 
      - 와이드-컬럼(wide-column)
        - 와이드 컬럼 데이터베이스는 빠른 트랜잭션 속도와 매우 짧은 지연 시간으로 대량의 데이터를 저장하는 데 최적화되어 있음. 이러한 데이터베이스는 매우 빠른 쓰기 속도와 방대한 양의 데이터로 확장될 수 있음 
        - 와이드 컬럼 데이터베이스는 페타바이트급 데이터, 초당 수백만 건의 요청 및 10ms 미만의 지연 시간을 지원할 수 있음 
        - 와이드 컬럼 데이터베이스의 운영 특성을 파악해 적절한 구성을 설정하고, 스키마를 설계하며, 적절한 행 키를 선택해 성능을 최적화하고 일반적으로 발생하는 운영 문제를 방지해야 함 
        - 대량의 데이터에 대한 신속한 스캔을 지원하지만, 복잡한 쿼리를 지원하지는 않으며 조회용 인덱스(행 키)는 오직 1개뿐임
      - 그래프 데이터베이스(graph databse)
        - 수학적 그래프 구조(노드와 에지의 집합)로 데이터를 명시적으로 저장함. Neo4j는 매우 인기 있으며 아마존, 오라클 및 기타 벤더는 그들만의 그래프 데이터베이스 제품을 제공함. 대략적으로 말하자면 요소(element)간 연결성을 분석할 때 그래프 데이터베이스는 매우 적합함 
        - 요소 간 연결을 기반으로 쿼리를 수행할 수 있으므로, 요소 간의 복잡한 순회를 이해해야 할 때는 그래프 데이터베이스가 적합함. 그래프 용어로 설명하자면, 우리는 노드와 에지를 저장함. 그래프 데이터베이스는 노드와 에지 모두에 대한 풍부한 데이터 모델을 지원함. 기본 그래프 데이터베이스 엔진에 따라 그래프 데이터베이스는 SPARQL, 자원 기술 프레임워크(RDF), GraphQL(GQL), 사이퍼(Cyper)등의 특수 쿼리 언어를 사용함 
        - 도큐먼트 또는 비정형 데이터를 다루는 데 익숙한 데이터 엔지니어에게 고유한 과제를 제기함. 엔지니어는 다음과 같은 작업을 수행할지 여부를 선택해야 함 
          - 원천 시스템 그래프 데이터를 기존에 선호하는 패러다임 중 하나로 매핑
          - 원천 시스템 자체 내애서 그래프 데이터 분석
          - 그래프별 전용 분석 도구 채택
        - 그래프 데이터는 관계형 데이터베이스의 행으로 다시 인코딩할 수 있으며, 분석 사용 사례에 따라 적합한 솔루션이 될 수 있음. 트랜잭션 그래프 데이터베이스도 분석용으로 설계되어 있지만, 대규모 쿼리가 운영 시스템에 과부하를 줄 수 있음. 최신의 클라우드 기반 그래프 데이터베이스는 대량의 데이터에 대한 읽기 중심의 그래프 분석을 지원함 
      - 검색 
        - 검색 데이터베이스는 데이터의 복잡하면서도 직관적인 의미와 구조적 특성을 검색하는 데 사용되는 비관계형 데이터베이스 
        - 텍스트 검색(text search)은 텍스트 본문에서 키워드 또는 구문을 검색해 정확히 일치하거나, 모호하거나, 의미적으로 유사한 일치 항목을 찾아내는 것. 로그 분석은 일반적으로 이상탐지, 실시간 모니터링, 보안 분석 및 운영 분석에 사용됨. 인덱스를 사용하면 쿼리를 최적화하고 속도를 높일 수 있음 
        - 데이터 엔지니어는 검색 데이터베이스(일래스틱서치, 아파치 솔라, 아파치 루씬, 알골리아 등)의 데이터를 다운스트림 KPI 보고서 또는 이와 비슷한 것으로 가져와야 할 수도 있음 
      - 시계열(time series)
        - 시계열 데이터베이스는 시계열 데이터의 검색과 통계 처리에 최적화됐음 
        - 시계열 데이터베이스는 IoT, 이벤트 및 애플리케이션 로그, 애드테크, 핀테크 등 다양한 사용 사례에서 고속으로 증가하는 데이터 용량의 요구 사항을 해결함. 이러한 워크로드는 쓰기 작업이 많은 편이며, 그 결과 시계열 데이터베이스는 메모리 버퍼링을 사용해 빠른 쓰기와 읽기를 지원하는 경우가 많음 
        - 온도 또는 공기 품질 센서와 같은 측정 데이터(measurement data)는 정기적으로 생성됨 
        - 이벤트 기반 데이터는 모션 센서가 움직임을 감지할 때처럼 이벤트가 발생할 때마다 생성되는 불규칙한 데이터 
        - 시계열 스키마에는 일반적ㄹㄱ으로 타임스탬프와 작은 필드 집합이 포함됨. 데이터는 시간에 따라 달라지므로 타임스탬프에 따라 정렬됨. 따라서 시계열 데이터베이스는 운영 분석에는 적합하지만, BI 사용 사례에는 적합하지 않음. 조인은 일반적이지 않지만, 아파치 드루이드와 같은 일부 준 시계열 데이터베이스는 조인을 지원함 
  - API
    - REST(representational state transfer)
      - RESTE는 GET과 PUT 같은 HTTP 동사를 중심으로 구축되었지만, 실제로 현대의 REST는 원래의 논문에 기재된 동사 매핑 중 일부만 사용함 
      - REST의 주요 아이디어 중 하나는 상호 작용이 (상태를 저장하지 않는) 무상태성(stateless)이라는 것. 리눅스 터미널 세션과 달리 작업 디렉터리와 같은 관련 상태 변수를 가진 세션의 개념은 없으며, 각 REST 호출은 독립적. REST 호출은 시스템 상태를 변경할 수 있지만, 이러한 변경은 현재 세션이 아닌 전체 시스템에 적용되는 전역 변경 사항임
      - REST API에서 데이터 수집 파이프라인 설정이 간소화됐음 
        - 데이터 공급자는 다양한 언어(특히 파이썬)에서 클라이언트 라이브러리를 제공하는 경우가 많음. 클라이언트 라이브러리는 API 상호 작용 코드를 구축하는 데 필요한 대부분의 표준 문안(기본 코드) 작업을 제거함. 클라이언트 라이브러리는 인증과 같은 중요한 세부 정보를 처리하고 기본 메서드를 접근 가능한 클래스에 매핑함 
        - API와 상호 작용하고 데이터 동기화를 관리하는 다양한 서비스와 오픈 소스 라이브러리가 등장했음. 많은 SaaS 및 오픈 소스 벤더가 공통 API를 위한 상용 커넥터를 제공함. 플랫폼에서는 필요에 따라 맞춤형 커넥터 구축 프로세스도 단순해짐 
    - GraphQL
      - 애플리케이션 데이터의 쿼리 언어이자 일반적인 REST API의 대안으로 페이스북에서 만들었음. 일반적으로 REST API는 쿼리를 특정 데이터 모델로 제한하지만, GraphQL은 단일 요청으로 여러 데이터 모델을 검색할 수 있는 가능성을 열어줌 
      - REST 보다 유연하고 표현력이 풍부한 쿼리를 수행할 수 있음. GraphQL은 JSON을 중심으로 구축되며 JSON 쿼리와 유사한 형태로 데이터를 반환함 
    - 웹훅(webhook)
      - 단순한 이벤트 기반 데이터 전송 패턴. 데이터 원본은 애플리케이션 백엔드, 웹 페이지 또는 모바일 앱일 수 있음. 
      - 원천 시스템에서 지정된 이벤트가 발생하면 데이터 소비자가 호스팅하는 HTTP 엔드포인트에 대한 호출이 트리거됨. 일반적인 API와는 반대로, 원천 시스템에서 데이터 싱크로 연결이 진행된다는 점에 유의하자. 이러한 이유로 웹훅은 종종 역 API(reverse API)라고 불림 
    - RPC와 gRPC
      - 원격 프로시저 호출(RPC, remote procedure call)은 분산 컴퓨팅에서 일반적으로 사용됨. 이를 통해 원격 시스템에서 프로시저를 실행할 수 있음 
      - gRPC는 2015년 구글에서 내부적으로 개발한 원격 프로시저 호출 라이브러리로, 이후 개방형 표준으로 출시됐음 
      - gRPC는 마찬가지로 구글이 개발한 프로토콜 버퍼 개방형 데이터 직렬화 표준(Protocol Buffers open data serialization standard)을 기반으로 구축됨 
      - gRPC는 HTTP/2를 통한 효율적인 양방향 데이터 교환을 강조함. 효율성이란 CPU 사용률, 소비 전력, 배터리 수명, 대역폭 같은 측면을 의미함. GraphQL과 마찬가지로 gRPC는 REST보다 훨씬 더 구체적인 기술 표준을 적용하므로 공통 클라이언트 라이브러리를 사용할 수 있고 엔지니어가 모든 gRPC 상호 작용 코드에 적용되는 기술 셋(skill set)을 개발할 수 있음 
  - 데이터 공유
    - 클라우드 데이터 공유의 핵심 개념은 멀티테넌트 시스템이 테넌트 간의 데이터 공유를 위한 보안 정책을 지원한다는 것. 구체적으로는 세분화된 권한 시스템을 갖춘 퍼블릭 클라우드 객체 스토리지 시스템이 데이터 공유를 위한 플랫폼이 될 수 있음. 널리 사용되는 클라우드 데이터 웨어하우스 플랫폼도 데이터 공유 기능을 지원함 
    - 많은 최신 공유 플랫폼(특히 클라우드 데이터 웨어하우스)은 행, 열, 중요한 데이터 필터링을 지원함. 또한 데이터 공유는 몇몇 일반적인 클라우드와 데이터 플랫폼에서 제공되는 데이터 마켓플레이스의 개념을 간소화함. 
      - 데이터 마켓플레이스는 데이터 상거래를 위한 중앙 집중식 위치를 제공하므로, 데이터 공급자는 데이터 대한 네트워크 접근 관리의 세부 사항을 걱정하지 않고 제품을 광고하거나 판매할 수 있음 
    - 데이터 공유는 조직 내 데이터 파이프라인을 간소화할 수도 있음. 데이터 공유를 통해 조직 단위에서 데이터를 관리하고 선택적으로 다른 단위와 공유할 수 있으며, 개별 부서에서는 컴퓨팅 및 쿼리 비용을 개별적으로 관리할 수 있어 데이터 분산이 용이해짐. 이는 데이터 메시와 같은 분산형 데이터 관리 패턴을 촉진함 
  - 서드파티 데이터 원천 
    - 기업이 데이터를 제공하려는 이유는 무엇일까? 데이터는 고정적이며, 사용자 애플리케이션에 자사 애플리케이션을 통합하고 확장할 수 있도록 함으로써 플라이휠(flywheel)이 만들어짐. 사용자 채택과 사용률이 높아진다는 것은 데이터가 더 많아짐을 의미하며, 이는 사용자가 애플리케이션과 데이터 시스템에 더 많은 데이터를 통합할 수 있다는 것을 의미함. 그 부작용은 서드파티 데이터 소스가 거의 무한대에 달한다는 것
    - 서드파티 데이터에 직접 접근하는 것은 일반적으로 API, 클라우드 플랫폼에서의 데이터 공유 또는 데이터 다운로드를 통해 이뤄짐. API는 종종 심층적인 통합 기능을 제공해 고객이 데이터를 끌어오고(pull) 내보낼(push) 수 있도록 함 
    - 예를 들어 많은 CRM은 사용자가 시스템과 애플리케이션에 통합할 수 있는 API를 제공함. CRM에서 데이터를 가져와 고객 스코어링 모델을 통해 CRM 데이터를 혼합한 다음, 역 ETL을 사용해 해당 데이터를 CRM으로 다시 전송해 영업 담당자가 더 적합한 잠재 고객에게 연락할 수 있도록 하는 일반적인 워크플로를 볼 수 있음 
  - 메시지 큐와 이벤트 스트리밍 플랫폼 
    - 이벤트 기반 아키텍처는 널리 보급되어 있으며 점점 인기 있어지고 있음 
      - (이벤트 기반 아키텍처의 핵심 계층인) 메시지 큐와 이벤트 스트리밍 플랫폼은 클라우드 환경에서 더 쉽게 설정하고 관리할 수 있음 
      - (실시간 분석을 직접 통합하는 애플리케이션인) 데이터 앱이 점차 증가하고 있음 
    - 이벤트 기반 아키텍처는 이벤트가 애플리케이션 작업을 트리거하고 실시간에 가까운 분석을 제공할 수 있으므로 이러한 환경에 이상적 
    - 메시지 큐(message queue)
      - 게시 및 구독 모델을 사용해 개별 시스템 간에 데이터(일반적으로 킬로바이트 수준의 작은 개별 메시지)를 비동기적으로 전송하는 메커니즘. 
      - 데이터는 메시지큐에 게시되어 1명 이상의 구독자에게 전달됨. 구독자는 메시지를 수신했음을 확인하고 큐에서 메시지를 삭제함 
      - 메시지 큐를 사용하면 애플리케이션과 시스템을 서로 분리할 수 있으며 마이크로서비스 아키텍처에서 널리 사용됨. 메시지 큐는 메시지를 버퍼링해 일시적인 부하 급증을 처리하고, 복제 기능을 갖춘 분산 아키텍처를 통해 메시지를 내구성 있게 보존함 
      - 메시지 큐는 분리된 마이크로서비스와 이벤트 기반 아키텍처의 핵심 요소. 메시지 큐에서 주의할 사항은 전달 빈도, 메시지 순서 지정 및 확장성 
      - 메시지 순서 지정 및 전달
        - 메시지가 생성, 전송, 수신되는 순서는 다운스트림 사용자에게 큰 영향을 미칠 수 있음. 일반적으로 분산 메시지 큐의 순서는 까다로운 문제
        - 메시지 큐는 종종 모호한 순서와 선입선출(FIFO) 개념을 적용함. 엄격한 FIFO는 메시지 A가 메시지 B보다 먼저 수집되면 메시지 A가 항상 메시지 B보다 먼저 전달된다는 의미. 실제로 메시지는 (특히 고도로 분산된 메시지 시스템에서) 잘못된 순서로 게시되거나 수신될 수 있음. 
      - 전달 빈도
        - 메시지가 정확히 한 번만 전송하거나 또는 적어도 한 번 전송할 수 있음.
          - 메시지가 정확히 한 번 발송되면 사용자가 메시지를 확인한 뒤 메시지는 사라지며 다시 전달되지 않음 
          - 적어도 한 번 송신된 메시지는 여러 명의 유저 또는 같은 유저가 2회 이상 소비할 수 있음. 이는 중복 또는 여분의 문제가 되지 않는 경우에 매우 유용함 
        - 이상적으로 시스템이 멱등성(idempotent) 상태여야 함. 멱등적인 시스템에서 메시지를 한 번 처리한 결과는 메시지를 여러 번 처리한 결과와 같음. 이를 통해 다양한 미묘한 시나리오를 설명할 수 있음 
      - 확장성 
        - 이벤트 기반 애플리케이션에서 가장 많이 사용되는 메시지 큐는 수평으로 확장 가능하며 여러 서버에서 실행됨. 따라서 이들 큐는 동적으로 스케일 업과 스케일 다운을 할 수 있으며, 시스템이 뒤처졌을 때 메시지를 버퍼링하고 장애에 대한 복원력을 확보하기 위해 메시지를 내구성 있게 저장할 수 있음 
    - 이벤트 스트리밍 플랫폼(event-streaming platform)
      - 메시지가 생산자로부터 소비자에게 전달된다는 점에서 어떤 면에서는 메시지 큐의 연장선에 있음. 
      - 메시지와 스트림의 큰 차이는 메시지 큐가 주로 특정 전달을 보장하는 메시지 라우팅에 사용된다는 것. 이와는 대조적으로, 이벤트 스트리밍 플랫폼은 정렬된 레코드 로그에서 데이터를 수집하고 처리하는데 사용됨. 이벤트 스트리밍 플랫폼에서는 데이터가 잠깐 유지되어 과거 시점의 메시지를 재생할 수 있음 
      - 토픽
        - 이벤트 스트리밍 플랫폼에서 생산자는 관련 이벤트 모음인 토픽에 이벤트를 스트리밍함.
        - 예를 들어 토픽에는 이상 거래 탐지, 고객 주문 또는 IoT 장치의 온도 측정값이 포함될 수 있음. 대부분의 이벤트 스트리밍 플랫폼에서는 하나의 토픽에 0개, 1개 또는 여러 개의 생산자와 소비자를 포함할 수 있음 
      - 스트림 파티션(stream partition)
        - 스트림을 여러 스트림으로 분할한 것. 예를 들어 다차선 고속도로에 비유할 수 있는데, 차선이 여러 개 있으면 병렬화와 더 높은 처리량을 실현할 수 있음. 메시지는 파티션 키에 따라 파티션 간에 분산됨. 파티션 키가 같은 메시지는 항상 같은 파티션에 저장됨 
        - 스트림 파티셔닝의 주요 관심사는 파티션 키가 핫스폿팅(hotspotting, 파티션 하나에 전달되는 메시지의 수가 불균형한 현상)을 생성하지 않게 하는 것. 예를 들어 IoT 장치가 미국의 특정 주에 있다고 알려진 경우 해당 주를 파티션 키로 사용할 수 있음 
        - 파티션 키를 사용해 파티션 간에 메시지를 균등하게 분배해야 함 
      - 내결함성과 복원성
        - 이벤트 스트리밍 플랫폼은 일반적으로 다양한 노드에 스트림이 저장되는 분산형 시스템. 노드가 다운되면 다른 노드가 해당 노드를 대체해 스트림에 계속 접근할 수 있음. 즉, 레코드는 손실되지 않으며 레코드를 삭제할 수도 있지만, 이는 또 다른 이야기 
        - 내결함성(tolerance)과 복원성(resilience) 덕분에 스트리밍 플랫폼은 이벤트 데이터를 안정적으로 생성, 저장 및 수집할 수 있는 시스템이 필요할 때 좋은 선택이 될 수 있음 
- 함께 작업할 대상 
  - 시스템 이해관계자(systems stakeholder)는 원천 시스템을 구축 및 유지 관리하며 소프트웨어 엔지니어, 애플리케이션 개발자, 서드파티 등이 이에 해당함.
  - 데이터 이해관계자는 원하는 데이터에 대한 접근을 소유하고 제어하며, 일반적으로 IT, 데이터 거버넌스 그룹 또는 서드파티에서 처리함 
  - 올바른 소프트웨어 엔지니어링, 데이터베이스 관리 및 개발 관행을 따르는 이해관계자의 능력에 의해 좌우됨. 이상적으로는 이해관계자가 데브옵스를 수행하고 애자일하게 작업하는게 좋음.
  - 데이터 엔지니어와 원천 시스템의 이해관계자 사이에 피드백 루프를 만들어 데이터의 소비와 사용 방법에 대한 인식을 형성하는게 좋음. 이는 데이터 엔지니어가 큰 가치를 얻을 수 있지만 가장 간과되고 있는 분야 중 하나. 업스트림 소스 데이터에 (스키마 변경, 데이터 변경, 서버 또는 데이터베이스 장애, 기타 중요한 이벤트 등) 어떤 문제가 발생할 경우에는 이러한 문제가 데이터 엔지니어링 시스템에 미치는 영향을 확실히 인식해야 함 
  - 업스트림 원천 시스템 소유자와 데이터 계약을 체결하면 도움이 될 수 있음. 이때 데이터 계약이란 무엇인가? 제임스 덴모어는 다음과 같이 정의함 
    - 데이터 계약은 원천 시스템의 소유자와 데이터 파이프라인에서 사용하기 위해 해당 시스템에서 데이터를 수집하는 팀 간의 서면 계약. 계약에는 어떤 방법(전체, 증분)으로, 얼마나 자주, 어떤 데이터가 추출되는지, 그리고 누가(사람,팀) 원천 시스템과 수집 모두에 대한 연락처인지를 명시해야 함. 
    - 데이터 계약은 깃허브 리포지터리 또는 내부 문서 사이트와 같이 잘 알려져 있고 찾기 쉬운 위치에 저장해야 함. 가능하면 데이터 계약을 표준화된 형식으로 지정해 개발 프로세스에 통합하거나 프로그래밍 방식으로 쿼리할 수 있도록 함 
  - 업스트림 제공업체와 SLA 설정도 검토하자. SLA는 의존하는 원천 시스템에서 기대할 수 있는 사항에 대한 기대치를 제공함. SLA의 예로는 안정적으로 사용할 수 있고 고품질인 원천 시스템의 데이터등이 있음. 
  - 서비스 수준 목표(SLO)는 SLA에서 합의한 내용과 비교해 성능을 측정함. 예를 들어 SLA의 예에 따르면 SLO는 원천 시스템의 가동 시간은 99%이다 등일 수 있음. 데이터 계약 또는 SLA/SLO가 너무 형식적이라고 생각될 때는 최소한 구두로 업타임, 데이터 품질 및 기타 중요한 사항에 대한 원천 시스템의 보증 관련 기대치를 설정함 
- 드러나지 않는 요소가 원천 시스템에 미치는 영향 
  - 데이터 엔지니어는 원천 시스템에서 데이터가 생성될 때 드러나지 않는 요소가 적용되도록 가능한 한 많은 업스트림 지원을 받아야 함 
  - 보안
    - 고려해야할 영역
      - 원천 시스템은 데이터가 저장 및 전송되는 동안 데이터를 안전하게 암호화하도록 설계되어 있는가?
      - 공용 인터넷을 통해 원천 시스템에 접근해야 하는가? 아니면 가상 프라이빗 네트워크(VPN)를 사용하는가?
      - 원천 시스템에 대한 비밀번호, 토큰 및 자격 증명을 안전하게 보관하라. 예를 들어 SSH(Secure Shell) 키를 사용하는 경우에는 키 관리자를 사용해 키를 보호함
      - 비밀번호에도 동일한 규칙이 적용됨. 비밀번호 관리자 또는 SSO(Single Sign-On) 벤더를 활용하자 
      - 원천 시스템을 신뢰하는가? 원천 시스템이 합법적인지 확인하되 항상 신뢰해야 함. 당신은 악의적인 행위자로부터 데이터를 수신하고 싶지는 않을 것 
  - 데이터 관리
    - 고려해야 할 영역 
      - 데이터 거버넌스 : 업스트림 데이터와 시스템 신뢰성이 높고 이해하기 쉬운 방식으로 관리되고 있는가? 누가 데이터를 관리하는가?
      - 데이터 품질 : 업스트림 시스템에서 데이터 품질과 무결성(integrity)을 어떻게 보장하는가? 원천 시스템 팀과 협력해 데이터 및 통신에 대한 기대치를 설정하자 
      - 스키마 : 업스트림 스키마가 변경되리라 에상하자. 가능한 경우 원천 시스템 팀과 협력해 스키마 변경에 대한 알림을 받자
      - 마스터 데이터 관리 : 업스트림 레코드의 생성은 마스터 데이터 관리 관행 또는 시스템에 의해 제어되고 있는가?
      - 개인정보보호와 윤리 : 원시 데이터에 접근할 수 있는가? 아니면 데이터가 난독화되는가? 소스 데이터의 의미는 무엇인가? 얼마나 오래 보존되는가? 보존 정책에 따라 위치가 변경되는가?
      - 규정 : 규정에 따라 데이터에 접근해야 하는가?
  - 데이터 옵스
    - 운영 우수성(데브옵스, 데이터옵스, MLOps, XOps)은 전체 스택을 위아래로 확장하고 데이터 엔지니어링과 수명 주기를 지원해야 함
    - 원천 시스템의 가동 시간과 사용률은 관찰 및 모니터링하고 사고가 발생했을 때 대응할 수 있어야 함 
    - 고려사항
      - 자동화
        - 코드 갱신이나 새로운 기능 등 원천 시스템에 영향일 미치는 자동화가 있음. 그리고 데이터 워크플로에 대해 설정한 데이터옵스 자동화가 있음. 원천 시스템의 자동화 문제가 데이터 워크플로 자동화에 영향을 미치는가? 그렇다면 이러한 시스템을 분리해 독립적으로 자동화를 수행할 수 있도록 하자.
      - 관찰 가능성
        - 운영 중단이나 데이터 품질 문제 등 원천 시스템에 문제가 발생했을 때는 어떻게 알 수 있는가? 원천 시스템 가동 시간 모니터링을 설정하자(또는 원천 시스템을 소유한 팀이 작성한 모니터링을 사용하자)
        - 원천 시스템의 데이터가 다운스트림 사용에 대한 예상과 일치하는지 확인할 수 있는 검사를 설정하자. 예를 들어 데이터의 품질은 양호한가? 스키마가 적합한가? 고객 기록은 일관성이 있는가? 사내 정책에 따라 데이터가 해시 처리되고 있는가? 
      - 사고 대응
        - 문제가 발생하면 어떻게 대처할 것인가? 예를 들어 원천 시스템이 오프라인으로 전환되면 데이터 파이프라인은 어떻게 작동하는가? 원천 시스템이 다시 온라인 상태가 되면 손실된 데이터를 다시 채울 계획은 무엇인가? 
  - 데이터 아키텍처
    - 고려해야할 사항
      - 신뢰성
        - 모든 시스템은 어느 시점에서 엔트로피에 시달리게 되며 출력은 예상에서 벗어날 것
        - 버그가 발생하고 무작위적인 결함이 발생함. 시스템이 예측 가능한 출력을 생성하는가? 시스템의 장애 발생 빈도는 어느 정도인가? 시스템을 충분한 신뢰성으로 되돌리기 위해 수리하는 데 걸리는 평균 시간은 얼마나 되는가?
      - 내구성
        - 모든 것은 실패함. 서버가 다운되거나 클라우드의 영역 또는 지역이 오프라인 상태가 되거나 다른 문제가 발생할 수 있음. 불가피한 장애 또는 운영 중단이 관리되는 데이터 시스템에 미치는 영향을 고려해야 함 
        - 원천 시스템은 하드웨어 장애 또는 네트워크 장애에 따른 데이터 손실을 어떻게 처리하는가? 장기간에 걸친 운영 중단에 대처하고 그 폭발 반경을 제한하는 계획은 무엇인가?
      - 가용성
        - 원천 시스템이 예정된 시간에 정상적으로 가동되고 실행되며 사용할수 있음을 보증하는 것은 무엇인가?
      - 사람
        - 원천 시스템의 설계는 누가 담당하며 아키텍처에 변경이 가해질지를 어떻게 알 수 있는가? 데이터 엔지니어는 원천 시스템을 유지 관리하는 팀과 협력해 이러한 시스템이 안정적으로 설계되도록 확인해야 함
        - 원천 시스템 팀과 SLA를 작성해 잠재적인 시스템 장애에 대한 예상치를 설정하자 
  - 오케스트레이션
    - 고려해야할 사항
      - 주기와 빈도
        - 데이터가 정해진 일정에 따라 제공되는가? 아니면 언제든지 새로운 데이터에 접근할 수 있는가?
      - 공통 프레임워크
        - 소프트웨어 엔지니어와 데이터 엔지니어가 동일한 컨테이너 관리 툴(예: 쿠버네티스)을 사용하는가? 애플리케이션과 데이터 워크로드를 동일한 쿠버네티스 클러스터에 통합하는 것이 의미가 있는가?
        - 에어플로와 같은 오케스트레이션 프레임워크를 사용하는 경우, 이를 업스트림 애플리케이션 팀과 통합하는 것이 합리적인가? 
  - 소프트웨에 엔지니어링
    - 원천 시스템에 접근하는 코드를 작성할 때 고려해야 할 사항들 
      - 네트워킹
        - 코드가 원천 시스템이 있는 네트워크에 접근할 수 있는지 확인함. 또한 보안이 고려된 네트워킹에 대해서도 항상 고려하자.
        - 공용 인터넷, SSH 또는 VPN 경유로 HTTPS URL에 접근하고 있는가?
      - 인증과 권한
        - 원처 시스템에 접근하기 위한 적절한 자격 증명(토큰, 사용자 이름/패스워드)을 가지고 있는가? 
        - 코드 또는 버전 컨트롤에 표시되지 않도록 이러한 자격ㅇ 증명을 어디에 저장할 것인가? 코드화된 작업을 수행할 올바른 IAM 역할이 있는가?
      - 접근 패턴
        - 데이터에 어떻게 접근하는가? API를 사용하고 있는가? REST/그래프 QL 요청, 응답 데이터 볼륨 및 페이지 수는 어떻게 처리하고 있는가?
        - 데이터베이스 드라이버를 통해 데이터에 접근할 경우에는 해당 드라이버가 접근 중인 데이터베이스와 호환되는가? 모든 접근 패턴에서 재시도나 타임아웃 등은 어떻게 처리되는가?
      - 오케스트레이션
        - 코드가 오케스트레이션 프레임워크와 통합되며 오케스트레이션 워크플로를 실행될 수 있는가? 
      - 병렬화 
        - 원천 시스템에 대한 병렬 접근을 어떻게 관리하고 확장하고 있는가?
      - 배포
        - 소스 코드 변경 사항의 배포를 어떻게 처리하고 있는가?

## 데이터 저장
- 원천 시스템은 일반적으로 데이터 엔지니어가 유지 관리하거나 제어하지 않음. 데이터 엔지니어가 직접 처리하는 스토리지는 분석 및 데이터 과학으로 그 가치를 제공하기 위해 원천 시스템에서 데이터를 수집하는 단계부터 데이터를 제공(서빙)하는 단계까지의 데이터 엔지니어링 단계를 포괄함 
- 데이터 스토리지의 기본 구성 요소
  - 데이터 엔지니어는 여전히 기본 구성 요소의 본질적인 특성, 성능, 고려 사항, 내구성, 비용에 관해 알고 있어야 함 
  - 대부분의 데이터 아키텍처에서 데이터는 데이터 파이프라인의 다양한 처리 단계를 거치면서 자기 스토리지, SSD, 메모리를 통과하는 경우가 많음. 데이터 스토리지와 쿼리 시스템은 일반적으로 분산 시스템, 다양한 서비스 그리고 여러 하드웨어 스토리지 계층과 관련된 복잡한 레시피(방안)를 따름 
  - 데이터 스토리지의 몇 가지 기본 구성 요소인 디스크 드라이브, 메모리, 네트워킹과 CPU, 직렬화 ,압축, 캐싱 등을 살펴보자
  - 자기 디스크 드라이브(magnetic disk)
    - 강자성 필름으로 코팅된 회전 플래터를 사용함. 이 필름은 쓰기 작업 중에 읽기/쓰기 헤드에 의해 자회되어 바이너리 데이터를 물리적으로 인코딩함. 읽기/쓰기 헤드는 읽기 작업 중에 자기장을 감지하고 비트 스트림을 출력함. 자기 디스크 드라이브는 오래전부터 사용되어 왔으며, 저장된 데이터의 기가바이트당 가격이 SSD보다 훨씬 저렴하므로 여전히 대용량 데이터 스토리지 시스템의 근간을 이룸 
    - HDD와 SSD는 각각 회전식 자기 디스크와 솔리드 스테이트 드라비를 각각 나타내는 용어 
    - 제한 사항
      - 데이터를 읽고 쓸 수 있는 속도인 디스크 전송 속도는 디스크 용량에 비례해 확장되지 않음 
      - 탐색 시간. 데이터에 접근하려면 드라이브가 읽기/쓰기 헤드를 디스크의 적절한 트랙으로 물리적으로 재배치해야 함.
      - 디스크 컨트롤러는 디스크에서 특정 데이터를 찾기 위해 읽기/쓰기 헤드 아래에서 해당 데이터가 회전할 때까지 기다려야 하며 그에 따라 회전 지연(rotational latency)이 발생함 
      - 트랜잭션 데이터베이스에 중요한 초당 입출력 작업 횟수, 즉 아이옵스(IOPS,input/output operations per second)
    - 자기 디스크는 데이터 스토리지 비용이 저렴하기 때문에 여전히 데이터 센터에서 선호됨. 또한 자기 드라이브는 병렬 처리를 통해 매우 높은 전송 속도를 유지할 수 있음. 클라우드 객체 스토리지의 핵심 개념은 클러스터 내의 수천 개의 디스크에 데이터를 분산할 수 있다는 것.
    - 데이터 전송 속도는 디스크 전송 속도가 아닌 네트워크 성능에 따라 제한되므로 여러 디스크에서 동시에 읽으면 극적으로 증가함. 따라서 네트워크 컴포넌트와 CPU는 스토리지 시스템의 주요 기본 컴포넌트이기도 함 
  - SSD(solid-state drive)
    - 솔리드 스테이트 드라이브는 플래시 메모리 셸에 데이터를 전하로 저장함. SSD는 자기 드라이브의 기계적 구성 요소를 제거하고, 데이터를 순전히 전자적인 방법으로 읽음 
    - SSD는 스토리지를 여러 개의 스토리지 컨트롤러가 병렬로 실행되는 파티션으로 분할해 데이터 전송 속도와 IOPS를 모두 확장할 수 있음 
    - 탁월한 성능 특성에 힘입어 SSD는 트랜잭션 데이터베이스에 혁신을 일으켰으며 OLTP 시스템의 상용 구현를 위한 공인된 표준으로 인정받고 있음. SSD는 초당 수천 건의 트랜잭션을 처리하는 PostgreSQL, MySQL, SQL 서버와 같은 관계형 데이터베이스를 지원함 
    - 일반적으로 상용 SSD의 경우 기가바이트당 20~30센트(USD)로, 자기 드라이브 용량당 비용의 거의 10배에 달함. 따라서 자기 디스크의 객체 스토리지는 데이터 레이크와 클라우드 데이터 웨어하우스의 대규모 데이터 스토리지를 위한 주요 옵션으로 부상했음 
    - SSD는 OLAP 시스템에서 여전히 중요한 역할을 담당함. 일부 OLAP 데이터베이스는 SSD 캐싱을 활용해 자주 접근하는 데이터에 대한 고성능 쿼리를 지원함. 지연 시간이 짧은 OLAP가 보급됨에 따라 이러한 시스템의 SSD 사용률도 증가할 것으로 예상됨 
  - 임의 접근 메모리(RAM, random-access memory)
    - RAM의 몇가지 특징
      - CPU에 연결되고 CPU 주소 공간에 매핑됨
      - CPU가 실행하는 코드와 이 코드가 직접 처리하는 데이터를 저장함 
      - 임의 접근 메모리는 휘발성(volatile)이며 자기 드라이브와 SSD는 비휘발성(nonvolatile). 때때로 장애가 발생해 데이터가 손상되거나 손실될 수 있지만, 일반적으로 드라이브는 전원을 꺼도 데이터를 유지함.RAM은 전원이 공급되지 않으면 1초 이내에 데이터가 손실됨 
      - SSD 스토리지보다 훨씬 빠른 전송 속도와 빠른 검색 시간을 제공함 
      - SSD 스토리지보다 훨씬 비싼 GB당 약 10억달러이다
      - 개별 CPU 및 메모리 컨트롤러에 연결된 RAM의 양에 제한이 있음. 이에 따라 복잡성과 비용이 더욱 증가함. 일반적으로 대용량 메모리 서버는 서로 연결된 여러 CPU를 1개의 보드로 사용하며,각 보드에는 RAM 블록이 장착되어 있음.
      - CPU 다이(die)에 직접 위치하거나 동일한 패키지에 있는 일종의 메모리인 CPU 캐시보다 훨씬 느림. 캐시는 처리 중에 초고속 검색을 위해 자주 저장되고 최근에 접근한 데이터를 저장함. CPU 설계에는 다양한 크기와 성능 특성을 가진 여러 계층의 캐시가 포함되어 있음 
    - 시스템 메모리에 관해 이야기할 때는 거의 항상 고밀도 저비용 메모리인 동적 RAM(dynamic RAM)을 의미함. 동적 RAM은 데이터를 콘덴서(capacitor)에 전하로 저장함. 이러한 콘덴서는 시간이 지남에 따라 누전되므로, 데이터 손실을 방지하려면 데이터를 자주 갱신(읽기 및 다시 쓰기)해야함. 하드웨어 메모리 컨트롤러는 이러한 기술적 세부사항을 처리하므로, 데이터 엔지니어는 대역폭과 검색 지연 시간의 특성만 신경 쓰면 됨. 정적 RAM(static RAM)과 같은 다른 형태의 메모리는 CPU 캐시와 같은 특수 애플리케이션에서 사용됨 
    - 현재의 CPU는 거의 항상 폰 노이만 구조를 채택하고 있으며 코드와 데이터는 동일한 메모리 공간에 함께 저장됨. 그러나 CPU는 일반적으로 보안을 강화하기 위해 메모리의 특정 페이지에서 코드 실행을 비활성화하는 옵션을 지원함. 이 기능은 코드와 데이터를 분리하는 하버드 구조를 연상시킴
    - RAM은 다양한 스토리지와 처리 시스템에서 사용되며 캐싱, 데이터 처리 또는 인덱스에도 쓰일 수 있음. 일부 데이터베이스는 RAM을 기본 스토리지 계층으로 취급해 초고속 읽기 및 쓰기 성능을 제공함. 이러한 애플리케이션에서 데이터 엔지니어는 RAM의 휘발성을 항상 염두에 두어야 함. 메모리에 저장된 데이터가 클러스터 간에 복제되더라도, 정전으로 인해 여러 노드의 다운이 발생하면 데이터가 손실될 수 있음. 데이터를 내구성 있게 저장하는 아키텍처에서는 배터리 백업을 사용해 정전 시 모든 데이터를 자동으로 디스크에 덤프할 수 있음 
  - 네트워킹과 CPU 
    - 점점 더 많은 스토리지 시스템이 성능, 내구성, 그리고 가용성을 향상하고자 분산되고 있음. 특히 개별 자기 디스크는 상대적으로 전송 성능이 낮지만, 디스크 클러스터는 읽기를 병렬화해 성능을 크게 확장한다고 언급한 바 있음. 복수 배열 독립 디스크(RAID,redundant array of independent disk)와 같은 스토리지 표준은 단일 서버에서 병렬로 작동하지만, 클라우드 객체 스토리지 클러스터는 네트워크를 통해 디스크가 분산되고 여러 데이터 센터와 가용 영역에도 분산되어 훨씬 더 큰 규모로 작동함
    - 가용 영역(availability zone)은 독립적인 전력, 물, 기타 자원 등을 갖춘 컴퓨팅 환경으로 이루어진 표준적인 클라우드 구성이다. 다중 영역 스토리지는 데이터의 가용성과 내구성을 모두 향상시킴
    - CPU는 서비스 요청 처리, 읽기 집계, 쓰기 분산에 대한 세부 사항을 처리함. 스토리지는 API, 백엔드 서비스 구성 요소 및 로드 밸런싱을 갖춘 웹 애플리케이션이 됨. 네트워크 장치의 성능과 네트워크 토폴로지는 높은 성능을 실현하는 핵심 요소 
    - 엔지니어는 데이터를 지리적으로 분산함으로써 얻을 수 있는 내구성 및 가용성과, 스토리지를 데이터 소비자 또는 기록자와 가까운 좁은 지역에 보관함으로써 얻을 수 있는 성능 및 비용상의 이점 사이에서 항상 균형을 유지해야 함 
  - 직렬화(serialization)
    - 또 다른 원시 스토리지 구성 요소이자 데이터베이스 설계의 핵심 요소. 직렬화에 대한 결정은 네트워크에서 쿼리가 얼마나 잘 수 행되는지와 함께 CPU 오버헤드, 쿼리 지연 시간 등에 영향을 미침. 예를 들어 데이터 레이크를 설계하려면 기본 스토리지 시스템과 더불어 상호 운용성 및 성능 고려 사항 사이의 균형을 맞추는 직렬화 표준을 선택해야 함 
    - 소프트웨어에 의해 시스템 메모리에 저장되는 데이터는 일반적으로 디스크에 저장하거나 네트워크를 통해 전송하기에 적합한 형식이 아님. 직렬화는 데이터를 평탄화하고 표준 포맷으로 패킹하는 프로세스로, 판독기가 디코딩할 수 잇음. 직렬화 형식은 데이터 교환의 표준을 제공함. 데이터를 행 기반 방식으로 XML, JSON 또는 CSV 파일로 인코딩해 다른 사용자에게 전달하면 표준 라이브러리를 사용해 데이터를 디코딩할 수 있음.
    - 직렬화 알고리즘에는 유형을 취급하는 로직이 있으며, 데이터 구조에 규칙을 부과하고 프로그래밍 언어와 CPU 간의 교환을 허용함. 직렬화 알고리즘에는 예외를 처리하는 규칙도 있음. 예를 들어 파이썬 객체에는 순환 참조를 포함할 수 있고, 직렬화 알고리즘은 순환이 발생하면 오류를 발생시키거나 중첩 깊이를 제한할 수 있음 
    - 저수준(low-level) 데이터베이스 스토리지도 직렬화의 한 형태. 행 중심의 관계형 데이터베이스는 데이터를 디스크의 행으로 구성해 빠른 조회와 제자리 갱신(in-place update)을 지원함. 컬럼형 데이터베이스는 데이터를 컬럼 파일로 구성해 매우 효율적인 압축을 최적화하고 대용량 데이터 볼륨의 빠른 검색을 지원함 
    - 데이터 엔지니어는 일반적인 직렬화 관행과 형식, 특히 현재 가장 인기 있는 형식(아파치 파케이), 하이브리드 직렬화(아파치 후디) 및 인메모리 직렬화(아파치 애로우)에 익숙해질 것을 권장함 
  - 압축(compression)
    - 기본적인 압축은 데이터를 더 작게 만들지만, 압축 알고리즘은 스토리지 시스템의 다른 세부 정보와 복잡한 방식으로 상호 작용함.
    - 고효율 압축은 스토리지 시스템에서 세 가지 주요 이점을 제공함 
      - 데이터 크기가 작으므로 디스크 공간을 덜 차지함 
      - 압축을 통해 디스크당 실제 검색 속도가 향상함
      - 네트워크 성능
    - 단점
      - 데이터를 압축 및 해제하려면 데이터를 읽거나 쓰는 데 시간과 자원이 추가로 소모딤 
  - 캐싱
    - 캐싱의 핵심 개념은 자주 접근하거나 최근에 접근한 데이터를 고속 접근 계층에 저장하는 것. 캐시가 빠를수록 비용은 커지고 사용 가능한 스토리지 공간을 줄어듬. 접근 빈도가 낮은 데이터는 더 저렴하고 느린 스토리지에 저장됨. 캐시는 데이터 서비스 처리 및 변환에 매주 중요함
    - 스토리지 시스템을 분석할 때 사용하는 모든 유형의 스토리지를 캐시 계층안에 배치하는 것이 유용함. 대부분의 실용적인 데이터 시스템은 다양한 성능 특성을 가진 스토리지로 구성된 많은 캐시 계층에 의존함. 이는 CPU 내부에서 시작되며 프로세서는 최대 4개의 캐시 계층을 배포할 수 있음. 이제 계층 구조에서 RAM과 SSD로 이동해보자. 클라우드 객체 스토리지는 데이터 제공 및 파이프라인에서의 동적 데이터 이동을 허용하면서 장기적인 데이터 보관과 내구성을 지원하는 하위 계층임 
    - 보관(archival) 스토리지는 역 캐시(reverse cache)로 생각할 수 있음. 보관 스토리지는 낮은 비용으로 열악한 접근 특성을 제공함. 보관 스토리지는 일반적으로 데이터 백업 및 데이터 보존 컴플라이언스 요건을 충족하는 데 사용됨. 일반적인 시나리오에서 이 데이터는 비상시에만 접근할 수 있음.(데이터베이스의 데이터가 손실되어 복구가 필요하거나 기업이 법적 증거를 발견하기 위해 이력 데이터를 다시 참조해야 할 경우 등)
- 데이터 스토리지 시스템
  - 스토리지 시스템은 기본 구성 요소 이상의 추상화 수준에 존재함. 예를 들어 자기 디스크는 원시 스토리지의 구성 요소이며, 주요 클라우드 객체 스토리지 플랫폼과 HDFS는 자기 디스크를 사용하는 스토리지 시스템. 데이터 레이크나 레이크 하우스 같은 더 높은 수준의 스토리지 추상화도 존재함 
  - 단일 머신 vs 분산 스토리지(distributed storage)
    - 데이터는 분산 스토리지라고 하는 여러 서버에 저장할 수 있음. 분산 스토리지는 데이터를 분산된 방식으로 저장하는 것이 목적인 분산 시스템 
    - 분산 스토리지는 여러 서버의 작업을 조정해 데이터르 더 빠르고 대규모로 저장, 검색 및 처리하는 동시에, 서버를 사용할 수 없게 될 경우를 대비해 중복성(redundancy) 기능을 제공함. 분산 스토리지는 대량의 데이터에 대한 내장형 중복성과 확장성을 원하는 아키텍처에서 흔히 볼 수 있음. 예를 들어 객체 스토리지, 아파치 스파크 및 클라우드 데이터 웨어하우스는 분산 스토리지 아키텍처에 의존함 
  - 최종 일관성 vs 강력한 일관성 
    - 분산 시스템의 문제점은 데이터가 여러 서버에 분산된다는 것. 이러한 시스템에서는 어떻게 데이터의 일관성을 유지할 수 있을까? 유감스럽게도 분산형 시스템은 스토리지와 쿼리 정확도 측면에서 딜레마를 안고 있음. 시스템 노드 간에 변경 내용을 복제하는 데는 시간이 걸리며, 대부분의 경우 현재 데이터를 가져오는 것과 분산 데이터베이스에서 일종의 현재 데이터를 가져오는 것 사이의 균형이 존재함 
    - 분산형 시스템에서 흔히 볼 수 있는 두 가지 일관성 패턴인 최종 일관성과 강력한 일관성을 살펴보자
      - 최종 일관성
        - ACID 컴플라이언스를 다뤘음. 또 다른 약어로 BASE로, 기본적으로 가용성을 보장하는(basically available), 소프트한 상태의(soft-state), 최종 일관성(eventual consistency)을 의미함(ACID의 반대). BASE는 최종 일관성의 기초 
        - 구성 요소 
          - 기본적으로 가용성을 보장 : 일관성을 보장하지는 않지만, 데이터베이스 읽기 및 쓰기는 최선의 노력을 기반으로 이루어지므로 대부분의 경우 일관된 데이터를 사용할 수 있음 
          - 소프트한 상태 : 트랜잭션의 상태가 불분명하며 트랜잭션이 커밋되었는지 커밋되지 않았는지 불확실함 
          - 최종 일관성 : 어느 시점에서 데이터를 읽으면 일관된 값을 반환홤 
        - 최종 일관성은 대규모 분산 시스템에서 공통적인 트레이드오프. 대량의 데이터를 처리하고자 여러 노드에 걸쳐 수평적 확장을 수행하려는 경우에는 결국 일관성이라는 대가를 치러야 함. 최종 일관성을 통해 모든 노드에서 최신 버전이 있는지 확인하지 않고도 데이터를 빠르게 검색할 수 있음 
      - 강력한 일관성(strong consistency)
        - 최종 일관성의 반대 개념으로 강력한 일관성을 갖춘 분상형 데이터베이스는 먼저 모든 노드에 대한 쓰기가 합의에 따라 분산되고, 데이터베이스에 대한 모든 읽기가 일관된 값을 반환하도록 보장함. 이러한 강력한 일관성을 쿼리 지연 시간이 길어지고 데이터 베이스에서 읽을 때마다 정확한 데이터가 필요할 때 사용할 수 있음 
      - 데이터 엔지니어는 세 가지 상황에 대한 일관성에 대한 결정을 내림 
        - 데이터베이스 기술 자체가 일정 수준의 일관성을 위한 단계를 설정함 
        - 데이터베이스의 구성 매개변수가 일관성에 영향을 미침 
        - 데이터베이스는 종종 개별 쿼리 수준에서 몇몇 일관성 구성을 지원함 
  - 파일 스토리지
    - 파일은 소프트웨어와 운영 체제에서 사용하는 특정 읽기, 쓰기 및 참조 특성을 가진 데이터 엔티티
    - 특성
      - 유한 길이 : 파일은 길이가 유한한 바이트 스트림
      - 추가 작업 : 호스트 스토리지 시스템의 한계까지 파일에 바이트를 추가할 수 있음
      - 임의 접근 : 파일의 모든 위치에서 조회하거나 갱신할 수 있음 
    - 파일 스토리지 시스템은 파일을 디렉터리 트리로 구성함. 파일의 디렉터리 참조는 다음과 같이 보일 수 있음. (/Users/matthewhousley/ouput.txt)
    - 로컬 디스크 스토리지 
      - 가장 친숙한 파일 스토리지 유형은 SSD 또는 자기 디스크의 로컬 디스크 파티션에 있는 운영체제 관리 파일 시스템. 신기술 파일 시스템(NTFS, New Technology File System)과 ext4는 각각 윈도우와 리눅스에서 널리 사용되는 파일 시스템.
      - 운영 체제는 디렉터리 엔티티, 파일 및 메타데이터 저장에 관한 세부 정보를 처리함. 파일 시스템은 데이트 쓰기 중에 전원이 끊겼을 경우에도 쉽게 복구할 수 있도록 설계되어 있지만, 쓰지 않은 데이터는 여전히 소실됨.
      - 로컬 파일 시스템은 일반적으로 쓰기 후 읽기 일관성을 지원함. 쓰기 후 바로 읽으면 쓰인 데이터가 반환됨. 또한 운영 체제는 파일에 대한 동시 쓰기 시도를 관리하기 위해 다양한 잠금 전략을 사용함.
      - 로컬 디스크 파일 시스템은 저널링, 스냅숏, 중복성, 여러 디스크에 걸친 파일 시스템 확장, 전체 디스크 암호화 및 압축과 같은 고급 기능도 지원할 수 있음 
    - 네트워크 결합 스토리지(network-attached storage, NAS)
      - 네트워크를 통해 클라이언트에 파일 스토리지 시스템을 제공함. NAS는 서버용으로 널리 쓰이는 설루션으로, 전용 NAS 인터페이스 하드웨어가 내장된 경우가 많음. 네트워크를 통해 파일 시스템에 접근하면 성능 저하가 발생하지만, 중복성과 안정성, 리소스의 세밀한 제어, 대규모 가상 볼륨을 위한 여러 디스크 간의 스토리지 풀링, 여러 시스템 간의 파일 공유 등 스토리지 가상화에도 상당한 이점이 있음 
      - 엔지니어는 NAS 설루션이 제공하는 일관성 모델을 알고 있어야 함. 특히 여러 클라이언트가 동일한 데이터에 접근할 가능성이 있는 경우에는 더욱 그렇다.
      - NAS의 대안으로 스토리지 영역 네트워크(SAN, storage area network)가 널리 쓰이지만, SAN 시스템 파일 시스템 추상화 없이 블록 수준의 접근을 제공함 
    - 클라우드 파일 시스템 
      - 클라우드 파일 시스템 서비스는 클라우드 환경 외부의 클라이언트를 포함해 여러 클라우드 VM과 애플리케이션을 함께 사용할 수 있도록 완벽하게 관리되는 파일 시스템을 제공함 
      - 클라우드 파일 시스템을 VM에 연결된 표준 스토리지
  - 블록 스토리지(block storage)
    - SSD와 자기 디스크에서 제공하는 원시 스토리지 유형. 클라우드에서는 가상화된 블록 스토리지가 VM의 표준. 이러한 블록 스토리지 추상화를 통해 물리적 디스크에서 제공하는 것 이상의 스토리지 크기, 확장성 및 데이터 내구성을 세밀하게 제어할 수 있음 
    - 블록은 디스크에서 지원하는 주소 지정이 가능한 최소 데이터 단위. 이전 디스크에서는 512바이트의 사용 가능한 데이터였던 블록이 현재 대부분의 디스크에서는 4,096바이트로 증가해, 쓰기의 세밀성을 떨어졌지만 블록 관리 오버헤드는 많이 감소했음. 일반적으로 블록에는 오류 검출, 수정 및 기타 메타데이터를 위한 추가 비트가 포함됨
    - 자기 디스크의 블록은 물리적 플래터에 기하학적으로 배치됨. 동일한 트랙의 두 블록은 헤드를 움직이지 않고도 읽을 수 있지만, 별도의 트랙에 있는 두 블록을 읽으려면 탐색이 필요함 
    - 블록 스토리지 애플리케이션
      - 블록 스토리지는 클라우드 VM의 운영 체제 부팅 디스크에 대한 기본 옵션으로 남아 있음. 블록 장치는 물리 디스크에서 직접 포맷하는 것과 비슷하게 포맷되지만, 스토리지는 일반적으로 가상화되어 있음 
      - RAID
        - 복수 배열 독립 디스크(redundant array of independent disk), 여러 디스크를 동시에 제어해 데이터의 내구성을 높이고 성능을 개선하며 여러 드라이브의 용량을 결합함. 
        - 어레이는 OS에 단일 블록 장치로 표시될 수 있음. 향상된 유효 대역폭과 높은 내결함성(다수의 디스크 장애에 대한 허용성) 사이의 원하는 균형에 따라 다양한 인코딩 및 패리티 방식을 사용할 수 있음 
      - 스토리지 영역 네트워크(SAN, storage area network)
        - 일반적으로 스토리지 풀에서 네트워크를 통해 가상화된 블록 스토리지 장치를 제공함. SAN 추상화를 통해 스토리지를 세밀하게 확장할 수 있고 성능, 가용성 및 내구성을 향상시킬 수 있음 
        - 온프레미스 스토리지 시스템을 사용하는 경우 SAN 시스템을 접할 수 있으며, SAN의 클라우드 버전도 접할 수 있음 
      - 클라우드 가상화 블록 스토리지(cloud virtualized block storage)
        - SAN과 유사하지만, 엔지니어가 SAN 클러스터와 네트워킹 세부 사항을 처리할 필요가 없음 
      - 로컬 인스턴스 볼륨
        - 클라우드 제공업체는 가상 머신을 실행하는 호스트 서버에 물리적으로 연결된 블록 스토리지 볼륨도 제공함. 이러한 스토리지 볼륨은 일반적으로 매우 저렴하며(아마존 EC2 인스턴스 스토어의 경우 VM 가격에 포함됨) 짧은 지연 시간과 높은 IOPS를 제공함 
        - 로컬에 연결된 디스크는 EBS 같은 가상화 스토리지 서비스에 제공하는 고급 가상화 기능을 지원하지 않음. 로컬에 연결된 디스크는 복제되지 않으므로, 호스트 VM이 계속 실행되더라도 물리적 디스크 장애로 인해 데이터가 손실되거나 손상될 수 있음. 또한 로컬로 연결된 볼륨은 스냅숏이나 기타 백업 기능을 지원하지 않음 
        - 이러한 제한에도 불구하고 로컬로 연결된 디스크는 매우 유용함. 대부분의 경우 디스크를 로컬 캐시로 사용하므로 EBS와 같은 서비스의 고급 가상화 기능이 모두 필요하지는 않음 
  - 객체 스토리지(object storage)
    - 모든 형태와 크기의 객체가 포함됨.
    - 여기서는 특수한 파일형 구조를 가리키는데, 이는 TXT, CSV, JSON, 이미지, 비디오, 오디오 등 모든 유형의 파일이 될 수 있음.
    - 객체 스토리지에는 모든 형태와 크기의 불변 객체가 포함됨. 로컬 디스크의 파일과 달리, 객체는 그 자리에서 수정할 수 없음 
    - 객체 스토리지는 최초의 서버리스 서비스 중 하나로, 엔지니어는 기본 서버 클러스터나 디스크의 특성을 고려할 필요가 없음. 
    - 객체 스토리지는 불변의 데이터 객체에 대한 키-값 쌍 저장소. 객체 저장소의 로컬 디스크에 파일 스토리지를 저장하면 쓰기 유연성이 크게 떨어짐. 객체는 랜덤 쓰기 또는 덧붙이기 작업을 지원하지 않음. 대신 바이트 스트림으로 한 번만 쓰임. 이 첫 번째 쓰기 작업이 끝나면 객체는 변경되지 않음. 객체의 데이터를 변경하거나 객체에 데이터를 추가하려면 객체 전체를 다시 작성해야 함. 
    - 객체 저장소는 일반적으로 범위 요청을 통한 임의 읽기를 지원하지만, 이러한 검색은 SSD에 저장된 데이터의 임의 읽기보다 성능이 훨씬 떨어질 수 있음 
    - 객체 저장소는 잠금을 지원하거나 동기화를 변경할 필요가 없으므로 대규모 디스크 클러스터에 데이터 스토리지를 사용할 수 있음. 객체 저장소는 여러 디스크에 걸쳐 매우 뛰어난 성능의 병렬 스트림 쓰기 및 읽기를 지원함. 
    - 클라우드 환경에서 쓰기 속도는 클라우드 제공업체가 설정한 할당량 제한까지 기록되는 스트림 수에 따라 확장됨. 읽기 대역폭은 병렬 요청 수, 데이터 읽기에 사용되는 가상 머신 수, CPU 코어수에 따라 확장할 수 있음. 이러한 특성 덕분에 객체 스토리지는 대용량 웹 트래픽을 처리하거나 고도로 병렬 분산된 쿼리 엔진에 데이터를 전달하는 데 이상적 
    - 클라우드 객체 스토리지는 컴퓨티과 스토리지를 분리하는 핵심 요소로, 엔지니어는 임시 클러스터로 데이터를 처리하고 필요에 따라 클러스터를 확장 및 축소할 수 있음 
    - 데이터 엔지니어링 애플리케이션 객체 저장소 
      - 데이터 엔지니어링 측며에서 객체 저장소는 대규모의 배치 읽기와 배치 쓰기에 뛰어난 성능을 제공함. 이는 대규모 OLAP 시스템의 사용 사례에 매우 적합함 
      - 객체 저장소는 매초마다 많은 소규모 갱신이 이루어지는 트랜잭션 워크로드에 적합하지 않으며, 이러한 사용 사례는 트랜잭션 데이터베이스 또는 블록 스토리지 시스템에서 훨씬 잘 처리됨. 객체 저장소는 각 작업에서 대량의 데이터를 갱신하는 낮은 속도의 갱신 작업에 적합함.
      - 객체 저장소는 이제 데이터 레이크의 스토리지 표준이 됐음. 데이터 레이크 초기에는 한 번 기록하고 여러 번 읽기(WORM)가 운영 표준이였지만, 이는 HDFS와 객체 저장소의 제한보다는 데이터 버전과 파일 관리의 복잡성과 더 관련이 있었음. 이후 이러한 복잡성을 관리하기 위해 아파치 후디와 델타 레이크 같은 시스템이 등장했으며, GDPR 및 CCPA 같은 개인정보보호 규제에 따라 삭제 및 갱신 기능이 필수 요소가 됐음 
      - 객체 스토리지는 이러한 정형 데이터 애플리케이션를 넘어 모든 형식의 비정형 데이터를 위한 이상적인 리포지터리.객체 스토리지 유형이나 구조에 제약이 없는 바이너리 데이터를 저장할 수 있으며 원시 텍스트, 이미지, 비디오 및 오디오용 ML 파이프라인에서 자주 사용됨 
    - 객체 조회
      - 객체 저장소는 키-값 쌍 저장소
      - 파일 저장소와 달리 객체 저장소는 디렉터리 트리를 사용해 객체를 검색하지 않음. 객체 저장소는 최상위 논리 컨테이너 (S3 및 GCS의 버킷)를 사용해 객체를 키로 참조함 
    - 객체 일관성 및 버전 관리
      - 객체 저장소는 제자리 갱신 또는 추가를 지원하지 않음. 객체를 갱신하려면 동일한 키로 새 객체를 작성함 
      - 객체 저장소는 최종 일관성이 있을 수도 있고 강력한 일관성이 있을 수도 있음. 예를 들어 최근까지 S3는 최종 일관성이 있었음. 객체의 새로운 버전이 같은 키로 작성된 이후 객체 저장소는 때때로 이전 버전의 객체를 반환하는 경우가 있었음. 최종 일관성의 최종 부분은 충분한 시간이 지나면 스토리지 클러스터가 최신 버전의 객체만 반환되는 상태가 된다는 것을 의미함. 이는 서버에 연결된 로컬디스크의 강력한 일관성 모델(쓰기 후 읽으면 가장 최근에 쓰인 데이터가 반환되는 모델)과는 대조적임 
      - 다양한 이유로 객체 저장소에 강력한 일관성을 부여하는 것이 바람직할 수 있으며 일르 실현하고자 하는 표준 방법이 사용됨. 한 가지 접근 방식은 강력한 일관성이 있는 데이터베이스(예: PostgreSQL)를 추가하는 것. 객체 작성은 두 단계로 진행됨
        - 객체를 쓴다
        - 객체 버전에 대해 반환된 메타데이터를 강력한 일관성의 데이터베이스에 쓴다
      - 버전 메타데이터(객체 해시 또는 객체 타임스탬프)는 객체 키와 함께 객체 버전을 고유하게 식별할 수 있음. 객체를 읽으려면 리더는 다음 단계를 수행함
        - 강력한 일관성의 데이터베이스에서 최신 객체 메타데이터를 가져옴
        - 객체 키를 사용해 객체 메타데이터를 쿼리함. 일관성 있는 데이터베이스에서 가져온 메타데이터와 일치하는 객체 데이터를 읽어옴
        - 객체 메타데이터가 일치하지 않으면 객체의 최신 버전이 반환될 때까지 순서 2를 반복함 
      - 실제 구현에는 이 쿼리 프로세스 중에 객체가 다시 쓰이는 경우 등 고려할 예외 및 에지 케이스가 있음. 이러한 단계는 API 뒤에서 관리할 수 있으므로, 객체 리더는 객체 접근 지연 시간이 길어져도 일관성 있는 객체 저장소를 볼 수 있음
      - 객체 버전 관리는 객체 일관성과 밀접한 관련이 있음 
        - 객체 저장소의 기존 키로 객체를 다시 쓰는 경우, 기본적으로 새로운 객체를 쓰고 기존 키에서 객체에 대한 참조를 설정하고 오래된 객체 참조를 삭제함. 클러스터 전체에서 모든 참조를 갱신하려면 시간이 걸리므로 오래된 읽기가 발생할 가능성이 있음. 결국 스토리지 클러스터 가비지 컬렉터는 참조되지 않은 데이터 전용 공간을 할당 해제하고, 디스크 용량을 새 객체에서 사용할 수 있도록 재활용함 
        - 객체 버전 관리가 켜지면 버전을 규정하는 객체에 메타데이터를 추가함. 기본 키 참조는 새 객체를 가리키도록 갱신되지만, 이전 버전에 대한 다른 포인터는 그대로 유지됨. 또한 클라이언트가 모든 객체 버전 목록을 취득해 특정 버전을 가져올 수 있도록 버전 목록도 유지함. 이전 버전의 객체는 여전히 참조되므로 가비지 컬렉터에 의해 정리되지 않음 
        - 버전을 사용해 객체를 참조하면 일부 객체 스토리지 시스템의 일관성 문제가 사라짐. 키와 버전 메타데이터가 함께 특정 불변의 데이터 객체에 대한 고유한 참조를 형성하기 때문. 삭제하지 않은 경우에는 이 쌍을 사용할 때 항상 동일한 객체를 다시 가져올 수 있음. 클라이언트가 객체의 기본 또는 최신 버전을 요청할 때는 일관성 문제가 계속 발생함 
        - 객체 버전 관리에서 엔지니어가 고려할 주요 오버헤드는 스토리지 비용. 객체의 과거 버전은 일반적으로 현재 버전과 동일한 관련 스토리지 비용이 발생함. 객체 버전 비용은 다양한 요인에 따라 매우 미미할 수도 있고 엄청나게 비쌀 수도 있음. 갱신 빈도와 마찬가지로 데이터 크기 역시 문제가 됨. 객체 버전이 많으면 데이터 크기가 상당히 커질 수 있음 
        - 객체 스토리지 시스템은 일반적으로 차등 스냅숏이 아닌 각 버전에 대한 전체 데이터를 저장함 
      - 엔지니어는 스토리지 수명 주기 정책을 도입할 수도 있음. 수명 주기 정책을 사용하면 특정 조건이 충족될 때(예를 들어 객체 버전이 특정 기간에 도달하거나 많은 최신 버전이 존재할 때) 오래된 객체 버전을 자동으로 삭제할 수 있음. 또한 클라우드 벤더는 다양한 아카이브 데이터 계층을 대폭 할인된 가격으로 제공하며, 수명 주기 정책을 사용해 아카이브 프로세스를 관리할 수 있음 
    - 스토리지 클래스 및 계층
      - 현재 클라우드 벤더는 접근 횟수를 줄이거나 내구성을 낮추는 대신 데이터 스토리지 가격을 할인하는 스토리지 클래스를 제공함. 이러한 스토리지 계층 중 상당수가 여전히 데이터 가용성은 높지만 스토리지 비용을 절감하는 대신 검색 비용이 많이 들기 때문에 접근 감소(reduced access)라는 용어를 사용함 
    - 객체 저장소 백업 파일 시스템 
      - 객체 저장소 동기화 설루션이 점점 인기를 얻고 있음. s3fs 및 아마존 S3 파일 게이트웨이 같은 도구를 사용하면 S3 버킷을 로컬 스토리지로 마운트할 수 잇음. 이러한 도구의 사용자는 파일 시스템에 대한 쓰기 특성과, 이러한 쓰기가 객체 스토리지 특성 및 가격과 어떻게 상호 작용하는지를 알아야 함 
      - 예를 들어 파일 게이트웨이는 S3의 고급 기능을 사용해 객체의 일부를 새로운 객체에 결합함으로써 파일 변경을 매우 효율적으로 처리함. 그러나 고속 트랜잭션 쓰기는 객체 저장소의 갱신 기능을 압도하게 됨. 객체 스토리지를 로컬 파일 시스템으로 마운트하는 것은 자주 갱신되지 않은 파일에 적합함 
  - 캐시 및 메모리 기반 스토리지 시스템 
    - RAM은 뛰어난 지연 시간과 전송 속도를 제공함. 그러나 기존 RAM은 단 1초라도 정전이 지속되면 데이터가 지워질 수 있기 때문에 데이터 손실에 매우 취약함 
    - RAM 기반 스토리지 시스템은 보통 애플리케이션 캐시에 중점을 두고 빠른 접근과 고대역폭을 위한 데이터를 제공함. 
    - 데이터는 일반적으로 보존을 위해 내구성이 더 높은 미디어에 작성해야 함. 이러한 초고속 캐시 시스템은 데이터 엔지니어가 초고속 검색 지연시간으로 데이터를 제공해야 할 때 유용함 
    - 예제: 멤캐시드 및 경량 객체 캐시
      - 멤캐시드(Memcached)는 데이터베이스 쿼리 결과, API 호출 응답 등을 캐시하기 위해 설계된 키-값 쌍 저장소. 멤캐시드는 문자열 또는 정수 유형을 지원하는 단순한 데이터 구조를 사용함 
      - 멤캐시드는 백엔드 시스템의 부하를 줄이면서도 매우 짧은 지연 시간으로 결과를 제공할 수 있음 
    - 예제: 레디스, 지속성 옵션이 있는 메모리 캐싱 
      - 레디스는 키-값 쌍 저장소이지만 목록이나 집합등의 다소 복잡한 데이터 유형을 지원함. 또한 레디스는 스냅숏과 저널링을 포함한 여러 지속성 메커니즘을 내장하고 있음. 일반적으로 구성에서 레디스는 대략 2초마다 데이터를 씀. 따라서 레디스는 매우 고성능 애플리케이션에 적합하지만, 소량의 데이터 손실도 견딜 수 있음 
  - 하둡 분산 파일 시스템
    - 하둡은 객체 스토리지와 유사하지만 중요한 차이점이 있음. 하둡은 동일한 노드에서 컴퓨팅과 스토리지를 결합하지만, 객체 저장소는 일반적으로 내부 프로세싱을 제한적으로 지원함 
    - 하둡은 대용량 파일을 수백 메가바이트 미만의 데이터 청크인 블록으로 분할함. 파일 시스템은 디렉터리, 파일 메타데이터, 그리고 클러스터 내의 블록 위치를 설명하는 상세 카탈로그를 유지하는 네임노드에 의해 관리됨. 일반적인 구성에서는 각 데이터 블록이 3개의 노드에 복제되는데, 그러면 데이터의 내구성과 가용성이 모두 향상됨
    - 디스크 또는 노드에 장애가 발생하면 일부 파일 블록의 복제 계수가 3 아래로 떨어짐. 네임노드는 다른 노드에 이러한 파일 블록을 복제하도록 지시해 다시 올바른 복제 계수에 도달함. 따라서 관련 장애(예:소행성이 데이터 센터에 충돌하는 등)가 발생하지 않는 한 데이터 손실 가능성은 매우 낮음.
    - 하둡은 단순한 스토리지 시스템이 아니며, 컴퓨팅 리소스를 스토리지 노드와 결합해 제자리 데이터 처리를 지원함.
    - 여전히 영향력을 발휘하는 하둡
      - 아파치 피그와 같은 많은 하둡 생테계 도구는 현재 위태로운 상황에 처했으며, 주로 레거시 작업을 실행하는 데 사용됨. 순수한 맵리듀스 프로그래밍 모델은 중단됐음. HDFS는 다양한 애플리케이션과 조직에서 여전히 널리 사용되고 있음 
      - 하둡은 여전히 많은 레거시 설치 환경에 등장함. 빅데이터 열풍이 한창일 때는 하둡을 도입한 많은 조직에서 새로운 기술로 즉시 마이그레이션할 계획이 없음. 이는 (수천 노드의)대규모 하둡 클러스터를 실행하고 온프레미스 시스템을 효과적으로 유지 관리할 수 있는 자원을 보유한 기업에 적합한 선택
      - 소규모 기업은 클라우드 설루션으로 마이그레이션하지 않고 소규모 하둡 클러스터를 실행하는 데 따른 비용 오버헤드와 확장 제한을 재고해야 할 수 있음. 
      - HDFS는 아마존 EMR 같은 수많은 최신 빅데이터 엔진의 핵심 요소. 실제로 아파치 스파크는 여전히 HDFS 클러스터에서 실행됨 
  - 스트리밍 스토리지
    - 메시지 큐의 경우, 저장된 데이터는 일시적이며 일정 기간이 지나면 사라질 것으로 예상됨. 그러나 아파치 카프카 같은 분산되고 확장 가능한 스트리밍 프레임워크는 매우 오랜 기간 동안 스트리밍 데이터를 보존할 수 있게 됐음. 카프카는 자주 접근하지 않은 오래된 메시지를 객체 스토리지에 푸시해 무기한 데이터 보존을 지원함.
    - 카프카 경쟁 제품들(아마존 키네시스, 아파치 펄사, 구글 클라우드 Pub/Sub 등)도 장기 데이터 보존을 지원함
    - 시스템의 데이터 보관과 밀접하게 관련된 개념이 리플레이(replay)다. 리플레이를 사용하면 스트리밍 시스템에 저장된 과거 데이터의 범위를 반환할 수 있음. 리플레이는 스트리밍 스토리지 시스템의 표준 데이터 검색 메커니즘. 리플레이는 시간 범위에 걸쳐 배치 쿼리를 실행하거나 스트리밍 파이프라인에서 데이터를 재처리하는 데 사용할 수 있음
    - 어떤 의미에서 트랜잭션 데이터베이스는 최초의 실시간 쿼리 엔진으로 등장했으며, 데이터가 기록되는 즉시 쿼리에 표시됨. 그러나 이러한 데이터베이스는, 특히 대량의 데이터에 걸쳐 실행되는 분석 쿼리의 경우 잘 알려진 확장 및 잠금 제한이 있음. 확장 가능한 행 지향 트랜잭션 데이터베이스 버전은 이러한 한계를 일부 극복했지만, 여전히 규모에 맞는 분석에 최적화되지는 않았음 
  - 인덱스, 파티셔닝 및 클러스터링
    - 인덱스는 특정 필드에 대한 테이블 맵을 제공하며 개별 레코드를 매우 빠르게 검색할 수 있게 해줌. 인덱스가 없으면 데이터베이스는 WHERE 조건을 충족하는 레코드를 찾기 위해 전체 테이블을 스캔해야 함.
    - 대부분의 RDBMS에서 인덱스는 기본 테이블 키(행의 고유 식별 가능)와 외부 키(다른 테이블과의 조인 가능)에 사용됨. 인덱스는 특정 애플리케이션의 요구를 충족하기 위해 다른 열에 적용할 수도 있음  
    - 행에서 열로의 진화
      - 초기 데이터 웨어하우스는 일반적으로 트랜잭션 애플리케이션에 사용되는 것과 동일한 유형의 RDBMS를 기반으로 구축됐음. MPP 시스템의 인기가 높아짐에 따라 분석 목적으로 대량의 데이터를 걸쳐 검색 성능을 크게 개선할 수 있는 병렬 프로세싱으로 전환됐음. 단, 이러한 행지향 MPP에서는 여전히 인덱스를 사용해 조인 및 상태 체크를 지원함 
      - 컬렴형 직렬화를 사용하면 데이터베이스는 특정 쿼리에서 피룡한 열만 스캔할 수 있으므로 디스크에서 읽는 데이터의 양을 대폭 줄일 수 있음. 또한 데이터를 열별로 배열하면 서로 유사한 값이 모이므로 압축 오버헤드를 최소화하면서 높은 압축률을 얻을 수 있음. 따라서 디스크나 네트워크를 통해 데이터를 더 빠르게 스캔할 수 있음 
      - 컬럼형 데이터베이스는 트랜잭션 사용 사례, 즉 다수의 개별 행을 비동기적으로 검색하려고 할 때 성능이 떨어짐. 그러나 복잡한 데이터 변환, 집계, 통계 계산 또는 대규모 데이터셋의 복잡한 조건 평가 등 대량의 데이터를 스캔해야 할 때는 매우 우수한 성능을 발휘함 
      - 과거에는 컬럼형 데이터베이스의 조인 성능이 낮았기 때문에 데이터 엔지니어는 가능한 한 광범위한 스키마, 배열 및 중첩된 데이터를 써서 데이터의 정규화를 해제(비정규화)해야 했음 
      - 컬럼형 데이터베이스의 조인 성능은 최근 몇 년동안 크게 향상된 만큼 비정규화활 때의 성능상 이점은 여전히 존재하지만, 더 이상 필수는 아님
    - 인덱스부터 파티션 및 클러스터링까지
      - 컬럼형 데이터베이스는 빠른 스캔 속도를 허용하지만, 스캔되는 데이터의 양을 최대한 줄이는 것이 여전히 유용함. 쿼리와 관련된 열의 데이터만 스캔할 뿐만 아니라 테이블을 필드 단위로 나눠 여러 하위 테이블로 분할할 수 있음. 
      - 분석 및 데이터 과학 사용 사례에서는 보통 시간 범위로 검색하므로 날짜 및 시간 기반 파티셔닝이 매우 일반적임. 컬럼형 데이터베이스는 일반적으로 다양한 다른 파티션 스키마도 지원함. 
      - 클러스터를 사용하면 파티션 내에서 데이터를 더 세밀하게 구성할 수 있음. 컬럼형 데이터베이스 내에 적용되는 클러스터링 스키마는 데이터를 하나 또는 여러 개의 필드로 정렬해 유사한 값을 조합함. 그러면 이러한 값을 필터링, 정렬 및 조인할 때 성능이 개선됨
    - 예제: 스노우플레이크 마이크로 파티셔닝
      - 마이크로 파티션(micro partition)은 압축되지 않은 50 ~ 500 MB 정도 크기의 행 집합. 스노우플레이크는 유사한 행을 함께 묶으려고 시도하는 알고리즘 방식을 사용함. 이는 날짜와 같은 단일 지정 필드에서 파티셔닝하는 등의 전통적이고 순진한 접근법과 대조됨
      - 스노우플레이크는 특히 여러 행에 걸쳐 필드에서 반복되는 값을 찾음. 이를 통해 조건절(술어)을 기반으로 쿼리를 적극적으로 정리할 수 있음 
      - 스노우플레이크는 중복되는 마이크로 파티션을 허용하므로, 중요한 반복을 보이는 여러 필드에서 파티션을 분할할 수 있음 
      - 효율적인 정리는 스노우플레이크 메타데이터 데이터베이스에 의해 촉진됨. 이 데이터베이스는 각 마이크로 파티션에 대한 설명(필드의 행 수와 값의 범위 포함)을 저장함. 각 쿼리 단계에서 스노우플레이크는 마이크로 파티션을 분석해 스캔해야 할 파티션을 결정함. 
      - 스노우플레이크는 하이브리드 컬럼형 스토리지라는 용어를 사용하는데, 이는 스토리지가 기본적으로 컬럼형이지만 테이블이 작은 행 그룹으로 분할된다는 사실을 부분적으로 나타냄. 메타데이터 데이터베이스는 기존 관계형 데이터베이스의 인덱스와 유사한 역할을 함 
- 데이터 엔지니어링 스토리지 개요 
  - 추상화의 주요 유형은 데이터 과학, 데이터 분석 및 보고 활용 사례를 지원하는 추상화. 여기에는 데이터 웨어하우스, 데이터 레이크, 데이터 레이크하우스 ,데이터 플랫폼, 데이터 카탈로그가 포함됨. 
  - 데이터 엔지니어에게 필요한 스토리지 추상화는 몇 가지 주요 고려 사항으로 요약됨
    - 목적 및 사용 사례 : 먼저 데이터를 저장하는 목적을 파악해야 함. 어떤 용도로 사용할 것인가?
    - 갱신 패턴 : 추상화는 대략 갱신, 스트리밍 입력 또는 갱식 입력(upsert)에 최적화되어 있는가?
    - 비용 : 직/간접적인 재정 비용은 얼마인가? 가치 실현 시간과 기회비용은 어떠한가?
    - 스토리지와 컴퓨팅 분리 : 스토리지와 컴퓨팅을 분리하는 추세지만, 대부분의 시스템은 분리와 코로케이션을 하이브리드화함. 이는 목적, 속도 및 비용에 영향을 미침
  - OLAP 데이터베이스와 데이터 레이크 사이의 경계가 점점 모호해지고 있음. 주요 클라우드 데이터 웨어하우스와 데이터 레이크는 충돌하고 있음. 하지만 미래에는 기능적으로나 기술적으로나 서로 매우 유사해질 수 있는 만큼, 이 두 개념 사이의 차이점은 오직 명칭만 남게 될 수도 있음 
  - 데이터 웨어하우스
    - 표준 OLAP 데이터 아키텍처. 데이터 웨어하우스라는 용어는 기술 플랫폼(예: 구글 빅쿼리와 테라데이터), 데이터 중앙 집중화를 위한 아키텍처 및 기업 내 조직 패턴을 의미함. 
    - 스토리지 동향 측면에서 보자면 기존의 트랜잭션 데이터베이스, 행 기반 MPP 시스템(예: 테라데이터 및 IBM 네티자), 컬럼형 MPP 시스템(예: 버티카 및 테라데이터 컬럼너)을 기반으로 데이터 웨어하우스를 구축하는 것에서 클라우드 데이터 웨어하우스 및 데이터 플랫폼으로 발전해 왔음 
    - 실제로 클라우드 데이터 웨어하우스는 제임스 딕슨이 처음 고안한 대로 대량의 미처리 원시 데이터를 저장하는 영역인 데이터 레이크에 데이터를 정리하는 데 자주 쓰임. 클라우드 데이터 웨어하우스는 대량의 원시 텍스트와 복잡한 JSON 문서를 처리할 수 있음. 단, 클라우드 데이터 웨어하우스는 실제 데이터 레이크와 달리 이미지, 비디오 또는 오디오와 같은 진정한 의미의 비정형 데이터를 처리할 수 없다는 한계가 있음. 클라우드 데이터 웨어하우스를 객체 스토리지와 결합해 완벽한 데이터 레이크 설루션을 제공할 수 있음 
  - 데이터 레이크
    - 원시 데이터가 가공되지 않은 원시 형태로 보존되는 대규모 저장소로 간주됐음. 초기의 데이터 레이크는 주로 하둡 시스템을 기반으로 구축되었으며, 이를 통해 저렴한 스토리지로 독점 MPP 시스템의 비용 부담 없이 대량의 데이터를 보존할 수 있었음 
    - 데이터 레이크 스토리지의 진화 측면에서 두 가지 주요 발전
      - 컴퓨팅과 스토리지를 분리를 향한 대규모 마이그레이션이 이뤄졌음. 이는 실제로 데이터의 장기 보존을 위해 하둡에서 클라우드 객체 스토리지로 전환한다는 것을 의미함
      - 데이터 엔지니어는 MPP 시스템에서 제공하는 기능(스키마 관리, 갱신, 병합, 삭제 기능)의 대부분이 실제로는 매우 유용하다는 것을 알게 됐음. 이는 데이터 레이크하우스라는 개념으로 이어졌음 
  - 데이터 레이크하우스 
    - 데이터 웨어하우스와 데이터 레이크의 측면을 결합한 아키텍처. 일반적으로 생각하듯이 레이크하우스는 마치 호수처럼 객체 스토리지에 데이터를 저장함. 그러나 레이크하우스는 이러한 배열에 데이터 관리를 간소화하고 데이터 웨어하우스와 유사한 엔지니어링 환경을 구축하도록 설계된 기능을 추가함. 즉, 강력한 테이블 및 스키마 지원과 점진적 갱신 및 삭제 관리 기능을 제공함.
    - 레이크하우스는 일반적으로 테이블 이력과 롤백도 지원하는데, 오래된 버전의 파일 및 메타데이터를 유지함으로써 실현됨. 
    - 레이크하우스 시스템은 데이터 관리 및 변환 도구와 함께 배포되는 메타데이터 및 파일 관리 계층. 데이터브릭스는 오픈 소스 스토리지와 관리 시스템인 델타 레이크를 통해 레이크하우스 개념을 크게 알림. 
    - 데이터를 객체 스토리지에 저장하고 자동화된 메타데이터 관리, 테이블 이력, 갱신 및 삭제 기능을 제공함. 기본 파일과 스토리지 관리의 복잡성은 사용자에게 완전히 숨겨져 있ㅁ음. 
    - 데이터 레이크하우스가 독점 도구에 비해 갖는 주요 이점은 상호 운용성. 개방형 파일 형식으로 저장하면 도구 간에 데이터를 훨씬 쉽게 교환할 수 있음. 전용 데이터베이스 형식의 데이터를 다시 초기화하면 처리, 시간 및 비용 측면에서 오버헤드가 발생함. 데이터 레이크하우스 아키텍처에서는 다양한 도구를 메타데이터 계층에 연결해 객체 스토리지에서 직접 데이터를 읽을 수 있음 
    - 데이터 레이크하우스에 있는 대부분의 데이터는 테이블 구조가 적용되지 않을 수 있다는 점을 강조하는게 중요함. 데이터 웨어하우스 기능을 필요한 곳에 적용하고, 다른 데이터는 원시 또는 비정형 형식으로 남겨둘 수 있음. 데이터 레이크하우스 기술은 빠르게 발전하고 있음. 아파치 후디와 아파치 아이스버그를 비롯해 델타 레이크의 새로운 경쟁자들이 다양하게 속속 등장하고 있음 
  - 데이터 플랫폼 
    - 코어 데이터 스토리지 계층에 긴밀하게 통합되어 상호 운용이 가능한 도구로 구성된 생태계를 구축했음. 
    - 플랫폼에서 직접 제공되지 않는 도구도 데이터 교환을 위한 추가적인 데이터 오버헤드를 감수하면 상호 운용할 수 있음. 
    - 플랫폼은 비정형 사용 사례에 대한 객체 스토리지와의 긴밀한 통합을 강조함 
  - Stream-to-Batch 스토리지 아키텍처
    - 기본적으로 스트리밍 스토리지 시스템의 토픽을 통과하는 데이터는 여러 소비자에게 기록됨. 이러한 소비자 중 일부는 스트림에 대한 통계를 생성하는 실시간 처리 시스템일 수 있음. 또한 배치 스토리지 사용자는 장기 보존 및 배치 쿼리를 위해 데이터를 씀. 배치 소비자는 (시간이나 배치 크기 등) 설정 가능한 트리거에 근거해 S3 객체를 생성할 수 있는 AWS 키네시스 파이어호스가 될 수도 있음
    - 빅쿼리와 같은 시스템은 스트리밍 데이터를 스트리밍 버퍼로 수집함. 이 스트리밍 버퍼는 자동으로 컬럼형 객체 스토리지로 다시 초기화됨. 쿼리 엔진은 스트리밍 버퍼와 객체 데이터 모두에 대한 원활한 쿼리를 지원해 사용자에게 거의 실시간에 가까운 최신 테이블 뷰를 제공함 
- 스토리지의 주요 아이디어와 동향
  - 데이터 카탈로그는 엔터프라이즈 데이터 엔지니어링 및 데이터 관리라는 트렌드에 적합함
  - 데이터 카탈로그
    - 데이터 카탈로그는 조직 전체의 모든 데이터에 대한 중앙 집중식 메타데이터 저장소 
    - 데이터 카탈로그는 최상위 수준의 데이터 스토리지 추상화는 아니지만, 다양한 시스템 및 추상화와 통합됨. 데이터 카탈로그느 일반적으로 운영 및 분석 데이터 원천에서 작동하며 데이터 계통과 데이터 관계 표현(presentation)을 통합하고 사용자가 데이터 설명을 편집할 수 있도록 함
    - 데이터 카탈로그는 종종 사용자가 데이터, 쿼리 및 데이터 저장소를 볼 수 있는 중앙 위치를 제공하는 데 쓰임. 데이터 엔지니어는 데이터 카탈로그 및 데이터 카탈로그 자체의 무결성과 통합되는 데이터 파이프라인과 스토리지 시스템의 다양한 데이터 통합을 설정하고 유지 관리해야 할 책임이 있음 
    - 카탈로그 애플리케이션 통합
      - 데이터 애플리케이션은 카탈로그 API와 통합되어 메타데이터 및 갱신을 직접 처리하도록 설계되는 게 이상적임
    - 자동화된 스캔
      - 실제로 카탈로그 시스템은 일반적으로 데이터 레이크, 데이터 웨어하우스 및 운영 데이터베이스 같은 다양한 시스템에서 메타데이터를 수집하는 자동화된 검색 계층을 사용해야 함. 
      - 데이터 카탈로그는 기존 메타데이터를 수집할 수 있으며, 스캔 도구를 사용해 주요 관계나 민감한 데이터의 존재 여부와 같은 메타데이터를 추론할 수도 있음 
    - 데이터포털 및 소셜 계층
      - 데이터 카탈로그는 일반적으로 웹 인터페이스를 통해 사용자가 데이터를 검색하고 데이터 관계를 볼 수 있는 사용자 접근 계층을 제공함. 
      - 데이터 카탈로그는 위키 기능을 제공하는 소셜 계층을 통해 향상될 수 있음. 이를 활용하면 사용자는 데이터셋에 대한 정보를 제공하고, 다른 사용자에게 정보를 요청하며, 갱신이 있을 때는 이를 게시할 수 있음 
    - 데이터 카탈로그 사용 사례
      - 데이터 카탈로그에는 조직적 활용 사례와 기술적 활용 사례가 모두 있음. 데이터 카탈로그를 사용하면 시스템에서 메타데이터를 쉽게 사용할 수 있음. 
      - 예를 들어 데이터 카탈로그는 데이터 레이크하우스의 주요 구성 요소이므로 쿼리를 위한 테이블 검색 기능을 제공함. 데이터 카탈로그를 조직적으로 사용하면 비즈니스 사용자, 분석가, 데이터 과학자 및 엔지니어가 질문에 답할 데이터를 검색할 수 있음. 데이터 카탈로그는 조직 간 커뮤니케이션과 협업을 간소화함
  - 데이터 공유(data sharing)
    - 조직과 개인은 데이터 공유를 통해 특정 데이터와 신중하게 정의된 권한을 특정 엔티티와 공유할 수 있음. 데이터 과학자는 데이터 공유를 통해 샌드박스의 데이터를 조직 내 공동 작업자와 공유할 수 있음. 조직 전체에서 데이터 공유는 협력업체 간의 협업을 촉진함 
    - 조직은 우발적인 노출이나 고의적인 유출을 방지하기 위해 데이터를 공유할 수 있는 사용자를 관리하는 정책을 신중하게 제거해야 함 
  - 스키마 
    - 스키마는 반드시 관계형(relational)일 필요는 없음. 오히려 데이터의 구조와 조직에 관한 정보가 많을수록 더 유용함. 데이터 레이크에 저장된 이미지의 경우, 이러한 스키마 정보는 이미지 형식, 해상도 및 이미지가 더 큰 계층에 적합한 방식을 설명할 수 있음 
    - 스키마는 데이터를 읽는 방법을 알려주는 일종의 로제타 스톤과 같은 역할을 할 수 있음. 주요스키마 패턴은 쓰기 스키마와 읽기 스키마 두 가지가 있음 
      - 쓰기 스키마
        - 기본적으로 전통적인 기존 데이터웨어하우스 패턴. 테이블에는 통합 스키마가 있으며, 테이블에 대한 모든 쓰기는 스키마를 준수해야 함 
        - 쓰기 스키마를 지원하려면 데이터 레이크가 스키마 메타스토어를 통합해야 함
      - 읽기 스키마
        - 스키마는 데이터를 쓸 때 동적으로 생성되며, 리더는 데이터를 읽을 때 스키마를 결정해야 함. 읽기 스키마는 파케이 또는 JSON 등 내장 스키마 정보를 구현하는 파일 형식을 사용해 구성되는 것이 이상적
        - CSV 파일은 스키마의 불일치로 악명이 높기 때문에 이 설정에서는 권하지 않음 
      - 주요 장점은 데이터 표준을 적용해 향후 데이터를 더 쉽게 소비하고 활용할 수 있다는 것. 한편 읽기 ㅅ스키마는 유연성을 강조해 거의 모든 데이터를 쓸 수 있음. 다만 향후 데이터를 소비하는 데 큰 어려움을 겪을 수 있음
  - 컴퓨팅과 스토리지의 분리 
    - 컴퓨팅과 스토리지의 코로케이션
      - 트랜잭션 데이터베이스의 경우에는 데이터 코로케이션을 통해 지연 시간이 짧은 디스크 읽기와 높은 대역폭을 확보할 수 있었음. 스토리지를 가상화하는 경우에도(예: 아마존 EBS 사용) 데이터는 호스트 시스템과 비교적 가깝게 배치됨
    - 컴퓨팅과 스토리지의 분리
      - 컴퓨팅과 스토리지를 분리하는 방향으로 전환하는 이유
        - 임시성과 확장성
          - 클라우드에서는 일시적인 것, 즉 임시성(ephemerality)으로의 극적인 변화를 목격했음. 일반적으로는 (서버를 수년 동안 쉬지 않고 하루 24시간 계속 가동한다는 가정 아래) 서버를 클라우드 벤더로부터 임대하는 것보도 구입 및 호스팅하는 것이 더 저렴함.
          - 실제로 워크로드는 매우 다양하며, 서버의 스케일 업 및 스케일 다운이 가능할 때 종량제 모델을 통해 상당한 효율성을 실현할 수 있음. 이는 온라인 소매업체의 웹 서버나 정기적으로만 실행되는 빅데이터 배치 작업에도 해당함
          - 임시 컴퓨팅 리소스를 사용하면 엔지니어는 대규모 클러스터를 스핀업해 제시간에 작업을 완료한 다음에 클러스터를 삭제할 수 있음. 일시적으로 매우 큰 대규모로 운용함으로써 얻을 수 있는 성능상의 이점은 객체 스토리지의 대역폭 제한을 능가할 수 있음 
        - 데이터 내구성과 가용성
          - 클라우드 객체 저장소는 데이터 손실 위험을 크게 줄이고 일반적으로 매우 높은 가동 시간(가용성)을 제공함 
          - 여러 영역을 사용할 수 있으면 데이터가 중단될 확률도 낮아짐. 한 영역의 리소스가 다운되면 엔지니어는 다른 영역의 동일한 리소스를 스핀업할 수 있음
          - 잘못된 구성 때문에 객체 스토리지의 데이터가 파괴될 무시무시한 가능성은 여전히 남아 있지만, 이를 쉽게 완화할 방법이 있음. 일반적으로 구성 변경은 한 번에 한 리전에만 배포되므로, 데이터를 여러 클라우드 리전으로 복사하면 이러한 위험은 줄어듬. 데이터를 여러 스토리지 공급자에 복제하면 위험을 더욱 줄일 수 있음 
        - 하이브리드 분리와 코로케이션
          - 멀티티어 캐싱(multitier caching)에서는 장기적인 데이터 보관 및 접근을 위해 객체 스토리지를 활용하지만, 쿼리 및 데이터 파이프라인의 다양한 단계에서 사용하기 위해 로컬 스토리지를 스핀업함. 구글과 아마존 모두 하이브리드 객체 스토리지(컴퓨팅과 긴밀하게 통합된 객체 스토리지)버전을 제공함
          - 예시: S3 및 HDFS를 사용하는 AWS EMR
            - 아마존 EMR과 같은 빅데이터 서비스는 데이터를 처리하기 위해 임시 HDFS 클러스터를 스핀업함. 엔지니어는 S3와 HDFS를 파일 시스템으로 참조할 수 있음. 일반적인 패턴은 SSD 드라이브에 HDFS를 설치하고 S3에서 데이터를 꺼낸 다음, 로컬 HDFS에 중간 처리 단계의 데이터를 저장하는 것. 이렇게 하면 S3에서 직접 처리하는 것보다 훨씬 높은 성능 향상을 실현할 수 있음. 
            - 클러스터 절차를 완료하고 클러스터와 HDFS가 삭제되면 전체 결과가 S3에 다시 기록됨. 다른 소비자는 S3에서 출력 데이터를 직접 읽음 
          - 예시: 아파치 스파크
            - 실제로 스파크는 보통 HDFS 또는 기타 임시 분산 파일 시스템에서 작업을 실행함으로써 처리 단계 간의 데이터 고성능 저장을 지원함. 또한 스파크는 처리 능력을 개선하기 위해 인메모리 데이터 스토리지에 크게 의존함. 
            - 스파크를 실행하기 위한 인프라를 소유할 때의 문제점은 DRAM(Dynamic RAM)이 매우 비싸다는 것. 클라우드에서 컴퓨팅과 스토리지를 분리하면 대량의 메모리를 빌린 다음에 작업이 완료되면 해당 메모리를 해제할 수 있음 
          - 예시: 아파치 드루이드
            - 아파치 드루이드는 고성능을 구현하기 위해 SSD에 크게 의존함. SSD는 자기 디스크보다 훨씬 더 비싸기 때문에 드루이드는 클러스터에 데이터 사본을 하나만 보관해 라이브스토리지 비용을 3배까지 절감함.
            - 데이터 내구성을 유지하는 것은 여전히 중요하기 때문에 드루이드는 객체 저장소를 내구성 계층으로 사용함. 데이터가 수집되면 처리되고 압축된 열로 직렬화되어 클러스터 SSD 및 객체 스토리지에 기록됨. 노드에 장애가 발생하거나 클러스터 데이터가 손상될 때는 데이터를 새 노드로 자동 복구할 수 있음. 또한 클러스터를 종료한 다음 SSD 스토리지에서 완전히 복구할 수 있음 
