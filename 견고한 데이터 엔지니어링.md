# 서평
- 이 책은 비즈니스에 가치를 더하는 적절한 데이터 엔지니어링이란 무엇일까요? 데이터 엔지니어가 고민해야 할 요소들은 무엇일까요? 라는 질문에 많은 생각과 답을 찾아가는데 도움을 주는 책인거 같습니다. 이 책에서 논의하는 데이터 엔지니어는 더 정확하게 묘사하자면 데이터 수명 주기 엔지니어로 표현할 수 있습니다.

# 데이터 엔지니어링 기반 구축하기
## 데이터 엔지니어링 상세 
- 데이터 엔지니어링이란?
  - 알텍스소프트의 데이터 엔지니어링의 개념, 프로세스 및 도구
    - 데이터 엔지니어링은 데이터 과학자, 데이터 분석가, 비즈니스 인텔리전스 개발자, 그리고 조직 내의 다른 전문가가 데이터를 사용할 수 있도록 만드는 일련의 작업이다. 대규모의 데이터를 수집 및 저장하면서 추가 분석을 수행할 수 있는 데이터를 준비하기 위한 시스템을 설계하고 구축하려면 데이터 엔지니어와 같은 전담 전문가가 필요하다. 간단히 말해서, 데이터 엔지니어는 조직의 데이터 인프라를 구축하고 운영해 데이터 분석가와 데이터 과학자가 추가 분석을 수행할 수 있도록 준비한다.
  - 데이터 엔지니어링 정의
    - 데이터 엔지니어링은 원시 데이터(raw data)를 가져와 분석 및 머신러닝과 같은 다운스트림 사용 사례를 지원하는, 고품질의 일관된 정보를 시스템과 프로세스의 개발, 구현 및 유지 관리이다. 데이터 엔지니어링은 보안, 데이터 관리, 데이터 운영, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링의 교차점이다.
    - 데이터 엔지니어는 원천 시스템에서 데이터를 가져오는 것부터 시작해 분석 또는 머신러닝과 같은 사용 사례에 데이터를 제공하는 것으로 끝나는 데이터 엔지니어링 수명 주기를 관리한다.
  - 데이터 엔지니어링 수명 주기
    - 단계
      - 데이터 생성(generation)
      - 데이터 저장(Storage)
      - 데이터 수집(Ingestion)
      - 데이터 변환(Transformation)
      - 데이터 서빙(Serving)
    - 데이터 엔지니어링 수명 주기는 전체 수명 주기에 걸쳐 중요한 아이디어인 드러나지 않는 요소(undercurrent)라는 개념을 포함함. 여기에는 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링이 포함됨
  - 데이터 엔지니어의 진화
    - 1980년부터 2000년까지: 데이터 웨어하우징에서 웹으로
      - 1980년대에 비즈니스 데이터 웨어하우스라는 용어가 형성되었으며 1989년 빌 인먼이 데이터 웨어하우스라는 용어를 공식적으로 만들었음.
      - IBM의 엔지니어들이 관계형 데이터 베이스와 구조적 질의 언어(SQL, Structured Query Language)를 개발한 이후 오라클은 이 기술을 대중화함
      - BI를 위한 전용  툴과 데이터 파이프라인이 필요해졌으며 랄프 킴벌과 빌 인먼은 데이터 모델링 기법과 접근 방식을 개발 했음
      - 데이터 웨어하우징은 대량의 데이터를 처리하고 전례 없는 막대한 양의 데이터를 지원하고자, 다수의 프로세서를 사용하는 새로운 대규모 병렬 처리(MPP) 데이터베이스로 확장성 있는 분석의 첫 시대를 열음. 이로 인해 BI 엔지니어, ETL 개발자, 데이터 웨어하우스 엔지니어와 같은 역할은 데이터 웨어하우스의 다양한 요구 사항을 해결함 
      - 인터넷은 1990년대 중반에 주류를 이루었고 AOL, 야후, 아마존과 같은 세대의 웹 우선(web-first) 기업을 탄생함. 닷컴 열풍은 웹 애플리케이션과 이를 지원하는 백엔드 시스템(서버, 데이터베이스 ,스토리지)에서 엄청난 활동을 만듬. 대부분의 인프라는 비용이 많이 들고, 거대했으며, 라이선스의 부담이 매우 컸음 
    - 2000년대 초: 현대 데이터 엔지니어링의 탄생
      - 닷컴 열풍이 무너지고 생존자 중 일부인 야후, 구글, 아마존 같은 기업들은 강력한 기술 기업으로 성장함. 1990년대의 전통적인 모놀리식 관계형 데이터베이스와 데이터 웨어하우스에 계속 의존하면서 시스템을 한계까지 몰아붙임.
      - 데이터의 폭발적 증가와 함께 서버, RAM, 디스크, 플래시 드라이브와 같은 범용 하드웨어도 저렴해지고 어디서나 사용할 수 있게 됐으며 몇 가지 혁신은 대규모 컴퓨팅 클러스터에서의 분산 연산 및 저장을 실현함. 이러한 혁신은 전통적인 모놀리식 서비스를 분산하고 분리하기 시작함.(빅데이터시대, 3V)
      - 2003년 구글은 구글 파일 시스템에 관한 논문을 발표했고, 그 직후인 2004년에는 초확장 데이터 처리 패러다임인 맵리듀스에 대한 논문을 발표했음.
      - 구글의 논문들은 야후의 엔지니어들이 2006년 아파치 하둡을 개발하고 나중에 오픈소스하는 데 영감을 주었음. 모든 규모와 유형의 기업들이 다루는 데이터가 테라바이트, 심지어 페타바이트 규모로 증가하면서 빅데이터 엔지니어 시대가 탄생함
      - 비슷한 시기에 아마존은 폭발적으로 증가하는 데이터 요구에 대응해야 했으며 EC2, S3, 다이나모DB를 비롯한 데이터 빌딩 블록을 구축했음. AWS가 아마존의 높은 수익성을 책임지는 성장 엔진이 되면서 구글 클라우드, 마이크로소프트 애저, 디지털오션과 같은 다른 퍼블릭 클라우드가 잇따라 등장하기 시작함.퍼블릭 클라우드는 소프트웨어와 데이터 애플리케이션의 개발 및 배포 방식에 혁명을 일으킴  
    - 2000년대와 2010년대: 빅데이터 엔지니어링
      - 하둡 생태계의 오픈 소스 빅데이터 도구는 빠르게 성숙했고, 배치 컴퓨팅에서 이벤트 스트리밍으로의 전환과 함께 또 다른 혁명이 발생했고 실시간 빅데이터의 새로운 시대를 열었음.
      - 엔지니어는 하둡, 피그, 하이브, 드레멜, HBase, 스톰, 카산드라, 스파크, 프레스토 등 최신 기술을 선택할 수 있었고 기존의 엔터프라이즈 지향적이고 GUI 기반인 데이터 도구는 갑자기 구식으로 느껴지며 맵리듀스의 출현으로 코드 우선(code-first) 엔지니어링이 유행했음
      - 데이터 도구가 폭발적으로 증가하면서 빅데이터 엔지니어가 탄생했으며 하둡,얀,HDFS,맵리듀스를 포함하는 하둡 생태계 같은 도구와 기술을 효과적으로 사용하려면 빅데이터 엔지니어가 소프트웨어 개발 및 저수준의 인프라 해키에 능숙해야 했지만, 강조점이 바뀌었음. 빅데이터 엔지니어는 보통 대규모 데이터를 제공하고자 상용 하드웨어의 대규모 클러스터를 유지 관리했고 핵심 기술 개발에서 데이터 전달로 초점이 옮겨짐.
    - 2020년대: 데이터 수명 주기를 위한 엔지니어링
      - 데이터 엔지니어는 역사적으로 하둡, 스파크 또는 인포매티카와 같은 모놀리식 프레임워크의 저수준의 세부 정보를 사용하는 경향이 있었음. 하지만 이제는 그 트렌드가 분산되고 모듈화되고, 관리되고, 고도로 추상화된 도구로 이동중임
      - 데이터 엔지니어링은 점차 궁극적인 비즈니스 목표를 달성하고자 다양한 기술을 마치 레고 블록처럼 연결하고 상호 운용하는 분야가 되고 있음
      - 데이터 엔지니어는 여전히 저수준의 데이터 프로그래밍 기술을 유지하고 필요에 따라 이를 사용합니다. 하지만 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션 및 일반 데이터 수명 주기 관리와 같은 가치 사슬의 상위 영역에 자신의 역할이 점점 더 집중되고 있음을 발견함
      - 이제 CCPA와 GDPR 같은 약어에 정통하며 파이프라인을 설계할때는 개인정보보호, 익명화, 데이터 가비지 수집 및 규정 준수에 관심을 가지고 고민함
- 데이터 엔지니어링 기술과 활동
  - 데이터 엔지니어의 기술 역량에는 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처 및 소프트웨어 엔지니어링과 같은 데이터 엔지니어링의 드러나지 않는 요소가 포함됨
  - 데이터 엔지니어는 수많은 복잡한 가변적 요소를 처리하고 비용, 민첩성, 확장성, 단순성, 재사용성, 상호 운용성의 축에 따라 지속해서 최적화를 수행해야 함
  - 데이터 성숙도와 데이터 엔지니어
    - 데이터 성숙도(data maturity)는 조직 전체어 걸쳐 더 높은 데이터 활용률(utilization), 기능(capability), 통합(ingegration)을 향해 나아가는 과정
    - 단순화된 기업용 데이터 성숙도 모델
      - 데이터로 시작하기
        - 데이터로 시작하는 조직의 데이터 엔지니어는 다음과 같은 사항에 중점을 두어야 함
          - 데이터 엔지니어는 기업의 목표를 지원하는 데이터 아키텍처를 설계하고 구축하는 중요한 계획에 대한 스폰서를 확보하는 것이 이상적
          - 적절한 데이터 아키텍처를 정의한다(데이터 아키텍트가 없을 가능성이 높으므로 보통 홀로 진행함). 이는 데이터 이니셔티브를  통해 달성하려는 경영 목표와 경쟁 우위를 결정한다는 의미로, 이러한 목표를 지원하는 데이터 아키텍처를 구축함 
      - 데이터로 확장하기
        - 해당 조직에서 데이터 엔지니어의 목표
          - 공식적인 데이터 관행 수립
          - 확장성 있고 견고한 데이터 아키텍처 구축
          - 데브옵스 및 데이터옵스 관행 채택
          - ML을 지원하는 시스템 구축
          - 차별화되지 않은 과중한 업무를 피하고, 경쟁 우위를 확보할 때만 커스터마이징 
      - 데이터로 선도하기
        - 이전 단계를 계속 구축함과 동시에 다음 작업을 수행함
          - 새로운 데이터의 매끄러운 배포와 사용을 위한 자동화를 구축함
          - 경쟁 우위로서 데이터를 활용하는 사용자 정의 도구와 시스템 구축에 주력함
          - 데이터 관리(데이터 거버넌스와 품질을 포함) 및 데이터옵스와 같은 데이터의 기업적 측면에 집중함
          - 데이터 카탈로그, 데이터 계보 도구, 메타데이터 관리 시스템을 포함해 데이터를 조직 전체에 노출하고 전파하는 도구를 배포함
          - 소프트웨어 엔지니어, ML 엔지니어, 분석가 등과 효율적으로 협업함
          - 역할이나 직책과 관계없이 사람들이 협업하고 공개적으로 토론할 수 있는 커뮤니티와 환경을 구축함
  - 데이터 엔지니어의 배경과 기술
    - 데이터 엔지니어는 정의상 데이터와 기술을 모두 이해해야 함.
      - 데이터 측면에서는 데이터 관리의 다양한 모범 사례를 알아야 함
      - 기술 측면에서는 데이터 엔지니어가 도구들의 다양한 옵션, 상호 작용 및 상충 관계를 알아야 함. 그러려면 소프트웨어 엔지니어링, 데이터옵스 및 데이터 아키텍처를 이해해야 함 
  - 기술 책임
    - 최근 들어 완전 관리형 서비스는 과거 엔지니어들에게 요구되는 수많은 저수준 프로그래밍 작업을 상당 부분 대체하게 됐음. 이제 엔지니어는 관리형 오픈 소스와 단순한 플러그 앤 플레이 SaaS 제품을 사용함
    - 예를 들어 데이터 엔지니어는 이제 고수준의 추상화에 주력하거나 오케스트레이션 프레임워크 내에서 파이프라인을 코드로 작성하는 작업에 더 집중함
    - 데이터 엔지니어링의 주요 언어
      - SQL
        - 스파크 SQL, 구글 빅쿼리, 스노우플레이크, 하이브 및 기타 여러 데이터 도구는 선언적이고 집합론적인 SQL 시맨틱을 사용해 대량의 데이터를 처리할 수 있음.
        - SQL은 아파치 플링크, 빔, 카프카와 같은 많은 스트리밍 프레임워크에서도 지원됨 
      - Python, Java, Scalar
      - 자바 가상 머신
        - 스파크, 하이브, 드루이드와 같은 아파치 오픈 소스 프로젝트에 널리 쓰임
        - JVM은 보통 파이썬보다 성능이 우수하며,(스파크와 빔등의 경우) 파이썬 API보다 저수준의 특성에 접근할 수 있음.
        - 널리 쓰이는 오픈 소스 데이터 프레임워크를 사용한다면 자바 또는 스칼라와 같은 언어를 이해하는 것이 유용함 
      - bash
    - 보저직인 프로그래밍 언어
      - R, 자바스크립트, Go, Rust, C/C++, C#, Julia 등
  - A에서 B로 이어지는 데이터 엔지니어링 역할의 연속성
    - A형 데이터 엔지니어
      - A는 추상화(abstraction)을 의미함. 이 경우 데이터 엔지니어는 차별화되지 않은 과중한 작업을 피하고, 데이터 아키텍처를 가능한 한 추상적이고 단순하게 유지함으로써 시간 낭비를 피함
      - A형 데이터 엔지니어는 주로 시판되는 기성 제품, 관리형 서비스와 도구들을 사용해 데이터 엔지니어링 수명 주기를 관리함.
      - A형 데이터 엔지니어는 데이터 성숙도 수준에 상관없이 산업계 전반에 걸쳐 다양한 회사에서 근무함
    - B형 데이터 엔지니어
      - B는 구축을(build)를 의미함
      - B형 데이터 엔지니어는 기업의 핵심 역량과 경쟁 우위를 확장하고 활용할 데이터 도구와 시스템을 구축함
      - B형 데이터 엔지니어는 데이터 성숙도 범위에서 (데이터로 확장하고 선도하는) 2단계 및 3단계에 해당하거나, 초기 데이터 사용 사례가 매우 독특하고 중요해서 작업을 시작하려면 맞춤형 데이터 도구가 필요한 회사에서 더 많이 찾아볼 수 있음 
- 조직 내 데이터 엔지니어
  - 내부 vs 외부 대면 데이터 엔지니어
    - 외부 대면(external-facing) 데이터 엔지니어는 일반적으로 소셜 미디어 앱, 사물 인터넷 장치, 전자 상거래 플랫폼과 같은 외부용 애플리케이션의 사용자와 연계함. 이 데이터 엔지니어는 이러한 애플리케이션에서 발생하는 트랜잭션 및 이벤트 데이터를 수집, 저장, 처리하는 시스템을 설계, 구축, 관리함
    - 내부 대면(internal-facing) 데이터 엔지니어는 일반적으로 비즈니스 및 내부 이해관계자의 요구 사항에 중요한 활동에 집중함. 예를 들면 BI 대시보드, 보고서, 비즈니스 프로세스, 데이터 과학, ML 모델용 데이터 파이프라인과 데이터 웨어하우스의 생성 및 유지 보수 등이 포함됨 
  - 데이터 엔지니어와 기타 기술 역할
    - 데이터 엔지니어는 소프트웨어 엔지니어, 데이터 아키텍트, 데브옵스 엔지니어 또는 사이트 신뢰성 엔지니어(SRE) 같은 데이터 생산자(data producer)와 데이터 분석가, 데이터 과학자, ML 엔지니어 등과 같은 데이터 소비자(data consumer)사이에서 허브 역할을 함. 또한 데이터 엔지니어는 데브옵스 엔지니어와 같이 운영 역할을 하는 사람들과 소통함
    - 업스트림 이해 관계자
      - 데이터 아키텍트
        - 데이터 아키텍트는 조직 내 데이터 관리를 위한 청사진을 설계하고, 프로세스와 전체 데이터 아키텍처 및 시스템을 매핑함. 또한 조직의 기술적 측면과 비기술적 측면을 연결하는 가교 역할을 수행함
        - 데이터 아키텍트는 사일로 및 사업부 전체에 걸쳐 데이터를 관리하는 정책을 구현하고, 데이터 관리 및 데이터 거버넌스와 같은 글로벌 전략을 조율하며, 중요한 이니셔티브를 안내함.
        - 데이터 아키텍트는 클라우드 마이그레이션과 신규 클라우드 설계에서 중심적인 역할을 수행하는 경우가 많음
      - 소프트웨어 엔지니어
        - 소프트웨어 엔지니어는 비즈니스를 운영하는 소프트웨어와 시스템을 구축함. 이들은 데이터 엔지니어가 소비하고 처리하는 내부 데이터(internal data)의 생성 업무에 큰 책임이 있음.
        - 소프트웨어 엔지니어가 구축한 시스템은 보통 애플리케이션 이벤트 데이터와 로그를 생성하는데 이는 그 자체로 중요한 자산임. 이러한 내부 데이터는 SaaS 플랫폼 또는 파트너 비즈니스에서 가져온 외부 데이터(external data)와 대조됨
      - 데브옵스 엔지니어와 사이트 신뢰성 엔지니어
        - 데브옵스 엔지니어와 사이트 신뢰성 엔지니어(SRE)는 종종 운영 모니터링을 통해 데이터를 생성함
    - 다운스트림 이해관계자
      - 데이터 과학자
        - 데이터 과학자는 예측과 추천을 위한 미래 지향적인 모델을 구축함. 그런 다음 이러한 모델을 라이브 데이터로 평가해 다양한 방식으로 가치를 제공함
        - 특히 널리 사용되는 수많은 데이터 과학 프레임워크는 적절히 확장되지 않으면 병목 현상이 발생할 수 있음. 단일 워크스테이션에서만 작업하는 데이터 과학자는 데이터 다운샘플링을 강요당해 데이터 준비가 상당히 복잡해지고 만들어낸 모델의 품질이 저하될 가능성이 있음. 게다가 로컬에서 개발된 코드와 환경은 실제 운영 환경에서 배포하기 어렵고, 자동화가 부족하면 데이터 과학 워크플로에 크게 방해가 됨
      - 데이터 분석가
        - 데이터 분석가(또는 비즈니스 분석가)는 비즈니스 성과와 동향을 파악하고자 함. 데이터 과학자가 미래지향적이라면 데이터 분석가는 보통 과거 또는 현재에 초점을 맞춤
        - 데이터 분석가는 일반적으로 데이터 웨어하우스 또는 데이터 레이크에서 SQL 쿼리를 실행함. 또한 계산 및 분석을 위해 스프레드시트를 활용하며 마이크로소프트 파워 BI, 루커, 태블로 등의 다양한 BI 도구를 사용할 수도 있음
        - 데이터 분석가는 자주 사용하는 데이터의 도메인 전문가로서 데이터 정의, 특징 및 품질 문제에 정통함. 데이터 분석가의 일반적인 다운스트림 고객은 비즈니스 사용자, 경영진 및 임원
      - 머신러닝 엔지니어와 인공지능 연구원
        - ML 엔지니어는 고급 ML 기술을 개발하고, 모델을 훈련하며, 확장된 운영 환경에서 ML 프로세스를 실행하는 인프라를 설계하고 유지 관리함
        - ML 엔지니어는 종종 ML과 파이토치 또는 텐서플로와 같은 딥러닝 기술 및 프레임워크에 대한 고급 실무 지식을 갖추고 잇음
        - ML 엔지니어는 운영 환경에서의 모델 훈련과 모델 배포를 위해 이러한 프레임워크를 실행하는 데 필요한 하드웨어와 서비스 및 시스템을 이해함
        - ML 워크플로는 보통 ML 엔지니어가 온디맨드 방식으로 인프라 자원을 스핀업하고 확장하거나 관리형 서비스에 의존할 수 있는 클라우드 환경에서 실행됨 

## 데이터 엔지니어링 수명 주기 
- 데이터 엔지니어링 수명 주기란?
  - 데이터 엔지니어링 수명 주기는 원시 데이터의 요소를 분석가, 데이터 과학자, ML 엔지니어 등이 사용할 수 있는 유용한 최종 제품으로 전환하는 단계로 구성됨
  - 데이터 생성
    - 원천 시스템(source system)은 데이터 엔지니어링 수명 주기에서 사용되는 데이터의 원본. 예를 들어 원천 시스템은 IoT 장치, 애플리케이션 메시지 대기열 또는 트랜잭션 데이터베이스일 수 있음
    - 데이터 엔지니어는 원천 시스템의 작동 방식, 데이터 생성 방식, 데이터의 빈도 및 속도, 생성되는 데이터의 다양성을 실무적으로 이해해야 함
    - 원천 시스템 평가: 주요 엔지니어링 고려 사항
      - 데이터 엔지니어가 고려할 원천 시스템의 평가 질문 스타터킷(starter kit)
        - 데이터 원천의 본질적인 특징은 무엇인가? 데이터 원천은 애플리케이션인가? IoT 장치의 스웜인가?
        - 원천 시스템에서 데이터는 어떻게 유지되는가? 데이터는 장기간 보존되는가? 아니면 일시적이고 빠르게 삭제되는가?
        - 데이터는 어느 정도의 속도로 생성되는가? 초당 몇 개의 이벤트가 발생할까? 시간당 몇 기가바이트인가?
        - 데이터 엔지니어는 출력 데이터에서 어느 정도의 일관성을 기대할 수 있는가? 출력 데이터에 대해 데이터 품질 검사를 실행할 때, 예상치 못한 출력값(예를 들면 null값)이나 잘못된 데이터 포맷과 같은 데이터 불일치 사례는 얼마나 자주 발생할까?
        - 에러는 얼마나 자주 발생하는가?
        - 데이터에 중복이 포함되지는 않는가? 
        - 일부 데이터값이 동시에 생성되는 다른 메시지보다 훨씬 늦게 도착할 수 있는가?
        - 수집된 데이터의 스키마는 무엇인가? 데이터 엔지니어가 데이터를 완전히 파악하려면 여러 테이블 또는 여러 시스템에 걸쳐 조인을 수행해야 하는가?
        - 스키마가 변경되면(예를 들어 새로운 열이 추가되었을 때) 어떻게 대처하고 다운스트림 이해관계자에게 전달할 수 있는가?
        - 원천 시스템에서 데이터를 얼마나 자주 가져와야 하는가?
        - (고객 계정 정보를 추적하는 데이터베이스 등) 상태가 있는 시스템(stateful system)의 경우, 데이터는 정기적인 스냅숏으로 제공되는가? 아니면 변경 데이터 캡처(CDC)로부터 갱신 이벤트로 제공되는가? 변경은 어떻게 수행되며, 원천 데이터베이스에서 이러한 변경을 어떻게 추적하는가?
        - 다운스트림 사용을 위한 데이터를 전송하는 데이터 제공업체는 누구(무엇)인가?
        - 데이터 원천에서의 데이터 조회가 성능에 영향을 미치는가?
        - 원천 시스템에 업스트림 데이터 의존 관계가 있는가? 이러한 업스트림 시스템의 특징은 무엇인가?
        - 늦거나 누락된 데이터 확인용으로 데이터 품질 검사가 실시되고 있는가?
      - 스키마리스 방식은 스키마가 없다는 뜻은 아님. 애플리케이션은 메시지 대기열, 플랫 파일(Flat file), BLOB 또는 몽고DB와 같은 도큐먼트 데이터베이스에 데이터가 기록될 때 스키마를 정의함.
      - 관계형 데이터베이스 스토리지를 기반으로 구축된 더 전통적인 모델은 데이터베이스에 적용된 고정 스키마(fixed schema) 방식을 사용하는데, 애플리케이션 쓰기는 이 스키마를 준수해야 함
  - 데이터 저장
    - 스토리지 시스템 평가: 주요 엔지니어링 고려 사항
      - 데이터 웨어하우스, 데이터 레이크하우스, 데이터베이스 또는 객체 스토리지를 위한 스토리지 시스템을 선택할 때 확인할 몇 가지 핵심 엔지니어링 질문
        - 이 스토리지 설루션은 아키텍처에서 요구하는 쓰기 및 읽기 속도와 잘 맞는가?
        - 스토리지가 다운스트림 프로세스의 병목 현상을 초래하지는 않는가?
        - 이 스토리지 기술이 작동하는 방식을 인지하고 있는가? 스토리지 시스템을 최적으로 활용하는가? 아니면 부자연스러운 행동을 하는가? 예를 들어 객체 스토리지 시스템에 높은 비율의 임의 접근(random access) 갱신을 적용하고 있지는 않은가?(이것은 성능 오버헤드가 큰 안티패턴)
        - 이 스토리지 시스템은 향후 예상되는 확장을 처리할 수 있는가? 사용 가능한 총 스토리지, 읽기 작업 속도, 쓰기 볼륨 등 스토리지 시스템의 모든 용량 제한을 고려해야 함
        - 다운스트림 사용자와 프로세스가 필요한 서비스 수준 협약(SLA)에 따라 데이터를 취득할 수 있는가?
        - 스키마 진화, 데이터 흐름, 데이터 계보 등에 대한 메타데이터를 캡처하고 있는가? 메타데이터는 데이터 활용성에 큰 영향을 미친다. 메타데이터는 미래에 대한 투자로, 검색 가능성과 제도적 지식을 획기적으로 향상시켜 미래의 프로젝트 및 아키텍처 변경을 간소화함
        - 순수 스토리지 설루션(객체 스토리지)인가? 아니면 복잡한 쿼리 패턴(예 클라우드 데이터 웨어하우스)을 지원하는가?
        - 스토리지 시스템이 스키마에 구애받지는 않는가(객체 스토리지)? 유연한 스키마(카산드라)인가? 강제 적용된 스키마(클라우드 데이터 웨어하우스)인가?
        - 데이터 거버넌스를 위해 마스터 데이터, 골든 레코드 데이터 품질 및 데이터 계보를 어떻게 추적하고 있는가?
        - 법령 준수 및 데이터 주권에 어떻게 대처하고 있는가? 예를 들어 특정 지리적 위치에는 데이터를 저장하고 다른 위치에는 저장하지 않을 수 있는가?
    - 데이터 접근 빈도 이해
      - 데이터의 온도 : 데이터 접근 빈도에 따라 데이터 온도가 결정됨
        - 핫 데이터 : 가장 자주 액세스 되는 데이터
          - 일반적으로 하루에 여러번 검색됨. 이러한 데이터는 빠른 검색용으로 저장되어야 하는데, 여기서 빠른은 사용 사례에 따라 달라짐
        - 미온적 데이터(lukewarm data): 가끔(매주 또는 매월) 액세스 되는 데이터
        - 콜드 데이터 : 거의 쿼리되지 앟ㄴ으며 아카이브 시스템에 저장하는 데 적합함
          - 콜드 데이터는 규정 준수의 목적으로 보관되거나, 다른 시스템에 심각한 장애가 발생했을 때 보관되는 경우가 많음
  - 데이터 수집
    - 수집 단계에서의 주요 엔지니어링 고려 사항
      - 시스템 설계 또는 구축을 준비할 때 수집 단계에 대한 몇 가지 주요 질문 
        - 수집 중인 데이터의 사용 사례는 무엇인가? 같은 데이터셋의 여러 버전을 생성하는 대신 이 데이터를 재사용할 수 있는가?
        - 시스템이 이 데이터를 안정적으로 생성하고 수집하고 있는가? 필요할 때 해당 데이터를 사용할 수 있는가?
        - 수집 후 데이터 목적지는 어디인가?
        - 데이터는 얼마나 자주 접근해야 하는가?
        - 데이터는 보통 어느 정도의 용량으로 도착하는가?
        - 데이터 형식은 무엇인가? 다운스트림 스토리지 및 변환 시스템에서 이 형식을 처리할 수 있는가?
        - 원천 데이터는 다운스트림에서 즉시 사용할 수 있는 양호한 상태인가? 그렇다면 얼마나 오래 사용할 수 있으며, 사용할 수 없게 되는 요인은 무엇인가?
        - 데이터가 스트리밍 소스에서 전송된 경우, 목적지에 도달하기 전에 데이터를 변환해야 하는가? 데이터가 스트림 자체 내에서 변환되는 형태의 변환이 적절할까?
    - 배치 vs 스트리밍
      - 우리가 다루는 대부분의 데이터는 본질적으로 스트리밍임. 스트리밍 수집을 사용하면 다른 애플리케이션이나 데이터베이스 또는 분석 시스템 등의 다운 스트림 시스템에 데이터를 실시간으로 연속해 제공할 수 있음
        - 많은 시스템에서 스토리지와 컴퓨팅 자원이 분리되고 이벤트 스트리밍과 처리 플랫폼이 보편화됨에 따라, 데이터 스트림의 지속적인 처리에 대한 접근성과 인기가 더욱 높아지고 있음 
      - 데이터는 거의 항상 원천에서 지속해 생성되고 갱신됨. 배치 수집은 이 스트림을 큰 청크로 처리하는 전문적이고 편리한 방법(예를 들어 하루 분량의 데이터를 단일 배치 방식으로 처리함)
        - 배치 데이터는 미리 설정된 시간 간격에 따라, 또는 데이터가 미리 설정된 크기 임계값에 도달하면 수집됨. 배치 수집은 한 방향으로만 이루어지며, 데이터가 배치로 분할되면 다운스트림 소비자의 지연 시간이 본질적으로 제한됨
        - 레거시 시스템의 제약 때문에 오랫동안 배치가 기본적인 데이터 수집 방식이었음. 배치 처리는 특히 분석 및 머신러닝(ML)에서 다운스트림을 사용할 때 데이터를 수집하는 매우 인기 있는 방법
    - 배치와 스트림 수집의 주료 고려 사항
      - 스트리밍 수집이 배치 수집보다 적절한 선택인지 여부를 판단할 때 자문해봐야 할 몇 가지 질문
        - 데이터를 실시간으로 수집하면 다운스트림 스토리지 시스템이 데이터 흐름 속도를 처리할 수 있는가?
        - 밀리초 단위의 실시간 데이터 수집이 필요할까? 아니면 매분마다 데이터를 축적하고 수집하는 마이크로 배치 접근 방식이 효과가 있을까?
        - 스트리밍 수집의 사용 사례로는 무엇이 있을까? 스트리밍을 구현하면 구체적으로 어떤 이점을 얻을 수 있을까? 데이터를 실시간으로 가져올 수 있다면, 배치 방식에 비해 개선될 수 있는 데이터에 대해 어떤 조치를 취할 수 있을까?
        - 스트리밍 우선 접근 방식은 단순 배치 방식보다 시간, 비용, 유지 보수, 다운타임 및 기회비용 측면에서 더 많은 비용을 소비할까?
        - 인프라에 장애가 발생했을 때 스트리밍 파이프라인과 시스템이 안정적이고 다중화되어 있는가?
        - 사용 사례에 가장 적합한 도구는 무엇인가? 관리형 서비스(아마존 키네시스, 구글 클라우드 Pub/Sub, 구글 클라우드 데이터플로)를 사용해야 하는가? 아니면 카프카, 플링크, 스파크, 펄사 등의 인스턴스를 구축해야 할까? 후자를 선택한다면 누가 관리의 역할을 맡을 것인가? 비용과 트레이드오프는 무엇일까?
        - ML 모델을 배포했을 때 온라인 예측 및 지속적인 훈련으로 얻을 수 있는 이점은 무엇일까?
        - 실제 운영 인스턴스에서 데이터를 가져오는가? 그렇다면 이 원천 시스템에 대한 수집 프로세스의 영향도는 얼마나 될까?
    - 푸시 vs 풀
      - 데이터 수집의 푸시 몯레에서 원천 시스템은 데이터베이스, 객체 저장소 또는 파일 시스템과 관계없이 타깃에 데이터를 씀
      - 풀 모델에서는 원천 시스템에서 데이터를 검색함
      - 배치 지향 수집 워크플로에서 일반적으로 사용되는 추출-변환-적재(ETL) 프로세스를 생각해보면 ETL의 추출 부분은 풀 수집 모델을 다루고 있음을 명확히 보여줌. 기존 ETL에서는 수집 시스템이 정해진 일정에 따라 현재 소스 테이블의 스냅숏을 쿼리함
      - 연속적인 CDC
        - 원천 데이터베이스에서 행이 변경될 대마다 메시지를 트리거하는 것. 이 메시지는 큐에 푸시되며, 수집 시스템이 해당 메시지를 가져감.
        - 다른 CDC 방식은 데이터베이스에 대한 모든 커밋을 기록하는 바이너리 로그를 사용하는 것인데, 데이터베이스가 로그를 푸시함. 수집 시스템은 로그를 읽지만, 그 외에는 데이터베이스와 직접 상호 작용하지 않음. 그에 따라 원천 데이터베이스에 대한 추가 부하는 거의 없거나 또는 전혀 추가되지 않음.
        - 배치 CDC의 일부 버전에서는 풀 패턴을 사용함. 예를 들어 타임스탬프 기반 CDC에서는 수집 시스템이 원천 데이터베이스를 쿼리하고 이전 갱신 이후에 변경된 행을 가져옴
  - 데이터 변환
    - 변환 단계에서의 주요 고려 사항
      - 데이터 엔지니어링 수명 주기 내에서 데이터를 변환할 때는 다음 사항을 고려해야 함
        - 변환에 드는 비용과 투자수익률(ROI)은 얼마인가? 관련된 비즈니스 가치는 무엇인가?
        - 변환은 가능한 한 단순하고 독립적인가?
        - 변환이 지원하는 비즈니스 규칙은 무엇인가? 
