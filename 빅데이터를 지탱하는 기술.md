# 주요 내용
- 빅데이터
  - 데이터 엔지니어(data engineer) : 시스템의 구축 및 운용, 자동화 등을 담당
  - 데이터 분석가 : 데이터에서 가치 있는 정보를 추출 
    - 확증적 데이터 분석(confirmatory data analysis) : 가설을 세우고 그것을 검증
    - 탐색적 데이터 분석(exploratroy data analysis) : 데이터를 보면서 그 의미를 읽어내려고 하는것 
- 이 책에서 다루는 것은 데이터 활용 방법이 아니라 '데이터 처리를 어떻게 시스템화하는가에 대한 문제'
- 데이터 처리 과정에 사용되는 소프트웨어와 데이터베이스, 프로그래밍 언어와 시각화 도구 등의 특징을 정리하여 데이터를 효율 높게 취급하기 위한 기초를 먼저 설명 워크플로우 관리와 스트림 처리 등의 데이터 처리 기술을 살펴봄
- 추가적으로 알아두면 좋은 것
  - 비지니스 인텔리전스(Business intelligence) : 기업의 업적 등을 수집해서 경영상의 의사결정에 도움을 주는 것
  - 데이터 마이닝(data mining) : 통계 분석과 머신러닝 등의 알고리즘을 사용하여 데이터로부터 가치 있는 정보를 발견

# 빅데이터 기초 지식
## Hadoop
- 웹 서버 등에서 생성된 데이터는 처음에 RDB와 NoSQL 등의 텍스트 데이터 저장됨 -> 그 후 모든 데이터가 Hadoop으로 모이고, 거기서 대규모 데이터 처리가 실행
- 다수의 컴퓨터에서 대량의 데이터를 처리하기 위한 시스템
- 구글에서 개발된 분산 처리 프레임워크인 'MapReduce'를 참고하여 제작 
  - 초기 Hadoop MapReduce를 동작시키리면 데이터 처리의 내용을 기술하기 위해 자바 언어로 프로그래밍
  - SQL과 같은 쿼리 언어를 Hadoop에서 실행하기 위한 소프트웨어로 Hive(하이브)가 개발됨

## NoSQL 데이터베이스(빈번한 읽기/쓰기 및 분산 처리가 강점)
- 전통적인 RDB의 제약을 제거하는것을 목표로 한 데이터베이스의 총칭
  - 키 밸류 스토어(key-value store/KVS) : 다수의 키와 값을 관련지어 저장
  - 도큐멘트 스토어(document store) : JSON과 같은 복잡한 데이터 구조를 저장
  - 와이드 칼럼 스토어(wide-column store) : 여러 키를 사용하여 높은 확장성을 제공 

## 엔터프라이즈 데이터 웨어하우스(enterprise data warehouse/EDW ,  데이터웨어하우스/DWH)
- 일부 기업에서 데이터 분석 기반으로 사용

## 데이터 디스커버리(data discovery)
- 대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 프로세스
- 셀프서비스용 BI 도구
  - BI 도구(business intelligence tool) : 예전부터 데이터 웨어하우스와 조합되어 사용된 경영자용 시각화 시스템, 대기업 IT 부서에 의해 도입되는 대규모 도구   

## 빅데이터 기술
- 기존의 데이터 웨어하우스와 다른 점 
  - 다수의 분산 시스템을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 점 

### 데이터 파이프라인
- 데이터 파이프라인(데이터 수집에서 워크플로 관리까지)
  - 차례대로 전달해나가는 데이터로 구성된 시스템 

### 데이터 수집
- 데이터 전송(data transfer)
  - 벌크(bulk) 형
    - 이미 어딘가에 존재하는 데이터를 정리해 추출하는 방법
    - 데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는 데에 사용
  - 스트리밍(streaming) 형
    - 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법으로 모바일 애플리케이션과 임베디드 장비 등에서 널리 데이터를 수집하는데 사용

### 스트림 처리와 배치 처리
- 스트림 처리(stream processing)
  - 스트리밍형 방법으로 받은 데이터는 아무래도 실시간으로 처리
- 배치 처리(batch processing)
  - 어느 정도 정리된 데이터를 효율적으로 가공하기 위한 구조 

### 분산 스토리지(객체 스토리지, NoSQL 데이터베이스)
- 분산 스토리지(distribute storage)
  - 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템
- 객체 스토리지(object storage) 
  - 한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장, Amazon S3

### 분산 데이터 처리(쿼리 엔진, ETL 프로세스)
- 빅데이터를 SQL로 집계
  - 1) 쿼리 엔진(query engine)
    - 분산 스토리지 상의 데이터를 SQL로 집계하기 위해, Hive 등
    - 현재 Hive 보다 고속인 대화형 쿼리 엔진(interactive query engine)
  - 2) ETL(extract-transform-load) 프로세스
    - 데이터를 추출(extract)하고, 그것을 가공(transform)한 후, 데이터 웨어하우스에 로드(load)
    - 외부의 데이터 웨어하우스 제품을 이용
    - 분산스토리지에서 추출한 데이터를 데이터 웨어하우스에 적합한 형식으로 변환

### 워크플로 관리
- 전체 데이터 파이프라인의 동작을 관리하기 위해
- 매일 정해진 시간에 배치 처리를 스케줄대로 실행, 오류가 발생한 경우에는 관리자에게 통지하는 목적
- 모니터링
  - 계획적으로 데이터의 변화를 추적해 나가는 것 
  - KPI(key performance indicator) : 프로젝트의 현황을 파악하기 위한 숫자로 업계마다 중요한 지표
    - 행동 가능(actionable) : 그 결과에 따라 자신의 다음 행동이 결정될지 여부 -> 자신의 행동을 결정할 때 직감에 의지하는 것이 아니라 객관적인 데이터를 근거하여 판단하는 것을 데이터 기반(data-driven) 의사 결정 
    - 웹 서비스의 KPI
      - DAU(Daily Active User) : 서비스를 이용한 1일 유저 수
      - 계속률(Customer Retention) : 서비스를 계속해서 이용하고 있는 유저의 비율
      - ARPPU(Average Revenue Per Paid User) : 유료 고객 1인당 평균 매출
    - 온라인 광고의 KPI
      - CTR(Click Through Rate) : 광고의 표시 횟수에 대한 클릭 비율
      - CPC(Cost Per Click) : 1회 클릭에 대해서 지불한 광고비
      - CPA(Cost per Acquisition) : 1건의 고객 취득을 위해 지불된 광고비 
       

## 데이터 웨어하우스와 데이터 마트 - 데이터 파이프라인 기본형
- 데이터 웨어하우스
  - 대량의 데이터를 장기 보존하는 것에 최적화
  - 정리된 데이터를 한 번에 전송하는것은 뛰어나지만 소량의 데이터를 자주 쓰고 읽는 데는 적합하지 않다
    - 데이터 소스(data source) : 업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버
    - 로우 데이터(raw data) : 원시 데이터 
- 데이터 마트
  - 데이터 분석과 같은 목적에 사용하는 경우에는 데이터 웨어하우스에서 필요한 데이터만을 추출하여 데이터 마트(data mart)를 구축

## 데이터 레이크
- 모든 데이터를 원래의 형태로 축적해두고 나중에 그것을 필요에 따라 가공하는 구조
- 여러 곳에서 데이터가 흘러들어오는 데이터를 축적하는 호수에 비유해 데이터의 축적 장소를 데이터 레이크(data lake)
- 대부분의 경우 CSV나 JSON 등의 범용적인 텍스트 

## 애드 혹 분석(ad hoc analysis)
- 자동화 등을 생각하지 않고 수작업으로 데이터를 집계(일회성 데이터 분석)

## 컴퓨터 시스템
- 기간계 시스템(mission-critical system)
  - 비즈니스 근간에 관련된 중요한 시스템으로 이것이 정지되면 업무가 멈추기 때문에 완벽하게 테스트를 반복하고 신중하게 운용
- 정보계 시스템(information system) 
  - 사내 커뮤니케이션과 의사 결정 등을 위해 이용하는 시스템 

# 빅데이터의 탐색
## 크로스 테이블(cross table)
- 행과 열이 교차하는 부분에 숫자 데이터가 들어가는 것 을 부름 

## 트랙잭션 테이블 
- 행 방향으로만 증가하게 하고, 열 방향으로는 데이터를 증가시키지 않는것 
  - 크로스 집계 : 트랜잭션 테이블에서 크로스 테이블로 변환하는 과정
  - 스프레드시트의 피벗 테이블 : 소량의 데이터를 크로스 집계하는데 편리한 것
  - 피벗 그래프 : 결과를 크로스 테이블에 정리할 뿐만 아니라 그것을 그래프로 시각화 한것 

## 룩업 테이블(테이블을 결합하여 속성 늘리기)
- 트랙잭션 테이블에 새로운 항목을 추가하는 것이 아니라, 다른 테이블과 결합하고 싶은 경우에 사용 

## SQL에 의한 테이블의 집계
- BI 도구와 pandas라면 수백만 레코드는 집계할 수 있지만, 그 이상이 되면 너무 느려져서 쓸 수가 없음
- 집계(aggregation) : 대량의 데이터를 크로스 집계하려면 SQL을 사용하여 데이터를 집계, 집계함수 
- 데이터 집계 프로세스 : 데이터를 먼저 SQL로 집계
- 시각화 프로세스 : 시각화 도구로 크로스 집계

## MPP(massive parallel processing : 대규모 병렬 처리)
- 분산된 데이터를 읽어 들이려면 멀티 코어를 활용하면서 디스크 I/O를 병렬 처리하는 것이 효과적 
- 대량의 데이터를 분석하기 위해 데이터베이스에서 널리 사용
- Amazon Redshift , Google BigQuery
- 데이터 집계에 최적화되어 있으며, 데이터 웨어하우스와 데이터 분석용의 데이터베이스에서 특히 많이 사용 
- MPP 데이터 베이스 
  - 하드웨어 수준에서 데이터 집계에 최적화된 데이터베이스 
  - MPP의 아키텍처 : Hadoop과 함께 사용되는 대화형 쿼리 엔진으로 채택 
  - 하나의 쿼리를 다수의 작은 태스크로 분해하고 이를 가능한 한 병렬로 실행 
    - MPP 데이터베이스에서는 여러 디스크에 분산된 데이터가 서로 다른 CPU 코어에 의해 읽혀 부분적인 쿼리 실행이 이루어짐, 그 결과들을 한 곳에 모이고 최종적인 결과가 출력 -> 이러한 일련의 처리는 가능한 한 동시에 병렬로 실행 
    - 디스크로부터의 로드가 병목 현상이 발생하지 않도록 데이터가 고르게 분산
    - 구조상, 고속화를 위해 CPU와 디스크 모두를 균형 있게 늘려야함 
  - 

## 데이터 접근
- 열 지향(column-oriented)
  - 빅데이터로 취급되는 데이터 대부분은 디스크 상에 있기 때문에 쿼리에 필요한 최소한의 데이터만을 가져옴으로써 지연이 줄어들게 됨
- 행 지향(row-orinted database)
  - 일반적으로 업무 시스템 등에서 사용되는 데이터베이스는 레코드 단위의 읽고 쓰기에 최적화 
  - Oracle Database MySQL

- 열 지향 데이터베이스, 칼럼 지향 데이터베이스(칼럼을 압축하여 디스크 I/O를 줄이기)
  - Teradata(테라데이터), Amazon Redshint
  - 칼럼별로 데이터를 보관해두고, 집계 시에 관련된 칼럼만 읽어 들임
  - 열 지향 데이터베이스는 그 데이터 구조상 집계하는 데는 고속이지만, 저장하는 데는 시간이 걸림

- 행 지향 데이터 베이스(각 행이 디스크 상에 일련의 데이터로 기록)
  - 테이블의 각 행을 하나의 덩어리로 디스크에 저장 
  - 각 행이 디스크 상에서 일련의 데이터로 쓰여짐, 새로운 레코드를 추가할 경우네 끝부분에 추가되므로 고속으로 쓰기가 가능
    - 2017-01-01 상품A 1234
    - 2018-01-01 상품B 1234
    - 2019-01-01 상품A 2345
  - 데이터 검색을 고속화하기 위해 인덱스를 만듬, 만약 인덱스가 없다면 저장되는 모든 데이터를 로드해야 원하는 레코드를 찾을 수 있으므로 많은 디스크 I/O가 발생해서 성능이 저하 -> 적절한 인덱스를 사용되도록 튜닝하는 것이 중요 

## 데이터 처리의 성능
- 일정 시간에 처리할 수 있는 데이터의 양(처리량, throughput) : 배치 처리 등의 대규모 데이터 처리에서 중요시
- 데이터 처리가 끝날 때까지의 대기 시간(지연), 주로 애드 혹 데이터 분석 등에서 중시 

## 대시보드 도구
- 대시보드 도구 : 새로운 그래프를 쉽게 추가할 수 있는 것이 중시
  - 정해진 지표의 일상적인 변화를 모니터링 하고 싶은 경우 
- BI 도구 : 대화형 데이터 탐색이 중요시 
  - 그래프를 클릭하여 상세한 표시로 전환하거나 집계에 기반이 되는 로우 데이터(원시 데이터)를 표시하는 등 시간을 들여 차분히 데이터를 보고 싶은 경우

- Redash(SQL에 의한 쿼리의 실행 결과를 그대로 시각화)
  - 다수의 데이터 소스에 대응하는 파이썬으로 만든 대시보드 도구로 SQL에 의한 쿼리의 실행 결과를 그대로 시각화하는 데에 적합 
  - Redash의 구조는 알기 쉽고, SQL로 쿼리를 작성해서 그래프로 만들거나 또는 그 결과를 팀 내에서 공유하기 위한 콘솔로 우수 
  - BI 도구만큼 ㅁ대량의 데이터를 처리할 수 없다는 점에서 주의가 필요 
- Superset(화면상에서 마우스 조작만으로 그래프 만들기)
  - 대화형 대시보드(interactive dashboard)를 작성하기 위한 파이썬으로 만든 웹 애플리케이션 
  - 화면상으로 마우스 조작으로 그래프를 만드는 것 
  - 데이터 집계는 외부 데이터 저장소에 의존하고 있음, 시계열 데이터에 대응한 열 지향 스토리지인 Druid를 표준으로 지원하며 스트리밍 형의 데이터 전송과 조합시킴으로써 실시간 정보를 취급 
- Kibana(Elasticsearch의 프런트 엔드에서 실시간으로 작성)
  - 자바스크립트로 만들어진 대화식 시각화 도구, 실시간 대시보드를 만들 목적으로 자주 이용
  - 검색 엔진인 Elasticsearch의 프런트 엔드로 개발되었기 때문에 도입에는 Elasticsearch가 필수적 
  - Elasticsearch 이외의 데이터 소스에는 대응하고 있지 않아 시각화하려는 데이터는 모두 Elasticsearch에 저장 

## OLAP(online analytical processing) 
- 데이터 집계를 효율화하는 접근 방법 중의 하나 
- MDX(multidimensional expressions) : 다차원 모델의 데이터 구조 등의 쿼리 언어로 집계
- 데이터 분석을 위해 만들어진 다차원 데이터를 OLAP 큐브(OLAP cube) -> 이것을 크로스 집계하는 구조가 OLAP 

## 테이블 비정규화
- 트랜잭션(transaction) : 시간과 함께 생성되는 데이터를 기록한 것
  - 한번 기록하면 변화하지 않음 
- 마스터(master) : 트랜잭션에 참고되는 각종 정보 
  - 상황에 따라 다시 쓰임 
- 팩트테이블(fact table) : 트랙잭션처럼 사실이 기록된 것 
- 디멘전 테이블(dimension table) : 거기에 참고되는 마스터 데이터 등 
- 스타 스키마(star schema) : 팩트 테이블을 중심으로 여러 디멘전 테이블을 결합하는것 
- 다차원 모델 
  - 비정규화 테이블을 준비했다면 그것을 다차원 모델에 의해 추상화
  - BI 도구의 기본이 되는 데이터 모델로 테이블 및 칼럼의 집합을 알기 쉽게 정리해 이름을 붙인 것 
  - 측정값(measure) : 숫자 데이터와 그 집계 방법을 정의하는 것 
  - 디멘젼(dimension) : 크로스 집계에 있어서의 행과 열을 이용하는 것 
- 브레이크 다운 분석(breadkdown analysis) : 복잡한 데이터를 분석하기 쉽게 하려면 데이터를 몇 개의 그룹으로 분산하여 각 그룹에 내용을 정리하는 것이 효과적 

# 대규모 분산 처리의 프레임워크
## 구조화 데이터와 비구조화 데이터
- 스키마(schema) : 테이블의 칼럼 명과 데이터형, 테이블 간의 관계 등을 일컬음
- 구조화된 데이터 : 스키마가 명확하게 정의된 데이터 
- 비구조화된 데이터 : 텍스트 데이터와 이미지, 동영상 등의 미디어 데이터가 포함된 스키마가 없는 데이터를 의미함
  - 비구조화 데이터를 읽어 들여 열 지향 스토리지로 변환하는 과정에서는 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비
  - Hadoop과 Spark 등의 분산 처리 프레임워크 
- 스키마리스 데이터(schemaless data) : CSV ,JSON, XML 등의 데이터는 서식은 정해져 있지만, 칼럼 수나 데이터형은 명확하지 않음 
- Apache ORC : 구조화 데이터를 위한 열 지향 스토리지로 처음에는 스키마를 정한 후 데이터를 저장
- Apache Parquet : 스키마리스에 가까운 데이터 구조로 되어 있어 JSON 같은 뒤얽힌 데이터도 그대로 저장 가능 

## Hadoop(분산 데이터 처리의 공통 플랫폼)
- 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체
- 분산 시스템의 구성 요소 
  - 분산 파일 시스템(distributed file system) : HDFS(Hadoop Distributed File System)
    - HDFS는 분산 시스템의 스토리지를 관리하여 데이터가 항상 여러 컴퓨터에서 복사되도록 함 
    - Hadoop에서 처리되는 데이터 대부분은 분산 파일 시스템인 HDFS에 저장
    - 네트워크에 연결된 파일 서버와 같은 존재, 다수의 컴퓨터에 파일을 복사하여 중복성을 높임 
  - 리소스 관리자(resource manager) : YARN(Yet Another Resource Negotiator)
    - YARN은 CPU와 메모리를 관리하고 리소스에 여유가 있는 컴퓨터에서 프로그램을 실행 
    - CPU나 메모리 등의 계산 리소스는 매니저인 YARN에 의해 관리됨
    - YARN은 애플리케이션이 사용되는 CPU코어와 메모리를 컨테이너(container)라 불리는 단위로 관리 
  - 분산 데이터 처리(distributed data processing)의 기반 : MapReduce
    - MapReduce도 YARN 상에서 동작하는 분산 애플리케이션 중 하나이며, 분산시스템에서 데이터 처리를 실행하는 데 사용 
    - 원래 대량의 데이터를 배치 처리 하기 위한 시스템 
    - 임의의 자바 프로그램을 실행시킬 수 있기 때문에 비구조화 데이터를 가공하는 적합 
    - 데이터 처리의 스테이지가 바뀔 때 대기 시간이 있어서 복잡한 쿼리에서는 대기 시간만 증가 
  - 쿼리 엔진
    - SQL 등의 쿼리 언어에 의한 데이터 집계가 목적이라면 그것을 위해 설계된 커리 엔진 
    - Apache Hive : 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어로 개발됨
      - Hive on Tez : HIve를 가속화하기 위한 노력의 하나로 개발된 것, 기존의 MapReduce를 대체할 목적으로 개발된 프로젝트, MapReduce에 있던 몇 가지 단점을 해소함으로써 고속화를 실현 
      - 대량의 비구조화 데이터를 가공하는 무거운 배치 처리에는 높은 처리량(Throughput)으로 리소스를 활용할 수 있는 Hive를 이용
      - SQL-on-Hadoop : Hadoop에서는 다수의쿼리 엔진이 개발되어 있으며 그것들을 총칭해서 일컬음
  - 대화형 쿼리 엔진
    - Hive를 고속화하는 것이 아니라 처음부터 대화형의 쿼리 실행만 전문으로 하는 쿼리 엔진 
      - Hive 메타 스토어(Hive Metastore)라고 불리는 특별한 데이터베이스에 저장 
      - Hive는 데이터베이스가 아닌 데이터 처리를 위한 배치 처리 구조 
      - 원래 데이터가텍스트이든 스키마리스 데이터이든 간에 그것이 Hive에서 읽을 수 있는 형식이라면 무엇이든지 쿼리를 조금 고쳐 쓰는 것만으로 어떤 테이블이라도 만들 수 있음 
        - 데이터 구조화가 완료되면 데이터 마트 구축 시작 -> 테이블을 결합 및 집약해서 비정규화 테이블을 만듬 -> Presto 같은 대화형 쿼리 엔진을 사용할 것인지, Hive 같은 배치형 쿼리 엔진을 사용할 것인지 고민 
        - 시간이 걸리는 배치 처리는 원칙적으로 Hive를 사용 ( 비정규화 테이블이 수억 레코드나 되면, 그것을 데이터 마트로 내보내는 것만으로도 상당한 시간이 소요) -> 쿼리 엔진 자체의 성능은 최종적인 실행 시간에 그다지 많은 영향을 끼치지 않고 배치형 시스템을 사용하는 편이 리소스의 이용 효율을 높일 수 있음 
    - Presto(페이스북에 출시됨)
      - Hive와 같은 배치형 쿼리 엔진은 대량 출력을 수반하는 대규모 데이터 처리에 적합하지만, 작은 쿼리를 여러 번 실행하는 대화형 데이터 처리에는 부적합, 쿼리 실행의 지연을 감소시키는 것을 목적으로 개발된 것이 대화형 쿼리 엔진 
      - 다수의 컴퓨터에서 실행되는 분산 시스템, 하나의 코디네이터(Presto Coordinator)와 여러 워커(Presto Worker)로 구성, 쿼리는 Presto CLI 등의 클라이언트에서 코디네이터로 전송됨 
      - 플러그인 가능한 스토리지 설계, Hive 메타 스토어 이외에도 다양한 데이터 소스를 테이블로 참고
      - ORC 형식의 로드에 최적화되어 있으며, 그것을 확장성이 높은 분산 스토리지에 배치하여 최대의 성능을 발휘 
      - 분산 결합(distribute join)을 실시, 같은 키를 갖는 데이터는 동일한 노드에 모임, 분산 결합에서는 노드 간의 데이터 전송을 위한 네트워크 통신이 발생하기 때문에 종종 쿼리의 지연을 초래 -> 브로드캐스트 결합(broadcast join)을 사용하여 처리 속도를 크게 고속화 가능, 결합하는 테이블의 모든 데이터가 각 노드에 복사됨
      - SQL의 실행에 특화된 시스템으로 쿼리를 분석하여 최적의 실행계획을 생성하고 그것을 자바의 바이트 코드로 변환 
    - Presto와 Impara는 YARN과 같은 범용적인 리소스 관리자를 사용하지 않고 SQL의 실행만 특화한 독자적인 분산 처리를 구현하고 있음, MPP데이터베이스처럼 멀티코어를 활용하면서 가능한 한 많은 데이터 처리를 병렬화함으로써 고속화를 실현 

- 다양한 소프트웨어 중에서 자신에게 맞는 것을 선택하고 그것들을 조합함으로써 시스템을 구성하는 것이 Hadoop을 중심으로 하는 데이터 처리의 특징  

## Spark - 인 메모리형의 고속 데이터 처리 
- 대량의 메모리를 활용하여 고속화를 실현하는 것 
- MapReduce를 대체하는 존재
- Hadoop을 이용하지 않는 구성도 가능하며, 분산 스토리지로 Amazon S3를 이용하거나 분산 데이터베이스인 카산드라(cassandra)에서 데이터를 읽어 들이는 것도 간으
- Spark의 실행은 자바 런타임이 필요하지만, Spark 상에서 실행되는 데이터 처리는 스크립트 언어를 사용할 수 있다는 점도 매력 
- Spark에서는 중간 데이터를 디스크에 쓰지 않고 메모리에 보존, 프로그램 실행 중에는 많은 메모리가 필요하지만, 실행 시간은 단축됨, 장애 등으로 메모리 상의 중간 데이터를 읽어버려도, 한 번 더 입력 데이터로 다시 실행하며 중간 데이터는 의도적으로 디스크 상에 캐시하는 것도 가능 
- SQL로 쿼리를 실행하기 위한 Spark SQL과 스트림 처리를 수행하기 위한 Spark Streaming
- 대규모 배치 처리뿐만 아니라 SQL에 의한 대화형 쿼리 실행과 실시간 스트림 처리에 이르기까지 널리 이용됨 
- 고속화를 방해하는 다른 하나 문제는 데이터 편차(data skew)로 중복이 없는 값을 세려면 데이터를 한곳에 모아야 해서 분산 처리하기 어려워지기 때문 

## 데이터 분석의 프레임워크 선택하기
- MPP 데이터베이스 - 완성한 비정규 테이블의 고속 집계에 적합
  - 구조화 데이터를 SQL로 집계하는 것뿐 -> 기존의 데이터 웨어하우스 제품과 클라우드 서비스를 이용하는것이 가장 좋음
  - 스토리지 및 계산 노드가 일체화되어 있어 처음에 ETL 프로세스 등으로 데이터를 가져오는 절차가 필요, 이 부분만 완성되면 그 다음은 SQL만으로 데이터를 집계할 수 있으므로 이 장에서 다루는 기술은 아무것도 필요없음
  - 확장성 및 유연성 등의 측면에서는 분산 시스템에 유리 
  - 시각화를 위한 데이터 마트로만 생각하면 유리 
- Hive - 데이터양에 좌우되지 않는 쿼리 엔진
  - 높은 확장성과 내결함성을 목표로 설계됨
  - 대규모 배치 처리를 꾸준히 실행한다는 점에서 실적
  - 텍스트 데이터를 가공하거나 열 지향 스토리지를 만드는 등의 무거운 처리는 아무래도 처리 시간이 길어지는 경향이 있어서 Hive에서 실행하는것이 적합
  - 분산시스템의 동향은 서서히 인 메모리의 데이터 처리로 옮겨 가고 있지만, Hive는 앞으로도 데이터양에 좌우되지 않는 쿼리 엔진으로 계속 이용될 것
- Presto - 속도 중시&대화식으로 특화된 쿼리 엔진
  - 속도로 인해 다양한 것을 희생, 쿼리의 실행 중에 장애가 발생하면 오류가 떠서 처음부터 다시 실행, 메모리가 부족하면 쿼리를 실행할 수 없는 경우도 있음 
  - 대화식 쿼리의 실행에 특화되어 있기 때문에 텍스트 처리가 중심이 되는 ETL 프로세스 및 데이터 구조화에는 적합하지 않음 
- Spark - 분산 시스템을 사용한 프로그래밍 환경
  - 인 메모리의 데이터 처리가 중심이며 Presto 뿐만 아니라 대화형 쿼리 실행에 적합
  - ETL 프로세스에서 SQL에 이르기까지의 일련의 흐름을 하나의 데이터 파이프라인으로 기술
  - 분산 시스템을 사용한 프로그래밍 환경으로 ETL프로세스이거나 머신러닝 같은 모든 데이터 처리에 사용 가능 
  - 메모리를 어떻게 관리하느냐가 중요 -> 여러 번 이용하는 데이터 캐시에 올려놓거나, 디스크에 스왑(Swap) 시킴으로써 메모리를 해제하는 등 메모리 사용을 프로그래머가 어느 정도 제어할 수 있음 
    - Apache Mesos : Yarn과 함께 분산 시스템에서 사용되는 리소스 관리자
      - OS 수준의 가상화 기술을 사용 , Yarn보다 더 엄격한 리소스 제어
      - Linux 컨테이너(LXC)가 사용되며 Docker 이미지를 사용하여 프로그램을 실행할 수 있음
      - YARN은 HDFS와 연계함으로써 데이터가 어디에 있는가 하는 정보를 사용하여 애플리케이션을 실행, HIve와 같은 대규모 배치 처리는 되도록 데이터 부근에서 실행하는 것이 효율이 높기 때문에 YARN을 사용하는 것이 적합, Mesos는 HDFS의 존재를 알지 못하므로 동일한 일을 실현하기 위해서는 이용자가 여러 궁리를 해야함

## 데이터 마트의 구축
- 팩트 테이블 - 시계열 데이터 축적하기
  - 추가(append) : 새로 도착한 데이터만을 증분으로 추가
  - 치환(replace) : 과거의 데이터를 포함하여 테이블 전체를 치환 
- 테이블 파티셔닝 - 물리적인 파티션으로 분할
  - 하나의 테이블을 여러 물리적인 파티션으로 나눔으로써 파티션 단위로 정리하여 데이터를 쓰거나 삭제할 수 있도록 함
    - 추가에 실패한 것을 알아채지 못하면 팩트 테이블의 일부에 결손이 발생
    - 추가를 잘못해서 여러 번 실행하면 팩트 테이블의 일부가 중복
    - 나중에 팩트 테이블을 다시 만들고 싶은 경우의 관리가 복잡 
- 집계 테이블 - 레코드 수 줄이기
  - 팩트 테이블을 어느 정도 모아서 집계하면 데이터의 양이 크게 줄어듬 
  - 일일 집계(daily summary) : 데이터를 1일 단위로 집계 
  - 카티널리티(cardinality) : 칵 칼럼이 취하는 값의 범위 
    - 성별과 같이 취합 할 수 있는 값이 적은 것은 카디널리티가 작음
    - IP주소와 같이 여러 값이 있는 것은 카디널리티가 커짐 
- 스냅샷 테이블 - 마스터의 상태를 기록하기
  - 마스터 데이터처럼 업데이트될 가능성이 있는 테이블에 대해서는 두 가지 방안이 존재
    - 스냅샷 테이블(snapshot table) : 정기적으로 테이블을 통째로 저장하는 방법
    - 이력테이블(history table) : 변경 내용만을 저장하는 방법, 마스터 변화 기록하기 
      - 변경된 데이터만을 증분으로 스냅샷 하거나 변경이 있을 때마다 그 내용을 기록
