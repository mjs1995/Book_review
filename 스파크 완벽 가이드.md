# 서평
- 이 책은 스파크의 기초적인 내용부터 처리,운용,관리,모니터링, 그리고 머신러닝, 그래프에 이르기까지 다양한 내용을 종합적으로 잘 설명하고 있습니다.

# 빅데이터와 스파크 간단히 살펴보기
- 스파크
  - 하둡의 장점뿐만 아니라 여러 오픈소스가 가진 장점을 함께 가지고 있음
  - 아파치 하이브의 장점인 HQL을 사용할 수 있을 뿐만 아니라 SQL에 친숙한 사용자를 위해 스파크 SQL을 제공함
  - 아파치 스톰의 스트리밍 처리 기술을 지원하는 스파크 스트리밍을 제공함
  - 머신러닝 처리를 위한 MLlib 라이브러리를 제공함
  - 스파크 GraphX를 제공
- 아파치 스파크
  - 통합 컴퓨팅 엔진이며 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합 ( 빅데이터를 위한 통합 컴퓨팅 엔진과 라이브러리 집합)
  - (파이썬,자바,스칼라,R)을 지원하며 SQL뿐만 아니라 스트리밍, 머신러닝에 이르기까지 넓은 범위의 라이브러리를 제공함
  - 단일 노트북 환경에서부터 수천 대의 서버로 구성된 클러스터까지 다양한 환경에서 실행함
  - 빅데이터 애플리케이션 개발에 필요한 통합 플랫폼을 제공하자는 목적
  - 간단한 데이터 읽기에서부터 SQL 처리, 머신러닝 그리고 스트림 처리에 이르기까지 다양한 데이터 분석 작업을 같은 연산 엔진과 일관성 있는 API로 수행할 수 있도록 설계
  - 클라우드 기반의 애저 스토리지,아마존 S3, 분산 파일 시스템인 아파치 하웁, 키/값 저장소인 아파치 카산드라, 메시지 전달 서비스인 아파치 카프카 등의 저장소를 지원함
  - SQL과 구조화된 데이터를 제공하는 스파크 SQL, 머신러닝을 지원하는 MLlib, 스트림 처리 기능을 제공하는 스파크 스트리밍과 새롭게 선보인 구조적 스트리밍 그리고 그래프 분석 엔진인 GraphX 라이브러리르 제공 
  - 스파크는 스칼라로 구현되어 자바 가상 머신 기반으로 동작함
  - 코드 스니펫(snippet) : 스니펫은 재사용이 가능한 소스 코드나 기계어의 작은 부분을 뜻하는 프로그래밍 용어

## 스파크 애플리케이션
- 드라이버(driver) 프로세스와 다수의 익스큐터(executor) 프로세스로 구성됨
- 정보의 유지 관리, 사용자 프로그램이나 입력에 대한 응답, 전반적인 익스큐터 프로세스의 작업과 관련된 분석, 배포 그리고 스케줄링 역할을 수행
- 익스큐터 : 드라이버 프로세스가 할당한 작업을 수행, 드라이버가 할당한 코드를 실행하고 진행 상황을 다시 드라이버 노드에 보고하는 두 가지 역할을 수행
- 언어 API
  - 스칼라 : 스파크는 스칼라로 개발되어 있으므로 스칼라가 스파크의 기본 언어
  - 자바 : 스파크가 스칼라로 개발되어 있지만, 스파크 창시자들은 자바를 이용해 스파크 코드를 작성할 수 있도록 심혈을 기울임
  - 파이썬 : 스칼라가 지원하는 거의 모든 구조를 지원함
  - SQL : ANSI SQL:2003 표준 중 일부를 지원함
  - 스파크 코어에 포함된 SparkR, R 커뮤니티 기반 패키지인 sparklyr
- 스파크 API
  - 저수준의 비구조적(unstructured) API
  - 고수준의 구조적(structured) API
- DataFrame
  - 스키마(schema) : 컬럼과 컬럼의 타입을 정의한 목록
  - 스프레드시프트는 한 대의 컴퓨터에 존재, 스파크 DataFrame은 수천 대의 컴퓨터에 분산(단일 컴퓨터에 저장하기에는 데이터가 너무 크거나 계산에 너무 오랜 시간이 걸릴 수 있기 때문)
- 파티션
  - 스파크는 모든 익스큐터가 병렬로 작업을 수행할 수 있도록 파티션이라 불리는 청크 단위로 데이터를 분할함
  - 파티션 : 클러스터의 물리적 머신에 존재하는 로우의 집합
- 트랜스포메이션
  - 스파크의 핵심 데이터 구조는 불변성(immutable) : 한번 생성하면 변경할 수 없음
  - DataFrame을 변경하려면 원하는 변경 방법을 스파크에 알려줘야 하는데 이를 트랜스포메이션
  - 좁은 의존성(narrow dependency) : 각 입력 파티션이 하나의 출력 파티션에만 영향을 미침, 파티션이 하나의 출력 파티션에만 영향을 미침 
  - 넓은 의존성(wide dependency) : 하나의 입력 파티션이 여러 출력 파티션에 영향을 미침, 스파크가 클러스터에서 파티션을 교환(셔플-shuffle)
  - 좁은 트랜스포메이션을 사용하면 스파크에서 파이프라이닝(pipelining)을 자동으로 수행함, DataFrame에 여러 필터를 지정하는 경우 모든 작업이 메모리에서 일어남
- 지연 연산(lazy evaluation)
  - 스파크가 연산 그래프를 처리하기 직전까지 기다리는 동작 방식을 의미
  - 특정 연산 명령이 내려진 즉시 데이터를 수정하지 않고 원시 데이터에 적용할 트랜스포메이션의 실행 계획을 생성함
- 액션
  - 콘솔에서 데이터를 보는 액션
  - 각 언어로 된 네이티브 객체에서 데이터를 모으는 액션
  - 출력 데이터소스에 저장하는 액션
  - 액션을 지정하면 스파크 잡(job) 시작, 스파크 잡은 필터(좁은 트랜스포메이션)를 수행한 후 파티션별로 레코드 수를 카운트(넓은 트랜스포메이션), 각 언어에 적합한 네이티브 객체에 결과를 모음
- 스파크 UI
  - 스파크 잡의 진행 상황을 모니터링 할 때 사용
  - 스파크 잡의 상태, 환경 설정, 클러스터 상태의 정보를 확인
  - 스파크 잡을 튜닝하고 디버깅할 때 매우 유용

## 스파크 기능
- 스파크 라이브러리 : 그래프 분석, 머신러닝, 그리고 스트리밍 등 다양한 작업을 지원하며, 컴퓨팅 및 스토리지 시스템과의 통합을 돕는 역할
- spark-submit : 대화형 셸에서 개발한 프로그램을 운영용 애플리케이션으로 쉽게 전환, 애플리케이션 코드를 클러스터에 전송해 실행시키는 역할
- 스파크 애플리케이션은 스탠드얼른,메소스, YARN 클러스터 매니저를 이용해 실행됨
- 타입 안정성을 제공하는 구조적 API
  - Dataset
    - 자바와 스칼라의 정적 데이터 타입에 맞는 코드
    - 정적 타입 코드(statically typed code)를 지원하기 위해 고안된 스파크의 구조적 API
      - 정적 타입 코드 : 자료형이 고정된 언어, 자바,스칼라,C,C++ 등의 프로그래밍 언어가 정적 타입에 해당
      - 동적 타입 프로그래밍 언어 : 파이썬, 자바스크립트 등 
    - Dataset은 타입 안정성을 지원하며 동적 타입 언어인 파이썬과 R에서는 사용할 수 없음
    - Dataset 클래스는 내부 객체의 데이터 타입을 매개변수로 사용
  - DataFrame
    - 다양한 데이터 타입의 테이블형 데이터를 보관할 수 있는 Row 타입의 객체로 구성된 분산 컬렉션
  - Dataset API
    - DataFrame의 레코드르 사용자가 자바나 스칼라로 정의한 클래스에 할당하고 자바의 ArrayList 또는 스칼라의 Seq 객체 등의 고정 타입형 컬렉션으로 다룰 수 있는 기능을 제공함
    - 타입 안정성을 지원하므로 초기화에 사용한 클래스 대신 다른 클래스를 사용해 접근할 수 없음
    - 다수의 소프트웨어 엔지니어가 잘 정의된 인터페이스로 상호작용하는 대규모 애플리케이션을 개발하는 데 특히 유용함
- 구조적 스트리밍
  - 스파크 2.2 버전에서 안정화(production-ready)된 스트림 처리용 고수준 API
  - 구조적 API로 개발된 배치 모드의 연산을 스트리밍 방식으로 실행, 지연 시간을 줄이고 증분 처리
  - 배치 처리용 코드를 일부 수정하여 스트리밍 처리를 수행하고 값을 빠르게 얻을 수 있다는 장점
  - 프로토타입을 배치 잡으로 개발한 다음 스트리밍 잡으로 변환할 수 있으므로 개념 잡기가 수월함
  - 셔플 파티션 수 : 셔플 이후에 생성될 파티션 수, 기본값은 200이지만 로컬 모드에서는 그렇게 많은 익스큐터가 필요하지 않으므로 5로 변경
    - spark.conf.set("spark.sql.shuffle.partitions","5")
  - 스트리밍 코드
    - read 메서드 대신 readStream 메서드 사용
    - maxFilesPerTrigger : 한 번에 읽을 파일수를 설정함
  - MLlib : 대용량 데이터를 대상으로 전처리(preprocessing), 멍잉(munging - 데이터 랭글링(data wrangling), 원본 데이터를 다른 형태로 변환하거나 매핑하는 과정), 모델 학습(model training) 및 예측(prediction)
- 저수준 API
  - RDD를 통해 자바와 파이썬 객체를 다루는 데 필요한 다양한 기본 기능을 제공
  - 스파크의 거의 모든 기능은 RDD를 기반
  - 드라이버 시스템의 메모리에 저장된 원시 데이터를 병렬처리(parallelize)하는 데 RDD를 사용

# 구조적 API: DataFrame, SQL, Dataset
