# 아파치 스파크
- 아파치 스파크 
  - 고속 범용 분산 컴퓨팅 플랫폼
  - 분산 아키텍처 때문에 처리 시간에 약간의 오버헤드(overhead : 어떤 연산을 처리하는 데 별도로 필요한 간접적인 컴퓨팅 리소스를 의미)가 필연적으로 발생                   
  - 하둡 생태계의 여러 도구가 제공한 다양한 기능을 플랫폼 하나로 통합함, 실시간 스트림 데이터 처리 , 머신 러닝, SQL 연산, 그래프 알고리즘, 일괄 처리 등 여러 종륳의 프로그램을 단일 프레임워크에서 구현 할 수 있음 
- 아파치 하둡
  - 분산 컴피팅용 자바 기반 오픈소스 프레임워크로 하둡 분산 파일 시스템(Hadoop Distributed File System, HDFS)과 맵리듀스 처리 엔진으로 구성됨
- 스파크를 구성하는 컴포넌트
  - 스파크 코어
    - RDD(Resilent Distributed Dataset) : 스파크 API의 핵심 요소, RDD는 분산 데이터 컬렉션(즉, 데이터셋)을 추상화한 객체로 데이터셋에 적용할 수 있는 연산 및 변환 메서드를 함께 제공
      - 불변성(immutable) : 읽기 전용(read-only)
      - 복원성(resilient) : 장애 내성
      - 분산(distributed) : 노드 한 개 이상에 저장된 데이터셋 
    - HDFS, GlusterFS, 아마존 S3 등 다양한 파일 시스템에 접근할 수 있음
    - 공유 변수(broadcast variable)와 누적 변수(accumulator)를 사용해 컴퓨팅 노드 간에 정보를 공유할 수 있음
    - 네트워크, 보안, 스케줄링 및 데이터 셔플링(shuffling)등 기본 기능이 구현되어 있음   
- 데이터 파티셔닝
  - 데이터를 여러 클러스토노드로 분할하는 메커니즘
  - 스파크의 성능과 리소스 점유량을 크게 좌우할 수 있는 RDD의 가장 기본적인 개념
  - 스파크 클러스터 : 병렬 연산이 가능하고 네트워크로 연결된 머신(즉, 노드)의 집합
  - RDD 파티션(과거에는 스플릿) : RDD 데이터의 일부(조각 또는 슬라이스)를 의미함
    - 스파크에서 RDD 파티션 개수는 매우 중요, 파티션 개수가 데이터를 클러스터에 분배하는 과정에 영향을 미칠 뿐만 아니라 해당 RDD에 변환연산을 실행할 태스크 개수와 직결되기 때문
  - HashPartitioner 
    - 각 요소의 자바 해시 코드를단순화mod 공식에 대입해 파티션 번호를 계산 
    - 각 요소의 파티션 번호를 거의 무작위로 결정하기 때문에 모든파티션을 정확하게 같은 크기로 분할할 가능성이 낮음
    - 대규모 데이터셋을 상대적으로 적은 수의 파티션으로 나누면 대체로 데이터를 고르게 분산시킬 수 있음
  - RangePartitioner 
    - 정렬된RDD의 데이터를 거의 같은 범위 간격으로 분할할 수 있음
    - 대상 RDD에서 샘플링한 데이터를 기반으로 범위 경계를 결정 
- 데이터 셔플링
  - 파티션 간의 물리적인 데이터 이동
  - 셔플리은 새로운 RDD의 파티션을 만들려고 여러 파티션의 데이터를 합칠 때 발생 
    - 맵 태스크 : 셔플링 바로 전에 수행한 태스크
    - 리듀스 태스크 : 바로 다음에 수행한 태스크
- 스파크의 DAG : RDD를 정점으로 RDD 의존 관계를 간선으로 정의한 그래프 
- 체크포인팅(checkpointing) : 스파크는 장애 발생 이전에 저장된 스냅샷을 사용해 이 지점부터 나머지 계보를 다시 계산함

# 스파크SQL
- SparkSession : SparkContext와 SQLContext를 통합한 래퍼(wrapper) 클래스
- DataFrame을 저장하고 불러오기
  - MySQL 및 PostreSQL 관계형 데이터베이스와 스카를 연동하는 Dialect 클래스(JDBC의 JdbcType 클래스와 스파크 SQL의 DataType클래스를 매핑하는 클래스)를 제공
  - JSON
    - XML을 대체하는 경량(lightweight) 데이터 포맷
    - 스파크는 JSON 스키마를 자동으로 유추할 수 있기 때문에 외부 시스템과 데이터를 주고받는 포맷으로 매우 적합
    - 데이터를 영구적으로 저장하는 데 사용하기에는 저장 효율이떨어진다는 단점
    - 포맷이 간단하고 사용이간편하며 사람이 읽을 수 있는형태로 데이터를 저장
  - ORC(Optimized Row Columnar)
    - 하둡의 표준 데이터 저장 포맷인 RCFile 보다 효율적으로 하이브의 데이터를 저장하도록 설계된 파일 포맷
    - 칼럼형 포맷 : 각 로우의 데이터를 순차적으로 저장하는 로우 포맷과 달리 각 칼럼의 데이터를 물리적으로 가까운 위치에 저장하는 방식을 의미
    - 로우 데이터를 스트라이프(stripe) 여러 개로 묶어서 저장
    - 파일 끝에는 파일 푸터(file footer)와 포스트 스크립트(postscript)영역이 있음
      - 파일 푸터 : 파일의 스트라이프 목록과 스트라이프별 로우 개수, 각 칼럼의 데이터 타입을 저장
      - 포스트 스크립트 영역 : 파일 압축과 관련된 매개변수들과 파일 푸터의 크기를 저장 
  - Parquet
    - 불필요한 의존 관계를 가지지 않으며 특정 프레임워크에 종속되지 않도록 설계됨
    - 칼럼별로 압축 방식을지정
    - 중첩된(nested) 복합 데이터 구조에 주점을 두고 설계
    - LZO, Snappy, GZIP 등 압축 라이브러리를 지원, 각 칼럼의 청크별로 최솟값과 최댓값의 통계를 저장해 쿼리를 실행할 때 일부 데이터를 건너뛸 수 있도록 연산을 최적화 
  - 카탈리스트 최적화 엔진(Catalyst optimizer) : DataFrame과 Dataset의 두뇌, DataFrame DSL과 SQL 표현식을 하위 레벨의 RDD 연산으로 변환 
  - 텅스텐 엔진 : 객체(정수형,문자열,튜플 등)를 이진수로 인코딩하고 메모리에서 직접 참조하는 방식으로 메모리 관리 성능을 개선
    - 온-힙 할당 모드 : 이진수로 인코딩한 객체를 JVM이 관리한느 대규모 long 배열에 저장
    - 오프-힙 할당 모드 : sun.misc.Unsafe 클래스를 사용해 마치 C 언어처럼 메모리를 주소로 직접 할당하고 해제

# 스파크 스트리밍 애플리케이션
-  스파크 
  - 확장성과 장애 내성을 갖춘 시스템
  - 강력한 대규모 데이터 분석 기능 외에도 동일한 API로 스트리밍 프로그램과 일괄 처리 프로그램을 모두 지원하는 통합 플랫폼을 제공
  - 실시간 레이어와 배치 레이어를 결합한 람다 아키텍처(lambda architecture)를 구축
  - 하둡과 호환되는 여러 파일 시스템(HDFS,아마존 S3)과 다양한 분산 시스템(플럼,카프카,트위터)에서 데이터를 읽어 들일 수 있는 커넥터를 제공
  - 아파치 카프카 : 확장성을 갖춘 분산 메시지 큐(queue) 시스템, 데이터 소스 및 저장 대상으로사용
  - 스파크클러스터 매니저 : 스파크 자체 클러스터, YARN 클러스터, 메소스 클러스터 
- 외부 데이터 소스
  - 카프카 : 빠른 성능과 확장성을 갖춘 분산 발행-구독(publish-subscribe) 메시징 시스템, 모든 메시지를유지하며 ,유실된 데이터를 재전송할 수 있음
  - 플럼 : 대량의 로그 데이터를 안정적으로 수집, 집계, 전송할 수 있는 분산 시스템
  - 아마존 Kinesis : 카프카와 유사한 아마존 웹 서비스의 스트리밍 플랫폼
  - 트위터 : 인기 소셜 네트워크인 트위터가 제공하는 데이터 API
  - ZeroMQ : 분산 메시징 시스템
  - MQTT : 경량(lightweight) 발행-구독 메시징 프로토콜 
- 스파크-카프카커넥터
  - 다이렉트 커넥터(direct connector) 
    - 입력된 메시지를 정확히 한 번(exactly-once) 처리함
  - 리시버 기반 커넥터(receiver-based connector) 
    - 메시지 한 개를 여러 번 읽어 옴
    - 데이터 유실을 방지하려고 로그 선행 기입(write-aheda logging) 기법을 사용, 그만큼계산 속도가 감소
- 스파크 스트리밍의 잡 성능
  - 성능 개선
    - 처리 시간 단축
      - 스케줄링이 지연되면 가장 먼저 스트리밍프로그램의 최정화를 시도한 배치당 처리 시간을 최대한 단축
      - 외부 시스템으로 데이터를 전송한다면 파티션 내에서 커넥션을 재사용하고 커넥션 풀링(connection pooling) 등 기법을 활용
      - 미니배치 주기를 더 길게 늘림
        - 잡 스케줄링, 태스크 직렬화, 데이터 셔플링 등 공통 작업에 걸리는 시간이 더 많은데이터로 고르게 분산되면서 개별 데이터 레코드당 처리 시간이 감소
        - 너무 길면 각 미니배치에 필요한 메모리양이 증가함 
        - 클러스터 리소스를 추가로 투입해 처리시간을 단축함
    - 병렬화 확대
      - 모든 CPU 코어를 효율적으로 활용하고 처리량을 늘리려면 결국 병렬화를 확대
    - 유입 속도 제한

# 스파크 MLlib
- 스파크를 활용한 머신러닝
  - 머신러닝 :알고리즘은 결국 주어진 작업을 해결하는방법으로 스스로 학습
  - 스파크의 분산 처리 능력을 이용해 매우 큰 규모의 데이터셋에서도 비교적 빠른 속도로 머신 러닝 알고리즘을 훈련하고 적용
  - 머신 러닝 작업의 대부분 한곳에서 수행할 수 있는 통합 플랫폼을 제공
  - 사용자는 스파크라는 단일 시스템에서 데이터를 수집해 준비하고 다각도로 분석할 수 있음, 데이터를 곧바로 모델 훈려과 평가에 활용하고, 완성된 모델을 운영 환경에까지적용할 수 있음, 이 모든 과정을 단일 API로 구현할 수 있음
  - 파이프라인(pipeline) : 머신러닝과 관련된 모든 연산 작업을 시퀀스 하나로 모아 마치 단일 연산처럼 한 번에 처리함 
  - 변환자(transformer) : 한 데이터셋을 다른 데이터셋으로 변환하는 머신 러닝 컴포넌트를 구현할 수 있음
  - 추정자(estimator) : 주어진 데이터셋을 학습해 변환자를 생성
  - 평가자(evaluator) : 모델 성능을 단일 지표로 평가
  - OVR 전략(One Vs. Rest)
    - 각 클래스당 모델을 하나씩훈련시키면서 다른 클래스들(즉,나머지(rest) 클래스들)을 음성으로 간주하는 방식으로 사용
    - 새로운 데이터 샘플을 분류할 때는 훈련된 모든모델에 이 샘플을 입력으로 전달하고, 가장 높은 확률을 출력하는 모델의 클래스를 샘플 레이블로 예측함
  - 랜덤포레스트
    - 의사 결정 트리를 여러 개 학습하고, 각 트르의 예측 결과를 모아서 가장 좋은 결과를 선택하는 앙상블 기법
      - 알고리즘의 과적합을 방지하고, 트리 하나로는 찾을 수 없는 전역 최적점을 찾을 수 있다는 이점을 제공 
    - 튜닝 작업을 많이 하지 않아도 좋은 성능을 낼 수 있으며 분류 및회귀 문제에도 모두 사용가능
    - 특징 변수 배깅(feature bagging) 기법을 사용
      - 알고리즘은 의사 결정 트리의 각 노드별로 특징 변수의 부분 집합을 무작위 선정하고, 이 집합 내에서만 다음 분기를 결정
      - 특징 변수 배깅이 필요한 이유는 의사 결정 트리들의 상관성(correlation)이 높을수록(즉, 트리가 서로 비슷할수록) 랜덤 포레스트의 모델의 오차율이 증가하기 때문, 특징 변수 배깅은 의사 결정 트리들을 차별화함
  - 군집화
    - 데이터를 여러 그룹으로 분할 :고객 세분화(customer segmentation)나 유사한 행동을 보인 고객을 그루핑하는 작업
    - 이미지 세분화(image segmentation) : 이미지 하나에서 구분 가능한영역을 인식하고 분리
    - 이상 탐지(anomaly detection)
    - 텍스트 분류(text categorization) 또는 주제 인식(topic recognition)
    - 검색 결과 그루핑 : yippy 검색 엔진은 검색 결과를 범주별로 묶어서 보여줌
    - 군집 비용(군집 왜곡(distoration) : k-평균 군집화 모델을 평가하는 기본 지표로, 각 군집의 중심점과 해당 군집에 포함된 각 데이터 포인트 간 거리를 제곱해 합산한것 

# GraphX
- 최단 거리(shortest path) : 한 정점에서 다른 정점들로 향하는 최단 경로를 찾음
  - 특정 정점에서 그래프의 각 정점으로 도달하기 위해 따라가야 할 간선의 최소 개수를 찾는 알고리즘
- 페이지랭크(page rank) : 정점으로 들어오고 나가는 간선 개수를 바탕으로 정점의 상대적 중요도를 계산함
  - 그래프 내각 정점의 중요도를 해당 정점에 도착하는 간선 개수를 기반으로 계산
- 연결요소(connected components) : 그래프에서 서로 완전히 분리된 서브그래프를 찾음
  - 모든 정점에서 다른 모든 정점으로 도달할 수 있도록 연결된서브그래프를 의미
  - 그래프의 연결요소가 오직 한 개만 있으며, 그래프의모든 정점이 다른 모든 정점으로 도달할 수 있을때를 뜻함
- 강연결요소(Strongly Connected Components, SCC) : 그래프에서 서로 연결된 정점들의 군집을 찾음 
  - 모든 정점이 다른모든 정점과 연결된 서브 그래프를 의미 

# 스파크옵스
# 스파크 클러스터 구동 
- 스파크 클러스터 : 복수의 머신에 분산된 방식으로 실행되는 프로세스들이 연결된 집합
- 스파크 런타임 컴포넌트
  - 클라이언트(client)
    - 클라이언트 프로세스 : 드라이버 프로그램을 시작, 스파크 애플리케이션을 실행하는 spark-submit 스크립트나 spark-shell 스크립트, 스파크 API를 사용한 커스텀 애플리케이션이 클라이언트 프로세스애 해당함
  - 드라이버(driver)
    - 스파크 애플리케이션의 실행을 관장하고 모니터링함
    - 클러스터 매니저에 메모리 및 CPU 리소스를 요청함
    - 애플리케이션 로직을 스테이지와 태스크로 분할
    - 여러 실행자에 태스크를 전달
    - 태스크 실행 결과를 수집
    - 클러스터 배포 모드(cluster-deploy mode) : 클러스터 배포 모드에서는 드라이버 프로세스 클러스터 내부에서 별도의 JVM프로세스로 실행하며, 드라이버 프로세스의 리소스(주로 JVM 힙 메모리)를 클러스터가 관리함
    - 클라이언트 배포 모드(client-deploy mode) : 클라이언트 배포 모드에서는 드라이버를 클라이언트의 JVM 프로세스에실행하며,클러스터가 관리하는 실행자들과 통신함
  - 실행자
    - 드라이버가 요청한태스크들을 받아서 실행하고, 그 결과를 드라이버로 반환하는 JVM 프로세스 
- 스파크 클러스터 유형
  - 스파크 자체클러스터
    - 스파크 전용 클러스터, 오직 스파크 애플리케이션에만 적합하도록 설계되었기 때문에 켈베로스(Kerberos) 인증 프로토콜로 보호된 HDFS를 지원하지 않음
  - YARN 클러스터
    - YARN은 하둡의리소스 매니저 및 작업 실행 시스템 
      - 이미 상당한 규모의 YARN 클러스터를 운영하는 조직이 많음, YARN 클러스터를 관리하고 모니터링하는 기술적노하우, 도구, 절차를 갖추고 있음
      - YARN을 사용하면 스파크뿐만 아니라 다양한 유형의 자바 애플리케이션을 실행할 수 있으므로 기존 레거시 하둡과 스파크 애플리케이션을 손쉽게 통합할 수 있음
      - 켈베로스를 기반으로 하는 보안 HDFS는 오직 YARN에서만 지원함
      - 스파크를 클러스터의 모든 노드에 설치할 필요가 없다
  - 메소스 클러스터
    - 확장성과 장애 내성을 갖춘 c++ 기반 분산 시스템 커널
    - c++와 파이썬 애플리케이션을 지원
    - 다양한 유형의 리소스(예: cpu, 디스크 공간, 네트워크 포트)를 스케줄링할 수 있다
    - 메소스는 2단계 스케줄링 아키텍처로 구성되므로 스케줄러 프레임워크의 스케줄러
  - 스파크 로컬 모드
    - 스파크 로컬 모드와 스파크 로컬 클러스터 모드는 단일 머신에서 실행하는 독특한 형태의 사프크 자체 클러스터
    - 스파크를 손쉽게 빠르게 구축하고 테스트할 수 있지만, 운영 환경으로 사용할 수 없음
- 잡스케줄링과 리소스 스케줄링
  - 잡 스케줄링 
    - 애플리케이션의 드라이버와 실행자가 시작되면 스파크 스케줄러는 이들과 직접 통신하면서 어떤 실행자가 어떤 태스크를 수행할지 결정함
    - 클러스터의 cpu 리소스 사용량을 좌우함
    - 클러스터 리소스 스케줄링 : 여러 스파크 애플리케이션의 실행자에리소스를 할당함
      - 단일 클러스터에서 실행하는 다수의 애플리케이션에 클러스터의 리소스를 나누어주는 작업은 클러스터 매니저가 담당
      - 스파크가지원하는 모든 유형의 클러스터매니저는 각 애플리케이션이 요청한 리소스를 제공하고, 애플리케이션이 실행이 끝나면 할당했던 리소스를 다시 회수하는 역할을 수행함 
    - 스파크 리소스 스케줄링 : 단일 스파크 애플리케이션 내에서 태스크를 실행할 CPU 및 메모리 리소스를 스케줄링함
    - 클러스터 매니저가 CPU와 메모리 리소스를 각 실행자에게 할당하면 스파크 애플리케이션 내부에서는 잡 스케줄리이 진행됨
    - 클러스터 매니저와 관계없이 스파크 자체에서 수행하는 작업으로, 잡을 어떻게 태스크로 분할하고 어떤 실행자에 전달할지 결정함 
    - 선입선출 스케줄러
      - 선착순, 가장 먼저 리소스를 요청한 잡이 모든 실행자의 태스크 슬롯을 필요한 만큼(또는 남은 만큼)전부 차지한다(FIFO 스케줄러는 각 잡이 단일 스테이지로 구성된다고 가정함)
    - 공정 스케줄러
      - 실행자 리소스(즉, 실행자의 스레드)를 놓고 경쟁하는스파크 잡들에라운드로빈(round robin)방식으로 균등하기 리소스를 분배함
    - 태스크 예비 실행
      - 예비 실행(SPECULATIVE EXECUTION) : 태스크가 실행자들에 분배되는 방식을 설정할 수 있다. 낙오(straggler) 태스크(동일 스테이지의 다른 태스크보다 더 오래 걸리는 태스크) 문제를 해결할 수 있음 
    - 데이터 지역성(data locality)
      - 스파크가 데이터와 최대한 가까운 위치에서 태스크를 실행하려고 노력하는 것을 의미 
- 스파크 웹 UI
  - 다양한 스파크의 환경과 잡 실행 통계 정보를 제공
  - Jobs 페이지
    - 현재 실행중인 잡, 완료된 잡, 실패한 잡의 통계정보를 제공함
  - Stages페이지
    - 잡의 스테이지를 요약한 정보를 제공함, 각 스테이지의 시작 시간, 실행 시간, 실행 현황, 입출력 데이터의크기, 셔플링 읽기 쓰기 데이터양을 확인가능
  - Storage 페이지
    - 캐시된 RDD 정보와 캐시 데이터가 점유한 메모리, 디스크,타키온 스토리지 용량을 보여줌 
  - Environment 페이지
    - 스파크 환경 매개변수뿐만 아니라 자바 및 스칼라의 버전, 자바 시스템 속성, 클래스패스 정보를 확인할 수 있음
  - Executors 페이지
    - 클러스터 내 모든 실행자 목록(드라이버 포함)과 각 실행자(또는 드라이버)별 메모리 사용량을 포함한 여러 통계 정보를 제공함
  

  - 실행자(executor)
