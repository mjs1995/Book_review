# 서평
- 2005년 더크 커팅이 오픈 소스로 공개한 하둡은 분산 저장 파일시스템인 HDFS와 분산 병렬 처리를 담당하는 맵리듀스로 구성되어 있음, 하둡이 나온 후 이를 기반으로 피그, 하이브, HBase, 스쿱, 플룸 등의 오픈 소스 기술이 등장했고, 이들을 모두 결합한 빅데이터 기술은 통칭하여 하둡 에코시스템이라고 부르게 되었음, 스파크의 등장으로 대용량 데이터를 저장하고 일괄 처리하는 수준에서 벗어나 머신러닝과 실시간 분석까지 아우르게 되었음 
- 이 책은 하둡의 핵심, 하둡 에코시스템 관련 프로젝트, 하둡 사례 연구를 다루고 있으며 이 책을 통해 각 기술의 핵심을 설명했고, 다른 기술과의 관계도 친절하게 설명하고 있다.

# 하둡 기초
- 전체 데이터에 질의하기
  - 맵리듀스의 접근법은 무차별대입(brute-force) 방식 처럼 보임 , 맵리듀스 전체가 한 번의 쿼리로 전체나 상당한 규모의 데이터셋을 처리하는 것이기 때문 
  - 맵리듀스는 일괄 질의 처리기고, 전체 데이터셋을 대상으로 비정형(ad hoc) 쿼리를 수행하고 합리적인 시간 내에 그 결과를 보여주는 능력을 지니고 있음 
- 일괄 처리를 넘어서
  - 맵리듀스의 강점은 기본적으로 일괄 처리 시스템, 대화형 분석에는 적합하지 않음, 질의를 실행한 후 수 초 이내에 결과를 받는 것을 불가능함 
  - 온라인 접근을 지원하는 첫 번째 구성요소인 HBase는 HDFS를 기본 저장소로 하는 키-값 저장소, HBase는 개별 행에 대한 온라인 읽기/쓰기와 산적한 데이터를 읽고 쓰는 일괄 처리를 둘다 지원하기 때문에 애플리케이션을 구축하는 데 좋은 솔루션이 될 수 있음
  - YARN은 클러스터 자원 관리 시스템으로, 맵리듀스뿐만 아니라 어떤 분산 프로그램도 하둡 클러스터에 저장된 데이터를 처리할 수 있게 해줌 
  - 다양한 처리 패턴
    - 대화형 SQL
      - 대화형 sQL은 맵리듀스 대신 장기 실행 전용 데몬(임팔라)이나 컨테이너를 재사용하는(테즈 기반의 하이브) 분산 쿼리 엔진을 사용함 
    - 반복 처리
      - 머신러닝과 같은 다수의 알고리즘은 근본적으로 반복 연산을 함 
    - 스트림 처리
      - 스톰, 스파크 스트리밍, 삼자와 같은 스트리밍 시스템은 실시간으로 실행되고 경계가 없는 스트림 데이터를 분산 계산하여 그 결과를 하둡 저장소나 외부 시스템에 보낼 수 있음
    - 검색
      - 솔라(Solr) 검색 플랫폼은 하둡 클러스터에서 실행될 수 있음, 솔라는 문서를 색인하여 HDFS에 저장하고 HDFS에 저장된 색인을 기반으로 검색 쿼리를 제공함 

# 맵리듀스 
- 분산형으로 확장하기
  - 데이터 흐름
    - 맵리듀스 잡은 클라이언트가 수행하는 작업의 기본 단위, 잡은 입력 데이터, 맵리듀스 프로그램, 설정 정보로 구성됨
    - 하둡은 잡을 맵 태스크와 리듀스 태스크로 나누어 실행함, 각 태스크는 YARN을 이용하여 스케줄링되고 클러스터의 여러 노드에서 실행됨, 특정 노드의 태스크 하나가 실패하면 자동으로 다른 노드를 재할당하여 다시 실행됨 
    - 하둡은 맵리듀스 잡의 입력을 입력 스플릿(input split) 또는 단순히 스플릿이라고 부르는 고정 크기 조각으로 분리함, 하둡은 각 스플릿마다 하나의 맵 태스크를 생성하고 스플릿의 각 레코드를 사용자 정의 맵 함수로 처리함 
    - 데이터 지역성 최적화(data locality optimiztation) : 하둡은 HDFS 내의 입력 데이터가 있는 노드에서 맵 태스크를 실행할 때 가장 빠르게 작동함, 클ㄹ러스터의 중요한 공유 자원인 네트워크 대역폭을 사용하지 않는 방법 
  - 컴바이너 함수
    - 하둡은 맵의 결과를 처리하는 컴바이너 함수(컴바이너 함수의 출력이 결국 리듀스 함수의 입력이 됨)를 허용, 컴바이너 함수는 최적화와 관련이 있음 
    - 하둡은 컴바이너 함수의 호출 빈도와 상관없이 리듀스의 결과가 언제나 같도록 보장함 
    - 컴바이너를 사용하면 매퍼와 리듀서 사이의 셔플 단계에서 전송되는 데이터양을 줄이는 데 큰 도움이됨 
    - 컴바이너 함수는 Reducer 클래스를 사용해서 정의함, MaxTemperatureReducer에 있는 리듀서 함수와 동일한 구현체를 사용함 
  - 분산 맵리듀스 잡 실행하기
    - 맵리듀스는 데이터 크기와 하드웨어 성능에 따라 확장할 수 있는데 이것이 바로 맵리듀스의 핵심임
- 하둡 스트리밍
  - 자바 외에 다른 언어로 맵과 리듀스 함수를 작성할 수 있는 맵리듀스 API를 제공함
  - 하둡과 사용자 프로그램 사이의 인터페이스로 유닉스 표준 스트림을 사용함, 사용자는 표준 입력을 읽고 표준 출력으로 쓸 수 있는 다양한 언어를 이용하여 맵리듀스 프로그램을 작성할 수 있음 
  - 스트리밍은 그 특성상 텍스트 처리에 매우 적합함, 맵의 입력 데이터는 표준 입력으로 맵 함수에 전달되고, 행 단위로 처리되어 표준 출력으로 쓰여짐, 맵의 출력 키-값 쌍은 탭으로 구분된 하나의 행으로 출력됨

# 하둡 분산 파일시스템
- 네트워크로 연결된 여러 머신의 스토리지를 관리하는 파일시스템
- HDFS(Hadoop Distributed FileSystem)라는 분산 파일시스템을 제공함
- HDFS 설계
  - 범용 하드웨어로 구성된 클러스터에서 실행되고 스트리밍 방식의 데이터 접근 패턴으로 대용량 파일을 다룰 수 있도록 설계된 파일시스템
  - 설계 특성
    - 매우 큰 파일
    - 스트리밍 방식의 데이터 접근
    - 범용 하드웨어
      - 하둡은 노드 장애가 발생할 확률이 높은 범용 하드웨어(여러 업체에서 제공하는 쉽게 구할 수 있는 하드웨어)로 구성된 대형 클러스터에서 문제없이 실행되도록 설계됨 
  - HDFS가 잘 맞지 않는 응용 분야
    - 빠른 데이터 응답시간
      - HDFS는 높은 데이터 처리량을 제공하기 위해 최적화되어 있고 이를 위해 응답 시간을 희생함, HBase가 하나의 대안이 될 수 있음
    - 수많은 작은 파일
    - 다중 라이터와 파일의 임의 수정
      - HDFS는 단일 라이터로 파일을 씀, 한 번 쓰고 끝나거나 파일의 끝에 덧붙이는 것은 가능하지만 파일에서 임의 위치에 있는 내용을 수정하는 것은 허용하지 않으며 다중 라이터도 지원하지 않음
- HDFS 개념
    - 블록 
        - 블록 크기는 한 번에 읽고 쓸 수 있는 데이터의 최대량 
        - HDFS 블록이 큰 이유
            - HDFS 블록은 디스크 블록에 비해 상당히 큼, 탐색 비용을 최소화하기 위해서, 블록이 매우 크면 블록의 시작점을 탐색하는데 걸리는 시간을 줄일 수 있고 데이터를 전송하는 데 더 많은 시간을 할애할 수 있음, 여러 개의 블록으로 구성된 대용량 파일을 전송하는 시간은 디스크 전송 속도에 크게 영향을 받음
        - 블록 추상화 개념을 도입하면서 얻은 이점
            - 파일 하나의 크기가 단일 디스크의 용량보다 더 커질 수 있다는 것
            - 파일 단위보다는 블록 단위로 추상화를 하면 스토리지의 서브시스템을 단순하게 만들 수 있다는 것 
            - 블록은 내고장성(fault tolerance)과 가용성(availability)을 제공하는 데 필요한 복제(replication)를 구현할 때 매우 적합함,블록의 손상과 디스크 및 머신의 장애에 대처하기 위해 각 블록은 물리적으로 분리된 다수의 머신(보통 3개)에 복제됨
            - 만일 하나의 블록을 이용할 수 없는 상황이 되면 다른 머신에 있는 복사본을 읽도록 클라이언트에 알려주면 됨 
    - 네임노드와 데이터노드
        - HDFS 클러스터는 마스터-워커 패턴으로 동작하는 두 종류의 노드, 마스터인 하나의 네임노드와 워커인 여러 개의 데이터노드로 구성되어 있음, 네임노드는 파일시스템의 네임스페이스를 관리함
        - 네임노드는 파일시스템 트리와 그 트리에 포함된 모든 파일과 디렉터리에 대한 메타데이터를 유지함 , 네임스페이스 이미지와 에디트 로그라는 두 종류의 파일로 로컬 디스크에 영속적으로 저장됨, 파일에 속한 모든 블록이 어느 데이터노드에 있는지 파악하고 있음 
        - HDFS 클라이언트는 사용자를 대신해서 네임노드와 데이터노드 사이에서 통신하고 파일시스템에 접근함 
        - 네임노드의 장애복구 기능
            - 파일시스템의 메타데이터를 지속적인 상태로 보존하기 위해 파일로 백업하는 것, 네임노드가 다수의 파일시스템에 영구적인 상태를 저장하도록 하둡을 구성할 수 있음, 백업 작업은 동기화되고 원자적으로 실행됨, 주로 권장하는 방법은 로컬 디스크와 원격의 NFS 마운트를 두 곳에 동시에 백업하는 것 
            - 보조 네임노드(secondary namenode)를 운영하는 것, 에디트 로그가 너무 커지지 않도록 주기적으로 네임스페이스 이미지를 에디트 로그와 병합하여 새로운 네임스페이스 이미지를 만드는 것, 주 네임노드에 장애가 발생할 것을 대비해서 네임스페이스 이미지의 복제본을 보관하는 역할을 함 
    - 블록 캐싱
        - 오프힙(off-heap, 자바 힙 외부에서 관리되는) 블록 캐시라는 데이터노드의 메모리에 명시적으로 캐싱할 수 있음
        - 조인을 할 때 작은 룩업 테이블을 캐싱하는 것은 좋은 활용사례임
        - 사용자나 애플리케이션은 캐시 풀(cache pool)에 캐시 지시자(cache directive)를 추가하여 특정 파일을 캐싱하도록 명령할 수 있음, 캐시 풀은 캐시 권한이나 자원의 용도를 관리하는 관리 그룹의 역할을 맡음 
- HDFS 패더레이션
    - HDFS 페더레이션을 적용하면 각 네임노드는 네임스페이스의 메타데이터를 구성하는 네임스페이스 볼륨과 네임스페이스에 포함된 파일의 전체 블록을 보관하는 블록 풀을 관리함 
- HDFS 고가용성
    - 네임노드는 여전히 단일 고장점(single point of failure - SPOF), 네임노드에 장애가 발생하면 맵리듀스 잡을 포함하여 모든 클라이언트가 파일을 읽거나 쓰거나 조회할 수 없게 됨, 네임노드는 메타데이터와 파일 블록의 매핑 정보를 보관하는 유일한 저장소이기 때문
    - 새로운 네임노드는 네임스페이스 이미지를 메모리에 로드하고 -> 에디트 로그를 갱신하고 -> 전체 데이터노드에서 충분한 블록 리포트를 받아 안전 모드를 벗어날 때까지 그 어떤 요청도 처리하지 못함 
    - HDFS 고가용성(high availability -HA)을 지원함, 고가용성은 활성대기상태로 설정된 한 쌍의 네임노드로 구현됨, 활성네임노드에 장애가 발생하면 대기 네임노드가 그 역할을 이어받아 큰 중단없이 클라이언트의 요청을 처리함         
- 장애복구와 펜싱
  - 대기 네임노드를 활성화시키는 전환 작업은 장애복구 컨트롤러라는 새로운 객체로 관리됨
  - 장애복구는 정기적인 유지관리를 위해 관리자가 수동으로 초기화할 수 있음
  - 우아한 장애복구(graceful failover) - 자애복구 컨트롤러는 두 개의 네임노드가 서로 역할을 바꾸게 하는 방법으로 전환 순서를 제어할 수 있음 
- 인터페이스
  - HTTP
    - HTTP로 HDFS에 접근하는 두 가지 방식
      - 클라이언트의 HTTP 요청을 HDFS 데몬이 직접 처리하는 방식 - 네임노드와 데이터노드에 내장된 웹 서버가 WebHDFS의 말단으로 적용함
      - 클라이언트 대신 DistributedFileSystem API로 HDFS에 접근하는 프록시를 경유하는 방식 - 하나 또는 그 이상의 독립(standalone) 프록시 서버를 통하는 것, 프록시 서버는 상태를 저장할 필요가 없으므로 표준 로드 밸런서를 사용해도 괜찮음, 클러스터의 모든 트래픽은 프록시를 경유하므로 클라이언트는 네임노드와 데이터노드에 직접 접근할 필요가 없음, 프록시를 통하면 엄격한 방화벽이나 대역폭 제한 정책을 적용하기 쉬움, 프록시를 통한 방식은 서로 다른 데이터 센터에 있는 하둡 클러스터 사이의 데이터 전송이나 외부 네트워크에 있는 클라우드에서 운영되는 하둡 클러스터에 접근할 때 일반적으로 이용되는 방법 
  - C 
    - 자바 FileSystem 인터페이스를 모방한 libhdfs라는 C 라이브러리를 제공함
    - libhdfs는 자바 파일시스템 클라이언트를 호출하기 위해 자바 네이티브 인터페이스(JNI)를 사용함 
  - NFS
    - NFSv3 게이트웨이를 이용하면 로컬 클라이언트 파일시스템에 HDFS를 마운트할 수 있음
    - 파일시스템을 다루는 ls나 cat 같은 Unix 유틸리티를 이용할 수 있으며, 파일 업로드 및 일반적인 프로그래밍 언어에서 파일시스템을 다루는 POSIX 라이브러리도 사용할 수 있음
  - FUSE
    - Filesystem in Userspace (사용자 공간에서의 파일시스템)로, 사용자 공간과 유닉스 파일시스템을 통합한 파일시스템을 지원함 
# YARN
- 하둡의 클러스터 자원 관리 시스템, 클러스터의 자원을 요청하고 사용하기 위해 API를 제공함 
- 맵리듀스, 스파크 등과 같은 분산 컴퓨팅 프레임워크는 클러스터 계산 계층(YARN)과 클러스터 저장 계층(HDFS와 HBase) 위에서 YARN 애플리케이션을 실행함
- 리소스 매니저와 노드매니저 등 두가지 유형의 장기 실행 데몬을 통해 핵심 서비스를 제공함
  - 클러스터에서 유일한 리소스 매니저는 클러스터 전체 자원의 사용량을 관리함
  - 모든 머신에서 실행되는 노드 매니저는 컨테이너를 구동하고 모니터링하는 역할을 맡음 
- 자원 요청
  - 분산 데이터 처리 알고리즘에서 클러스터의 네트워크 대역폭을 효율적으로 활용하기 위해서는 지역성을 보장하는 것이 가장 중요함
  - YARN은 특정 애플리케이션이 호출한 컨테이너에 대해 지역성 제약을 규정하는 것을 허용함, 지역성 제약은 특정 노드나 랙 또는 클러스터의 다른 곳(외부 랙)에서 컨테이너를 요청할 때 사용됨 
- 애플리케이션 수명
  - 실행 시간 보다는 사용자가 실행하는 잡의 방식에 따라 애플리케이션을 분리하는 것이 좋음
    - 사용자의 잡 당 하나의 애플리케이션이 실행되는 방식으로, 맵리듀스 잡이 여기에 속함
    - 워크플로나 사용자의 잡 세션(잡은 서로 관련이 없을 수도 있음)당 하나의 애플리케이션이 실행되는 방식, 첫 번째 유형보다 훨씬 더 효율적, 순차적으로 실행되는 잡이 동일한 컨테이너를 재사용할 수 있기 때문, 잡 사이에 공유 데이터를 캐싱할 수 있는 큰 장점도 있음, 사례로는 스파크
    - 서로 다른 사용자들이 공유할 수 있는 장기 실행 애플리케이션, 일종의 코디네이션 역할을 수행함, 아파치 슬라이더는 클러스터에서 다양한 애플리케이션을 구동시키는 장기 실행 애플리케이션 마스터를 가지고 있응, 임팔라는 여러 임팔라 데몬이 클러스터 자원을 요청할 수 있도록 프록시 애플리케이션을 제공함 
- YARN 애플리케이션 만들기
  - 잡의 방향성 비순환 그래프(DAG)를 실행하고 싶으면 스파크나 테즈가 더 작합함, 스트리밍 처리는 스파크, 쌈자 또는 스톰을 사용하는 것이 좋음 
  - 아파치 슬라이더는 기존의 분산 애플리케이션을 YARN 위에서 실행하도록 해줌 
  - 아파치 트윌(Apache Twill) 
    - 슬라이더와 비슷하지만 YARN에서 실행되는 분산 애플리케이션을 개발할 수 있는 간단한 프로그래밍 모델을추가로 제공함
    - 자바 Runnable 객체를 확장한 클러스터 프로세스를 정의한 후 클러스터의 YARN 컨테이너에서 이를 실행하는 기능을 제공함
    - 실시간 로깅(runnalbes의 로그 이벤트를 클라이언트에 스트리밍으로 돌려줌)과 명령 메시지(클라이언트에서 runnables 전송) 기능 등을 제공함 
  - 분산 쉘(distributed shell) - 복잡한 스케줄링 요구사항이 있는 애플리케이션
    - 클라이언트 또는 애플리케이션 마스터가 YARN 데몬과 통신하기 위해 YARN의 클라이언트 API를 어떻게 사용하는지 잘 보여주고 있음 
- YARN과 맵리듀스1의 차이점
  - 맵리듀스 1에는 잡의 실행과정을 제어하는 하나의 잡트래커와 하나 이상의 태스크트래커등 두 종류의 데몬이 있음
  - 잡트래커
    - 여러 태스크트래커에서 실행되는 태스크를 스케줄링함으로써 시스템에서 실행되는 모든 잡을 조율함
    - 맵리듀스 1에서 잡 스케줄링(태스크와 태스크트래커를 연결)과 태스크 진행 모니터링(태스크를 추적하고, 실패하거나 느린 태스크를 다시 시작하고, 전체 카운터를 유지하는 방법으로 태스크 장부(bookeeping)을 맡고 있음, 반면 YARN은 이러한 역할을 분리된 객체인 리소스 매니저와 애플리케이션 마스터(맵리듀스 잡당 하나)를 통해 처리함
    - 완료된 잡에 대한 잡 이력을 저장하는 역할을 맡음, 잡트래커의 부하를 줄이기 위해 별도의 데몬인 히스토리 서버를 통해 수행될 수도 있음, YARN에서 이와 동일한 역할은 애플리케이션의 이력을 저장하는 타임라인 서버가 맡고 있음 
  - 태스크트래커
    - 태스크를 실행하고 진행 상황을 잡트래커에 전송하기 때문에 잡트래커는 각 잡의 전체적인 진행 상황을 파악할 수 있음 
  - 맵리듀스1과 YARN 컴포넌트의 비교
    - 잡트래커 - 리소스 매니저, 애플리케이션 마스터, 타임라인 서버
    - 태스크트래커 - 노드 매니저
    - 슬롯 - 컨테이너
  - YARN을 사용하여 얻을 수 있는 이익
    - 확장성
      - 맵 리듀스 1보다 큰 클러스터에서 실행될 수 있음
    - 가용성
      - 고가용성(high availability - HA)은 서비스 데몬에 문제가 발생했을 때 서비스에 필요한 작업을 다른 데몬이 이어받을 수 있도록 상태 정보를 항상 복사해두는 방법으로 구현함 
    - 효율성
    - 멀티테넌시(다중 사용자)
      - 하둡이 맵리듀스를 뛰어넘어 다양한 분산 애플리케이션을 수용할 수 있다는 것 
