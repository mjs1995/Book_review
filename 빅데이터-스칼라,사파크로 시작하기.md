# 서평
- ![image](https://user-images.githubusercontent.com/47103479/157253528-710265e6-c7ec-46c5-92fb-c154717abdb4.png)
- 스파크를 이용하여 ELT 및 튜닝을 하면서 스파크에 대한 공부를 하기 위해서 책을 읽게 되었다. 이 책은 스칼라와 스파크에 대한 개념을 체계적으로 설명하고 있으며 코드를 활용한 예시를 통해서 경험할 수 있다는게 매력적이였다.
- 하둡 에코시스템 중 스칼라, 스파크에 대한 개념에 대해 정리가 필요하신분에게 추천하며 스칼라와 스파크의 구조에 대해서 정리하며 기본기를 튼튼히 다듬었습니다.
- 책을 읽고 나서 현재 업무 하고 있는 하둡 에코시스템의 시스템 설정값에 대해 다시 하번 보게되면서 개선 포인트나 튜닝 포인트에 대해 생각을 하게 되었습니다. 스칼라와 스파크의 전체적인 구성을 익히기에 좋았습니다.

# 빅데이터 - 스칼라(scala), 스파크(spark)로 시작하기	
- 스파크는 인메모리(In-Memory) 기반의 처리로 하둡의 맵리듀스에 비해서 100배 빠른 속도를 제공하고, 머신러닝, 그래프처리 등 빅데이터 분석을 위한 통합 컴포넌트를 제공
- 스칼라로 작성되어 자바 보다 간결한 코드로 같은 작업을 표현할 수 있음
- 스칼라는 JVM에서 동작하기 때문에 기존에 사용하던 자바 라이브러리를 모두 사용할 수 있음

## 스칼라
- 객체 지향 언어의 특징과 함수형 언어의 특징을 함께 가지는 다중 패러다임 프로그래밍 언어
- JVML(Java Virtual Machine Language)
  - 자바가상머신(JVM)에서 동작하는 JVML
  - JVML : 자바가상머신(JVM) 위에서 동작하는 언어들로 scala, kotlin, Groovy 등
- 함수형 언어
  - 함수형 언어의 특징을 가지기 때문에 자바에 비하여 코드길이가 짧음
  - 겟터, 셋터, 생성자를 제거하고, 표현식을 간소화 하여 자바대비 짧은 코드로 동일한 내용을 작성
- 바이트 코드 최적화
- 동시성에 강함
  - 변경 불가능한 Immutable 변수를 많이 가지고 있음
  - 속성을 변경 불가능하게 하고, 순수 함수를 사용하여 병렬 프로그래밍 처리에 강함
- 함수형 프로그래밍
  - 함수형 언어는 함수형 프로그래밍의 패러다임을 따르는 프로그래밍 언어
  - 함수형 프로그래밍은 프로그래밍 패러다임의 하나로 자료 처리를 수학적 함수의 계산으로 취급하고 상태 변화와 가변 데이터를 피하는 것
    - 순수 함수(pure function) : 함수의 실행이 외부에 영향을 끼치지 않는 함수
    - 익명 함수(anonymous function) : 선언부가 없는 익명 함수를 생성하여 코드 길이를 줄이고, 프로그래밍 로직에 집중
    - 고차함수(higher-order function) : 함수를 인수로 취하는 함수
- 가변 변수(variable)는 var, 불변 변수(value)는 val로 선언
- 커링은 여러 개의 인수 목록을 여러 개의 괄호로 정의
- 클로저는 내부에 참조되는 모든 인수에 대한 묵시적 바인딩을 지닌 함수
- 패턴 매칭은 자바의 switch 문과 유사하지만, 자바와는 달리 기본 자료형외에 케이스 클래스를 이용한 처리가 가능
- 믹스인 컴포지션은 클래스와 트레잇을 상속할 때 서로 다른 부모의 변수, 메소드 를 섞어서 새로운 정의를 만드는 것
- 트레잇(trait)은 자바의 인터페이스와 유사,기본 메소드는 상속되고, override 키워드를 이용하여 메소드를 재정의 할 수도 있음 
- 싱글톤 객체 : obejct 선언자로 싱글톤 객체를 생성
  - 컴패니언(Companions) : 싱글톤 객체와 클래스가 같은 이름을 사용
- 콜렉션 : 기본 콜렉션 자료구조를 제공, 배열, 리스트, 셋, 튜플, 맵 등
  - 배열 : 길이가 고정된 고정된 자료구조
  - 리스트 : 가변적인 길이의 데이터를 저장하기 위한 자료구조
  - 셋 : 중복을 허용하지 않는 자료 구주
  - 튜블 : 불변의 데이터를 저장하는 자료구조
  - 맵 : 사전 형식으로 데이터를 저장하는 구조
  - map 함수 : 콜렉션의 각 아이템에 대해서 동일한 작업을 해야할 때 사용
  - reduce, fold 함수 : 콜렉션의 데이터를 집계(fold 함수는 기본값을 제공)
  - groupBy : 데이터를 키를 기준으로 병합할 때 사용
  - filter : 콜렉션의 데이터를 필터링하여 없애거나 분류할 때 사용
  - zip : 두개의 콜렉션은 같은 인덱스의 데이터를 묶을 수 있음
  - mapValues : Map 타입의 데이터에서 밸류만 map 함수 처리를 하고 싶을 때 사용하는 함수
  - 정렬은 sorted, sortWith, sortBy 세가지 메소드를 이용할 수 있음

# 스파크
- 인메모리 기반(인-메모리 컴퓨팅은 메모리 내에서 데이터의 저장 뿐 아니라 데이터의 연산까지 수행하는 최첨단 칩 기술)의 대용량 데이터 고속 처리 엔진
- 범용 분산 클러스터 컴퓨팅 프레임워크
- 특징
  - Speed
    - 인메모리(In-Memory) 기반의 빠른 처리
      - 맵리듀스는 작업의 중간 결과를 디스크에 쓰기 때문에 IO로 인하여 작업 속도에 제약이 생깁니다. 스파크는 메모리에 중간 결과를 메모리에 저장하여 반복 작업의 처리 효율이 높음
  - Ease of Use
    - 다양한 언어 지원(Java, Scala, Python, R, SQL)을 통한 사용의 편이성
  - Generality
    - SQL, Streaming, 머신러닝, 그래프 연산 등 다양한 컴포넌트 제공
      -  단일 시스템 내에서 스파크 스트리밍을 이용한 스트림 처리, 스파크 SQL을 이용한 SQL 처리, MLib 를 이용한 머신러닝 처리, GraphX를 이용한 그래프 프로세싱을 지원
  - Run Everywhere
    - YARN, Mesos, Kubernetes 등 다양한 클러스터에서 동작 가능
    - HDFS, Casandra, HBase 등 다양한 파일 포맷 지원
      - 기본적으로 TXT, Json, ORC, Parquet 등의 파일 포맷을 지원
- 컴포넌트 구성
  - 스파크 코어
    - 메인 컴포넌트로 작업 스케줄링, 메모리 관리, 장애 복구와 같은 기본적인 기능을 제공
    - RDD, Dateset, DataFrame을 이용한 스파크 연산을 처리
  - 스파크 라이브러리
    - 빅데이터 처리를 위한 작업용 라이브러리
    - Spark SQL
      - SQL을 이용하여 RDD, DataSet, DataFrame 작업을 생성하고 처리
    - Spark Streaming
      -  실시간 데이터 스트림을 처리하는 컴포넌트, 스트림 데이터를 작은 사이즈로 쪼개어 RDD 처럼 처리
    - MLib : MLib는 스파크 기반의 머신러닝 기능을 제공하는 컴포넌트
    - GraphX : 분산형 그래프 프로세싱이 가능하게 해주는 컴포넌트
  - 클러스터 매니저
    - 스파크 작업을 운영하는 클러스터 관리자
    - 스탠드얼론(Standalone) 관리자를 이용할 수도 있고, 메조스(Mesos), 얀(YARN), 큐버네티스(Kubernetes) 등의 관리자를 지원
- 스파크 구조
  - 드라이버 : 작업을 관리
  - 클러스터 매니저 : 작업이 실행되는 노드를 관리
- 스파크 애플리케이션의 구조
  - 마스터-슬레이브 구조
  - 드라이버 : 스파크 애플리케이션은 작업을 관장
    - 스파크 컨텍스트 객체를 생성하여 클러스터 매니저와 통신하면서 클러스터의 자원 관리를 지원하고, 애플리케이션의 라이프 사이클을 관리
  - 익스큐터 : 실제 작업이 동작
    - ![image](https://user-images.githubusercontent.com/47103479/155868102-7f649053-06d3-43bc-9605-4251b552fa08.png)
- 스파크 애플리케이션
  - 스파크 실행 프로그램으로 드라이버와 익스큐터 프로세스로 실행되는 프로그램
  - 클러스터 매니저가 스파크 애플리케이션의 리소스를 효율적으로 배분
  - 드라이버(Driver)
    - 스파크 애플리케이션을 실행하는 프로세스
    - main 함수를 실행하고, 스파크 컨텍스트(SparkContext) 객체를 생성
    - 스파크 애플리케이션의 라이프 사이클을 관리하고, 사용자로 부터 입력을 받아서 애플리케이션에 전달 
    - 작업 처리 결과를 사용자에게 알려줍
    - 실행 시점에 디플로이 모드를 클라이언트 모드와 클러스터 모드로 설정할 수 있음, 클라이언트 모드는 클러스터 외부에서 드라이버를 실행하고, 클러스터 모드는 클러스터 내에서 드라이버를 실행
  - 익스큐터(Executor)
    - 태스크 실행을 담당하는 에이전트로 실제 작업을 진행하는 프로세스
    - YARN의 컨테이너
    - 태스크 단위로 작업을 실행하고 결과를 드라이버에 알려줌
    - 익스큐터가 동작 중 오류가 발생하면 다시 재작업을 진행
  - 태스크(Task)
    - 익스큐터에서 실행되는 실제 작업
    - 익스큐터의 캐쉬를 공유하여 작업의 속도를 높일 수 있음
- 스파크 잡의 구성
  - 잡(Job) : 스파크 애플리케이션으로 제출된 작업
  - 스테이지(Stage) : 잡을 작업의 단위에 따라 구분한 것이 스테이지
  - 태스크(Task) : 익스큐터에서 실행되는 실제 작업, 데이터를 읽거나, 필터링 하는 실제 작업을 처리
  - ![image](https://user-images.githubusercontent.com/47103479/155868111-bfce0dae-952b-4351-ab1b-f1685838b364.png)
- 클러스터 매니저
  - YARN
    - 하둡 클러스터 매니저
    - 리소스 매니저, 노드 매니저로 구성 됨
  - Mesos
    - 동적 리소스 공유 및 격리를 사용하여 여러 소스의 워크로드를 처리
    - 아파치의 클러스터 매니저
    - 마스터와 슬레이브로 구성됨
  - StandAlone
    - 스파크에서 자체적으로 제공하는 클러스터 매니저
    - 각 노드에서 하나의 익스큐터만 실행 가능
- 스파크 모니터링
  - 스테이지와 태스크 목록
  - RDD 크기와 메모리 사용량
  - 환경변수 정보
  - 익스큐터의 정보
  - 스파크 컨텍스트 웹UI
    - 스파크 컨텍스트가 실행되면 4040포트로 웹UI를 실행
    - 스파크 컨텍스트가 실행되고 있는 동안에만 사용 가능
  - 스파크 히스토리 서버
    - 실행중인 작업과 실행이 끝난 작업의 히스토리를 확인하기 위한 서버
    - start-history-server.sh로 실행하고 기본 접속 포트는 18080
    - 영구적인 저장소에 스파크 작업 내역을 저장 하고 사용자의 요청에 정보를 반환
    - REST API : 스파크 히스토리 서버는 작업 애플리케이션에 대해 REST API를 이용해 json 형태의 정보를 제공

## 스파크 애플리케이션
- 실행방법
  - jar 파일로 묶어서 실행하거나, REPL 환경에서 실행할 수 있음
  - 스칼라나, 자바로 작성한 스파크 애플리케이션을 jar 파일로 실행할 때나, 파이썬, R 파일을 spark-submit을 이용해 실행할 수 있음
  - spark-submit 설정값
  - ![image](https://user-images.githubusercontent.com/47103479/157047897-6bfa3706-c307-4a9a-aa66-1d10b74ae70c.png)
  - ![image](https://user-images.githubusercontent.com/47103479/157047964-7e94a05f-37a6-46ee-8089-48feae744dce.png)
  - ![image](https://user-images.githubusercontent.com/47103479/157047997-ff7172c4-798c-4ae1-b9d0-2dfbf98e1540.png)
  - ![image](https://user-images.githubusercontent.com/47103479/157048048-d7f59945-10f5-4e74-b558-c6e5357b79bd.png)

## RDD
- RDD는 외부 데이터를 읽어서 처리하거나, 자체적으로 컬렉션 데이터를 생성하여 처리할 수 있음
- 데이터 처리는 파티션 단위로 분리하여 작업을 처리
- 트랜스포메이션(transformation), 액션(action) 두가지 타입의 연산
  - 트랜스포메이션은 필터링 같은 작업으로 RDD에서 새로운 RDD를 반환
  - 트랜스포메이션은 RDD를 이용해서 새로운 RDD를 생성
  - 액션은 RDD로 작업을 처리하여 결과를 반환
  - 액션은 RDD를 이용해서 작업을 처리하여 결과를 드라이버에 반환하거나, 파일시스템에 결과를 쓰는 연산
- 액션이 실행될 때마다 새로운 연산을 처리합니다. 작업의 처리 결과를 재사용하고 싶으면 persist() 메소드를 사용하여 결과를 메모리에 유지하도록 할 수 있음
- 스파크 컨텍스트(SparkContext) 객체를 이용하여 생성할 수 있음
  - SparkConf 객체를 이용해서 설정값을 생성하고, 이를 이용해서 초기화
  - 내부 데이터 이용(Parallelized Collections)
 : parallelize() 메소드를 이용, map(), reduce(), filter() 등의 RDD 연산1을 이용하여 처리
  - 외부 데이터 이용
    - 스파크 컨텍스트의 textFile() 메소드를 이용하여 처리
- 브로드캐스트(broadcast)
  - 브로드 캐스트는 맵리듀스의 디스트리뷰트 캐쉬(distribute cache)와 유사한 역활을 하는 모든 노드에서 공유되는 읽기 전용 값
  - broadcast() 
- 데이타셋, 데이터 프레임
  - 뷰생성 
    - 데이터프레임을 SQL로 조회하기 위해서 데이터프레임에 이름을 부여
    - createOrReplaceTempView를 이용하여 데이터프레임을 뷰로 등록하고, SQL에서 사용
- 저장 모드(SaveMode)
  - 데이터를 저장할 때 mode를 이용해서 파일을 덮어쓸 것인지, 이어쓸 것인지 설정할 수 있음
  - 테이블 저장
    - 테이블을 저장할 때는 saveAsTable을 이용
  - 스파크 SQL 저장
    - coalesce를 이용하여 파티션의 개수를 지정하여 파티션의 개수(최종 파일의 개수)를 지정
    - ![image](https://user-images.githubusercontent.com/47103479/157048152-ff05a2f7-4cd4-4ea5-baa5-c4c64a0797bd.png)
  - 테이블 저장
    - 테이블을 저장할 때는 saveAsTable을 이용
  - ![image](https://user-images.githubusercontent.com/47103479/157048246-06d70aea-d40d-48e8-ab6c-afd857c529dc.png)
  - ![image](https://user-images.githubusercontent.com/47103479/157050581-0eecefbc-cfc7-4d24-8f2e-aab6a04ad303.png)

# 스파크 스트리밍
- 실시간 데이터 분석을 위한 스파크의 컴포넌트
- 디스트림(DStream)
- 스트리밍 컨텍스트
- 스트리밍 워드 카운트
- 윈도우 트랜스포메이션
- 디스트림 연산
- ![image](https://user-images.githubusercontent.com/47103479/157050704-4ad585eb-0e37-42a7-bf61-7ee6756eed87.png)
- ![image](https://user-images.githubusercontent.com/47103479/157050730-76fb5bb7-e9bf-4502-b5ce-1dcee090accc.png)
- ![image](https://user-images.githubusercontent.com/47103479/157050781-0d0dc8d5-9182-42af-bfb8-215c6f7b6b82.png)
- ![image](https://user-images.githubusercontent.com/47103479/157050806-2568e368-2c10-4d45-b6a3-48f7dbdbf83f.png)

