- 선행 연구(pilot study) : 본격적인 조사 및 연구에 앞서, 소규모로 조사 대상에 대한 연구 및 실헝해보는 것
	- PoC(Proof of Concept) : 프로젝트에 사용되는 기술과 컨셉을 정의
	- Pov(Proof of Value) : 해당 프로젝트에 비지니스적으로 어떤한 효율이 있는지 가치를 증명
	- BMT(BenchMark Test) : 대규모 인프라에 대한 성능과 인프라를 테스트 

# 빅데이터 이해하기 
- 빅데이터 개념
	- 6V (3V + 2V = 1V)
		- 크기(Volume) : 방대한 양의 데이터(테라, 페타바이트 이상의 크기)
		- 다양성(Varity) : 정형(DBMS,전문 등) + 비정형(SNS,동영상, 사진, 음성, 텍스트 등)
		- 속도(Velocity) : 실시간으로 생서ㅏㄴ되며, 빠른 속도로 데이터를 처리/분석
	
		- 진실성(Veracity) : 주요 의사결정을 위해 데이터의 품질과 신뢰성 확보
		- 시각화(Visualization) : 복잡한 대규모 데이터를 시각적으로 표현
			- 인사이트 : 현상 이해, 현상 발견, 현상 예측
		- 가치(Value) : 비즈니스 효익을 실현하기 위해 궁극적인 가치를 창출 
			- 비즈니스 : 비용 절감, 수익 창출, 문제 해결 
- 빅데이터 목적
	- 빅데이터 인사이트 
		- 현상 이해 : 대규모 데이터로부터 통계 장표를 추출하고 과거에 발생하는 일에 대한 원인을 파악 
		- 현상 발견 : 지금까지 알지 못했던 데이터 패턴을 발견해서 해석하고, 무슨 일이 새롭게 발생했는지 알아내는것 
		- 현상 예측 : 이해와 발견을 통해서 예측 모형을 만들고(모델) 현재 발생하고 있는 데이터를 모형에 입력해서 미래에 발생할 현상을 예측하는 것  
- 빅데이터 프로젝트
	- 플랫폼 구축형 프로젝트
		- 전형적인 빅데이터 SI(System Integration) 구축형 사업, 빅데이터의 하드웨어와 소프트웨어를 설치 및 구성, 수집-> 적재 -> 처리 -> 탐색 -> 분석의 기능을 구현, 3~6 개월 정도로 추진
		- 조직도 : 프로젝트 관리자(PM) - 아키텍트 - 플랫폼 파트(설치/구성) , 전처리 파트 (수집/적재), 후처리 파트(처리/탐색/분석)
	- 빅데이터 분석 프로젝트
		- 빅데이터 플랫폼 구축 완료후 수행, 빅데이터 탐색으로 데이터 이해가 높아질때 시작,  조직의 가치사슬 중, 대규모 분석이 필요한 시점에 추진, 1~3개월 일정으로 추진, 1~3개월 일정으로 추진, 분석주제영역(마케팅/고객, 상품/서비스 개발, 리스크 관리)
		- IT와 현업의 기술의 조화가 이루어지도록 추진 , 프로젝트 관리자 -> 비즈니스, 데이터 분석, 데이터 엔지니어링
	- 빅데이터 운영 프로젝트
		- 구축 완료된 플랫폼을 중자기적으로 유지 관리
		- 대규모 하드웨어/소프트웨어로 운영 비용 높음
		- 빅데이터 분야별 전무가 그룹이 확보 되야 함(플랫폼 전문가, 데이터분석전문가, 업무전문가)
		- 빅데이터 거버넌스 체계를 수집 해야 함 
			- 전사의 시스템, 여러 부서들 여러 업무 담당자들이 빅데이터 시스템에 들어와서 추출,분석,주변 시스템과 공유 하므로 필요한 프로세스들을 표준화하고 그때마다 필요한 역할들도 명확히 정의, 만들어진 결과물에 대한 표준화 작업 필요
- 빅데이터 구현 기술
	- 수집 - 적재 -처리/탐색 - 분석/응용
- 빅데이터에서 R&R
	- 빅데이터_AI 파일럿 시스템 : 분석가모델러, 개발자인프라, 데이터 엔지니어, 관리자기획자 
 - 빅데이터 보안
	- 시스템 
	- 데이터(개인정보 비식별화, 비식별화+대체키 활용)
	- 네트워크, 물리적, 코드
	- 접근제어
		- 아파치 녹스(클라이언트와 하둡에코시스템의 중간역할), 
		- 아파치 센트리 서버(계정과 권한 정보 통합 관리, 중앙 서버), 
		- 아파치 레인지 서버(시스템에 깊숙히 관여하는 플러그인 서버가 있으며 센트리 서버와 유사)
		- 커베로스(kerberos Key Distribution Center) : 인증서버와 티켓 발생 서버를 통해 티켓획득하고 인증과 접근 제한 통제함 
	- 전송 보안 


# 파일럿 프로젝트 환경 구성
- 빅데이터 파일럿 프로젝트
	- 1.파일럿 프로젝트 도메인 이해
		- 파일럿 프로젝트의 기본 도메인을 이해하고, 이와 관련된 빅데이터 요구사항을 도출 및 분석한다.
	- 2.빅데이터 파일럿 아키텍처 이해
		- 스마트카의 빅데이터 분석을 위한 소프트웨어/하드웨어 아키텍처를 이해한다.
	- 3.빅데이터 파일럿 프로젝트용 PC 환경 구성
		- 파일럿 프로젝트 환경을 구성하기 위해 독자들의 PC에서 사용을 기본 소프트웨어로 설치하고 구성한다. 이 과정에서 자바, 이클립스 ,오라클 버추얼 박스 등을 설치한다
	- 4.빅데이터 파일럿 프로젝트용 PC 서버 구성
		- 3개의 가상 머신을 생성하고, 분산 클러스터 환경을 구성하기 위한 3대의 리눅스 서버(CentOS)를 설치 및 구성한다.
	- 5.CM(Cloudera Manager) 설치
		- 빅데이터 소프트웨어들을 설치/관리하는 Cloudera Manager를 설치한다. CM을 이용해 빅데이터 파일럿 프로젝트의 기본 소프트웨어인 하둡,주키퍼를 설치한다.
	- 6.스마트카 로그 시뮬레이터 설치
		- 스마트카의 상태 정보와 운행 정보를 시뮬레이션해 로그 데이터를 생성하는 자바 프로그램을 설치한다.
	- 7.파일럿 환경 관리
		- 파일럿 환경을 안전하게 시작하고 종료하는 방법을 설명한다.
## 스마트카 서비스 
- ![image](https://user-images.githubusercontent.com/47103479/154844522-46e778e1-6699-4f04-bb5e-3338999a64dd.png)
- 요구사항 1
	- 차량의 다양한 장치로부터 발생하는 로그 파일을 수집해서 기능별 상태를 점검한다.
	- ![image](https://user-images.githubusercontent.com/47103479/154844535-612e023e-c567-485d-b001-dfc37ff3400a.png)
- 요구사항 2
	- 운전자의 운행 정보가 담긴 로그를 실시간으로 수집해서 주행 패턴을 분석한다.
	- ![image](https://user-images.githubusercontent.com/47103479/154844551-dd4cdfdb-9997-4d92-8db8-c2087af4486a.png)
- 파일럿 프로젝트 데이터셋
	- 1.스마트카 상태 정보 데이터셋(배치)
	- 2.스마트카 운전자 운행 데이터셋(실시간)
	- 3.스마트카 마스터 데이터셋(운전자의 프로파일정보,이름,성별,거주지)
	- 4.스마트카 물품구매 이력 데이터셋
- ![image](https://user-images.githubusercontent.com/47103479/154844562-a19099f8-152e-437d-ae9a-1d87779437fa.png)
- 소프트웨어 아키텍처
	- ![image](https://user-images.githubusercontent.com/47103479/154844971-a33ed3e8-0d2b-474d-8451-0b1fbdf36702.png)
	- ![image](https://user-images.githubusercontent.com/47103479/154844957-e6b38254-ec12-4200-b6c1-c8a8e9672ca5.png)
	- 수집 레이어
		- ![image](https://user-images.githubusercontent.com/47103479/154844997-b3c75a95-1e97-43be-a4a1-1628f41c1cec.png)
	- 적재 레이어
		- ![image](https://user-images.githubusercontent.com/47103479/154844985-2db5fe3e-e16f-430a-a92e-b49faf705d65.png)
	- 처리/탐색 레이어
		- ![image](https://user-images.githubusercontent.com/47103479/154845031-75c87f51-175e-4b1e-ada7-f5b7ffff6b99.png)
	- 분석/응용 레이어
		-  ![image](https://user-images.githubusercontent.com/47103479/154845025-9492b2f0-73f7-4ab5-b889-e3180a6a5d23.png)
- 빅데이터 전문가
	- 플랫폼 전문가 : 하둡 에코시스템 설치 및 구성
	- 수집/적재 전문가 : 대규모 데이터 연동 및 통합
	- 처리/탐색 전문가 : 데이터 모델 설계 및 처리
	- 분석/응용 전문가 : 도메인 분석 및 인사이트 도출
- ![image](https://user-images.githubusercontent.com/47103479/154845012-16fea5d1-dc81-440d-94af-fc16cebeb921.png)
## 클라우데라
- ![image](https://user-images.githubusercontent.com/47103479/154848946-401d2d8d-e942-46fc-a351-90d9009afb77.png)
- ![image](https://user-images.githubusercontent.com/47103479/154847021-76146440-c734-4346-8bb0-5f67338f7195.png)
- ![image](https://user-images.githubusercontent.com/47103479/154848679-31cc7f4a-1e17-40bc-bf04-f685b265a359.png)
- ![image](https://user-images.githubusercontent.com/47103479/154848703-3e338650-a231-43de-b271-169c820abbd1.png)
- ![image](https://user-images.githubusercontent.com/47103479/154848706-7e1f65af-1683-4d49-bf77-21e1a6383463.png)
- ![image](https://user-images.githubusercontent.com/47103479/154848743-6d2d0650-6f89-42e0-9fd7-fe67b056c000.png)
- ![image](https://user-images.githubusercontent.com/47103479/154848769-3e3e6cda-9f80-4c2e-80f6-e57e76bedea8.png)
- ![image](https://user-images.githubusercontent.com/47103479/154848808-625b91a0-2d2b-4fe1-b4d5-264689b5d61e.png)

## 하둡과 주키퍼 명령 사용해 보기
- FileZilla : server02.hadoop.com / bigdata / bigdata
	- ![image](https://user-images.githubusercontent.com/47103479/154970882-c383a386-10cd-477c-8115-caa8ea878fd2.png)
	- ![image](https://user-images.githubusercontent.com/47103479/154970985-dddc77c4-0b61-4840-a7ce-de211655f9a4.png)

- HDFS 파일의 비정상 상태
	- HDFS 점검 명령 실행할 때 CORRUPT FILES, MISSING BLOCKS, MISSING SIZE, CORRUPT BLOCKS 등의 항목에 숫자 표기
	- 강제 셧다운이 빈번하고 리소스가 부족한 테스트 환경에서 자주 발생하는 현상 
	- $ hdfs dfsadmin -safemode leave : 강제로 안전 모드 해제
	- $ hdfs fsck / -delete : 손상된 파일을 강제로 삭제
	- $ hdfs fsck / -move : 손상된 파일을 /lost + found 디렉터리로 옮김
- 주키퍼 명령어(메타정보 관리하고 생성하고 동기화하는데 사용) 
	- zookeeper-client 
	- create /pilot-pjt bigdata : 노드 만듬
	- ls / : 노드 조회
	- get /pilot-pjt  : 집노드 읽기
	- delete /pilot-pjt : 집노드 삭제
```shell
$ cd /home/bigdata
$ hdfs dfs -put Sample.txt /tmp 
$ hdfs dfs -ls /tmp # 디렉토리 목록 조회
$ hdfs dfs -cat /tmp/Sample.txt # 파일 내용 보기 
$ hdfs dfs -stat '%b %o %r %u %n' /tmp/Sample.txt #파일의 크기(%b), 파일 블록 크기(%o), 복제 수(%r), 소유자명(%u), 파일명(%n) 정보 보여줌
$ hdfs dfs -mv /tmp/Sample.txt /tmp/Sample2.txt # move명령어 이름변경 뒷단으로
$ hdfs fsck / # 하둡의 파일 시스템 상태 검사(전체 크기, 디렉터리 수, 파일 수, 노드 수 등 파일 시스템의 전체 상태를 보여줌)
	      # Missing blocks: , Corrupt blocks: , Missing replicas: 유심히 보기 	
$ hdfs dfsadmin -report # 하둡 파일시스템의 기본 정보 및 통계를 보여줌
$ hdfs dfs -get /tmp/Sample2.txt # 뒷 디렉터리에 Sample2.txt 파일이 생성됨
$ hdfs dfs -rm /tmp/Sample2.txt # 저장한 파일 삭제(휴지통) , 특정시간(24시간,CDH 기준) 지나면 완전 삭제, 휴지통 삭제 필요없을때는 -skipTrash
$ 
```
## 스마트카 로그 시뮬레이터
```shell
# 실시간 로그
$ cd /home
$ mkdir /home/pilot-pjt
$ mkdir -p /home/pilot-pjt/working/car-batch-log 
$ mkdir -p /home/pilot-pjt/working/driver-realtime-log
#$ mkdir /home/pilot-pjt/working
#$ mkdir /home/pilot-pjt/working/car-batch-log
#$ mkdir /home/pilot-pjt/working/driver-realtime-log
$ chmod 777 -R /home/pilot-pjt

# /usr/bin 심볼릭 링크 재설정
$ rm /usr/bin/java
$ rm /usr/bin/javac
$ ln -s /usr/java/jdk1.8.0_181-cloudera/bin/javac /usr/bin/javac
$ ln -s /usr/java/jdk1.8.0_181-cloudera/bin/java /usr/bin/java
$ java -version
$ (cd working/) java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20200901 10
$ cd /home/pilot-pjt/working/driver-realtime-log/
$ ps -ef | grep DriverLogMain
$ kill -9 20040 (포트번호) or ctrl + c (실행하고있는 파일에서)

# 스마트 카 로그 (24시간 동안 실행된 상태 정보)
$ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20200901 10
$ ctrl + c
$ cd /home/pilot-pjt/working/SmartCar/
$ ls -ltrh
$ tail -f SmartCarStatusInfo_20200901.txt
```
- ![image](https://user-images.githubusercontent.com/47103479/155133824-4fa6853d-4e43-4909-8f06-041603b20acb.png)
- ![image](https://user-images.githubusercontent.com/47103479/155134255-2d61b64c-97ed-4185-9c56-6a4fd9038674.png)
- 돌고있을때 ctrl+c 로 중지가능
- ![image](https://user-images.githubusercontent.com/47103479/155134542-59dac8f0-995b-473c-ab0d-7f105b3c2eed.png)
- ![image](https://user-images.githubusercontent.com/47103479/155134932-a5167e3c-c71d-48eb-a7e8-9cd925bd5dcf.png)
- ![image](https://user-images.githubusercontent.com/47103479/155135039-f74e049b-5592-4035-86d6-7658a5f73021.png)

## 파일럿 환경 관리
- 1) 버추얼 박스 실행 - Server01,Server02 실행 - 2개의 가상 머신 창 활성화, CentOS구동
- 2) PuTTY로 Server01 SSH 접속해서 CM이 구동완료됬는지 확인 - $ service cloudera-scm-server status(cloudera-scm-server is running---)
- 3) 크롬 브라우저 실행해서 CM 관리자 화면 접속(http://server01.hadoop.com:7180)
- 4) HDFS,주키퍼,카프카,YARN 등의 소프트웨어들은 의존 관계 맺고있음 (선후관계존재), 재시작할때는 의존관계 고려(cluster 1아래 선택), 콤보박스 아래 재시작 메뉴 선택 
- 5) CM 클러스터 중지 -> Server01, server02 PuTTY 서버에서 시스템 종료 명령 실행 ($ halt) -> (안될시) 가상 머신 목록 Server01,02 모두 전원 끄기 
- ![image](https://user-images.githubusercontent.com/47103479/155136625-52a8a622-9931-45cf-b7c5-07dc0c62e00e.png)
- ![image](https://user-images.githubusercontent.com/47103479/155136701-616ab7f0-edb9-470d-9617-8aee9c169016.png)
- ![image](https://user-images.githubusercontent.com/47103479/155136805-7759f15a-6e8f-4081-a6ab-fd74d072f29f.png)

## 빅데이터 실환경
- NameNode(A) - Active
- HBase Master(S) - Standby
- 데이터 노드 확인하기!(국내에서는 수백 수천대까지 운영)
- 대규모 빅데이터 클러스터 아키텍처 ex
	- 서비스 연계망, 내부망, 10Gbps Switch
	- 데이터 서버66대
	- 마스터 서버 7대
	- 분석서버 6대
	- 배치 서버 2대
	- 실시간 처리 서버 5대
	- 분산큐 5대
	- 로그 수집/전처리 5대
	- 모니터링 1대

## 파일럿 서버 환경 구성
- 1) PuTTY - 새네트워크 추가 
- 2) CentOS 6.x 설치 -> 오라클 버추얼 박스 새로만들기 -> Linux, Server01 -> 메모리크기 2048,새 가상 하드디스크, VDI, 동적할당 ,  하드디스크 30GB -> 서버 네트워크 설정 -> 어댑터 1(NAT) , 어댑터 2(호스트 전용 어댑터), 무작위모드 - 모두 허용 
- 3) 설정 -> 저장소 >> 비어있음 >> 광학 디스크 >> CentOS-6.10-x86_64-LiveDVD.iso
- 4) Server01 시작후 CentOS6 Install >> Hostname: server01.hadoop.com 으로 설정 >> Asia/Seoul , UTC 사용 >> adminuser/adminuser 아이디 비밀번호 설정 >> use all space >> Server01 끄고 - 설정 - 저장소 - CentOS-6.10-x86 삭제하기
- 5) server01 재부팅 >> bigdata/bigdata/bigdata/bigdata로 create User >> Synchronize 시간대 클릭 >> Enable kdump 해제하기 
- 6) 네트워크 및 커널 설정
	- CentOS Application >> System tool >> terminal(X-Winodw 부팅을 해제) 
	- $ vi /etc/inittab >> 숫자 5를 3으로 변경 >> $ reboot 
	- root / adminuser 
	- vi /etc/sysconfig/network-scripts/ifcfg-eth0 의 네트워크 주소 모두입력(네트워크-어댑터2-MAC 주소) >> IPADDR 확인 
	- vi /etc/udev/rules.d/70-persistent-net.rules >> PCI 부분 모두 주석처리 
	- 재부팅
	- $ service networt restart
	- $ ifconfig eth0
	- SSH 접속을 위한 패키지 설치
		- $ yum install openssh*
		- $ service sshd restart
		- $ chkconfig sshd on
		- $ reboot
		- 리부팅
		- $ service network restart
		- vi /etc/hosts >> 192.168.56.101 server01.hadoop.com server01 / 192.168.56.102 server02.hadoop.com server02 추가 
		- vi /etc/sysconfig/network >> HOSTNAME에 server01.hadoop.com 설정 > $service network restart 
	- Server01의 방화벽 및 기타 커널 매개변수 등 설정 (책참고)
- 7) 가상머신 복제
	- VM Server01 복제 >> 모든 네트워크 카드의 MAC 주소 초기화 >> 완전한 복제 
	- Server02 - 어댑터 2 MAC주소 변경
	- Server01과 같이 모두수행 

## 인프라
- 빅데이터 인프라 설치 및 구성
	- 수십~수백 대의 x86 서버들을 대규모로 설치하고 10여 개 이상의 빅데이터 오픈소스 소프트웨어 복잡하게 설치 -> 수작업을 통한 서버/소프트웨어 제어하는데 한계
	- 자동화된 소프트웨어 설치/관리 작업 툴 이용
		- Puppet, Ansible, Chef, Ambari, Cloudera Manager, BigTop 등으로 대규모 인프라스트럭처를 구성하는데 활용 
		- 호튼웍스의 Ambaril와 클라우데라 CM(Cloudera Manager)는 빅데이터 전용 설치/환경 구성 툴로 빅데이터 소프트웨어들을 웹 GUI 환경에서 쉽게 활용할 수 있도록 지원
- 클라우데라 매니저(CM)
	- CM 주요 기능/ 설명
	- 프로비저닝 - 하둡 에코시스템을 편리하게 설치, 삭제, 수정 관리
	- 매니지먼트 - 설치한 에코시스템의 설정 변경 및 최적화 지원
	- 모니터링 - 하드웨어의 리소스 및 설치 컴포넌트의 상태 모니터링/대시보드
	- 설치
		- $ cd /root
		- $ wget https://archive.cloudera.com/cm6/6.3.1/redhat6/yum/cloudera-manager.repo
		- $ mv /root/cloudera-manager.repo /etc/yum.repos.d/
		- $ yum install oracle-j2sdk1.8 # JDK 1.8 설치
		- $ yum install cloudera-manager-daemons cloudera-manager-server # CM 데몬 서버 설치
		- $ yum install cloudera-manager-server-db-2 # DB 설치
		- $ service clouder-scm-server-db start 
		- $ vi /var/lib/clouder-scm-server-db/data/pg_hba.conf # PostgreSQL 서버의 원격 접근 제한 설정 >> (마지막 3번째줄 reject -> md5) >> host all all 0.0.0.0/0 trust >> service clouder-scm-server-db start
		- 메모장 열기 C:\\Windows\System32\drivers\etc\hosts 에서 server01,02 가상 머신 정보 추가 
	- Apache Hadoop - 하둡 배포판 3.0.0
		- 오픈소스로 공개돼 있는 하둡을 기반으로 특정 기업 또는 조직이 커스터마이징해서 만들어낸 독자적인 하둡 패키지를 의미
		- 클라우데라사의 CDH(Cloudera Distributed Hadoop), 호튼웍스사의 HDP(Hortonworks Data Platform)

# 빅데이터 수집
- 빅데이터 수집 데이터
	- ![image](https://user-images.githubusercontent.com/47103479/156038207-fec639c5-d649-44f4-82ce-9fc66cbe49e1.png)
- 빅데이터 수집 절차
	- ![image](https://user-images.githubusercontent.com/47103479/156038383-1e17caac-712d-4a8a-81c8-32e7ebd10808.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156041415-0c6f9a5e-406c-43a6-af33-7e5a4805d916.png)

- 플럼
	- ![image](https://user-images.githubusercontent.com/47103479/156039085-2a8a667e-f0ae-4f50-a8e4-01babfc6661f.png)
	- 아키텍처
		- 플럼 에이전트 >> Source -> Channel -> Sink
		- ![image](https://user-images.githubusercontent.com/47103479/156039764-97879dc1-2009-47c8-a6ce-0761af925adc.png)
		- ![image](https://user-images.githubusercontent.com/47103479/156040086-8b195313-63f6-48b9-87a8-8072cbd93f9d.png)
	- 설치
		- ![image](https://user-images.githubusercontent.com/47103479/156155347-4dad19b5-81d8-46fa-9195-61866606ddb5.png)
	- 플럼 구성 >> agent 이름 변경 및 구성 변경 >> config파일 
- 카프카
	- ![image](https://user-images.githubusercontent.com/47103479/156040395-52fd8bcb-e270-4103-8c30-6a22a00cbb73.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156040623-d1f145c3-3ac8-497f-995a-07cafa2e2914.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156040664-faf3c922-9a55-4610-8207-f7db5250d5f4.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156040700-ca0ac706-29e1-4163-8755-207367d6c0cb.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156040928-86134e35-2bc6-49f1-b7e4-91c9bb485e08.png)
	- 설치
		- ![image](https://user-images.githubusercontent.com/47103479/156156472-3cf6070c-33d3-4f6c-816e-244b52da9999.png)
	- 카프카 Producer와 Consumer의 메시지 송수신 점검
		- ![image](https://user-images.githubusercontent.com/47103479/156158401-e367470c-518b-4146-a1b6-4ac3ac54a5f3.png)
		- ![image](https://user-images.githubusercontent.com/47103479/156158882-00bfd541-85bd-4b34-8087-6c5e78087e66.png)
		- ![image](https://user-images.githubusercontent.com/47103479/156159114-9b252e00-ef32-45ce-8f56-613f03a63193.png)
		- ![image](https://user-images.githubusercontent.com/47103479/156159514-ce5cc9ad-284a-45ae-ba14-95858aafee8b.png)
		- ![image](https://user-images.githubusercontent.com/47103479/156159669-326b7266-f770-4083-8cc7-bd50e5dc405d.png)
		- ![image](https://user-images.githubusercontent.com/47103479/156159806-457b6a90-e6a3-43b9-a5c0-bcdb76dc521e.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156169089-d4ab50d9-bc31-4656-9e66-8dcb5ea4c9dd.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156169113-0033fc0e-158f-4bf1-b9ef-2a77d0ee7076.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156169613-d51220cd-dc9e-4399-a1db-9600baf9a959.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156169736-721cd7bf-7089-48bd-a094-3e4b4af521e8.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156169872-2fb7aade-b73b-416c-ad29-5e7fb3b237c5.png)
	- real time log 확인
		- ![image](https://user-images.githubusercontent.com/47103479/156170135-60235db8-03c9-4612-b0c6-edf2a6b71991.png)
	- 배치 로그 파일 확인 
		- ![image](https://user-images.githubusercontent.com/47103479/156170601-a8ec3360-15c4-4bcf-bc13-b7539033ad19.png)
		- ![image](https://user-images.githubusercontent.com/47103479/156170660-053792b1-3d68-4e32-bc56-7d3a880570ce.png)
	- 로그 시뮬레이터 종료
		- ![image](https://user-images.githubusercontent.com/47103479/156170841-22649d20-8f9b-423c-a6f1-6c210e4494b0.png)

# 빅데이터 적재 - 대용량 파일
- 빅데이터 적재 유형
	- ![image](https://user-images.githubusercontent.com/47103479/156915744-0cced22f-0f7c-4f63-8e54-a77776c6486e.png)
- 빅데이터 적재 저장소 유형
	- ![image](https://user-images.githubusercontent.com/47103479/156915754-e2f0b82b-4e4a-49da-a689-6bd9ebb9a4ef.png)
- 하둡
	- 대용량 데이터 분산 저장하는 것
	- 분산 저장된 데이터를 가공/분석 처리하는 기능 
	- ![image](https://user-images.githubusercontent.com/47103479/156915918-7dd12a6f-1e0c-4f80-8a86-e5f32559ba47.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156915934-b211231d-a7c7-4bfe-b8a9-eb59540336e7.png)
	- 하둡 아키텍처 1.X
	- ![image](https://user-images.githubusercontent.com/47103479/156915984-9275cf4f-20c8-4ed0-b9ae-02e58358a71d.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156916045-f584029d-e51b-4c3a-9edc-819b5cb9c24d.png)
	- 하둡 활용 방안
		- ![image](https://user-images.githubusercontent.com/47103479/156916060-f52cb7c0-e16c-4173-9211-2c61dfe73474.png)
	- 여러 컴퓨터에서 분산 저장돼 있는 데이터로부터 어떻게 효율적으로 일을 나눠서(Map) 실행시킬 수 있느냐고, 다음으로 여러 컴퓨터가 나눠서 실행한 결과들을 어떻게 하나로 모으냐(Reduce)는 것이다. 이를 쉽고 편하게 지원하는 프레임워크가 하둡의 맵리듀스(MapReduce)
		- ![image](https://user-images.githubusercontent.com/47103479/156916131-8b318cab-886d-4a59-b646-9bdbf2df4f95.png)
- 주키퍼
	- ![image](https://user-images.githubusercontent.com/47103479/156916208-89371cef-711c-4006-a05e-6f7c5d52d420.png)
	- 주키퍼 아키텍처
		- ![image](https://user-images.githubusercontent.com/47103479/156916218-8d5d0fd4-627d-4be8-be0f-43dba38c6597.png)
- 적재 아키텍처
	- ![image](https://user-images.githubusercontent.com/47103479/156916657-e74d6f26-3233-4e83-9886-6a03bcd34a68.png)
	- ![image](https://user-images.githubusercontent.com/47103479/156916666-45fba040-142a-43d6-9b61-679c0413b289.png)
- ![image](https://user-images.githubusercontent.com/47103479/156919022-f7ca4637-8f26-4dac-8950-5b45c4ffd61a.png)
- ![image](https://user-images.githubusercontent.com/47103479/156924830-4e4807fa-d3d7-407e-a0a3-6e3131a3fd27.png)

```shell
- http://server01.hadoop.com:9870
- 리소스 매니저 : http://server01.hadoop.com8088/cluster
- 잡(Job) 히스토리 : http://server01.hadoop.com:19888/jobhistory
```

# 빅데이터 적재 - 실시간 데이터
- ![image](https://user-images.githubusercontent.com/47103479/158591789-3b289fe0-691b-481b-af26-9eddac8b8540.png)
- ![image](https://user-images.githubusercontent.com/47103479/158591862-98365882-b4c4-4ead-9353-ba379c97f05c.png)
- HBase
	- 하둡 기반 컬럼 지향 NoSQL 데이터베이스, 스키마 변경 자유롭고, 리전이라는 수십,수백대의 분산서버로 샤딩과 복제기능을 지원해주는 성능과 안정성이 보장됨, 하둡의 확장성과 내고장성 이용가능, 실시간 처리를 위한 스피드레이어에 많이 사용됨
	- ![image](https://user-images.githubusercontent.com/47103479/158592030-d2307491-3200-4724-8458-312927c7d72a.png)
	- key/value
	- 아키텍처
	- ![image](https://user-images.githubusercontent.com/47103479/158592530-4267f26c-b674-4a8a-af50-3e848e06974b.png)
	- 활용방안
	- ![image](https://user-images.githubusercontent.com/47103479/158592720-760f0cf1-4c05-4988-8090-f38f8aca31b8.png)
- 레디스
	- 분산 캐시시스템, NoSQL 데이터베이스 처럼 대규모데이터를 관리할 수 있는 능력을 갖춘 인메모리 데이터 그리드 소프트웨어
	- ![image](https://user-images.githubusercontent.com/47103479/158593020-539d75ca-6231-42df-a8b5-a846d01f811a.png)
	- key/value
	- 아키텍처
	- ![image](https://user-images.githubusercontent.com/47103479/158593269-53d4c294-7612-4ad9-972d-80dc4be43e8b.png)
	- ![image](https://user-images.githubusercontent.com/47103479/158593298-9fc894d0-02ab-42a8-863f-0e98f624318b.png)
	- ![image](https://user-images.githubusercontent.com/47103479/158593353-3ae962d4-3b63-4f16-81d8-40443b90d1ff.png)
	- ![image](https://user-images.githubusercontent.com/47103479/158593388-44006867-45e9-4f7a-95c4-fa5bf6ae94c7.png)
- Storm
	- 카프카의 컨슈머 위치 역할, 대규모 스트리밍 데이터를 중간에 병렬처리하면서 영구 저장소에 빠르게 적재해주는 기능 , 영구데이터에 저장하기전에 전처리,집계,분석해줌 
	- ![image](https://user-images.githubusercontent.com/47103479/158593992-42115cf3-0169-4f9b-9575-b588697b7baf.png)
	- 아키텍처
	- ![image](https://user-images.githubusercontent.com/47103479/158594563-08321590-91bd-4a70-93bc-3893352ed16c.png)
	- 활용 방안 
	- ![image](https://user-images.githubusercontent.com/47103479/158594643-bc73381f-786b-452c-8592-1766b2ae1f13.png)
- Esper
	- 에스퍼는 과속하는 로직, 룰을 정의하는것(쿼리로 정의) 
	- ![image](https://user-images.githubusercontent.com/47103479/158594960-763e49c5-e2bb-4267-8522-4f024b72fb30.png)
	- 아키텍처
	- ![image](https://user-images.githubusercontent.com/47103479/158594989-e6425b3b-ed74-4478-a1f0-a6a14a730660.png)
	- ![image](https://user-images.githubusercontent.com/47103479/158595031-b6adc272-040b-421a-bbee-74a3b773d462.png)
	- 활용 방안
	- ![image](https://user-images.githubusercontent.com/47103479/158595080-dfeee408-3553-4139-bb10-f929e3177edc.png)
- 실시간 적재 아키텍처
	- ![image](https://user-images.githubusercontent.com/47103479/158595834-ccd35303-60fc-4153-8be8-0efbd1b08420.png)

- HBase
- ![image](https://user-images.githubusercontent.com/47103479/158770524-726d92cc-fe48-4471-a081-d592486c09c0.png)
- redis
```shell
$ echo "http://vault.centos.org/6.10/os/x86_64/" > /var/cache/yum/x86_64/6/base/mirrorlist.txt
$ echo "http://vault.centos.org/6.10/extras/x86_64/" > /var/cache/yum/x86_64/6/extras/mirrorlist.txt
$ echo "http://vault.centos.org/6.10/updates/x86_64/" > /var/cache/yum/x86_64/6/updates/mirrorlist.txt
$ yum install -y gcc*
$ yum install -y tcl

# HBase
$ hbase org.apache.hadoop.hbase.util.RegionSplitter DriverCarInfo HexStringSplit -c 2 -f cf1

```
- ![image](https://user-images.githubusercontent.com/47103479/158771720-7398bff5-88b8-4fd4-bd35-b48b4f0712e1.png)
- ![image](https://user-images.githubusercontent.com/47103479/158773076-99dbe444-f754-4c42-b771-e3a0bd32001a.png)

- Storm
- ![image](https://user-images.githubusercontent.com/47103479/158776490-cbc5bd0a-6de3-4806-974a-6b58ef1740d4.png)

- ![image](https://user-images.githubusercontent.com/47103479/158778589-cdb54936-780c-4c54-aa15-8e7f5b6cf14b.png)
- $ storm jar bigdata.smartcar.storm-1.0.jar com.wikibook.bigdata.smartcar.storm.SmartCarDriverTopology DriverCarInfo
- ![image](https://user-images.githubusercontent.com/47103479/158806369-a9f6f36d-60b8-4cf7-aeb1-29940493f261.png)
- ![image](https://user-images.githubusercontent.com/47103479/158810115-2f9ca552-84a8-484f-b707-331d5779dba6.png)
