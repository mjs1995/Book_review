# 서평

# 데이터 분석 개요
- 데이터 분석 기반을 만들 때 생각할 요소
  - 수집 : 어떤 데이터를 모을 것인가. 어떤 데이터를 보관할 것인가
  - 변환 : 데이터를 어떻게 전처리해서 분석하기 쉬운 형태로 바꿀 것인가
  - 보존 : 데이터를 어디에 저장할 것인가
  - 분석 : 어떤 기반에 넣어서 데이터를 분석하고 활용할 것인가. 데이터를 넣는 것 뿐만 아니라 분석을 위한 좋은 환경을 만들기 위해서 어떻게 해야할까
  - 표시 : 어떻게 데이터를 시각화하고, 결과를 전달할까
  - 운영 : 데이터를 분석하기위한 기반을 장기적으로 운영하기 위해서는 어떻게 해야할까. 엔지니어가 아니라도 활용할 수 있는 환경을 만들기 위해서는 어떻게 해야할까
- 대상이 되는 데이터
  - 마스터 데이터 : 시간이 지나도 바뀌지 않는 데이터. 예를 들어 상품명과 같은 것은 시간이 지나도 바뀌지 않음.
  - 시계열 데이터 : 어떤 시간에 발생하는 사건을 기록하는 데이터. 로그 데이터와 같은 경우
  - 설정 데이터 : 상황에 따라 애플리케이션의 동작을 변경하기 위해서 보존하는 데이터 
- SoR(System of Record) : 기록(Transaction)을 위한 시스템. 입출력의 내용을 문제없이 바르게 처리하기를 기대하는 시스템. 예를 들어 신용카드에 의한 결제나 항공권의 예약시스템 등의 경우 
- SoE(System of Engagement) : 관계강화(Engagement)를 위한 시스템. 고객의 이용을 촉진하기 위한 시스템.예를 들어 상품을 추천하는 시스템이나 고객에게 검색결과를 보여주는 시스템의 경우
- 의사결정을 위한 데이터 분석
  - 데이터에 근거한 의사결정
    - 데이터와 정보의 관점에서 보면 의사결정이란 것은 불확실성 그리고 그에 관련한 불이익과 이익을 관리하는 것이다.
  - 데이터 분석의 단계와 엔지니어링
    - 분석의 목적은 수치를 해석하는 것이 아니라 의사결정을 하는 것에 있음. 그리고 그 결과로 사업에 공헌하거나 서비스를 개선할 수 있음. 시각화도 마찬가지로 결과를 내는 수단이며, 사고의 도구
  - 웹상의 시각화
    - 특징
      - 인터랙티브한 데이터의 취급이 가능하므로 드릴다운, 드릴업이 가능함
        - 인터랙티브한 데이터의 취급이란 포인팅 디바이스(대체적으로 마우스를 말함)에 의한 조작이나 조건 검색에 의해서 현재 표시된 데이터를 가공하고 양방향으로 데이터를 취급하는 것
        - 드릴다운은 특정 상태의 데이터에서 조건을 더 지정하여 범위를 좁히는 것
        - 드릴업은 조건검색을 뺌으로써 좀더 넓은 범위의 데이터를 보는 것을 의미함 
      - 임의의 데이터 또는 분석 상태에 대한 URI를 발행할 수 있음
      - URI를 공유하는 것으로 간단히 여러 사람이 같이 분석할 수 있음 

# 로그 데이터의 기초
- 서비스 개선을 위한 로그
  - hot data : 발생한 직후의 데이터. 발생하고 바로 이용됨. 또는 고빈도로 조회되는 데이터를 말함
    - hot data는 준 실시간의 분석을 가능케 함 
      - 지금 이 수간에 트래픽에 어떤 변화기 있는가
      - 특정 캠페인을 실시간 타이밍에 어떤 상품의 주문이 증가 했는가
      - 특정 콘텐츠에 갑자기 request가 집중되고 있는데, 어떤 경로에서 들어오고 있는 것인가
    - 액세스가 빈번하게 일어나는 데이터를 hot data라고 함 
  - cold data : 작성되고 난 뒤 이용될 때까지 일정 시간이 걸리는 데이터
    - cold data는 일단 데이터를 스토리지에 저장한 뒤에 이용될 때까지 일정기간 조회되지 않음, 장기적으로 백업을 위한 데이터  
  - warm data : hot data와 cold data의 사이에 있는 데이터 
- 펀더멘탈 매트릭스(기초 지표) : 행동의 종류 * 고객의 속성 * 상품의 속성 * 시간단위 * 기본 통계량 

# 데이터 분석 기반 구축
- 인덱스 : Elasticsearch에서 도규멘트를 저장하는 단위
- Mapping이라는 것은 어떤 인덱스에 대해서 각 필드의 형과 인덱싱의 방법을 지정하는 기능

# 데이터 분석 기반 운영
- ETL
  - Extract : Fluentd에서는 Input계의 플러그인에 해당함
  - Transform : Fluentd에서는 filter 플러그인을 이용함으로써 이 Transform의 사양을 처리하는 것이 가능함
  - Load : Fluentd에서는 out_elasticsearch 플러그인이 담당 
- 데이터 분석 시스템 가용성
  - 데이터 멱등성
    - At most once
      - 메시지는 바로 송신할 것. 만약 메시지의 송신이 성공했다면 다시는 송신하지 말 것. 다만. 저장소가 꽉 차거나 해서 메시지를 잃어버릴 수 있음
    - At least once
      - 각각의 메시지는 적어도 한 번은 송신됨. 실패한 경우에는 메시지는 중복될 수도 있음
    - Exactly once
      - 각각의 메시지를 정확하게 한 번만 전송함
    - Fluentd에서는 At most once와 At least once를 지원하고 있음. 비동기로 데이터를 전송하는 것으로 높은 throughput를 실현할 수 있기 때문
  - Exactly once의 실현은 어려움
    - 비동기이면서 분산시스템에서 Exactly once를 실현하는 것은 매우어려운 과제
  - retry(재시도)
    - Load의 처리는 몇 가지의 요인으로 실패할 가능성이 있음
      - 쓰기를 할 곳의 데이터 저장소 용량이 꽉 차버렸음
      - 쓰기를 할 곳에 네트워크가 끊어졌음
      - Fluentd가 동작하고 있는 머신의 전원이 갑자기 끊어졌음
  - 더욱 가용성을 높히기 위해서 : 큐를 사용함
    - Fluentd에서도 멱등성과 재시도에 대해서 시도하고 있지만 Fluentd 노드 자체에 장애가 발생하거나, 데이터를 전부 잃어버렸을 때는 Fluentd의 가용성을 높이는 것이 어려움
    - Amazon Kinesis
      - AWS에서 스트림 처리용의 메시징 기반. 분산 메시지큐라고 하는 시스템. 분산 메시지큐를 이용하면 메시지의 다중화가 가능하기 때문에 하나의 노드에서 데이터를 가지는 것보다 데이터의 안전성을 향상할 수 있음 
      - 분산 메시지큐에 넣은 데이터는 거기에서 데이터를 꺼내는 워커가 정기적으로 추출하고 재이용함 
- 데이터 저장소 비교
  - 관리형 데이터 웨어하우스
    - 운영에 할당할 리소스와 각 데이터 저장소의 튜닝에 시간을 절약하면서 이 데이터 저장소와 미들웨어를 활용하고 싶은 경우에는 호스팅 서비스를 이용하는 것도 검토해볼 수 있음
    - Fluentd를 이용하는 경우라면 Treasure Data를 자연스럽게 사용할 수 있음
    - Google Cloud Platform이 제공하는 완전관리형 서비스인 BigQuery는 Dremel이 베이스 가 되는 대규모 컬럼지향형 데이터구조에 대해서 쿼리가 가능함
  - 스토어, 서비스의 검토 항목
    - 데이터 저장소, 서비스, 스트림처리를 나누어 사용하는 이유
      - 코스트
        - TCO(Total Cost of Ownership - 총보유비용)와 분석에 드는 비용. TCO는 데이터의 저장에서부터 파기할 때까지 필요한 시간과 지출을 의미함
        - 데이터가 늘어나면 늘어날수록 일반적으로 데이터의 보유 비용은 늘어남 
      - 정보의 신선도
        - 분석 대상이 되는 데이터에서 준실시간으로 결과를 알고 싶은지, 어느 정도 시차를 두어도 되는지에 따라 분석방법이 달라짐
      - 확장성(scalability)
        - 각각의 스토어에 관한 확장성과 스트림처리의 아키텍처의 확장성 양쪽을 의미함
      - 스키마의 유연성
        - 어떤 타이밍에 데이터의 스키마를 결정할 것인가라는 점을 다루고 있음
        - Schema on write : 데이터의 스키마가 처음부터 결정되어 있다면, 쓰기를 할 때 데이터의 스키마가 고정되어 있어도 문제가 없음. 쓰기를 할 때 스키마가 결정되는 방식. 관계형 데이터 베이스에 데이터를 넣을 때는 테이블이 필요하기 때문에 최초에 테이블을 만들고 데이터를 넣는 것을 말함
        - Schema on read : 데이터를 읽을 때 스키마를 결정하는 방식. 데이터를 저장할 때에 스키마를 결정할 필요가 없음. 데이터의 스키마가 자주 변할 때는 이 방법을 다루기 좋음
        - Schema on write에서는 스키마를 변경하기 위해 시간이 걸리지만, 인터렉티브한 쿼리에 대해서 고속으로 답할 수 있는 이점이 있음 
      - 중간데이터의 유지
        - 행동모델을 도출하기 전에 전단계에서 필요한 데이터를 산출하거나 집계하는 것으로도 데이터는 생겨남. 이 데이터를 중간 데이터라고 함 
  - 저장소의 검토 포인트
    - 장기간 데이터를 유지해야할 피룡가 있고, 10테라바이트 정도의 데이터를 매시간 분석대상으로 할 필요가 있다면 현 시점에서는 Hadoop이나 BigQuery 또는 몇 가지의 MPP(Massively Parallel Processing)데이터베이스가 선택지가됨
    - Elasticsearch가 유효한 선택지
      - 데이터를 어느 정도 기간만 유지해도 됨
      - 스트림에서 데이터를 처리하면서, 직전1시간의 1분단위 데이터를 집계할 필요가 있음
      - 어느 정도의 확장성을 필요로 함 
    - 스트림 처리를 한 뒤에 집계 데이터만 유지할 필요가 있고, 매초의 집계가 필요한 경우라면 CEP(Complex Event Processing) 엔진과 같은 스트림처리를 하는 아키텍처가 맞음
    - 복수의 데이터베이스와 미들웨어를 조합해서 분석 기반을 구축하는 것이 코스트 효율이 좋고 효과적으로 분석할 수 있는 기반을 만드는 방법. 배치 처리와 스트림처리를 병용하는 아키텍처, 그 중에서도 분산컴퓨팅 환경에서의 제안은 람다(lambda) 아키텍처라고 함 

# 로그 수집 미들웨어
- 서비스 개선에 없어서는 안될 로그 수집
  - AARRR 모델
    - 서비스 개선으로 이어지는 요소로서의 로그를 검토할 때는 참고할 수 있는 사고방식
    - 서비스 이용에서 유저 행동의 단계를 5개로의 요소로 나누어서 단계(phase)별로 기표를 만들고 개선 정책을 세우기 쉽도록하는 프레임워크
    - 분석결과를 보고 다음 행동을 선택하는, 데이터주도(data driven) 경영을 지향하는 기업 또는 팀에게는 꼭 필요한 사고방식
    - AARRR 각각의 요소에 드는 비용과 성과 그리고 필요한 컨버전율, 컨버전 비용의 분석이라는 프레임워크는 유용함
      - Acquisition : 유저획득
        - SEO(검색엔진 최적화. 검색엔진에서 검색결과의 상위에 나올 수 있도록 하는 작업을 말함)나 성과보수형 광고(affiliate). 소셜이나 TV, 웹 등에서 광고를 목적으로 하는 정책에서 얼마나 첫방문이 늘었는지를 측정한 지표. 투입한 코스트를 방문 유저로 나누어서 비율로 측정함
      - Activation : 활성화
        - 처음으로 이용한 유저가 어느 정도 활성하였는가를 측정하는 지표
        - 활성화한 유저(액티브 유저) 수를 방문 유저 수로 나누어서 비율을 측정함
      - Retention : 지속
        - 반복 이용을 독촉하는 메일이나 스마트폰 알림통지, 리타게팅 광고 등에서 어느 정도의 활성화 유저를 획득했는지를 계측하는 지표
        - 정책별로 비활성화 유저가 재방문해서 재활성화 유저가 되기까지의 전환율 
      - Referral : 소개
        - 기존 유저가 다른 누군가에게 서비스를 소개해서 얼마나 신규 유저를 얻을 수 있는지 측정하는 지표
        - 소개 기능의 이용율과 그로부터 실제로 얻게 되는 신규 유저의 전환율로 측정함
      - Revenue : 수익화
        - 유저가 서비스 안에서 어느 정도 수익에 공헌했는지 어느 정도 과금을 했는지를 측정하는 지표
        - 금액에 상관없이 수익에 이른 비율과 ARPU(Average revenue per user : 유저당 평균매출, 한 사람의 유저가 특정기간 동안 발생시키는 평균 매출액)라고 하는 유저당 평균 금액으로 측정함 
        - AARRR 모델을 사용함으로써 서비스의 어떤 부분에 어떤 숙제가 있는지 명확해지고, 현재 상황에서 개선점과 마케팅의 전략을 세우기 쉽게 됨 
- 현대적인 로그 수집
  - 빈번하게 변화하는 데이터 구조에도 유연하게 대응할 수 있음
  - 단시간에 집계할 수 있고, PDCA(Plan-Do-Check-Act. 계획, 실행, 평가, 개선의 4단계를 반복하는 사이클을 의미함) 사이클을 빠르게 돌릴 수 있음
  - 액세스 증가에 따라 데이터 양이 급증하더라도 서버 수와 처리양을 늘려서 스케일링이 가능함
  - 로그의 추출과 집계
    - JSON Lines(JSONL) : 한 행에 하나의 JSON 오브젝트를 저장하는 로그 형식
    - LabeledTSV 형식(LTSV) : 값의 이름인 라벨과 값을 하나의 콜론으로 구분하고, 각각의 요소들은 탭으로 구분하는 데이터 포맷. LTSV 형식은 JSON 형식에 비해서 자유도가 떨어지지만, 단순한 형식이기 때문에 복잡한 정규표현식은 사용하지 않아도 됨
  - 로그 출력의 동기처리
    - 애플리케이션에서 직접 로그 파일을 남길 때는 배타처리와 동기처리가 필요함. 배타처리라는 것은 같은 파일에 동시에 쓰기를 하면 깨진 문자열이 남은 것을 방지하기 위해서 파일락(file lock)을 FLOCK 등으로 락을 점유하여 중복쓰기를 방지하는 것을 말함
    - 멀티스레드나 멀티프로세스 프로그램에서 하나의 파일에 로그를 출력하는 경우에는 쓰기 순서가 바뀌지 않도록 동기처리도 필요함
  - 로그의 로테이트(rotate) 처리
    - 일반적인 미들웨어에서 로그 로테이트를 하기 위해서 보통 HUP(Hang Up) 시그널을 사용함. 로그 파일에 쓰기를 일단 중지하고, 새로운 파일에 쓰기를 시작하도록 하는 처리
  - 로그 전송 시의 네트워크 부하
    - 유지관리면에서 좋은 방법
      - 미세하게 sleep 처리를 넣어서 네트워크 점유시간을 짧게 유지함
      - 네트워크 통신 속도에 제한하는 커맨드를 같이 사용함
      - 실행 스케줄을 장비별로 미묘하게 다르게 함 
- 로그 수집 미들웨어
  - Scribe - C++ - 2008년 - Facebook
  - Flume - Java - 2010년 - Apache Project
  - Fluentd - C + Ruby - 2011년 - TreasureData Inc.
  - Logstash - JRuby - 2011년 - elasticsearch Inc.
  - 로그 수집 미들웨어 특징
    - 해석 가능할 정도의 짧은 소요시간
      - 로그 수집 제품의 특징인 비동기통신을 활용하면 시계열 데이터 처리에 어울려 거의 실시간으로 로그를 수집해서 활용할 수 있게 됨 
      - 실시간으로 신선한 데이터를 다루는 것의 장점
        - 데이터 스트림 처리의 데이터 수집 대기 시간을 줄임으로써 신선하고, 정밀한 집계
        - 유저의 신선하고 상세한 행동 로그를 가지고 높은 정밀도의 추천과 매칭
        - 마케팅 정책의 압도적으로 빠른 효과 측정(TV 광고나 광고메일, 웹 광고 등)
        - 시스템 리소스의 실시간 트러블 모니터링으로 문제의 빠른 해결
        - 센서 데이터를 활용한 스트림 컴퓨팅(에너지 최적화, 재난방지 등)
        - 차량의 위치 정보와 사람의 행동, 도로별 정체 상황을 분석한 교통제어
        - 신용카드 등의 웹사이트에서의 부정이용의 검출
        - 소셜데이터의 수집 등을 통한 주식 알고리즘 트레이딩
        - 행동 로그를 가지고 관객의 위약 예측을 해서 위약 예방 마케팅의 실시 
    - 우수한 리소스 사용
      - 로그 수집 미들웨어의 특징인 비동기통신, 즉 데이터스트림에 의한 순차송신방식은 쇼트패킷이 아니라 롱패킷방식으로 우수한 네트워크 전송방식
      - 1건의 레코드를 하나의 파일로 버퍼링하면 잦은 파일액세스가 발생하므로, 복수의 레코드를 묶어서 chunk라는 묶음으로 버퍼링해서 비동기로 상위서버에 전송함 . 로그전송량이 급증하더라도 랜덤액세스가 잘 일어나지 않고 비교적 큰 블럭액세스가 되기 때문에 디스크I/O 처리를 점유함으로 인한 응답속도저하를 방지할 수 있음 
      - 부하가 줄어들고, 시스템의 응답성능을 어느 정도 확보할 수 있음 
    - 비동기화 처리에 의한 빠른 처리
      - RDBMS(Relational DataBase Management System)와 로컬 파일에 배타락(Exclusive Lock)을 걸고 트랜잭션 처리를 하면 확실성은 늘어나지만, 쓰기에 대한 성능이 점점 한계가 옴 
      - 로그 수집 미들웨어를 이용해서 TV나 메일링리스트, 시기적 요인 등에 의해 액세스 집중으로 초당 레코드 건수가 급증하더라도 큐잉으로 대응할 수 있음. 유저의 응답시간에 거의 영향을 주지 않고 로그 수집을 할 수 있게 됨 
    - 통신의 예외 처리 / 재시도 처리
      - 직접 구현하기 매우 까다로운 예외처리와 재시도 처리를 맡길 수 있음 
        - 통신중에 네트워크가 순단(네트워크가 간혈적으로 끊기는 현상)하는 경우
        - TCP(Transmission Control Protocol)층에서는 서버에 도달해서 소켓 버퍼에 들어와 ACK 응답이 오지만 애플리케이션층에서 문제가 발생해서 소실하는 경우
        - TCP층에서는 문제가 없었지만, 애플리케이션층에서 도착한 ACK 응답이 소실되었을 때
        - 폭주에 의해서 응답이 없고, 상대 서버에 바로 보낼 수 없는 경우 
