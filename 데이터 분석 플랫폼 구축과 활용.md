# 서평

# 데이터 분석 개요
- 데이터 분석 기반을 만들 때 생각할 요소
  - 수집 : 어떤 데이터를 모을 것인가. 어떤 데이터를 보관할 것인가
  - 변환 : 데이터를 어떻게 전처리해서 분석하기 쉬운 형태로 바꿀 것인가
  - 보존 : 데이터를 어디에 저장할 것인가
  - 분석 : 어떤 기반에 넣어서 데이터를 분석하고 활용할 것인가. 데이터를 넣는 것 뿐만 아니라 분석을 위한 좋은 환경을 만들기 위해서 어떻게 해야할까
  - 표시 : 어떻게 데이터를 시각화하고, 결과를 전달할까
  - 운영 : 데이터를 분석하기위한 기반을 장기적으로 운영하기 위해서는 어떻게 해야할까. 엔지니어가 아니라도 활용할 수 있는 환경을 만들기 위해서는 어떻게 해야할까
- 대상이 되는 데이터
  - 마스터 데이터 : 시간이 지나도 바뀌지 않는 데이터. 예를 들어 상품명과 같은 것은 시간이 지나도 바뀌지 않음.
  - 시계열 데이터 : 어떤 시간에 발생하는 사건을 기록하는 데이터. 로그 데이터와 같은 경우
  - 설정 데이터 : 상황에 따라 애플리케이션의 동작을 변경하기 위해서 보존하는 데이터 
- SoR(System of Record) : 기록(Transaction)을 위한 시스템. 입출력의 내용을 문제없이 바르게 처리하기를 기대하는 시스템. 예를 들어 신용카드에 의한 결제나 항공권의 예약시스템 등의 경우 
- SoE(System of Engagement) : 관계강화(Engagement)를 위한 시스템. 고객의 이용을 촉진하기 위한 시스템.예를 들어 상품을 추천하는 시스템이나 고객에게 검색결과를 보여주는 시스템의 경우
- 의사결정을 위한 데이터 분석
  - 데이터에 근거한 의사결정
    - 데이터와 정보의 관점에서 보면 의사결정이란 것은 불확실성 그리고 그에 관련한 불이익과 이익을 관리하는 것이다.
  - 데이터 분석의 단계와 엔지니어링
    - 분석의 목적은 수치를 해석하는 것이 아니라 의사결정을 하는 것에 있음. 그리고 그 결과로 사업에 공헌하거나 서비스를 개선할 수 있음. 시각화도 마찬가지로 결과를 내는 수단이며, 사고의 도구
  - 웹상의 시각화
    - 특징
      - 인터랙티브한 데이터의 취급이 가능하므로 드릴다운, 드릴업이 가능함
        - 인터랙티브한 데이터의 취급이란 포인팅 디바이스(대체적으로 마우스를 말함)에 의한 조작이나 조건 검색에 의해서 현재 표시된 데이터를 가공하고 양방향으로 데이터를 취급하는 것
        - 드릴다운은 특정 상태의 데이터에서 조건을 더 지정하여 범위를 좁히는 것
        - 드릴업은 조건검색을 뺌으로써 좀더 넓은 범위의 데이터를 보는 것을 의미함 
      - 임의의 데이터 또는 분석 상태에 대한 URI를 발행할 수 있음
      - URI를 공유하는 것으로 간단히 여러 사람이 같이 분석할 수 있음 

# 로그 데이터의 기초
- 서비스 개선을 위한 로그
  - hot data : 발생한 직후의 데이터. 발생하고 바로 이용됨. 또는 고빈도로 조회되는 데이터를 말함
    - hot data는 준 실시간의 분석을 가능케 함 
      - 지금 이 수간에 트래픽에 어떤 변화기 있는가
      - 특정 캠페인을 실시간 타이밍에 어떤 상품의 주문이 증가 했는가
      - 특정 콘텐츠에 갑자기 request가 집중되고 있는데, 어떤 경로에서 들어오고 있는 것인가
    - 액세스가 빈번하게 일어나는 데이터를 hot data라고 함 
  - cold data : 작성되고 난 뒤 이용될 때까지 일정 시간이 걸리는 데이터
    - cold data는 일단 데이터를 스토리지에 저장한 뒤에 이용될 때까지 일정기간 조회되지 않음, 장기적으로 백업을 위한 데이터  
  - warm data : hot data와 cold data의 사이에 있는 데이터 
- 펀더멘탈 매트릭스(기초 지표) : 행동의 종류 * 고객의 속성 * 상품의 속성 * 시간단위 * 기본 통계량 

# 데이터 분석 기반 구축
- 인덱스 : Elasticsearch에서 도규멘트를 저장하는 단위
- Mapping이라는 것은 어떤 인덱스에 대해서 각 필드의 형과 인덱싱의 방법을 지정하는 기능

# 데이터 분석 기반 운영
- ETL
  - Extract : Fluentd에서는 Input계의 플러그인에 해당함
  - Transform : Fluentd에서는 filter 플러그인을 이용함으로써 이 Transform의 사양을 처리하는 것이 가능함
  - Load : Fluentd에서는 out_elasticsearch 플러그인이 담당 
- 데이터 분석 시스템 가용성
  - 데이터 멱등성
    - At most once
      - 메시지는 바로 송신할 것. 만약 메시지의 송신이 성공했다면 다시는 송신하지 말 것. 다만. 저장소가 꽉 차거나 해서 메시지를 잃어버릴 수 있음
    - At least once
      - 각각의 메시지는 적어도 한 번은 송신됨. 실패한 경우에는 메시지는 중복될 수도 있음
    - Exactly once
      - 각각의 메시지를 정확하게 한 번만 전송함
    - Fluentd에서는 At most once와 At least once를 지원하고 있음. 비동기로 데이터를 전송하는 것으로 높은 throughput를 실현할 수 있기 때문
  - Exactly once의 실현은 어려움
    - 비동기이면서 분산시스템에서 Exactly once를 실현하는 것은 매우어려운 과제
  - retry(재시도)
    - Load의 처리는 몇 가지의 요인으로 실패할 가능성이 있음
      - 쓰기를 할 곳의 데이터 저장소 용량이 꽉 차버렸음
      - 쓰기를 할 곳에 네트워크가 끊어졌음
      - Fluentd가 동작하고 있는 머신의 전원이 갑자기 끊어졌음
  - 더욱 가용성을 높히기 위해서 : 큐를 사용함
    - Fluentd에서도 멱등성과 재시도에 대해서 시도하고 있지만 Fluentd 노드 자체에 장애가 발생하거나, 데이터를 전부 잃어버렸을 때는 Fluentd의 가용성을 높이는 것이 어려움
    - Amazon Kinesis
      - AWS에서 스트림 처리용의 메시징 기반. 분산 메시지큐라고 하는 시스템. 분산 메시지큐를 이용하면 메시지의 다중화가 가능하기 때문에 하나의 노드에서 데이터를 가지는 것보다 데이터의 안전성을 향상할 수 있음 
      - 분산 메시지큐에 넣은 데이터는 거기에서 데이터를 꺼내는 워커가 정기적으로 추출하고 재이용함 
- 데이터 저장소 비교
  - 관리형 데이터 웨어하우스
    - 운영에 할당할 리소스와 각 데이터 저장소의 튜닝에 시간을 절약하면서 이 데이터 저장소와 미들웨어를 활용하고 싶은 경우에는 호스팅 서비스를 이용하는 것도 검토해볼 수 있음
    - Fluentd를 이용하는 경우라면 Treasure Data를 자연스럽게 사용할 수 있음
    - Google Cloud Platform이 제공하는 완전관리형 서비스인 BigQuery는 Dremel이 베이스 가 되는 대규모 컬럼지향형 데이터구조에 대해서 쿼리가 가능함
  - 스토어, 서비스의 검토 항목
    - 데이터 저장소, 서비스, 스트림처리를 나누어 사용하는 이유
      - 코스트
        - TCO(Total Cost of Ownership - 총보유비용)와 분석에 드는 비용. TCO는 데이터의 저장에서부터 파기할 때까지 필요한 시간과 지출을 의미함
        - 데이터가 늘어나면 늘어날수록 일반적으로 데이터의 보유 비용은 늘어남 
      - 정보의 신선도
        - 분석 대상이 되는 데이터에서 준실시간으로 결과를 알고 싶은지, 어느 정도 시차를 두어도 되는지에 따라 분석방법이 달라짐
      - 확장성(scalability)
        - 각각의 스토어에 관한 확장성과 스트림처리의 아키텍처의 확장성 양쪽을 의미함
      - 스키마의 유연성
        - 어떤 타이밍에 데이터의 스키마를 결정할 것인가라는 점을 다루고 있음
        - Schema on write : 데이터의 스키마가 처음부터 결정되어 있다면, 쓰기를 할 때 데이터의 스키마가 고정되어 있어도 문제가 없음. 쓰기를 할 때 스키마가 결정되는 방식. 관계형 데이터 베이스에 데이터를 넣을 때는 테이블이 필요하기 때문에 최초에 테이블을 만들고 데이터를 넣는 것을 말함
        - Schema on read : 데이터를 읽을 때 스키마를 결정하는 방식. 데이터를 저장할 때에 스키마를 결정할 필요가 없음. 데이터의 스키마가 자주 변할 때는 이 방법을 다루기 좋음
        - Schema on write에서는 스키마를 변경하기 위해 시간이 걸리지만, 인터렉티브한 쿼리에 대해서 고속으로 답할 수 있는 이점이 있음 
      - 중간데이터의 유지
        - 행동모델을 도출하기 전에 전단계에서 필요한 데이터를 산출하거나 집계하는 것으로도 데이터는 생겨남. 이 데이터를 중간 데이터라고 함 
  - 저장소의 검토 포인트
    - 장기간 데이터를 유지해야할 피룡가 있고, 10테라바이트 정도의 데이터를 매시간 분석대상으로 할 필요가 있다면 현 시점에서는 Hadoop이나 BigQuery 또는 몇 가지의 MPP(Massively Parallel Processing)데이터베이스가 선택지가됨
    - Elasticsearch가 유효한 선택지
      - 데이터를 어느 정도 기간만 유지해도 됨
      - 스트림에서 데이터를 처리하면서, 직전1시간의 1분단위 데이터를 집계할 필요가 있음
      - 어느 정도의 확장성을 필요로 함 
    - 스트림 처리를 한 뒤에 집계 데이터만 유지할 필요가 있고, 매초의 집계가 필요한 경우라면 CEP(Complex Event Processing) 엔진과 같은 스트림처리를 하는 아키텍처가 맞음
    - 복수의 데이터베이스와 미들웨어를 조합해서 분석 기반을 구축하는 것이 코스트 효율이 좋고 효과적으로 분석할 수 있는 기반을 만드는 방법. 배치 처리와 스트림처리를 병용하는 아키텍처, 그 중에서도 분산컴퓨팅 환경에서의 제안은 람다(lambda) 아키텍처라고 함 
