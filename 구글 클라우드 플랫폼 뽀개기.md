# 서평
- 이 책은 GCP에 어떤 서비스들이 있고 서비들을 어떻게 사용해야 하는지 하나하나 실습을 통해 알려주고 있습니다. 또한 서비스들의 역할이 무엇인지, 어떻게 사용하는지에 대해서 자세하게 설명해주고 있습니다.

# Google Cloud Platform
- 클라우드 서비스 
  - 서버나 스토리지 같은 자원이 필요할 때 이를 구글이나 아마존, 마이크로소프트와 같은 벤더로부터 빌려서 사용하고, 사용한 만큼의 비용을 지불하는 서비스 
  - 클라우드가 아닌 기존의 방식
    - 서버를 운영한다면, 서버를 직접 구입 및 임대하여 데이터 센터(IDC)에 입주시키는 방식을 사용해야함. 서비스를 위한 서버가 IDC 내부에 설치되기 때문에 초기에 서버 구입 및 임대에 큰 비용이 발생하고, 설치 및 세팅을 위한 시간도 발생함 
    - 장애가 발생하여 서버 접속이 되지 않으면 직접 IDC를 방문해서 처리해함  
    - 서비스 규모가 커져서 업그레이드를 하기 위해서도 추가 서버나 스토리지를 구매하여 직접 IDC에 방문해 물리적으로 업그레이드를 해야 했음
    - 구매한 서버를 더 이상 필요로 하지 않게 되었을 경우 부채로 남게됨 
  - 클라우드 서비스 방식
    - 서버가 필요할 경우 클라우드 콘솔에 접속해서 바로 VM 인스턴스를 생성해서 사용하면 됨 
    - 서비스가 커져서 업그레이드가 필요한 경우에도 콘솔 내에서 바로 업그레이드를 할 수 있으며, 서비스를 종료하지 않고도 가능함 
    - 더 이상 해당 서버가 필요 없어질 경우에는 바로 인스턴스를 종료하거나 삭제하면 됨 
  - IaaS : 컴퓨팅, 네트워킹, 스토리지 및 기타 인프라 자원을 빌려서 사용할 수 있기 때문에 개발자는 자기 입맛대로 서비스를 구축하여 사용할 수 있음(Compute Engine, Cloud Virtual Network, Cloud DNS 등) 
  - PaaS : 서비스 개발 시 필요로 하는 플랫폼을 제공하기 때문에 개발자는 이러한 플랫폼을 이용하여 미들웨어나 프레임워크를 설치하지 않고도 보다 쉽게 서비스를 구축할 수 있음(App Engine, CloudSQL 등) 
  - SaaS : 클라우드 환경에서 운영되는 소프트웨어로 모든 소프트웨어가 클라우드 내에서 이뤄지기 때문에 별도의 소프트웨어를 설치하거나 개발할 필요가 없음 
- GCP 내 대표적인 서비스 
  - |서비스 명| 설명|
    |:--:|:--:|
    |Compute Engine|확장 가능한 고성능 VM 인스턴스|
    |App Engine|웹 애플리케이션 배포 및 웹 호스팅
    |Cloud Storage|글로벌 에지 캐싱을 제공하는 객체 Repository
    |Cloud SQL|MySQL과 PostgreSQL
    |BigQuery|머신 러닝이 내장되어 있으며 확장성이 우수한 완전 관리형 데이터 웨어 하우스 
    |Cloud Dataproc|관리자 하둡과 스파크 서비스 
    |Cloud PubSub|메시지 큐잉 서비스
    |Kubernetes Engine|쿠버네티스를 사용한 컨테이너 기반 서비스 구축 
    |Cloud Dataflow|실시간 배치 처리 및 스트림 데이터 처리
    |Cloud Functions|이벤트 기반 서버리스 컴퓨팅 플랫폼
    |Stackdriver|통합 모니터링 서비스
    |Cloud Source Repositories|관리형 버전 관리 서비스 
    |Cloud Dataprep|분석을 위해 데이터를 탐색, 정리, 준비해주는 클라우드 데이터 서비스 
    |Cloud Composer|아파치 에어플로우를 기반으로 하는 관린형 워크플로 서비스 
    |Cloud AutoML|고품질의 커스텀 머신 러닝 모델을 편하게 학습시켜주는 서비스 
    |Cloud ML Engine|머신 러닝 서비스
    |Cloud Natural Language|자연어 분석 서비스 
    |Cloud Speech-to-Text|음성을 텍스트로 변환해주는 서비스
    |Cloud Text-to-Speech|텍스트를 음성으로 변환해주는 서비스 
    |Cloud Translation|구글의 대표적인 서비스인 구글 번역기와 동일한 서비스 
    |Cloud Vision|이미지 분석 서비스 
    |Cloud IAM|ID 및 액세스 관리 서비스 
    |Persistent Disk|VM 인스턴스용 블록 Repository
    |Knative|서버리스로 빌드, 배포, 관리할 수 있는 Kubernetes 서비스 
    |Cloud Bigtable|NoSQL 데이터베이스
    |Cloud Memorystore|Redis 기반의 인-메모리 DB 서비스 
    |Google Data Studio|데이터 시각화 서비스 

# 기본 개념 
- GCP 리소스(데이터 센터)
  - GCP는 전 세계 곳곳의 구글 데이터 센터에 위치한 컴퓨터와 하드 디스크 같은 물리적 가상 머신과 같은 가상 리소스로 구성됨 
  - 큰 대륙 규모를 리전이라 하는데 리전 내부에도 물리적으로 지역이 나뉘며 이를 존이라 함 
  - 각 영역은 Region - Detail Region - Zone으로 구성되며, 예를 들어 동아시에 있는 aZone은 asia-east1-a로 표기됨. 리소스 분포를 통해 장애 대비, 지연 감소 등의 이점을 얻을 수 있음 
- Global, Region, Zone 리소스 
  - 여러 리존과 존에 접근이 가능한 리소스도 있지만, 같은 지역에 위치한 리소스에서만 접근을 할 수도 있음 
- GCP 클라우드 콘솔
  - 클라우드 쉘(Cloud Shell), GCP용 브라우저 기반 대화형 쉘 환경을 제공함 
  - 클라우드 쉘은 바쉬(Bash), 빔(Vim), Python, 자바, 고, 도커, 클라우드 SDK(gcloud)와 같은 자주 사용하는 도구 및 언어들이 미리 설치되어 있기 때문에 별도의 설치 없이 CLI 명령어를 통해 GCP 내의 리소스에 명령을 내릴 수 있음 
  - 클라우드 쉘이 제공하는 기능
    - 웹 브라우저에서 인스턴스에 명령줄로 액세스
    - 기본 제공 코드 편집기(Vim, 이맥스(Emacs))
    - 5GB의 영구 디스크 Repository
    - 사전 설치된 구글 클라우드SDK 및 기타 도구 
    - Java, Go, Python, Node.js, PHP, Ruby, .NET 같은 언어 지원 
    - 웹 미리보기 기능 
    - GCP 콘솔 프로젝트 및 리소스 액세스를 위한 자체 승인 기능 
- 클라우드 SDK(gcloud)
  - GCP는 웹 기반의 GUI 환경인 GCP 클라우드 콘솔 이외에도 터미널에서 명령을 통해 GCP에 액세스 할 수 있는 gcloud라는 CLI 도구를 지원함 
  - gcloud를 이용하면 명령어로 GCP 내의 모든 리소스를 사용할 수 있음 
- 클라이언트 라이브러리
  - 구글 클라우드 클라이언트(Google Cloud Client) 라이브러리는 구글 클라우드 API를 호출하기 위한 클라이언트 라이브러리 

# Cloud IAM
- Cloud IAM(Identity and Access Management)은 구글 클라우드 서비스의 ID 및 액세스 관리를 할 수 있도록 제공해주는 서비스로 누가(ID) 어떤 리소스(GCP Service)에 대한 어떤 액세스 권한(Role)을 갖는지 제어할 수 있게 함 
- 관리자는 누가, 언제, 어떤 리소스에 접근하여 이용하는지에 대한 제어를 할 수 있어서 클라우드 리소스를 중앙에서 쉽게 관리할 수 있음. 복잡한 조직 구조, 많은 작업 그룹과 프로젝트를 지닌 기업에서도 조직 전체에 적용되는 통합 보기를 제공하고, 규정 준수 프로세스를 간편하게 돕는 감사 기능이 내장되어 있음 
- Cloud IAM에서 정책을 만들면 IAM에서 사용하는 ID별로 역할을 줄 수 있는데, 이는 GCP 내의 리소스 별로 개별 설정할 수 있음 
- IAM 정책(IAM Policy) 
  - Cloud IAM 정책은 사용자에게 부여되는 액세스 권한의 유형을 가지고 있는 리스트 
  - 정책은 역할별 해당 역할에 대한 권한을 가진 멤버 리스트로 구성되며, 사용자가 리소스에 액세스할 때 정책을 통해 액세스 제어를 함 
  - IAM Policy 객체는 Json 형태의 목록으로 구성됨
    - bindings
    - role
    - members
    - 구글 계정(user)
    - 서비스 어카운트(serviceAccount)
    - 구글 그룹(group:)
    - G Suite or Cloud ID 도메인(domain:) 
- 정책 계층 구조
  - 조직(Organization) 노드는 계층 구조의 루트 노드이고, 프로젝트 조직의 하위 항목이며, 기타 리소스는 프로젝트의 하위 항목임. 각 리소스는 단 하나의 상위 항목만을 가짐 
  - Cloud IAM 정책은 조직, 폴더, 프로젝트, 리소스 등 리소스 계층 구조의 모든 수준에 설정할 수 있음 
- Cloud IAM의 역할
  - |역할 이름|역할 칭호|권한|
    |:---:|:---:|:---:|
    |roles/owner|소유자|프로젝트 및 프로젝트 내의 모든 리소스에 대한 역할 및 관리, 프로젝트에 대한 결제 설정|
    |roles/editor|편집자|뷰어 권한에 리소스 변경과 같이 상태 변경 작업까지 포함이 됨|
    |roles/viewer|뷰어|읽기 전용 작업에 대한 권한이 부여됨. 기존 리소스 또는 데이터의 조회가 여기에 해당됨|
  - 커스텀 역할 : 사용자가 직접 정의하며 하나 이상의 역할을 결합할 수 있음 
- 서비스 계정
  - 서비스 계정은 사용자가 아닌 애플리케이션 또는 가상 머신에 속한 계정으로 애플리케이션은 사용자 계정이 아닌 서비스 계정을 이용하여 GCP API에 접근함 
  - 서비스 계정 고유의 이메일 주소로 식별이됨 
    - ID로 사용 : 서비스 계정에 역할을 부여하여 프로젝트와 같은 리소스에 액세스되게 할 수 있음 
    - 리소스로 사용: 사용자에게 해당 서비스 계정에 액세스할 권한을 부여할 수 있음 
  - 서비스 계정 키 
    - 각 서비스의 계정은 서비스 계정 키 쌍과 연결이 되며 서비스 계정 키에는 2가지 유형이 있음 
      - GCP 관리: GCP에서 서비스 간 인증에 사용됨. 각 키의 순환 주기는 약 일주일 정도 
      - 사용자 관리: 새로운 키를 만들면 비공개 키(구글에서 보관하지 않기 때문에 다시 다운로드 불가)를 다운로드하게 됨. 서비스 계정 당 최대 10개의 서비스 계정 키를 만들 수 있으며, 10년이 지나면 자동으로 만료됨 

# Compute Engine
- Compute Engine은 GCP에서 제공하는 가상 머신 서비스로 AWS의 EC2에 해당하는 서비스로 다양한 인스턴스 구성 및 이미지를 제공합니다 
- 지원하는 OS이미지로는 데비안(Debian), CentOS, 우분투(Ubuntu), 수세(SUSE), 레드햇(Red Hat), 윈도우 서버(Windows Server) 등이 있음
- Compute Engine은 소프트웨어 또는 업데이트와 같은 호스트 시스템 이벤트가 발생하더라도, VM 인스턴스가 계속 실행될 수 있게 해주는 라이브 이전 기능을 제공함. 사용자는 VM을 재부팅할 필요 없이 동일 영역에서 실행 중인 인스턴스를 또 다른 호스트로 라이브 이전할 수 있음 
- 머신 유형
  - 메모리,vCPU,디스크 등을 포함하여 인스턴스에 제공할 수 있는 가상화된 하드웨어 리소스 모음을 지정함
  - 커스텀 머신 유형: 인스턴스 생성 시 사용할 vCPU 수와 메모리 용량 등 머신 유형을 설정할 수 있음 
  - 이미지 
    - Compute Engine에서는 구글에서 제공하는 운영체제 이미지를 사용하여 인스턴스의 부팅 디스크를 만들 수 있고, 공개 이미지와 커스텀 이미지가 있음.
    - 공개 이미지는 구글, 오픈소스 커뮤니티, 제 3자 공급업체에서 제공하고 관리함 
    - 커스텀 이미지는 사용자의 프로젝트에서만 사용할 수 있는 이미지로 부팅 디스크 및 다른 이미지에서 커스텀 이미지를 생성한 다음에 해당 이미지를 이용하여 인스턴스를 만들 수 있음 
- 실시간 이전(Live Migration)
  - Compute Engine은 소프트웨어 또는 하드웨어 업데이트와 같은 호스트 시스템 이벤트가 발생하더라도 인스턴스를 종료 및 재부팅할 필요 없이 계속 실행시키는 실시간 이전이라는 기능을 제공함 
  - Compute Engine은 사용자가 VM을 재부팅할 필요 없이 동일 영역에서 실행 중인 인스턴스를 또 다른 호스트로 라이브 이전함 
- 선점형 VM 인스턴스(Preemptible VM Instances) 
  - GCP 내에서 아무도 사용하고 있지 않은 리소스를 사용함으로써 일반 인스턴스보다 훨씬 더 저렴한 가격으로 만들고, 실행할 수 있는 인스턴스
  - 제약 사항 
    - Compute Engine은 시스템 이벤트가 발생하면 언제든 선점형 인스턴스를 종료할 수 있음 
    - Compute Engine은 언제나 선점형 인스턴스를 24시간 동안 실행한 후 종료함 
    - 선점형 인스턴스는 한정된 Compute Engine은 리소스이므로 사용하지 못할 수도 있음 
    - 선점형 인스턴스는 유지관리 이벤트 발생 시 Live Migration을 지원하지 않음 
    - 이러한 제한사항 때문에 Google Compute Engine SLA에서 제외됨 
- 인스턴스 템플릿
  - VM 인스턴스 및 인스턴스 그룹을 만드는 데 사용할 수 있는 리소스 
  - 인스턴스 템플릿은 머신 유형, 부팅 디스크 이미지 또는 컨테이너 이미지, 영역, 라벨, 그 외의 속성 등을 이용하여 템플릿을 만들고, 이를 통해서 관리형 인스턴스 그룹이나 개별 VM 인스턴스를 만들 수 있음 
  - 인스턴스 템플릿의 가장 큰 목적은 동일한 구성의 인스턴스를 여러 개 만들기 위해서임 
- 인스턴스 그룹 
  - 관리형 인스턴스 그룹 
    - 관리형 인스턴스 그룹은 인스턴스 템플릿을 사용하여 동일한 인스턴스 그룹을 만들 수 있음 
    - 관리형 인스턴스 그룹은 다양한 장점을 가지는데 그 중 하나가 별다른 설정 없이도 자동으로 오토 스케일링을 지원한다는 것 
    - 애플리케이션 기반의 상태 확인을 이용하는 자동 복구 정책을 설정 할 수 있어서 애플리케이션이 관리형 인스턴스 그룹에 제대로 응답을 하는지 주기적으로 확인하고, 만약 특정 인스턴스에서 문제가 발생하여 정상적으로 응답하지 않으면 인스턴스가 자동으로 다시 생성됨 
    - 관리형 인스턴스 그룹을 사용하면 부하 분산 서비스인 로드 밸런서(Load Balancer)를 붙여서 그룹의 모든 인스턴스에 트래픽을 분산할 수 있음 
    - 새로운 버전의 소프트웨어를 관리형 인스턴스 그룹의 인스턴스에 쉽게 배포할 수 있음. 이를 이용하면 롤링 업데이트, 카나리아 업데이트와 같은 유연한 롤아웃 시나리오를 지원하고, 배포 속도와 범위는 물론 서비스 중단 수준을 제어할 수 있음 
    - 단일 영역에 인스턴스를 배포하는 영역 관리형 인스턴스 그룹 
    - 동일 리전 내 영ㅇ역에 배포하는 리전 관리형 인스턴스 그룹 
      - 애플리케이션의 부하를 여러 영역에 분산시켜 보다 높은 가용성을 제공함. 자연 재해 등의 문제로 특정 영역에서 문제가 발생하더라도 높은 가용성을 유지할 수 있음 
    - 컨테이너를 이용하여 애플리케이션의 배포를 간소화할 수 있음 
  - 비관리형 인스턴스 그룹 
    - 임의로 다른 구성을 가진 인스턴스를 추가하거나 제거할 수 있음. 오토 스케일링, 자동 복구, 롤링 업데이트 지원, 인스턴스 템플릿 사용은 제공하지 않음. 
    - 가용성이 높고 확장 가능한 작업 부하를 배포하는 데는 적합하지 않음 
- 전역(Global), 영역(Region), 지역(Zone)
  - 모든 Compute Engine 리소스는 전역, 지역, 영역 리소스임 
  - 전역 리소스는 모든 지역 또는 영역의 리소스에서 액세스할 수 있어서 서로 다른 영역의 VM 인스턴스가 동일한 전역 이미지를 사용할 수 있음. 지역 리소스는 동일한 지역내의 리소스에서만 액세스할 수 있음 
  - 전역 리소스
    - 전역 리소스는 동일한 프로젝트 내의 모든 영역에 있는 모든 리소스가 액세스 할 수 있음 
    - 주소, 이미지, 스냅샷, 인스턴스 템플릿, VPC 네트워크, 방화벽, 경로, 전역 작업 
  - 지역 리소스 
    - 동일한 지역 내의 모든 리소스가 액세스할 수 있음 
    - 주소, 서브넷, 지역 관리형 인스턴스 그룹, 지역 영구 디스크, 지역 작업 
  - 영역 리소스 
    - 영역에서 호스팅 되는 리소스를 뜻함 
    - 인스턴스 ,영구 디스크, 머신 유형, 영역 관리형 인스턴스 그룹, 영역별 작업 
- 인스턴스 스냅샷
  - 스냅샷은 만들어진 인스턴스의 특정 시접에 백업을 할 수 있음. 스냅샷을 이용하여 백업 시점으로 복수할 수도 있음. 스냅샷을 이용하여 커스텀 이미지를 생성할 수도 있음 
- Marketplace에서 인스턴스 만들기
  - GCP 마켓플레이스에는 바로 사용할 수 있는 솔루션이 설정되어 있는 이미지들을 바로 이용할 수 있음 
  - 이미 설정까지 끝난 이미지를 마켓플레이스에서 바로 생성하여 사용할 수 있음 
- 인스턴스 그룹 만들기(오토 스케일링 적용하기) 
  - 단일 영역 : 인스턴스들이 한 영역(Zone)에 생성이 되기 때문에 지연 시간이 조금이라도 늘어나는 것을 방지할 수 있음 
  - 다중 영역 : 인스턴스가 다양한 영역에 생성이 되기 때문에 특정 영역 전체에서 오작동이 발생할 경우 작업이 실패하는 것을 방지할 수 있음 
  - 관리형 인스턴스 그룹: 동일한 구성의 인스턴스 그룹(오토 스케일링 지원) 
  - 비관리형 인스턴스 그룹: 서로 다른 구성의 인스턴스 그룹(오토 스케일링 미지원)

# VPC
- VPC(Virtual Private Cloud)는 GCP 리소스를 위한 관리형 네트워킹 기능을 제공함. VPC는 크게 네트워크와 인터페이스 및 IP 주소, VPC 공유 및 피어링, 하이브리드 클라우드, 부하 분산 등의 기능을 제공함 
- VPC 네트워크는 Google Cloud Platform 내에서 가상화된다는 점을 제외하면 실제 네트워크와 거의 동일한 방식으로 작동함 
- VPC 네트워크는 데이터 센터의 지역 가상 서브넷으로 구성되며, 글로벌 광역 네트워크로 연결된 글로벌 리소스임 
- VPC는 가상화된 여러 네트워크 인터페이스르 지원하며, IP 주소 및 별칭 IP 범위를 지정할 수 있음. VPN이나 인터커넥트(interconnect)를 사용하여 온프레미스 및 다른 베더의 클라우드 서비스와 연결할 수 있는 하이브리드 클라우드 기능도 제공함
- 부하 분산은 GCP 내의 트래픽 및 작업 부하를 여러 VM 인스턴스에 분산 시키기 위해 사용하는데, VPC는 HTTP(s), 부하 분산, SSL 프록시, TCP 프록시 등의 기능을 제공함 
- VPC 네트워크
  - 특징
    - VPC 네트워크는 연결된 라우터와 방화벽 규칙을 포함한 전역 리소스 
    - 서브넷은 지역 리소스로, 각 서브넷은 CIDR을 이용하여 IP 주소 범위를 정의함 
    - 인스턴스에서 송수신되는 트래픽은 방화벽 규칙으로 제어할 수 있음 
    - 내부 IP 주소가 있는 인스턴스 Google API 및 서비스와 통신할 수 있음 
    - 네트워크 관리는 IAM을 사용하여 관리할 수 있음 
    - 공유 VPC를 사용하려면, VPC 네트워크를 공용 호스트 프로젝트에 유지할 수 있음 
    - VPC 네트워크 피어링으로 VPC 네트워크를 다른 프로젝트 또는 조직의 다른 VPC 네트워크에 연결할 수 있음 
    - Cloud VPN이나 Cloud interconnec를 사용하면 온프레미스 환경이나 타 벤더의 클라우드 서비스를 연결할 수 있는 하이브리드 환경을 지원하게 됨 
    - VPC 네트워크는 IPv4 유니 캐스트 트래픽만 지원함. 네트워크 내의 브로드 캐스트, 멀티캐스트 또는 IPv6 트래픽을 지원하지 않음 
    - 각 프로젝트는 사전 정의된 default 네트워크로 시작을 하며, 커스텀을 통한 네트워크를 선택할 수도 있음 
  - 네트워크와 서브넷 
    - 자동 모드 : 네트워크가 생성될 때 각 지역마다 서브넷이 하나씩 자동 생성됨 
    - 커스텀 모드 : 네트워크가 생성될 때 자동으로 서브넷이 만들어지지 않기 때문에 개발자가 직접 서브넷과 IP 범위를 설정함 
    - 자동모드 네트워크를 사용하면 각 리전에 서브넷이 자동으로 생성되기 때문에 유용하며, 서브넷의 사전 정의된 IP 범위가 다르기 때문에 겹치지 않음 
- 방화벽 규칙 
  - 각 VPC 네트워크는 사용자가 구성할 수 있는 가상 방화벽을 구현함. 방화벽 규칙을 사용하여 패킷을 허용하거나 거부할 수 있음 
  - 방화벽 규칙은 VPC 네트워크 수준에 정의되며, 규칙 자체는 네트워크 간에 공유될 수 없음 
  - 방화벽 규칙은 IPv4 트래픽만 지원하며, 대상을 지정할 때는 CIDR 표기법을 이용함 
  - 방화벽 규칙에 의해 수행되는 작업은 허용(allow) 또는 거부(deny) 중 하나 
  - 방화벽 규칙은 수신(ingress) 또는 송신(egress) 트래픽 모두에 적용되도록 정의함 
- 경로 
  - VM 인스턴스 및 VPC 네트워크에 인스턴스에서 내부 또는 외부로 트래픽을 보내는 방법을 알려줌 
  - 기본 경로 : VPC 네트워크를 만들면 GCP 시스템에서 자동으로 기본 경로를 만듬. 기본 경로는 VPC 네트워크에서 나가는 경로를 정의함 
  - 서브넷 경로 : VPC 네트워크 서브넷으로 가는 경로 
  - 커스텀 정적 경로 : 사용자가 수동으로 만든 정적 경로이거나 하나 이상의 클라우드 라우터에서 자동으로 유지되는 동적 경로 
- 전달 규칙(Forwarding Rule) : 대상 풀 및 대상 인스턴스와 작동하여 부하 분산 및 프로토콜 전달 기능을 지원함 
- 별칭 IP 범위 : VM의 네트워크 인터페이스 내부 IP 주소 범위를 별칭으로 할당할 수 있음 
- 다중 네트워크 인터페이스 : 여러 네트워크 인터페이스를 통해 네트워크 VM이 다른 VPC 네트워크 간 또는 인터넷 간 트래픽을 보호하는 게이트웨이 역할을 함 
- 공유 VPC 
  - 조직에서 여러 프로젝트의 리소스를 공통 VPC 네트워크에 연결할 수 있음 
  - 호스트 프로젝트의 VPC 네트워크를 공유 VPC 네트워크라고 하며, 공유 VPC 네트워크에 연결된 다른 프로젝트들은 서비스 프로젝트라고 함 
- VPC 네트워크 피어링
  - 모든통신이 개인 RFC 1918 IP 주소를 사용하여 이루어짐 
  - 피어링 기술을 이용하면 공개 IP를 사용한 네트워킹에 비해 지연을 줄일 수 있음. 서비스 소유자는 서비스를 외부에 노출하여 그 와 관련된 위험을 감수할 필요가 없고, 내부 IP를 사용하여 통신하기 때문에 외부 IP를 사용하여 통신했을 때 발생하는 네트워크 추가 비용도 아낄 수 있음 
- Cloud VPN 
  - VPN은 가상의 사설 네트워크를 통해서 물리적 온프레미스 네트워크 또는 다른 벤더의 클라우드 서비스와 연결을 할 수 있음. 클라우드 VPN은 IPSec을 이용하여 암호화된 연결을 하기 때문에 온프레미스 네트워크와 VPC 네트워크 사이에 안전하게 연결할 수 있음. 2개의 네트워크 사이에는 터널을 통해서 암호화된 형태로 트래픽을 주고받을 수 있음 
- Cloud Interconnect
  - 인터커넥트는 고속의 물리적 연결을 사용하여 VPC 네트워크를 온프레미스 네트워크에 연결할 수 있음 
  - 고속의 물리적 연결을 사용하여 VPC 네트워크를 온프레미스 네트워크에 연결할 수 있음 
- Cloud Load Balancing: 작업이나 트래픽이 발생하는 경우 여러 리소스로 작업을 분산시켜서 가용성 및 확장성 있는 서비스를 만들 수 있도록 도와줌 

# Cloud Load Balancing & Auto Scaling
- Cloud Load Balancing 
  - 로드 밸런싱은 한 번에 많은 요청으로 트래픽이 증가했을 때 이를 처리할 수 있을 만큼 여러 대의 VM에 트래픽을 분산해서 보내, 부하 발생 시 처리를 하는 기술 
  - Cloud Load Balancing은 사용자 트래픽 전체에 적용되어 완전하게 배포되는 소프트웨어 관리형 서비스로 모든 트래픽(HTTP(S), TCP, UDP)에 적용할 수 있음 
  - 갑자기 높은 부하가 들어왔을 때 그것을 받아내지 못하는 경우가 있는데 이를 방지하기 위해 미리 그만한 부하를 일정 시간 주어서 로드 밸런싱 크기를 키우는 작업을 해야함. 이러한 작업을 가동 준비 과정(pre-warm up)이라 함. GCP의 Cloud Load Balancing은 갇동 준비 과정 없이 Compute Engine에서 애플리케이션을 최대 범위까지 확장할 수 있음 
  - 한 번에 많은 양의 트래픽을 받게 되었을 때 트래픽 처리가 가능한 다른 지역으로 트래픽을 우회시켜 예상치 못한 즉각적인 대규모 트래픽 급증도 처리할 수 있음. 자동 확장 기능은 사용자 및 트래픽 증가에 따라 자동으로 확장이 되며 장애 발생 시 가까운 지역을 우선적으로 라우팅하고, 그곳도 장애가 발생한다면 자동으로 다른 지역으로 차례로 라우팅을 해주는 지능형 자동 확장형 
  - Global vs Regional 차이 
    - 글로벌 로드 밸런싱은 글로벌하게 서비스가 이뤄져야 할 때 하나의 애니캐스트 IP를 통해서 전역으로 부하 분산이 이뤄지며, IPv6를 지원함. 
    - 리저널 로드 밸런싱은 하나의 지역에 집중적으로 트래픽이 발생할 때 이용할 수 있으며, 오직 IPv4만 지원함 
  - Exteranl vs Interanl 차이 
    - 외부 로드 밸런싱은 VPC 네트워크가 아닌 다른 네트워크를 통해서 트래픽이 발생하는 경우 이용을 하고, 다른 네트워크 사용 없이 VPC 네트워크 내에서만 트래픽이 발생한다면 내부 로드 밸런싱(Internal)을 사용할 수 있음 
- Auto Scaling 
  - 오토 스케일링은 리소스 사용량에 따라서 VM이 자동으로 증가하고 감소하는 기능 
  - 급격하게 트래픽이 증가하면 동종 인스턴스들이 자동으로 생성되어서 이를 분산하게 되고, 만약 트래픽이 감소하여 더 이상 필요하지 않으면 생성된 인스턴스들을 자동으로 감소시킴
  - CPU 사용률 : 인스턴스 그룹의 평균 CPU 사용률을 관찰하여 원하는 사용률을 유지하도록 인스턴스 그룹에 VM 인스턴스를 추가하거나 삭제하라고 함 
  - 로드밸런싱 사용량 : Cloud Load Balancing에서의 사용량을 관찰하여 조절하며, 이 부분은 로드 밸런싱의 백엔드 서비스에서 정의함 
  - Stackdriver Monitoring 측정 항목 : Stackdriver는 GCP 내의 리소스들을 자동으로 또는 맞춤으로 모니터링하고 로깅해줄 수 있는 서비스로, Stackdriver에서 제공하는 측정 항목을 기준으로 오토 스케일링 할 수 있음 

# GCS(Google Cloud Storage)
- GCS는 Google Cloud Platform의 대표적인 객체 Repository. 이를 이용하면 데이터 양에 관계없이 언제, 어디서나 데이터를 저장하고 이를 가져올 수 있음 
- 컨텐츠를 제공하거나, 백업 데이터를 저장하거나, 사용자에게 대량의 데이터 객체를 배포하는 등의 용도로도 사용할 수 있음 
- GCS의 주요 개념 
  - 프로젝트 : GCP의 프로젝트와 동일한 개념으로 GCS의 모든 데이터는 프로젝트에 속하게 됨 
  - 버킷 
    - 버킷은 폴더나, 디렉터리의 개념과 다르게, 버킷 안에 또 다른 버킷을 만들 수 없음. 버킷은 전역에서 고유해야 하기 때문에 GCP 전체에서 고유한 이름을 사용하여야 함 
    - 버킷 생성 시 전역에 고유한 이름, 버킷과 컨텐츠가 저장되는 지리적 위치, Repository 등급을 지정함 
    - 버킷은 라벨을 달 수 있으며, 키-값 형태로 GCP의 다른 리소스와 그룹화 할 수 있으며 적용할 수 있는 라벨의 최대 개수는 버킷 당 64개 
  - Repository 등급 
    - Multi-Regional Storage, Regional Storage, Nearline Storage, Coldline. Storage 
  - 객체 
    - 버킷에 저장되는 파일들, 객체에는 크게 객체 데이터와 객체 메타데이터 2가지 구성 요소를 가지며 객체 데이터는 일반적으로 GCS에 저장되는 파일을 의미함. 객체 메타 데이터는 키-값 형태로 구성이 되며 다양한 객체의 퀄리티를 설명을 담당함 
  - 지리적 중복
    - 지리적 중복 데이터는 최소 100마일 이상 떨어진 두 곳 이상의 중복 저장이 되기 때문에 자연재해와 같은 대규모 장애 발생 시에도 최대한의 데이터 가용성을 보장함 
  - 객체 불변성 
    - 객체는 변경이 불가함 
    - Repository에 업로드한 객체는 변경을 할 수 없음. 만약 변경을 하고 싶으면 삭제 후 다시 업로드해야 함. 저장된 객체를 덮어쓸 수 있음 
- Repository 등급 차이 및 비교 
  - 멀티 리저널 스토리지(Multi-Regional Storage)
    - 웹 사이트의 컨텐츠, 비디오 스트리밍, 양방향 작업 부하, 모바일 게임 등 자주 액세스되는 데이터를 저장하는 데 적합함. 
    - 가장 높은 가용성을 제공함. 지리적 중복을 제공하여 최소 약 160KM 이상 떨어진 2곳 이상의 지리적 장소에 중복이 되기 때문에 자연재해 같은 대규모 장애 발생 시에도 최대한의 데이터 가용성을 보장함 
    - 웹 사이트 콘텐츠, 비디오 스트리밍 또는 게임 및 모바일 애플리케이션 같이 전 세계적으로 자주 액세스되는 데이터 저장(1GB당 월별 과금: $0.026)
  - 리저널 스토리지(Regional Storage)
    - 대규모 지리적 영역에서 중복을 분산시키는 대신 특정 지역 위치에서 저렴한 비용으로 데이터를 저장할 수 있음.
    - Compute Engine이나 쿠버네티스 엔진 클러스터와 함께 이용하여, 동일한 지역 위치에 데이터를 저장하는데 적합함 
    - 데이터 집약적인 계산에서 다중 지역 위치에 데이터를 저장할 때보다 높은 성능을 얻을 수 있음. 여러 영역으로 데이터 요청이 가지 않아도 되어 네트워크 요금도 줄일 수 있음 
    - 데이터 분석과 같이 자주 사용하는 Cloud Dataproc 또는 Compute Engine 같이 동일한 지역에 액세스를 하는 경우 계산 수행 시 높은 성능에 있어 이점을 가질 수 있음(1GB당 월별 과금: $0.02)
  - 니어라인 스토리지(Nearline Storage)
    - 액세스하지 않는 데이터를 저장하는 데 적합한 저가의 Repository 
    - 멀티 리저널 스토리지와 리저널 스토리지와 비교했을 때 가용성이 상대적으로 낮음. 최소 저장 기간은 30일이며 데이터 액세스 비용이 합리적이어서 Repository 비용을 절약하는 데는 더 나은 선택 
    - 평균적으로 한 달에 한 번 정도 읽거나 수정할 계획인 데이터가 있다면 데이터를 저장하기에 매우 적절한 Repository 
    - 자주 액세스하지 않을 데이터(한 달에 한번), 백업 및 지연 시간이 긴 멀티미디어 컨텐츠에 적합(1GB당 월별 과금: $0.01)
  - 콜드라인 스토리지(Coldline Storage) 
    - 저장 비용이 가장 저렴한 Repository 
    - 데이터 보관 및 온라인 백업 및 재해복구를 위한 Repository로 매우 적절함. 콜드라인 스토리지는 다른 Repository보다 가용성이 상대적으로 낮고, 최소 저장 기간은 90일이며, 데이터 액세스 비용과 높은 운영 비용이 들기 때문에 1년에 한 번 정도 데이터에 액스세할 때 부합함
    - 적합한 데이터로 백업 데이터 정도가 있음 
    - 자주 액세스하지 않을 데이터(1년에 한 번) 일반적으로 재해 복구 또는 나중에 필요할 수도, 필요 없을 수도 있는 데이터에 해당(1GB당 월별 과금: $0.007)
  - |특징|Multi-Regional|Regional|Nearline|Coldline|
    |:--:|:--:|:--:|:--:|:--:|
    |데이터 관점 접근 방법|매우 자주 액세스|동일한 리전 내에서 자주 접근|한달에 한번미만으로 접근|1년에 한번 미만으로
    |SLA|99.95%|99.90%|99.00%|99.00%|
    |ACCESS APIS|일관된 APIs|일관된 APIs|일관된 APIs|일관된 APIs|일관된 APIs
    |저장 비용|매우 높음|높음|<-GB당 한달 저장 가격->|낮음|매우 낮음|
    |복구 비용|매우 낮음|낮음|<-GB당 데이터 이동 총 가격->|높음|매우 높음|
    |유스 케이스|컨텐츠 저장 및 전송|지역 내에서의 분석 및 트랜스코딩|백업|아카이빙,재난 복구용 
- gsutil 명령어 살펴보기
  - gsutil은 CLI 환경에서 GCS에 액세스할 수 있는 명령어로 다음과 같은 작업을 할 수 있음 
    - 버킷 생성 및 삭제
    - 객체 업로드, 다운로드, 삭제
    - 버킷 및 객체 나열 
    - 객체 이동, 복사 및 이름 바꾸기 
    - 객체 및 버킷의 ACL 수정 

# Cloud SQL
- 대표적인 관계형 데이터베이스인 MySQL과 PostgreSQL 
- Google Cloud Platform에서 유지 및 관리를 해주는 완전 관리형 데이터베이스 서비스로 손쉽게 설정과 유지 보수 및 관리 가능함 
- 고성능, 확장성, 편의성을 제공하기 때문에 데이터베이스의 관리는 GCP에 맡기고 애플리케이션 개발에 집중할 수 있음 
- MySQL은 전 세계에서 가장 많이 쓰이는 오픈 소스 관계형 데이터베이스로, 오라클에서 관리 및 지원을 하고 있음. 다중 스레드, 다중 사용자 형식의 구조적 질의어 형식의 데이터베이ㅅ ㅡ관리 시스템 
- MySQL과 MySQL용 Cloud SQL의 차이
  - 지원되지 않는 기능 
    - 사용자 정의 함수
    - InnoDB memcached 플러그인
    - Federated Engine
    - SUPER 권한 
- PostgreSQL용 Cloud SQL의 특징
  - 확장 가능성 및 표준 준수를 강조하는 객체 관계형 데이터베이스 관리 시스템 중 하나로 BSD 허가권으로 배포되며 많은 오픈소스 개발자 및 회사들이 개발에 참여하고 있음 
  - 다른 관계형 데이터베이스 시스템과 달리 연산자, 복합 자료형, 집계 함수, 자료형 변환자, 확장 기능 등 다양한 데이터베이스 객체를 사용자가 임의로 만들 수 있는 기능을 제공하기 때문에 단순 자료 Repository가 아닌 개발 언어처럼 무한한 기능을 구현할 수 있도록 해줌 
  - 객체 지향 언어들과 같이 테이블을 만들고 그 테이블을 상속하는 하위 테이블을 만들 수 있음 

# BigQuery
- 확장성이 뛰어난 구글의 기업용 서버리스 기반의 데이터 웨어하우스로 관리할 인프라가 없기 때문에 데이터 분석에 집중할 수 있으며, 인프라 및 데이터를 관리할 관리자도 필요하지 않음 
- ANSI:2011을 준수하는 표준 SQL을 지원하기 때문에 기존에 SQL을 알고 있는 사용자도 손쉽게 이용할 수 있는 장점이 있으며, ODBC 및 JDBC 드라이버를 제공하여 데이터를 쉽고 빠르게 통합할 수 있음 
- BigQuery는 몇 초 만에 기가바이트급에서 페타바이트급에 이르는 데이터를 대상으로 초고속으로 SQL 쿼리를 실행할 수 있음. 매월 무료로 최대 1TB 상당의 데이터를 분석하고 10GB의 데이터를 저장할 수 있음 
- 스토리지와 컴퓨팅이 분리되어 있기 때문에 데이터 웨어하우스의 용량을 원하는 대로 게획할 수 있는 탄력적인 확장성을 가짐. 자동 확장과 고성능 스트리밍 수집 방식을 지원해서 실시간 분석의 어려움도 간편하게 해결할 수 있음 
- 내부적으로 관리형 열형식 스토리지, 대량 동시 실행, 자동 성능 최적화 기능을 제공하고 있어서 데이터 크기에 관계없는 클라우드 데이터 레이크를 구축하고 동시에 빠르게 분석할 수 있음 
- 구글 시트, 구글 드라이브 등으로 손쉽게 데이터를 읽을 수 있으며 인포매티카와 탈랜드 같은 ETL 도구와의 연동도 지원함. 태블로, 마이크로스트레티지,루커, 데이터 스튜디오와 같은 BI 도구와 자체적으로도 BI Engine을 지원하여 누구나 손쉽게 보고서와 대시보드를 만들 수 있음 
- 모든 배치와 스트리밍 데이터를 분석할 수 있으며, 강력한 스트리밍 수집 기능은 실시간으로 데이터를 캡처하고 분석해, 통계를 항상 최신 상태로 유지함 
- BigQuery ML을 이용하여 SQL 쿼리를 통해 ML 모델을 학습시키는 것이 가능하며, 클라우드 ML 엔진(Cloud ML Engine) 및 텐서플로(Tensorflow)와도 통합이 가능함. BigQuery GIS를 이용하면 일반적으로 GIS 함수에 대한 SQL 지원을 BigQuery 내에서 이용할 수 있음 
- BigQuery 구조 
  - project : 가장 큰 개념으로, 프로젝트에는 결제 및 승인된 사용자에 대한 정보가 저장되며 각 프로젝트에는 이름과 고유 ID가 있음. 하나의 프로젝트에는 여러 개의 데이터세트(Dataset)가 들어갈 수 있음 
  - Dataset : RDB의 데이터베이스와 같은 개념으로, Dataset는 특정 프로젝트에 포함되며, 테이블과 뷰에 대한 액세스를 구성하고 제어하는 데 사용함. 하나의 Dataset에는 여러 개의 Table을 가질 수 있음 
  - Table : RDB의 Table과 같은 개념으로, 행으로 구성된 개별 레코드가 포함됨. 각 레코드는 컬럼으로 구성되며, 모든 테이블은 컬럼명, 데이터 유형, 기타 정보를 설명하는 스키마로 정의됨. 
  - 기본 테이블 : 기본 BigQuery Repository에서 지원되는 테이블 
  - 외부 테이블 : BigQuery 외부 Repository에서 지원되는 테이블 
  - 뷰 : SQL 쿼리로 정의된 가상 테이블 
  - Job : 쿼리, 데이터 로딩, 생성, 삭제 등 작업에 대한 단위 
- BigQuery SQL
  - 표준 SQL은 BigQuery 2.0부터 지원하기 시작했음. 표준 SQL은 SQL 2011 표준을 준수하며, 중첩 및 반복 데이터 쿼리를 지원함 
- BigQuery ML 
  - BigQuery에서 Python이나 자바와 같은 프로그래밍 언어 없이 표준 SQL 쿼리만으로 머신 러닝 모델을 만들고 실행할 수 있음 
  - 장점 
    - Python이나 자바와 같은 프로그래밍 언어를 사용하지 않고 SQL을 사용해 모델을 만들고 실행할 수 있음 
    - 데이터 웨어하우스 내에서 모델을 만들고 실행하기 때문에 데이터를 내보내지 않아도 됨. 이로 인해서 속도 면에서 큰 장점을 가질 수 있음 
- BigQuery GIS
  - 지리 데이터 유형과 표준 SQL 지리 함수를 사용하여 BigQuery에서 지리공간 데이터를 분석하고 시각화할 수 있음 

# Cloud Composer 
- 파이프라인을 작성하여 예약 및 모니터링할 수 있는 통합 워크플로 관리 서비스 
- 내부적으로는 아파치 에어플로를 기반으로 한 워크플로 통합 서비스로 Google Cloud Platform의 다양한 서비스들이 활용되어 있음. 구글 쿠버네티스 엔진을 기반으로 한 배포 환경을 가지고 있으며, Cloud SQL을 이용하여 메타 데이터를 저장하고, 앱 엔진을 활용하여 에어플로 웹 서비스를 호스팅하며, 로그 관리는 Stackdriver를 이용함 
- Python을 기반으로 DAG와 태스크에 대한 코드를 작성할 수 있으며, 분산 환경 및 웹 UI 기반의 강력한 모니터링 기능을 제공해 간편하게 모니터링을 할 수 있음. 멀티 클라우드를 지원하기 때문에 온프레미스와 다른 클라우드 서비스들과 교차하는 워크플로를 작성할 수 있음 
- Apache Airflow
  - 아파치 에어플로는 유명한 여행 서비스 회사인 에어비앤비에서 개발된 워크플로 통합 도구로 현재는 아파치 재단에서 인큐베이팅 하고 있는 프로젝트 
  - 데이터 분석가 및 개발자 모두가 익숙한 언어인 Python을 기본으로 태스크에 대한 코드를 작성할 수 있어서 적급성이 낮은 면이 있음. 웹 UI 기반의 강력한 모니터링 툴을 제공하기 때문에 웹 브라우저를 통해서 손쉽게 모니터링할 수 있다는 장점 
- Cloud Composer 주요 개념 
  - DAG
    - DAG라고 하는 비순환 그래프 
    - 하나의 DAG가 하나의 워크플로, 워크플로 안에 오퍼레이터를 이용해 태스크를 만들어 담을 수 있음 
    - 오퍼레이터는 DAG안에 정의되는 작업 함수이며 이를 이용해 태스크를 만듬 
  - 데이터 저장
    - Cloud Composer는 생성 시 자동으로 Google Cloud Storage 내에 버킷을 만들고, 클라우드 스토리지 FUSE를 사용하여 에어플로 인스턴스와 GCS서로 매핑함 
    - 버킷의 이름은 환경 영역, 이름 및 랜덤한 ID를 기반으로 생성됨. 버킷에 저장된 데이터를 통해 컴포저를 관리할 수 있음 

# Source Repositories 
- Source Repositories 
  - Google Cloud Platform에서 지원하는 비공개 Git Repository. 확장이 가능하며 GCP 내부의 서비스이다 보니 간편하게 다른 GCP 서비스 들과 연결하여 빌드, 배포, 디버깅을 할 수 있음 
  - 무제한 비공개 Git Repository를 제공하며, GCP 내부에 있는 Cloud Build를 사용해 CI/CD 환경도 구축할 수 있음. GCP Console에서 제공하는 소스 브라우저를 사용하면 Repository 내의 Repository 파일을 확인할 수 있으며 필터링 기능을 사용하여 특정 브랜치, 태그, 커밋만 표시할 수 있음 
  - 강력한 정규 표현식을 지원하기 때문에 여러 디렉터리에서 내가 찾고자 하는 프로젝트나 파일 코드를 손쉽게 찾을 수 있음. 깃허브나 빗버켓(Bitbucket) Repository 를 Cloud Source Repositories에 연결할 수 있으며, 연결된 Repository는 자동으로 동기화됨
  - Source Repositories는 데이터 저장을 여러 데이터 센터에 지리적으로 분산하여 저장하기 때문에 자연재해같은 상황에서도 높은 가용성으로 관리됨 
  - 자동 로깅 기능을 사용하면 Stackdriver Logging에 로그를 보내 데이터 액세스 추적 및 문제 해결을 도움. Repository 활동을 로깅하면 최근 Repository 동기화 활동과 다른 사용자의 만들기, 삭제, 권한 변경사항, Repository 액세스와 같은 관리 작업의 로그를 검토할 수 있음. Repository 동기화 중 오류가 로깅 되면 경고가 전송되도록 알림 설정을 할 수도 있음 

# Cloud Pub/Sub
- GCP의 대표적인 메시징 서비스로 카프카나 래빗MQ(RabbitMQ)와 같은 오픈소스 메시징 서비스와 동일한 서비스
- 글로벌 규모에서도 낮은 지연 시간과 안정적인 메시지 전달을 제공하고, 서버리스 환경이기 때문에 별도의 인스턴스를 관리할 필요 없이 사용량에 따라 초당 수억 개까지 메시지를 확장할 수 있음 
- Cloud Pub/Sub은 초당 5억 건의 메시지를 전송할 수 있으며, 이는 용량으로는 초당 1TB에 해당함 
- 비동기 데이터 전달 시 중간에 Pub/Sub을 통해 전달함으로써 안정적인 메시지 전달을 제공하며, 메시지를 생산하는 Topic(게시)와 메시지를 해당 주제로부터 받는 Subscription(구독)으로 구성되어 1:다, 다:1, 다:다의 구성을 가짐. 
- 데이터는 구글 내부의 비공개 네트워크를 통해 데이터 센터에 지능적으로 자동 분산됨 
- 메시징 서비스 
  - 메시지(데이터)들은 큐에 넣고 차례로 전달해주는 서비스 
  - 서버-클라이언트 구조에서는 사용자가 요청하면 서버가 그에 대한 처리를 한 후에 사용자에게 응답함. 서버가 동시에 처리할 수 있는 양은 한정적인 관계로 요청 메시지를 큐에 쌓아놓고 처리할 수 있기 때문에 응답을 하는 서버가 죽더라도 그 사이에 요청이 들어온 메시지들은 메시지 큐에 쌓여있어서 서버가 살아났을 때 처리를 할 수도 있음. 
  - 여러 대의 서버가 하나의 큐를 바라보도록 하면 처리할 데이터가 많아져도 서버는 자신의 처리량에 맞는 요청만 가져와서 처리할 수도 있음 
- Pub/Sub의 구성
  - Topic(주제) : 게시자가 메시지를 전송하는 이름이 지정된 리소스
  - Subscription(구독) : 특정 주제의 메시지 수신 의향을 나태내는 이름이 지정된 항목 
  - Message(메시지) : 서비스를 통해 이동하는 데이터 
  - Publisher(게시자) : 특정 주제에 대한 메시지를 만들어 메시지 서비스를 전송하는 사람 
  - Subscriber(구독자) : 지정한 구독에 대한 메시지를 받는 사람 
- Pull(가져오기) / Push(내보내기) 구독 방법 
  - Pull 방식은 Subscriber가 Message를 요청할 때 전달받는 구조의 구독 방식 
  - Push 방식은 Message가 오면 바로 Subscriber에게 전달하는 방식 
  - Pull vs Push 
    - ||Pull|Push
      |:--:|:--:|:--:|
      |엔드포인트|자격을 증명한 인터넷상의 모든 기기는 API 호출 가능| 자격 증명이 어려운 서비스(구독자)에서 사용할 수 있음 
      |부하 분산|여러 구독자가 Share와 같은 Pull 요청을 구성할 수 있음|엔드포인트가 부하분산기가 될 수 있음|
      |구성|구성필요x|GCP 콘솔에서 내보내기 엔드포인트를 구성해야함(구독자와 같은 프로젝트에 있는 App Engine 제외) 
      |흐름 관리|구독자가 전달 속도를 조절함|Cloud Pub/Sub 서버가 자동으로 흐름 제어를 구현|
      |지침|대량 메시지 처리의 효율성과 처리량이 중요한 경우|Google Cloud 종속 서비스외의 환경 동일한 webhook에 의한 여러 주제를 처리해야하는 경우, App Engine 표준 구독자
- 메시지 서비스의 성능 판단
  - 확장성 : 확장 가능한 서비스는 지연 시간이나 가용성의 현저한 저하 없이 점점 증가하는 로드를 처리할 수 있어야 함 
  - 가용성 : 시스템의 가용성은 다양한 유형의 문제를 얼마나 잘 처리해서 최종 사용자가 오류 해결을 알아차리지 못하게 하는가를 기준으로 측정함 
  - 지연 시간 : 시스템 성능을 시간 기준으로 측정한 것으로 대부분의 서비스는 지연 시간을 최소화하려고 함 

# Cloud Dataproc
- Cloud Dataproc
  - 클라우드 네이트브 아파치 하둡 및 아파치 스파크 서비스 
  - 완전 관리형 클라우드 서비스이기에 더 간단하고 효율적으로 하둡 및 스파크 클러스터를 생성할 수 있음. 환경 구축을 위해서 몇 시간에서 며칠씩 걸리던 작업이 몇 분에서 몇 초만에 끝나게 됨 
  - 클러스터 배포, 로깅, 모니터링과 같은 관리는 GCP에서 자동으로 지원해주기 때문에 직접 인프라 관리를 할 필요 없이 사용자는 작업과 데이터에 집중할 수 있으며, 언제든 클러스터를 만들고 다양한 가상 머신 유형, 디스크 크기, 노드 수, 네트워킹 옵션 등 여러 리소스를 최적화하고 확장할 수 있음 
  - 다수의 마스터 노드를 사용해 클러스터를 실행하고 실패해도 다시 시작되도록 설정을 할 수 있기 때문에 높은 가용성을 보장함. 사용하기 쉬운 Web UI, Cloud SDK, RESTful API 등 다양한 방식으로 클러스터를 관리할 수 있음 
  - 클러스터 모드 
    - 단일 노드(마스터 1, 작업자 0) : 마스터 노드 하나만 설정함 
    - 표준 (마스터 1, 작업자 N) : 마스터 노드 1개와 작업자 노드 N개를 설정함 
    - 고가용성 (마스터 3, 작업자 N) : 마스터 노드 3개와 작업자 노드 N개를 설정함 
- Apache Hadoop
  - 아파치 하둡은 분산 환경의 병렬 처리 프레임워크로, 크게 보면 분산 파일 시스템인 HDFS와 데이터 처리르 위한 맵리듀스 프레임워크로 구성되어 있음. 
  - 하둡은 여러 대의 서버를 이용해 하나의 클러스터를 구성하며, 이렇게 클러스터로 묶이 서버의 자원을 하나의 서버처럼 사용할 수 있는 클러스터 컴퓨팅 환경을 제공함. 
  - 기본적인 작동 방법은 분석할 데이터를 하둡 파일 시스템인 HDFS에 저장해 두고 HDFS 상에서 MapReduce 프로그램을 이용해 데이터 처리를 수행하는 방식
  - 하둡 파일 시스템은 하나의 네임노드와 여러 개의 데이터 노드로 구성되며, 하나의 네임노드가 나머지 데이터 노드를 관리하는 형태로 작동함 
  - HDFS는 여러 대의 서버에 데이터를 다중 복제해서 저장하는 방식으로 안정성을 보장하며, 최근에는 클러스터 자원 관리 시스템인 Yarn(MapReduce v2)의 도입과 더불어 하나의 클러스터에 1개 이상의 네임노드를 설정할 수 있는 네임노드 페더레이션 기능을 제공하는 등 안정적인 서비스가 가능해졋음 
- Apache Spark
  - 아파치 스파크는 하둡과 유사한 클러스터 기반의 분산 기능을 제공하는 오픈 소스 프레임워크. 처리 결과를 항상 파일 시스템에 유지하는 하둡과 달리, 메모리에 저장하고 관리할 수 있는 인 메모리 캐싱 기능을 제공함으로써 속도가 빠르고 머신 러닝 같은 반복적인 데이터 처리에 뛰어난 성능을 보임 
  - 맵리듀스뿐만 아니라, 스트리밍, 머신러닝, 그래프 처리, SQL 처리 등 범용적인 분산 클러스터 환경을 제공함 
  - Spark는 데이터를 읽고, 변형하고, 집계를 할 수 있으며, 복잡한 통계 모델들을 쉽게 학습하고 배포할 수 있음. 제공하는 언어로는 Java, Scala, R, Python 등이 있음 
- Hadoop Ecosystem
  - 하둡 에코시스템은 하둡과 관련된 프레임워크들임. 하둡 코어 프로젝트(HDFS, MapReduce)와 수집, 분석 등의 하둡 서버 프로젝트로 구성이 되는데, 다양한 종류의 프레임워크들을 제공하기 때문에 사용자의 필요에 따라 다양하게 조합해서 이용할 수 있음 

# Cloud Dataflow
- 배치 및 스트림 모드로 데이터를 변환하고 처리할 수 있는 완전 관리형 서비스 
- 아파치 빔과 같은 프로젝트로 리소스 프로비저닝 및 관리에 대한 서버리스 접근 방식 덕분에 무제한에 가까운 용량을 이용해 대규모 데이터 처리 과제를 해결할 수 있음. Apache Beam SDK를 통한 자바 및 Python API를 제공하기 때문에 간단하고 빠르게 파이프라인을 개발할 수 있음 
- 서버리스 환경이기 때문에 성능, 확장, 가용성, 보안 등 사용자가 직접 클러스터를 관리할 필요 없이 GCP에서 관련된 모든 관리를 자동으로 해주기 때문에 서비스를 위한 프로그래밍에 전념할 수 있어 간접 운영비가 사라짐 
- GCP의 통합 로그 기록 및 모터링 솔루션인 Stackdriver를 통해 파이프라인에 대한 모니터링 및 문제 해결에 도움을 받을 수 있음 
- 지원하는 프로그래밍 언어 
  - Apache Beam 언어로는 Java, Python, Go
- Dataflow vs Dataproc
  - |Dataflow|Dataproc|
    |:---:|:---:|
    |Apache Beam 기반|Apache Hadoop / Spark 기반|
    |Serverless|DevOps|
    |기존에 레거시 없이 새로 접근할 때 적합|Apache 빅데이터 생태계(Hadoop Eco System)에 적합
- Dataflow 흐름도
  - Pipeline: 데이터 처리를 위한 큰 흐름 
    - 파이프라인은 처음부터 끝까지 전체 데이터 처리 작업을 캡슐화함. 입력 데이터 읽기, 해당 데이터 변환 및 출력 데이터 쓰기가 포함됨. 모든 dataflow 프로그램은 파이프라인을 생성해야 함 
  - Pipeline I/O : 데이터의 Input과 Output을 위한 부분 
  - Transform : 데이터의 변환 및 가공, 변경한 데이터는 PCollection에 저장
    - 피트랜스폼(Ptransform)은 파이프라인에서 데이터 처리 작업 또는 단계를 나타냄 
  - PCollection : 데이터 저장을 위한 데이터 타입 (Input과 Output)
    - Dataflow pipeline이 작동하는 분산 데이터세트를 나타냄. 파이프라인은 외부 데이터 원본에서 데이터를 읽어서 초기 PCollection을 생성하지만, 드라이버 프로그램 내의 메모리 내 데이터에서 PCollection을 만들 수 있음 
    - PCollection은 데이터 플로 파이프라인 내에서 데이터를 저장하는 개념으로 한 번 생성되면, 그 데이터는 수정이 불가능함. 데이터를 변경하거나 수정하기 위해서는 PCollection을 새로 생성해야 함 
      - 요소 유형(Element type) : PCollectio의 요소는 모든 유형이 될 수 있지만, 모두 동일한 유형이어야 함 
      - 불변성(Immutability) : PCollection은 변경이 불가능하기 때문에 변경을 위해서는 새로운 PCollection을 생성해야 함 
      - 무작위 접근(Random access) : PCollection은 개별 요소에 대한 무작위 액세스를 지원하지 않음 
      - 크기와 경계(Size and boundedness) : PCollection의 크기는 제한을 할 수도 있고 제한 하지 않을 수도 있음 
      - 요소 타임 스탬프(Element timestamps) : PCollection 각 요소에는 고유한 타임 스탬프가 있음 
- Unbounded Data(스트리밍 데이터) 처리 
  - 스트리밍 데이터와 같은 경우에는 데이터가 끊이지 않고 들어오기 때문에 결과를 내보내야 하는 타이밍을 잡기 애매함. 시간을 기준으로 작업을 끊어서 처리하는데 이를 윈도잉(Windowing)이라고 함 
  - Window 개념 
    - 스트리밍 데이터는 계속 들어오기 때문에 특정 시간기간 단위로 지속적으로 처리를 하고 저장을 해주어야 함 
    - Fixed Window
    - Sliding Window
    - Session Window
