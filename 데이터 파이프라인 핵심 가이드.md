# 서평
- 데이터 분석이 잘 이뤄지기 위해서는 분석에 필요한 형태로 잘 정리된 데이터가 필요하고, 원하는 분석 결과를 얻기 위해서는 적합한 기간의 정확한 데이터가 필요함, 이러한 데이터들은 잘 구성된 데이터 파이프라인 안에서만 만들어질수 있음 
- 이 책은 데이터 파이프라인의 전반적인 소개와 패턴을 다룸, 데이터 파이프라인 각 단계를 계획할 때부터 구성 후 검증하고 유지 관리하는 전체 과정에서 고려할 점들과 활용할 수 있는 예시 코드를 함께 제공함 

# 데이터 파이프라인 소개
- 데이터 파이프라인이란?
  - 다양한 소스에서 새로운 가치를 얻을 수 있는 대상으로 데이터를 옮기고 변환하는 일련의 과정, 분석,리포팅,머신러닝 능력의 기초가됨
  - 데이터 파이프라인의 복잡성은 원본 데이터의 크기와 상태, 구조 및 분석 프로젝트의 요구사항에 따라서도 달라짐
  - 데이터 추출, 데이터 가공, 데이터 유효성 검사를 포함한 여러 단계로 구성되며, 때로는 데이터를 최종 목적지로 전달하기 전에 머신러닝 모델을 학습하거나 실행하는 단계가 있기도 함
  - 파이프라인에는 여러 시스템과 프로그래밍 언어의 작업이 포함되는 경우가 많음
  - 데이터 팀은 일반적으로 종속성을 공유하고 조정해야 하는 수많은 데이터 파이프라인을 소유하고 유지함 
- 누가 파이프라인을 구축할까?
  - 데이터 엔지니어는 분석 상태계를 뒷받침하는 데이터 파이프라인을 구축하고 유지하는 데 전문적인 역량을 갖추고잇음 
  - 데이터 과학자 및 분석가와 긴밀히 협력하여 데이터를 어떻게 처리해야 하는지 파악하고 요구사항을 확장 가능한 프로덕션 상태로 전환하는 데 도움을 줌 
    - SQL과 데이터 웨어하우징 기초
      - 숙련된 데이터 엔지니어는 고성능의 SQL 작성 방법을 알고 데이터웨어하우징 및 데이터 모델링의 기본 사항을 이해함
    - 파이썬 그리고/또는 자바
    - 분산 컴퓨팅
      - 데이터 양이 많아지고 데이터를 신속하게 처리하고 하는 요구사항이 늘어나면서 데이터엔지니어들은 분산 컴퓨팅 플랫폼을 사용하기 시작, 
      - 분산 컴퓨팅은 여러 시스템의 성능을 결합하여 대량의 데이터를 효율적으로 저장, 처리 및 분석함
        - 하둡 분산 파일 시스템(HDFS)를 통한 분산 파일 스토리지, 맵리듀스를 통한 처리, 피그(pig)를 통한 데이터 분석 등을 포함하는 하둡 에코시스템, 아파치 스파크는 하둡을 빠르게 능가하는 또 다른 인기 분산 처리 프레임워크 
      - 데이터 엔지니어는 이러한 프레임워크를 언제 어떻게 활용해야 하는지 알아야 함 
    - 기본 시스템 관리
      - 리눅스 명령줄에 능숙, 응용 프로그램 로그 분석, 크론 작업 예약, 방화벽 및 기타 보안 설정의 문제 해결과 같은 작업을 수행할 수 있어야함
    - 목표 지향적 사고방식
      - 데이터 엔지니어가 파이프라인을 구축하는 이유를 알 때 더 나은 아키텍처 결정을 내릴 수 있음
- 왜 파이프라인을 구축할 까?
  - 원본 데이터는 정리, 정형화, 정규화, 결합, 집계, 그리고 때로는 마스킹 또는 보안을 위해 정제됨 
- 어떻게 데이터 파이프라인을 구축할까?
  - 오픈소스도 있고, 상업용도 있고, 자체 개발 제품도 있음
  - 파이프라인 구축을 위한 가장 인기 있는 솔루션 및 프레임워크를 살펴보고 조직의 요구 사항과 제약 조건에 따라 어떤 제품을 사용할지 결정하는 방법을 알아봄
  - 파이프라인을 구축하고 이를 안정적이고 안전하게 제시간에 제공하고 처리하는 인프라를 지원해야함 

# 최신 인프라 데이터
- 데이터 소스의 다양성
  - 최신 데이터 인프라의 핵심 구성 요소
    - 데이터 소스의 다양성
    - 데이터 수집 도구
    - 클라우드 데이터 웨어하우스와 데이터 레이크
    - 모델링 도구 및 프레임워크
    - 워크플로 오케스트레이션 플랫폼 
- 소스 시스템 소유권
  - 데이터 수집(data ingestion) : 한 소스에서 데이터를 추출하여 다른 소스로 로드하는 것
  - 소스 시스템이 위치하는 곳이 어디인지를 이해하는 것은 여러 가지로 중요함
    - 타사 데이터 소스에 위치한 데이터에 액세스하려고 한다면 액세스 방법에 제한이 있을수 있음
    - 데이터를 사용자가 필요로 하는 형태에 맞추어 정의하는 등
    - 데이터 수집이 시스템에 의도하지 않는 부하를 가하는지부터 데이터를 점진적(incremental)으로 로드할 수 있는지 여부까지 다양한 과제가 발생하기 때문
- 수집 인터페이스 및 데이터 구조
  - 소스 데이터를 얻는 방법과 형식
    - Postgres 또는 MySQL 데이터베이스와 같은 애플리케이션 뒤에 있는 데이터베이스
    - REST API와 같은 시스템 상단의 추상화 계층
    - Apache Kafka와 같은 스트림 처리 플랫폼
    - 로그, 쉼표로 구분된 값(csv) 파일 및 기타 플랫 파일을 포함하는 공유 네트워크 파일 시스템(NFS) 또는 클라우드 스토리지 버킷
    - 데이터 웨어하우스 또는 데이터 레이크
    - HDFS 또는 HBase 데이터베이스의 데이터 
  - 데이터 구조
    - REST API의 JSON
    - MySQL 데이터베이스의 잘 구성된 데이터
    - MySQL 데이터베이스의 테이블의 열 내의 JSON
    - 반정형화된 로그 데이터
    - CSV,고정 폭 형식(FWF) 및 기타 플랫 파일 형식
    - 플랫 파일의 JSON
    - Kafka의 스트림 출력
  - 분석 프로젝트에 더 적합한 형태로 정형화하기 위해서는 데이터 수집 이 외에도 클렌징, 변환 작업 등의 추가 단계가 파이프라인에 필요할 수 있음
  - JSON과 같은 반정형 데이터가 점점 보편화 되고 있으며 속성-값 구조와 객체의 중첩(nesting)구조의 이점을 가지고 있음
  - 관계형 데이터베이스와 달리 같은 데이터세트 안의 데이터 구조가 모두 동일하다는 보장은 없음, 파이프라인에서 누락되거나 불완전한 데이터를 처리하는 방법은 상황에 따라 달라지며 데이터의 유연성이 증가할수록 점점 더 많이 필요함 
- 데이터 클레징 작업과 유형성 검사
  - 지저분한 데이터의 특성
    - 중복되거나 모호한 레코드
    - 고립된 레코드
    - 불완전하거나 누락된 레코드
    - 텍스트 인코딩 오류
    - 일치하지 않는 형식(ex-대시(-)가 있는 전화 번호와 없는 전화번호)
    - 레이블이 잘못되었거나 레이블이 지정되지 않은 데이터
  - 데이터 생태계에 주요 특성과 접근 방식 
    - 최악을 가정하고 최상을 기대하라 
    - 가장 적합한 시스템에서 데이터를 정리하고 검증하라
    - 자주 검증하라 
- 클라우드 데이터 웨어하우스 및 데이터 레이크
  - 데이터 웨어하우스 
    - 사용자가 원하는 질문에 대답할 수 있는 데이터 분석 활동을 지원하기 위해 서로 다른 시스템의 데이터가 모델링되어 저장되는 데이터베이스
    - 데이터 웨어하우스의 데이터는 리포팅 및 분석 쿼리를 위해 정형화되고 최적화됨
  - 데이터 레이크
    - 데이터가 저장되지만 데이터 웨어하우스처럼 데이터 구조나 쿼리 최적화가 필요 없는 곳임
- 데이터 수집 도구
  - Singer
  - Stitch
  - Fivetran
- 데이터 변환 및 모델링 도구
  - 파이프라인은 머신러닝, 분석 및 리포팅과 같은 새로운 목적을 위해 데이터를 변환하고 모델링하는 작업으로 구성됨
  - 데이터 변환
    - 데이터 변환은 ETL 또는 ELT 프로세스 T(Transform)에 해당하는 광범위한 용어
  - 데이터 모델링
    - 데이터 모델링은 보다 구체적인 데이터 변환 유형, 데이터 모델은 데이터 분석을 위해 데이터를 이해하고 최적화된 형식으로 정형화하고 정의함
    - 데이터 모델은 일반적으로 데이터 웨어하우스에서 하나 이상의 테이블로 표시됨 
- 워크플로 오케스트레이션 플랫폼
  - 조직의 데이터파이프라인의 복잡성과 수가 증가함에 따라 데이터 인프라에 워크플로 오케스트레이션 플랫폼을 도입하는 것이 중요함
  - 파이프라인에서의 작업의 스케줄링 및 흐름을 관리해줌
  - 워크플로 관리 시스템(WMS), 오케스트레이션 플랫폼 또는 오케스트레이션 프레임워크
  - 아파치 에어플로우, Luigi, AWS Glue와 같은플랫폼은 좀 더 일반적인 용도로 설계되어 다양한 데이터 파이프라인에 사용됨
  - 구체적인 사용 사례와 플랫폼(Kubeflow Pipeline의 경우 Docker 컨테이너에 구축된 머신러닝 워크플로)을 위해 설계됨 
