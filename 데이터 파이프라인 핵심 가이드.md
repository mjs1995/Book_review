# 서평
- 데이터 분석이 잘 이뤄지기 위해서는 분석에 필요한 형태로 잘 정리된 데이터가 필요하고, 원하는 분석 결과를 얻기 위해서는 적합한 기간의 정확한 데이터가 필요함, 이러한 데이터들은 잘 구성된 데이터 파이프라인 안에서만 만들어질수 있음 
- 이 책은 데이터 파이프라인의 전반적인 소개와 패턴을 다룸, 데이터 파이프라인 각 단계를 계획할 때부터 구성 후 검증하고 유지 관리하는 전체 과정에서 고려할 점들과 활용할 수 있는 예시 코드를 함께 제공함 

# 데이터 파이프라인 소개
- 데이터 파이프라인이란?
  - 다양한 소스에서 새로운 가치를 얻을 수 있는 대상으로 데이터를 옮기고 변환하는 일련의 과정, 분석,리포팅,머신러닝 능력의 기초가됨
  - 데이터 파이프라인의 복잡성은 원본 데이터의 크기와 상태, 구조 및 분석 프로젝트의 요구사항에 따라서도 달라짐
  - 데이터 추출, 데이터 가공, 데이터 유효성 검사를 포함한 여러 단계로 구성되며, 때로는 데이터를 최종 목적지로 전달하기 전에 머신러닝 모델을 학습하거나 실행하는 단계가 있기도 함
  - 파이프라인에는 여러 시스템과 프로그래밍 언어의 작업이 포함되는 경우가 많음
  - 데이터 팀은 일반적으로 종속성을 공유하고 조정해야 하는 수많은 데이터 파이프라인을 소유하고 유지함 
- 누가 파이프라인을 구축할까?
  - 데이터 엔지니어는 분석 상태계를 뒷받침하는 데이터 파이프라인을 구축하고 유지하는 데 전문적인 역량을 갖추고잇음 
  - 데이터 과학자 및 분석가와 긴밀히 협력하여 데이터를 어떻게 처리해야 하는지 파악하고 요구사항을 확장 가능한 프로덕션 상태로 전환하는 데 도움을 줌 
    - SQL과 데이터 웨어하우징 기초
      - 숙련된 데이터 엔지니어는 고성능의 SQL 작성 방법을 알고 데이터웨어하우징 및 데이터 모델링의 기본 사항을 이해함
    - 파이썬 그리고/또는 자바
    - 분산 컴퓨팅
      - 데이터 양이 많아지고 데이터를 신속하게 처리하고 하는 요구사항이 늘어나면서 데이터엔지니어들은 분산 컴퓨팅 플랫폼을 사용하기 시작, 
      - 분산 컴퓨팅은 여러 시스템의 성능을 결합하여 대량의 데이터를 효율적으로 저장, 처리 및 분석함
        - 하둡 분산 파일 시스템(HDFS)를 통한 분산 파일 스토리지, 맵리듀스를 통한 처리, 피그(pig)를 통한 데이터 분석 등을 포함하는 하둡 에코시스템, 아파치 스파크는 하둡을 빠르게 능가하는 또 다른 인기 분산 처리 프레임워크 
      - 데이터 엔지니어는 이러한 프레임워크를 언제 어떻게 활용해야 하는지 알아야 함 
    - 기본 시스템 관리
      - 리눅스 명령줄에 능숙, 응용 프로그램 로그 분석, 크론 작업 예약, 방화벽 및 기타 보안 설정의 문제 해결과 같은 작업을 수행할 수 있어야함
    - 목표 지향적 사고방식
      - 데이터 엔지니어가 파이프라인을 구축하는 이유를 알 때 더 나은 아키텍처 결정을 내릴 수 있음
- 왜 파이프라인을 구축할 까?
  - 원본 데이터는 정리, 정형화, 정규화, 결합, 집계, 그리고 때로는 마스킹 또는 보안을 위해 정제됨 
- 어떻게 데이터 파이프라인을 구축할까?
  - 오픈소스도 있고, 상업용도 있고, 자체 개발 제품도 있음
  - 파이프라인 구축을 위한 가장 인기 있는 솔루션 및 프레임워크를 살펴보고 조직의 요구 사항과 제약 조건에 따라 어떤 제품을 사용할지 결정하는 방법을 알아봄
  - 파이프라인을 구축하고 이를 안정적이고 안전하게 제시간에 제공하고 처리하는 인프라를 지원해야함 

# 최신 인프라 데이터
- 데이터 소스의 다양성
  - 최신 데이터 인프라의 핵심 구성 요소
    - 데이터 소스의 다양성
    - 데이터 수집 도구
    - 클라우드 데이터 웨어하우스와 데이터 레이크
    - 모델링 도구 및 프레임워크
    - 워크플로 오케스트레이션 플랫폼 
- 소스 시스템 소유권
  - 데이터 수집(data ingestion) : 한 소스에서 데이터를 추출하여 다른 소스로 로드하는 것
  - 소스 시스템이 위치하는 곳이 어디인지를 이해하는 것은 여러 가지로 중요함
    - 타사 데이터 소스에 위치한 데이터에 액세스하려고 한다면 액세스 방법에 제한이 있을수 있음
    - 데이터를 사용자가 필요로 하는 형태에 맞추어 정의하는 등
    - 데이터 수집이 시스템에 의도하지 않는 부하를 가하는지부터 데이터를 점진적(incremental)으로 로드할 수 있는지 여부까지 다양한 과제가 발생하기 때문
- 수집 인터페이스 및 데이터 구조
  - 소스 데이터를 얻는 방법과 형식
    - Postgres 또는 MySQL 데이터베이스와 같은 애플리케이션 뒤에 있는 데이터베이스
    - REST API와 같은 시스템 상단의 추상화 계층
    - Apache Kafka와 같은 스트림 처리 플랫폼
    - 로그, 쉼표로 구분된 값(csv) 파일 및 기타 플랫 파일을 포함하는 공유 네트워크 파일 시스템(NFS) 또는 클라우드 스토리지 버킷
    - 데이터 웨어하우스 또는 데이터 레이크
    - HDFS 또는 HBase 데이터베이스의 데이터 
