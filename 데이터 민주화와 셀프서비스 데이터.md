# 서평

# 소개
- 데이터 민주화란 데이터에 쉽게 접근할 수 있도록 기반을 만들어 데이터를 잘 아는 사람부터 잘 모르는 사람까지 누구나 데이터를 쉽게 사용해 인사이트를 도출할 수 있도록 한느 것 
- 셀프서비스 데이터란 데이터 엔지니어나 데이터 과학자가 관여하지 않더라도 마케터, 사업 담당자, 서비스 운영 담당자 등 조직 내 모든 사람이 스스로 데이터에 접근해 인사이트를 추출할 수 있도록 만들어진 데이터 기반을 의미함 
- 원시 데이터에서 인사이트로의 여정 지도 
  - 전통적인 데이터 웨어하우스와 현재의 빅데이터 시대에서 인사이트를 추출하는 방식의 주요 차이점 
  - ||데이터 웨어하우징 시대의 인사이트 추출|빅데이터 시대의 인사이트 추출
    |:---:|:---:|:---:|
    |데이터 형식|정형 데이터|정형,반정형,비정형 데이터
    |데이터 특성|대용량 데이터|데이터의 4V:볼륨,속도,다양성,진시성
    |데이터 카탈로그 작성|데이터를 집계할 때 정의됨|데이터를 읽을 때 정의됨
    |인사이트의 신선함|인사이트는 주로 소급형(비드니스 마지막 주 기준 지표)|인사이트는 소급형,대화형,실시간,예측의 조합
    |쿼리 처리 방식|단일 솔루션으로 결합된쿼리 프로세서와 데이터 스토리지|쿼리 처리와 데이터 스토리지가 분리됨
    |데이터 서비스|단일 솔루션으로 통합|작업에 적합한 도구를 선택하는 데 많은 치환을 허용하는 믹스 앤 매치(mix-and-match)방식
  - 발견
    - 모든 인사이트 도출 프로젝트는 사용 가능한 데이터 세트와 개발 산출물을 발견하고, 인사이트를 발전시키는 데 필요한 추가 데이터를 수집하는 것부터 시작함
    - 데이터 세트의 메타데이터 세부 정보 발견
      - 마일스톤은 데이터가 생성된 위치, 데이터 속성이 생성된 방법 등 메타데이터 속성을 이해하는 것 
      - 메타데이터를 수집하고 상호 연결이 가능하려면 데이터스토어, 수집 프레임워크, 스케줄러, 메타데이터 카탈로그, 규정 준수 프레임워크 등에 접근이 필요함
      - 마일스톤을 완료하는 데 걸리는 시간은 해석시간(time to interpret)을 지표로 추적함 
    - 사용 가능한 데이터 세트 및 아티팩트 검색
      - 마일스톤은 모든 관련 데이터 세트와 아티팩트, 예를 들어 뷰, 파일, 스트림, 이벤트, 지표, 대시보드, ETL, 임시 쿼리를 찾는 것이라고 할 수 있음 
      - 탐색 시간 지표(time to find)로 추적됨 
    - ML 모델에서의 기능 재사용 또는 생성
      - 피처화 시간(time to featurize) 지표로 추적함 
    - 누락된 데이터 집계
      - 비즈니스 대시보드를 만들려면 식별된 데이터 세트(고객 활동 및 결제 청구 기록)를 결합해 리텐션 리스크(retention risk)에 대한 인사이트를 생성
      - 데이터 가용성 확보 시간(time to data availability)
    - 클릭스트림 이벤트 관리
      - 클릭, 뷰와 이전 애플리케이션 페이지, 방문자 기기 유형 등 연관된 맥락까지의 고객 활동을 분석해야 함
      - 클릭스트림 데이터(clickstream data)는 우선 수집, 필터링되고 보강돼야 인사이트 생성에 사용할 수 있음 
      - 클릭 시간(time to click)지표로 추적함 
  - 준비
    - 준비 단계에서는 인사이트 추출을 위해 실제 비즈니스 로직 구축용 데이터를 준비하는데 집중함. 준비는 데이터 집계, 정리, 표준화, 변환, 비정규화를 포함하는 반복적이고 시간 집약적인 작업이며 여러 가지 도구와 프레임워크를 포함함
    - 규제 준수 요건을 충족하기 위해 데이터 거버넌스(data governance)를 보장함 
  - 중앙 저장소 내의 집계 데이터 관리 
    - 비즈니스 대시보드는 과거 일괄 처리 데이터 스트리밍 행동 데이터 이벤트를 결합해야 함. 데이터는 데이터 모델과 온디스크 형식을 고려해 효율적으로 유지 관래돼야 함
    - 데이터 레이크 관리 시간(time to data lake management) 지표에 의해 추적됨 
  - 데이터의 구조화, 정리, 보강, 유효성 검사
    - 랭글링 시간(time to wrangle) 지표로 추적함 
  - 데이터 권한 규정 준수 보장
    - 규정 준수(compliance)는 고객 경험을 인사이트로 더 잘 제공하는 것과 고객 동의 내에서 데이터가 사용되도록 보장하는 것 사이의 균형 조정 행위 
    - 규정 준수 시간(time to comply) 지표로 추적함 
  - 구축
    - 인사이트를 추출하는 데 필요한 실제 로직을 작성하는 데 집주앟ㅁ
    - 데이터 액세스 및 분석을 위한 최상의 접근 방식 결정 
      - 구축 단계의 출발점은 인사이트 로직을 작성하고 실행 전략을 결정하는 것 
      - 장기간 실행되는 일괄 처리(batch) 프로세스는 Hive 또는 Spark에 있는 반면 짧은 대화형 쿼리는 Presto 클러스터에서 실행됨 
      - 가상화 시간(time to virtualize)지표로 추적함
    - 변환 로직 작성
      - 대시보드 또는 모델 인사이트의 실제 로직은 ETL, ELT 또는 스트리밍 분석 패턴으로 작성됨. 비즈니스 로직은 변화에 대한 관리가 용이할 뿐만 아니라 실행성과 확장성이 있는 실제 코드로 번역돼야 하며 가용성, 품질, 변경 관리를 위해 모니터링돼야 함 
      - 변환 시간(time to transform) 지표로 추적함
    - 모델 학습
      - 학습은 CPU와 GPU 같은 전문 하드웨어가 조합된 서버로 구성된 팜(farm)에서 운영됨 
      - 학습 시간(time to train) 지표에 의 추적됨 
    - ML 모델 변경 사항의 지속적인 통합 
      - ML 모델 파이프라인은 소스 스키마 변경, 형상 로직, 종속 데이터 세트, 데이터 처리 설정, 모델 알고리즘을 통해 지속적으로 진화함 
      - 통합 시간(time to integrate) 지표에 의해 추적됨 
    - 인사이트 A/B 테스트
      - 버킷 테스트, 분할 테스트 또는 통제된 실험이라고 알려진 A/B 테스트는 데이터 중심 의사 결정을 위한 표준 접근 방식이 되고 있음 
      - A/B 테스트 시간(time to A/B test)
  - 운영화
    - 여정 지도의 운영화 단계에서는 인사이트가 프로덕션에 배포됨
    - 쿼리 검증 및 최적화
      - 어디에나 만능으로 적용되는 쿼리의 최적 조절 값은 없고 데이터 모델, 쿼리 유형, 클러스터 크기, 동시 쿼리 로드 등에 따라 달라짐. 쿼리 최적화는 지속적인 활동. 
      - 최적화 시간(time to optimize) 지표에 의해 추적됨 
    - 파이프라인 오케스트레이션 
      - 오케스트레이션은 파이프라인 서비스 수준 계약(SLA, Service Level Agreement)을 보장하고 기본 리소스의 효율적인 활용을 보장하는 균형 조정 행위 
      - 파이프라인은 데이터 수집, 준비, 변환, 학습, 배포 전반에 걸쳐 서비스를 호출함. 데이터 사용자가 이러한 서비스 전반에서 정확성, 견고성, 적시성을 모니터링하고 디버깅하는 것이 중요함 
      - 파이프라인 오케스트레이션은 멀티테넌트(multitenant)로, 여러 팀과 비즈니스 유즈 케이스를 지원함 
      - 오케스트레이션 시간(time to orchestrate) 지표에 의해 추적됨 
    - ML 모델 배포 
      - 배포 시간(time to deploy) 지표 
    - 인사이트 품질 모니터링
      - 인사이트 품질 확보 시간(time to insight quality) 지표 
    - 지속적인 비용 모니터링
      - 비용 관리는 종래의 종량제 모델과 달리 사용량에 따라 선형적으로 비용이 증가하는 클라우드에서 특히 중요함 
      - 비용 최적화 시간(time to optimize cost) 지표로 추적됨 
- 인사이트 시간 스코어가드 정의
  - 인사이트 시간(time to insight)은 원시 데이터에서 인사이트까지의 전체 여정을 완료하는 데 걸리는 시간을 측정하는 전반적인 지표 
  - 각 마일스톤의 척도를 합치면 전체 인사이트 시간 척도가 됨 
  - 인사이트 시간 스코어가드(scorecard)를 사용함. 전체 여정 지도에서 가장 시간이 많이 걸리는 마일스톤을 찾는 것이 이 활동의 목표 
    - 해석 시간(time to intepret) : 데이터 세트의 메타데이터 세부 정보를 인사이트 개발에 사용하기 전에 해석하는 마일스톤에 연관된 지표 
    - 탐색 시간(time to find) : 검색 관련 데이터 세트와 아티팩트의 마일스톤에 연관된 지표 
    - 피처화 시간(time to featurize) : ML 모델 학습에 필요한 기능 관리 마일스톤과 연관된 지표 
    - 데이터 가용성 확보 시간(time to data availability) : 사일로 간에 데이터를 이동하는 마일스톤과 연관된 지표 
    - 클릭 시간(time to click) : 클릭스트림 데이터 이벤트의 수집, 관리, 분석 마일스톤과 연관된 지표 
    - 데이터 레이크 관리 시간(time to data lake management) : 중앙 저장소에서 데이터를 관리하는 마일스톤과 연관된 지표 
    - 랭글링 시간(time to wrangle) : 데이터 구조화, 정리, 보강, 검증의 마일스톤과 연관된 지표 
    - 규정 준수 시간(time to comply) : 데이터 권한 규정 준수를 보장하는 마일스톤과 연관된 지표 
    - 가상화 시간(time to virtualize) : 데이터 구축, 분석의 접근 방식을 선택하는 마일스톤과 연관된 지표 
    - 변환 시간(time to transform) : 데이터 및 ML 파이프라인에서 변환 로직을 구현하는 마일스톤과 연관된 지표 
    - 학습 시간(time to train) : ML 모델 학습 마일스톤과 관련된 지표 
    - 통합 시간(time to integrate) : ML 파이프라인의 코드, 데이터, 설정의 변경을 통합하는 마일스톤과 연관된 지표 
    - A/B 테스트 시간(time to A/B test) : A/B 테스트의 마일스톤과 연관된 지표 
    - 최적화 시간(time to optimize) : 쿼리 및 빅데이터 프로그램을 최적화하는 마일스톤과 연관된 지표 
    - 오케스트레이션 시간(time to orchestrate) : 프로덕션의 파이프라인 조정 마일스톤과 연관된 지표 
    - 배포 시간(time to deploy) : 프로덕션에 인사이트를 배포하는 마일스톤과 연관된 지표 
    - 인사이트 품질 확보 시간(time to insight quality) : 생성된 인사이트의 정확성을 보장하는 마일스톤과 연관된 지표 
    - 비용 최적화 시간(time to optimize cost) : 비용을 최적화하는 마일스톤과 연관된 지표 
- 셀프서비스 로드맵 실행 
  - 현재 스코어카드를 정의하는 것부터 시작
  - 데이터 사용자에 대한 설문 조사를 기반으로 여정 지도를 가장 많이 늦추는 두 세가지 지표를 식별하고 현재 작업이 구현되는 방식에 대한 기술적 분석을 수행하라. 지표의 중요도는 현재 프로세스, 데이터 사용자 기술, 기술 구성 요소, 데이터 속성, 유스 케이스 요구 사항에 따라 기업마다 다르다는 것을 인식하라
  - 각 지표는 매슬로우의 구현 패턴 계층부터 시작하라. 각 장은 하나의 지표에 대한 자동화 단계가 증가하는 패턴을 다룸 
  - 각 분기마다 지표 우선순위를 전념하고 셀프서비스화에 집중하면서 단계별 기기, 걷기, 달리기 전략을 따르자 

# 셀프서비스 데이터 발견 
## 메타데이터 카탈로그 서비스 
- 빅데이터 시대 이전에는 데이터를 중앙 웨어하우스에 추가하기 전에 먼저 분류함 
- 쓰기스키마(schema-on-write) : 스키마, 계보, 소유자, 비즈니스 분류법 등을 포함한 메타데이터 세부 정보를 먼저 카탈로그화했음. 
- 읽기스키마(schema-on-read) : 오늘날 데이터 레이크의 접근 방식에는 머저 데이터를 집계한 뒤 데이터 사용 시에 데이터 세부 정보를 추론함 
- 데이터 세트 이해하기
  - 데이터 과학자는 새로운 모델을 구축하거나 새로운 측정 기준을 수립하거나 임시 분석을 수행하는 첫 번째 단계로 데이터의 출처, 사용 방법, 지속 방법 등에 대한 세부 정보를 이해해야 함 
  - 메타데이터 카탈로그는 질문에 대한 단일 진실 공급원(SSOT, Single Source Of Truth) 
- 데이터 세트 분석하기
  - 데이터 과학자는 데이터 세트 속성과 쿼리 유형을 기반으로 작업에 적합한 도구를 사용하며 ,하나의 데이터 세트를 Pig, Spark, Presto, Hive 등 여러 쿼리 엔진에서 번갈아가며 사용할 수 있음 
- 지식 확장하기 
  - 팀지식 : 데이터 과학자는 프로젝트를 위해 서로 다른 데이터 세트로 작업하면서 비즈니스 어휘, 데이터 품질 등에 대한 추가 세부 정보를 발견함 
- 해석 시간 최소화
  - 해석 시간은 데이터 과학자가 인사이트를 구축하기 전에 데이터 세트의 세부 정보를 이해하는 데 걸리는 시간을 말함 
  - 기술 메타데이터 추출하기
    - 기술 메타데이터는 데이터 세트의 논리적, 물리적 메타데이터 세부 정보로 구성됨 
    - 물리적 메타데이터는 생성 및 수정 타임스탬프, 물리적 위치 및 형식, 스토리지 계층, 보존 세부 정보와 같은 물리적 레이아웃과 지속성에 관련된 세부 정보를 포함함
    - 논리적 메타데이터에는 데이터 세트 스키마, 데이터 원본 세부 정보, 데이터 세트를 생성하는 프로세스 ,데이터 세트의 소유자 및 사용자가 포함됨 
    - 기술 메타데이터는 여러 소스 간 연관 관계를 고려하지 않고 각각의 데이터 소스를 크롤링 해서 추출함 
    - 메타데이터를 수집하는 데 세 가지 주요 과제 
      - 형식 차이 
      - 스키마 유추
      - 변경 추적 
- 운영 메타데이터 추출하기 
  - 두 가지 주요 버킷 
    - 계보(lineage)
      - 데이터 세트가 어떻게 생성됐는지와 다른 데이터 세트에 대한 종속성을 추적함 
      - 특정 데이터 세트의 계보는 모든 종속 입력 테이블, 파생 테이블, 출력 모델 및 대시보드를 포함함 
      - 최종 출력 도출을 위해 변환 로직을 구현하는 작업이 포함됨 
    - 데이터 프로파일링 통계
      - 가용성 및 품질 통계
      - 데이터 세트의 열 수준 및 설정 수준 특성을 포착함 
      - 완료 시간, 처리된 데이터 ,파이프라인과 관련된 오류를 포착하는 실행 통계도 포함됨 
  - 서로 다른 다양한 유형의 데이터베이스, 스케줄러, 쿼리 엔진, BI(비즈니스 인텔리전스) 툴로 인해 서로 다른 처리 프레임워크, 데이터 플랫폼, 스케줄링 시스템에 걸친 전반적인 데이터 흐름과 계보를 이해하는 것은 어려운 과제. 처리 프레임워크의 다양성을 고려하면서 세부 사항을 짜맞춰 연결하는 것이 이 과제에 해당함. UDF, 외부 매개변수 등의 경우에는 코드로부터 계보를 유추하는 것이 쉽지 않기 때문 
  - 팀 지식 수집하기 
    - 팀 지식의 네 가지 범주 
      - 주석, 문서, 속성 설명 형식의 사용자 정의 메타데이터
      - 비즈니스 직관적 계층 구조(business-intuitive hierarchy)에서 데이터 개체 및 메트릭을 연결하고 구성하기 위한 비즈니스 분류법 또는 어휘
      - 규정 준수, 개인 식별 가능 정보(PII, Personally identifiable information) 데이터 필드, 데이터 암호화 요구 사항 등과 같은 측면의 데이터 세트 상태
      - 가장 인기 있는 테이블, 쿼리, 기타 형태의 ML 증강 메타데이터(ML-augmented metadata) 
- 구현 패턴
  - 메타데이터 카탈로그 서비스에 대한 자동화 수준 
    - 소스 특화 커넥터 패턴 : 서로 다른 데이터 소스에 연결하고 데이터와 연결된 메타데이터 정보를 추출하는 작업을 간소화함
    - 계보 상관 패턴 : 소스 테이블과 대상 테이블을 상관시키는 변환 계보를 추출하는 작업을 자동화함
    - 팀 지식 패턴 : 비즈니스 문맥 수집과 데이터 사용자 간의 지식 공유를 단순화함 
  - 메타데이터 카탈로그 서비스는 금융산업규제당국(finra)의 Herd, 우버의 Databook, 링크드인의 WhereHows와 Data Hub, 넷플릭스의 Metacat, 아파치의 Atlas 프로젝트, AWS Glue 같은 클라우드 서비스가 있음 
  - 소스 특화 커넥터 패턴
    - 소스 특화 커넥터 패턴은 기술 메타데이터 집계를 위해 소스에서 메타데이터를 추출함
    - 데이터 세트는 URN(Uniform Resource Name) 기반 이름을 사용해 식별됨 
    - 두 가지 구성 요소(building block)
      - 커스텀 추출기
        - 소스 특화 커넥터는 메타데이터를 연결하고 지속적으로 가져오는 데 사용됨. 커스텀 추출기를 RDBMS, Hive, 깃허브 등의 데이터스토어에 연결하기 위해 자격 증명을 인증하려면 적절한 액세스 권한이 필요함 
        - 추출기가 소스에 연결되면 데이터 세트의 형식, 스키마, 관련 속성을 결정하는 분류자(classifier)를 구현해 세부 정보를 수집함 
      - 연합 지속성(federated persistence)
        - 메타데이터 세부 정보는 정규화된 방식으로 유지됨 
  - 계보 상관 패턴(lineage correlation pattern) 
    - 데이터 및 작업에 걸친 운영 메타데이터를 연결해 실행 통계와 결합함 
    - 작업 실행 레코드를 계보와 결합함으로써 데이터 신선도, 서비스 수준 협약(SLA, Service Level Agreement), 영향을 받는 특정 테이블의 다운스트림 작업, 사용량에 따른 파이프라인 내의 테이블 순위 등에 관한 질문에 답변할 수 있음 
      - 쿼리 구문 분석
      - 파이프라인 상관관계
      - 실행 통계를 통한 계보 보강 
    - 아파치 Atlas는 Sqoop, Hive, Kafka, Storm 등 여러 Hadoop 에코시스템 구성 요소에 걸쳐 계보를 추출함. Atlas는 Hadoop job ID가 주어지면 job history 노드에서 job conf 쿼리를 수집함. Sqoop 작업에도 비슷한 접근법이 적용돼 있음. 
    - Atlas는 테이블 수준 계보 외에도 다음과 같은 유형의 종속성을 추적해 열 수준 계보를 지원함
      - 단일 종속성 : 출력 열의 값이 입력 열과 동일함 
      - 표현 종속성 : 출력 열은 런타임 시 입력 열의 일부 표현식(Hive SQL 표현식)에 의해 변환됨
      - 스크립트 종속성 : 출력 열은 사용자가 제공한 스크립트에 의해 변환됨 
      - 강점은 종속성을 재구성하는 간섭 없는 방법을 제공함. 단점은 계보가 쿼리 유형을 100% 커버하지 못하고 대략적이라는 것 
  - 팀 지식 패턴
    - 팀 지식의 세 가지 주요 유형
      - 데이터 문서 : 속성 의미, 열거형, 데이터 설명의 세부 정보가 포함됨
      - 비즈니스 분류법 및 태그 : 비즈니스 영역과 주제 영역에 따라 데이터를 분류하는 분려법으로, 비즈니스 내에서 사용되는 개념이 포함됨 
      - 플리거블 검증(pluggable validation) : 테이블 소유자는 테이블에 대한 감사 정보를 메타데이터로 제공할 수 있음. 테이블 작성에 사용할 열 기본값과 검증 규칙을 제공할 수 있음 

## 검색서비스
- 인사이트를 개발하는 반복적인 프로세스 중 연관 데이터 세트(테이블, 뷰, 스키마, 파일, 스트림, 이벤트)와 아티팩트(지표, 대시보드, 모델, ETL, 임시 쿼리)를 찾는 것에 초점을 맞춤 
- 검색 서비스를 통해 데이터 사용자는 키워드, 와일드카드 검색, 비즈니스 용어 등을 사용해 원하는 것을 표현함. 
- 소스 발견, 데이터 세트 및 아티팩트 인덱싱, 결과 순위 지정, 액세스 거버넌스(access governance) 보장, 지속적인 변경 관리 등의 어려운 업무를 보이지 않는 곳에서 수행함 
- 데이터 세트 및 아티팩트 인덱싱
  - 인덱싱의 두 가지 작업
    - 데이터 세트와 아티팩트의 소스 찾기
    - 해당 소스를 조사해 스키마와 메타데이터 속성 같은 세부 정보 수집 
  - 접근 제어하기 
    - 데이터 세트 및 아티팩트 소스에 안전하게 연결
    - 검색 결과에 대한 접근 제한 
- 검색 서비스를 구축하는 데는 세 가지 주요 모듈 
  - 인덱서 모듈 
    - 사용 가능한 데이터 세트와 아티팩트를 발견하고, 스키마 및 메타데이터 속성을 추출하고, 카탈로그에 추가함. 이 모듈은 변경 내용을 추적하고 세부 정보를 지속적으로 업데이트함 
  - 순위 모듈 : 관련성과 인기도의 조합에 따라 검색 결과의 순위를 매기는 역할을 함
  - 액세스 모듈 : 데이터 사용자에게 표시되는 검색 결과가 접근 제어 정책을 준수하도록 함 
- 요구 사항 순위 매기기 
  - 데이터 세트와 아티팩트에 관련된 메타데이터의 범주
  - |메타데이터 범주|속성 예|
    |:---:|:---:|
    |기본|크기,형식,최종 수정, 가명, 접근 제어 목록
    |콘텐츠 기반|스키마,기록 수,데이터 핑거프린트,키 필드
    |계보|읽기 작업,쓰기 작업, 다운스트림 데이터 세트, 업스트림 데이터 세트
    |사용자 정의|태그, 카테고리
    |사람|소유자,팀 접근, 팀 업데이트
    |시간|변경 히스토리 
  - 접근 제어 요구 사항
    - 사용자별 정책은 역할 기반 접근 제어(RBAC, Role-Based Access Control), 속성별 정책은 속성 기반 접근 제어(ABAC, Attribute-Based Access Control), 사용자 그룹에 대한 가시성 제한은 RBAC 정책이며 데이터 태그 또는 개인 식별 정보(PII)에 대해 정의된 정책은 ABAC 정책 
    - 다른 특수 처리 요구 사항이 필요할 수 있음 
      - 행 또는 열 값의 마스킹 
      - 데이터 세트와 아티팩트를 특정 타임스탬프까지 볼 수 없도록 하는 시간 변동 정책(분기별 결과가 공식적으로 발표된 날짜까지 표를 볼 수 없음) 
  - 비기능 요구 사항
    - 비기능 요구 사항(NFR,Nonfunctional Requirement)
      - 검색 응답 시간 : 검색 서비스가 초 단위로 검색 쿼리에 응답하도록 하는 것이 중요함 
      - 대규모 인덱 지원을 위한 확장 : 기업이 성장함에 따라 수천 개의 데이터 세트와 아티팩트를 지원하도록 검색 서비스를 확장하는 것이 중요함 
      - 새로운 소스에 대한 손쉬운 온보딩 : 데이터 소스 소유자가 검색 서비스에 소스를 추가할 때의 UX를 단순화해야 함 
      - 자동 모니터링과 알림 : 서비스 상태는 모니터링하기 쉬워야 함. 프로더션 중 문제가 발생하면 자동 경고가 생성돼야 함 
- 구현 패턴
  - 기존 작업 지도에 따라 검색 서비스에 대한 자동화 수준은 세 가지 
    - 푸시 풀 인덱서 패턴 : 사용 가능한 데이터 세트와 아티팩트를 발견하고 지속적으로 업데이트함 
    - 하이브리드 검색 순위 패턴 : 데이터 사용자가 데이터 프로젝트의 요구 사항에 맞는 가장 관련성 높은 데이터 세트와 아티팩트를 찾을 수 있도록 결과의 순위를 매김 
    - 카탈로그 접근 제어 패턴 : 데이터 사용자 및 기타 특성에 따라 검색 서비스에 표시되는 데이터 세트와 아티팩트에 대한 접근을 제어함 
  - 푸시 풀 인덱서 패턴
    - 기업의 사일로 전체에서 사용 가능한 데이터 세트와 아티팩트를 발견하고 업데이트함 
    - 데이터 세트를 인덱싱할 수 있는 넷플릭스의 오픈소스 Metacat 카탈로그
      - Metacat은 데이터 세트 세부 정보를 추출하기 위해서뿐 아니라 데이터 소스가 Kafka와 같은 이벤트 버스에 업데이트를 게시하는 푸시 알림 모델에서도 풀 모델을 사용함. 데이터 소스는 명시적 REST API를 호출해 변경 이벤트를 게시할 수도 있음. Metacat에서는 변경 사항이 아마존 SNS에도 게시됨. SNS에 이벤트를 게시하면 데이터 플랫폼의 다른 시스템이 이러한 메타데이터 또는 데이터 변경에 따라 반응을 할 수 있음 
      - 강점 
        - 인덱스 업데이트가 시기적절함. 새 소스는 주기적으로 크롤링되고 변경 이벤트 처리를 위해 이벤트 버스에 푸시됨 
        - 다양한 범주의 메타데이터 속성을 추출하고 업데이트하기 위한 확장 가능한 패턴
        - 푸시 및 풀 방식의 조합을 고려할 때 많은 소스를 지원하도록 확장 가능함 
      - 약점
        - 다양한 소스 유형에 대한 구성과 배포가 어려울 수 있음 
        - 풀을 통해 세부 정보에 접근하려면 소스 권한이 필요한데, 규제된 소스에는 우려 사항이 될 수 있음 
  - 하이브리드 검색 순위 패턴
    - 문자열 입력이 주어지면 순위 패턴이 데이터 세트와 아티팩트의 목록을 생성함. 이 목록은 테이블 이름, 비즈니스 어휘 개념, 분류 태그 등의 문자열로 구성될 수 있음 
    - 이 패턴의 성공 기준은 가장 관련성 높은 결과가 목록의 상위 다섯 건에 들어있는지 여부 
    - 하이브리드 검색 순위 패턴의 예로는 아문센(Amundsen) 오픈소스 프로젝트 
      - 아문센은 데이터 세트와 아티팩트를 인덱싱함. 입력 구문 분석에서는 정확한 매칭 개선을 위해 자동 완성(type-ahead) 기능을 구현함. 입력 문자열은 와일드카드와 키워드, 범주, 비즈니스 어휘 등을 지원함 
      - 아문센은 얇은 Elasticsearch 프록시 계층을 구현해 카탈로그와 상호 작용함으로써 퍼지 검색을 가능하게 함. 
      - 메타데이터는 Neo4j에서 유지됨. 인덱스 구축을 위해서는 데이터 수집 라이브러리를 사용함 
  - 카탈로그 제어 패턴
    - 메타데이터 카탈로그에 접근 제어를 시행하고 세분화된 권한 부여 및 접근 제어를 위한 중앙 집중식 접근 방식을 제공함 
    - 카탈로그 접근 제어 패턴의 세 단계 
      - 분류
      - 정의
        - 정책 정의는 크게 두 가지의 광범위한 버킷으로 나뉨. 
        - 역할 기반 접근 제어 : RBAC,Role-Based Access Control, 사용자를 기반으로 정책이 정의됨 
        - 속성 기반 접근 제어 : ABAC,Attriubte-Based Access Control, 사용자 정의 태그, IP 주소를 기반으로 하는 지리적 태그, 시간 기반 태그 등과 같은 속성을 기반으로 정책이 정의됨 
      - 시행 
        - 검색 결과에서 접근 제어 정책을 시행하는 세 가지 방법
        - 모든 사용자를 위한 기본 메타데이터 : 검색 쿼리에 대한 응답 결과로 기본 메타데이터(이름,설명,소유자,업데이트 날짜, 사용자 정의 태그 등)를 모든 사용자엑 접근 권한 여부에 관계없이 표시함 
        - 선택적 고급 메타데이터 : 선별된 사용자가 접근 제어 정책에 따라 열 통계 및 데이터 미리 보기와 같은 고급 메타데이터를 가져옴 
        - 열 및 행 마스킹 ; 접근 제어에 따라 동일한 데이터 세트의 열 개수는 물론 데이터 미리 보기의 행이 달라짐 
    - 세분화된 권한 부여와 접근 제어를 위해 널리 사용되는 오픈소스 솔루션의 예로 아파치 Ranger 
      - Atlas 카탈로그와 모든 Hadoop 에코시스템에 대한 보안 정책 구현을 위한 중앙 집중식 프레임워크를 제공함 
      - 개별 사용자, 그룹, 접근 유형, 사용자 정의 태그, IP 주소와 같은 동적 태그 등을 기반으로 한 RBAC 및 ABAC 정책을 지원함 
    - 강점
      - 카탈로그 수준의 중장 집중식 접근 제어 정책을 통해 쉽게 관리할 수 있음 
      - 다양한 사용자 및 유스 케이스에 따라 조정 가능한 접근 제어 기능을 제공함 
    - 약점
      - 카탈로그 접근 제어 정책이 데이터 원본 정책과 동기화되지 않을 수 있음

# 피처 저장소 서비스 
- 요구 사항 정의
  - 피처 연산
    - 피처 비닝(feature binning) : 연속 피처를 개별 피처로 변환
    - 피처 해싱(feature hashing) : 원-핫 인코딩된 피처의 메모리 풋프린트(memory footprint)를 줄이기 위함 
    - Spark는 대규모 데이터 세트로 작업하는 사용자 간의 데이터 랭글링에 선호됨. 작은 데이터 세트로 작업하는 사용자는 Numpy, pandas와 같은 프레임워크를 선호함. 피처 엔지니어링 작업은 노트북(notebook), 파이썬 파일 또는 .jar 파일을 사용해 빌드되고 samza, Spark, Flink, Beam과 같은 연산 프레임워크에서 실행됨 
- 구현 패턴
  - 하이브리드 피처 연산 패턴 : 피처 연산을 위한 일괄 처리 및 스트림 처리를 결합하는 패턴을 정의함 
  - 피처 레지스트리 패턴 : 학습자 추론을 위한 기능을 제공하는 패턴을 정의함 
- 하이브리드 피처 연산 패턴 
  - 세 가지 구성 요소 
    - 일괄 처리 연산 파이프라인 
      - 전통적인 일괄 처리 작업에서는 몇 시간마다 또는 매일 ETL 작업으로 실행돼 과거 피처 값을 계산함 
    - 스트리밍 연산 파이프라인
      - 실시간 메시지 버스의 데이터 이벤트에 대해 수행되는 스트리밍 분석을 통해 낮은 지연 시간으로 피처 값을 계산함 
    - 피처 사양 
      - 일관성을 보장하기 위해 데이터 사용자는 새로운 피처에 대한 파이프라인을 생성하는 대신 도메인 특화 언어(DSL, Domain-Specific Language)를 사용해 피처 사양을 정의함 
  - 우버의 Michelangelo
    - 아파치 Spark와 Samza의 조합을 구현함. Spark는 일괄 처리 피처를 연산하는 데 사용되며 결과는 Hive에서 유지됨. 일괄 처리 작업은 피처 그룹을 연산하고, 이를 컬럼당 피처로서 단일 Hive 테이블에 씀 
    - 스트리밍 파이프라인의 경우 Kafka 토픽은 Samza 스트리밍 작업과 함께 소비돼 Cassandra에서 키-값 형식으로 유지되는 준실시간 피처 값을 생성함 
    - 히스토리 피처의 대량 사전 연산 및 과거 피처의 로딩이 정기적으로 Hive에서 Cassandra로 이뤄짐 
  - 강점 
    - 일괄 처리 및 스트리밍 타임 윈도우에 걸쳐 최적의 피처 연산 성능을 제공함 
    - 피처를 정의하는 DSL은 학습과 추론을 위한 파이프라인 구현 불일치에 관련된 모순을 방지함 
  - 약점 
    - 프로덕션 환경에서 구현되고 관리하는 것은 쉽지 않음. 데이터 플랫폼이 상당히 성숙해야 함 
- 피처 레지스트리 패턴 
  - 피처를 쉽게 검색하고 관리할 수 있음 
  - Hopsworks 피처 저장소 
    - 사용자가 피처 저장소를 SQL 또는 프로그래밍 방식으로 쿼리하면 피처 저장소는 피처를 데이터프레임으로 변환함 
    - Hopworks 피처 저장소의 피처 그룹 및 학습 데이터 세트는 Spark/Numpy/pandas 작업에 연결돼 있어 필요할 때 피처를 재현하고 재연산할 수 있음 
  - 강점 
    - 학습 데이터 세트와 피처 값의 성능 기준에 맞는 성능을 제공함 
    - 데이터 사용자의 피처 분석 시간을 단축함 
  - 약점 
    - 수백 개의 모델을 제공하는 동안 잠재적인 성능 병목 현상이 나타남
    - 피처가 계속 증가해 피처 분석을 위한 확장을 지속함 

# 데이터 이동 서비스 
- 원시 데이터를 전문 쿼리 엔진으로 이동
  - 점점 더 많은 쿼리 처리 엔진이 다양한 유형의 쿼리 및 데이터 워크로드에 최적화되고 있음 
  - 시계열 데이터 세트의 데이터 분할(slice-and-dice) 분석의 경우 데이터는 Druid와 Pinot 같은 전문 분석 솔루션으로 복사됨 
- 데이터 품질 검증 
  - 실제 배포 환경에서는 소스 오류, 어댑터 실패, 집계 문제 등과 같은 다양한 이유로 품질 오류가 발생할 수 있음
  - 데이터 이동 중 데이터 패리티(data parity) 모니터링은 데이터 품질 오류를 발견하지 못하거나 비즈니스 지표 및 ML 모델의 정확성에 영향을 미치지 않도록 하기 위해 반드시 필요함 
- 요구 사항 정의
  - 데이터 이동 서비스의 네 가지 주요 모듈 
    - 수집 모듈 : 소스에서 대상 데이터스토어로 데이터를 한 번 또는 지속적으로 복사하는 것을 담당함 
    - 변환 모듈 : 소스에서 대상으로 복사되는 데이터의 변환을 담당함 
    - 규정 준수 모듈 : 분석 목적으로 데이터를 이동함으로써 규정 준수 요구 사항을 충족함 
    - 검증 모듈 : 소스와 대상 간의 데이터 패리티를 보장함 
수집 요구 사항 
  - 요구 사항 수집의 일부로 수집할 데이터스토어 범주
    - |데이터스토어 범주|인기 있는 예시|
      |:---:|:---:|
      |트랜잭션 데이터베이스|Oracle, SQL Server, MySQL|
      |NoSQL 데이터스토어|Cassandra, Neo4j, MongoDB|
      |파일 시스템|Hadoop FileSystem, NFS appliance, Samba|
      |데이터 웨어하우스|Vertica, Oracle Exalogic, AWS Redshift|
      |오브젝트 저장소|AWS S3|
      |메시징 프레임워크|Kafka, JMS|
      |이벤트 로그|Syslog,NGNIX logs|
  - 데이터 규모
    - 데이터 엔지니어가 이해해야 하는 구모의 주요 측면
      - 행의 개수로 볼 때 테이블의 크기가 얼마나 큰가(즉, 수천 개의 행이 있는지, 수십억 개의 행이 있는지)?
      - TB 단위로 표의 대략적인 크기는 얼마인가?
      - 지속적으로 복사해야 하는 테이블의 수는 얼마인가?
    - 삽입, 업데이트, 삭제 횟수와 관련해 테이블이 빠르게 변경되는지 여부를 추정하는 변화율 
- 규정 준수 요구 사항 
  - 구정 준수에 대한 여러 측면을 고려해야 함
  - 매슬로우의 욕구 계층 구조(역피라미드) 
    - 삼각형의 맨 아래에는 규정 준스를 위한 3A인 인증(authentication), 접근 제어(access control), 감사 추적(audit tracking)이 있음 
    - 그 위에 암호화 및 마스킹과 관련해 개인 식별 정보(PII)를 처리할 때 고려해야할 사항이 있음 
    - 다음은 SOX,PCI 등과 같은 규정 주수 관련 요구 사항 
    - 맨 위에는 CCPA, GDPR 등의 법률에 따른 데이터 권한 준수가 있음 
