# 서평

# 소개
- 데이터 민주화란 데이터에 쉽게 접근할 수 있도록 기반을 만들어 데이터를 잘 아는 사람부터 잘 모르는 사람까지 누구나 데이터를 쉽게 사용해 인사이트를 도출할 수 있도록 한느 것 
- 셀프서비스 데이터란 데이터 엔지니어나 데이터 과학자가 관여하지 않더라도 마케터, 사업 담당자, 서비스 운영 담당자 등 조직 내 모든 사람이 스스로 데이터에 접근해 인사이트를 추출할 수 있도록 만들어진 데이터 기반을 의미함 
- 원시 데이터에서 인사이트로의 여정 지도 
  - 전통적인 데이터 웨어하우스와 현재의 빅데이터 시대에서 인사이트를 추출하는 방식의 주요 차이점 
  - ||데이터 웨어하우징 시대의 인사이트 추출|빅데이터 시대의 인사이트 추출
    |:---:|:---:|:---:|
    |데이터 형식|정형 데이터|정형,반정형,비정형 데이터
    |데이터 특성|대용량 데이터|데이터의 4V:볼륨,속도,다양성,진시성
    |데이터 카탈로그 작성|데이터를 집계할 때 정의됨|데이터를 읽을 때 정의됨
    |인사이트의 신선함|인사이트는 주로 소급형(비드니스 마지막 주 기준 지표)|인사이트는 소급형,대화형,실시간,예측의 조합
    |쿼리 처리 방식|단일 솔루션으로 결합된쿼리 프로세서와 데이터 스토리지|쿼리 처리와 데이터 스토리지가 분리됨
    |데이터 서비스|단일 솔루션으로 통합|작업에 적합한 도구를 선택하는 데 많은 치환을 허용하는 믹스 앤 매치(mix-and-match)방식
  - 발견
    - 모든 인사이트 도출 프로젝트는 사용 가능한 데이터 세트와 개발 산출물을 발견하고, 인사이트를 발전시키는 데 필요한 추가 데이터를 수집하는 것부터 시작함
    - 데이터 세트의 메타데이터 세부 정보 발견
      - 마일스톤은 데이터가 생성된 위치, 데이터 속성이 생성된 방법 등 메타데이터 속성을 이해하는 것 
      - 메타데이터를 수집하고 상호 연결이 가능하려면 데이터스토어, 수집 프레임워크, 스케줄러, 메타데이터 카탈로그, 규정 준수 프레임워크 등에 접근이 필요함
      - 마일스톤을 완료하는 데 걸리는 시간은 해석시간(time to interpret)을 지표로 추적함 
    - 사용 가능한 데이터 세트 및 아티팩트 검색
      - 마일스톤은 모든 관련 데이터 세트와 아티팩트, 예를 들어 뷰, 파일, 스트림, 이벤트, 지표, 대시보드, ETL, 임시 쿼리를 찾는 것이라고 할 수 있음 
      - 탐색 시간 지표(time to find)로 추적됨 
    - ML 모델에서의 기능 재사용 또는 생성
      - 피처화 시간(time to featurize) 지표로 추적함 
    - 누락된 데이터 집계
      - 비즈니스 대시보드를 만들려면 식별된 데이터 세트(고객 활동 및 결제 청구 기록)를 결합해 리텐션 리스크(retention risk)에 대한 인사이트를 생성
      - 데이터 가용성 확보 시간(time to data availability)
    - 클릭스트림 이벤트 관리
      - 클릭, 뷰와 이전 애플리케이션 페이지, 방문자 기기 유형 등 연관된 맥락까지의 고객 활동을 분석해야 함
      - 클릭스트림 데이터(clickstream data)는 우선 수집, 필터링되고 보강돼야 인사이트 생성에 사용할 수 있음 
      - 클릭 시간(time to click)지표로 추적함 
  - 준비
    - 준비 단계에서는 인사이트 추출을 위해 실제 비즈니스 로직 구축용 데이터를 준비하는데 집중함. 준비는 데이터 집계, 정리, 표준화, 변환, 비정규화를 포함하는 반복적이고 시간 집약적인 작업이며 여러 가지 도구와 프레임워크를 포함함
    - 규제 준수 요건을 충족하기 위해 데이터 거버넌스(data governance)를 보장함 
  - 중앙 저장소 내의 집계 데이터 관리 
    - 비즈니스 대시보드는 과거 일괄 처리 데이터 스트리밍 행동 데이터 이벤트를 결합해야 함. 데이터는 데이터 모델과 온디스크 형식을 고려해 효율적으로 유지 관래돼야 함
    - 데이터 레이크 관리 시간(time to data lake management) 지표에 의해 추적됨 
  - 데이터의 구조화, 정리, 보강, 유효성 검사
    - 랭글링 시간(time to wrangle) 지표로 추적함 
  - 데이터 권한 규정 준수 보장
    - 규정 준수(compliance)는 고객 경험을 인사이트로 더 잘 제공하는 것과 고객 동의 내에서 데이터가 사용되도록 보장하는 것 사이의 균형 조정 행위 
    - 규정 준수 시간(time to comply) 지표로 추적함 
  - 구축
    - 인사이트를 추출하는 데 필요한 실제 로직을 작성하는 데 집주앟ㅁ
    - 데이터 액세스 및 분석을 위한 최상의 접근 방식 결정 
      - 구축 단계의 출발점은 인사이트 로직을 작성하고 실행 전략을 결정하는 것 
      - 장기간 실행되는 일괄 처리(batch) 프로세스는 Hive 또는 Spark에 있는 반면 짧은 대화형 쿼리는 Presto 클러스터에서 실행됨 
      - 가상화 시간(time to virtualize)지표로 추적함
    - 변환 로직 작성
      - 대시보드 또는 모델 인사이트의 실제 로직은 ETL, ELT 또는 스트리밍 분석 패턴으로 작성됨. 비즈니스 로직은 변화에 대한 관리가 용이할 뿐만 아니라 실행성과 확장성이 있는 실제 코드로 번역돼야 하며 가용성, 품질, 변경 관리를 위해 모니터링돼야 함 
      - 변환 시간(time to transform) 지표로 추적함
    - 모델 학습
      - 학습은 CPU와 GPU 같은 전문 하드웨어가 조합된 서버로 구성된 팜(farm)에서 운영됨 
      - 학습 시간(time to train) 지표에 의 추적됨 
    - ML 모델 변경 사항의 지속적인 통합 
      - ML 모델 파이프라인은 소스 스키마 변경, 형상 로직, 종속 데이터 세트, 데이터 처리 설정, 모델 알고리즘을 통해 지속적으로 진화함 
      - 통합 시간(time to integrate) 지표에 의해 추적됨 
    - 인사이트 A/B 테스트
      - 버킷 테스트, 분할 테스트 또는 통제된 실험이라고 알려진 A/B 테스트는 데이터 중심 의사 결정을 위한 표준 접근 방식이 되고 있음 
      - A/B 테스트 시간(time to A/B test)
  - 운영화
    - 여정 지도의 운영화 단계에서는 인사이트가 프로덕션에 배포됨
    - 쿼리 검증 및 최적화
      - 어디에나 만능으로 적용되는 쿼리의 최적 조절 값은 없고 데이터 모델, 쿼리 유형, 클러스터 크기, 동시 쿼리 로드 등에 따라 달라짐. 쿼리 최적화는 지속적인 활동. 
      - 최적화 시간(time to optimize) 지표에 의해 추적됨 
    - 파이프라인 오케스트레이션 
      - 오케스트레이션은 파이프라인 서비스 수준 계약(SLA, Service Level Agreement)을 보장하고 기본 리소스의 효율적인 활용을 보장하는 균형 조정 행위 
      - 파이프라인은 데이터 수집, 준비, 변환, 학습, 배포 전반에 걸쳐 서비스를 호출함. 데이터 사용자가 이러한 서비스 전반에서 정확성, 견고성, 적시성을 모니터링하고 디버깅하는 것이 중요함 
      - 파이프라인 오케스트레이션은 멀티테넌트(multitenant)로, 여러 팀과 비즈니스 유즈 케이스를 지원함 
      - 오케스트레이션 시간(time to orchestrate) 지표에 의해 추적됨 
    - ML 모델 배포 
      - 배포 시간(time to deploy) 지표 
    - 인사이트 품질 모니터링
      - 인사이트 품질 확보 시간(time to insight quality) 지표 
    - 지속적인 비용 모니터링
      - 비용 관리는 종래의 종량제 모델과 달리 사용량에 따라 선형적으로 비용이 증가하는 클라우드에서 특히 중요함 
      - 비용 최적화 시간(time to optimize cost) 지표로 추적됨 
- 인사이트 시간 스코어가드 정의
  - 인사이트 시간(time to insight)은 원시 데이터에서 인사이트까지의 전체 여정을 완료하는 데 걸리는 시간을 측정하는 전반적인 지표 
  - 각 마일스톤의 척도를 합치면 전체 인사이트 시간 척도가 됨 
  - 인사이트 시간 스코어가드(scorecard)를 사용함. 전체 여정 지도에서 가장 시간이 많이 걸리는 마일스톤을 찾는 것이 이 활동의 목표 
    - 해석 시간(time to intepret) : 데이터 세트의 메타데이터 세부 정보를 인사이트 개발에 사용하기 전에 해석하는 마일스톤에 연관된 지표 
    - 탐색 시간(time to find) : 검색 관련 데이터 세트와 아티팩트의 마일스톤에 연관된 지표 
    - 피처화 시간(time to featurize) : ML 모델 학습에 필요한 기능 관리 마일스톤과 연관된 지표 
    - 데이터 가용성 확보 시간(time to data availability) : 사일로 간에 데이터를 이동하는 마일스톤과 연관된 지표 
    - 클릭 시간(time to click) : 클릭스트림 데이터 이벤트의 수집, 관리, 분석 마일스톤과 연관된 지표 
    - 데이터 레이크 관리 시간(time to data lake management) : 중앙 저장소에서 데이터를 관리하는 마일스톤과 연관된 지표 
    - 랭글링 시간(time to wrangle) : 데이터 구조화, 정리, 보강, 검증의 마일스톤과 연관된 지표 
    - 규정 준수 시간(time to comply) : 데이터 권한 규정 준수를 보장하는 마일스톤과 연관된 지표 
    - 가상화 시간(time to virtualize) : 데이터 구축, 분석의 접근 방식을 선택하는 마일스톤과 연관된 지표 
    - 변환 시간(time to transform) : 데이터 및 ML 파이프라인에서 변환 로직을 구현하는 마일스톤과 연관된 지표 
    - 학습 시간(time to train) : ML 모델 학습 마일스톤과 관련된 지표 
    - 통합 시간(time to integrate) : ML 파이프라인의 코드, 데이터, 설정의 변경을 통합하는 마일스톤과 연관된 지표 
    - A/B 테스트 시간(time to A/B test) : A/B 테스트의 마일스톤과 연관된 지표 
    - 최적화 시간(time to optimize) : 쿼리 및 빅데이터 프로그램을 최적화하는 마일스톤과 연관된 지표 
    - 오케스트레이션 시간(time to orchestrate) : 프로덕션의 파이프라인 조정 마일스톤과 연관된 지표 
    - 배포 시간(time to deploy) : 프로덕션에 인사이트를 배포하는 마일스톤과 연관된 지표 
    - 인사이트 품질 확보 시간(time to insight quality) : 생성된 인사이트의 정확성을 보장하는 마일스톤과 연관된 지표 
    - 비용 최적화 시간(time to optimize cost) : 비용을 최적화하는 마일스톤과 연관된 지표 
- 셀프서비스 로드맵 실행 
  - 현재 스코어카드를 정의하는 것부터 시작
  - 데이터 사용자에 대한 설문 조사를 기반으로 여정 지도를 가장 많이 늦추는 두 세가지 지표를 식별하고 현재 작업이 구현되는 방식에 대한 기술적 분석을 수행하라. 지표의 중요도는 현재 프로세스, 데이터 사용자 기술, 기술 구성 요소, 데이터 속성, 유스 케이스 요구 사항에 따라 기업마다 다르다는 것을 인식하라
  - 각 지표는 매슬로우의 구현 패턴 계층부터 시작하라. 각 장은 하나의 지표에 대한 자동화 단계가 증가하는 패턴을 다룸 
  - 각 분기마다 지표 우선순위를 전념하고 셀프서비스화에 집중하면서 단계별 기기, 걷기, 달리기 전략을 따르자 

# 셀프서비스 데이터 발견 
## 메타데이터 카탈로그 서비스 
- 빅데이터 시대 이전에는 데이터를 중앙 웨어하우스에 추가하기 전에 먼저 분류함 
- 쓰기스키마(schema-on-write) : 스키마, 계보, 소유자, 비즈니스 분류법 등을 포함한 메타데이터 세부 정보를 먼저 카탈로그화했음. 
- 읽기스키마(schema-on-read) : 오늘날 데이터 레이크의 접근 방식에는 머저 데이터를 집계한 뒤 데이터 사용 시에 데이터 세부 정보를 추론함 
- 데이터 세트 이해하기
  - 데이터 과학자는 새로운 모델을 구축하거나 새로운 측정 기준을 수립하거나 임시 분석을 수행하는 첫 번째 단계로 데이터의 출처, 사용 방법, 지속 방법 등에 대한 세부 정보를 이해해야 함 
  - 메타데이터 카탈로그는 질문에 대한 단일 진실 공급원(SSOT, Single Source Of Truth) 
- 데이터 세트 분석하기
  - 데이터 과학자는 데이터 세트 속성과 쿼리 유형을 기반으로 작업에 적합한 도구를 사용하며 ,하나의 데이터 세트를 Pig, Spark, Presto, Hive 등 여러 쿼리 엔진에서 번갈아가며 사용할 수 있음 
- 지식 확장하기 
  - 팀지식 : 데이터 과학자는 프로젝트를 위해 서로 다른 데이터 세트로 작업하면서 비즈니스 어휘, 데이터 품질 등에 대한 추가 세부 정보를 발견함 
- 해석 시간 최소화
  - 해석 시간은 데이터 과학자가 인사이트를 구축하기 전에 데이터 세트의 세부 정보를 이해하는 데 걸리는 시간을 말함 
  - 기술 메타데이터 추출하기
    - 기술 메타데이터는 데이터 세트의 논리적, 물리적 메타데이터 세부 정보로 구성됨 
    - 물리적 메타데이터는 생성 및 수정 타임스탬프, 물리적 위치 및 형식, 스토리지 계층, 보존 세부 정보와 같은 물리적 레이아웃과 지속성에 관련된 세부 정보를 포함함
    - 논리적 메타데이터에는 데이터 세트 스키마, 데이터 원본 세부 정보, 데이터 세트를 생성하는 프로세스 ,데이터 세트의 소유자 및 사용자가 포함됨 
    - 기술 메타데이터는 여러 소스 간 연관 관계를 고려하지 않고 각각의 데이터 소스를 크롤링 해서 추출함 
    - 메타데이터를 수집하는 데 세 가지 주요 과제 
      - 형식 차이 
      - 스키마 유추
      - 변경 추적 
- 운영 메타데이터 추출하기 
  - 두 가지 주요 버킷 
    - 계보(lineage)
      - 데이터 세트가 어떻게 생성됐는지와 다른 데이터 세트에 대한 종속성을 추적함 
      - 특정 데이터 세트의 계보는 모든 종속 입력 테이블, 파생 테이블, 출력 모델 및 대시보드를 포함함 
      - 최종 출력 도출을 위해 변환 로직을 구현하는 작업이 포함됨 
    - 데이터 프로파일링 통계
      - 가용성 및 품질 통계
      - 데이터 세트의 열 수준 및 설정 수준 특성을 포착함 
      - 완료 시간, 처리된 데이터 ,파이프라인과 관련된 오류를 포착하는 실행 통계도 포함됨 
  - 서로 다른 다양한 유형의 데이터베이스, 스케줄러, 쿼리 엔진, BI(비즈니스 인텔리전스) 툴로 인해 서로 다른 처리 프레임워크, 데이터 플랫폼, 스케줄링 시스템에 걸친 전반적인 데이터 흐름과 계보를 이해하는 것은 어려운 과제. 처리 프레임워크의 다양성을 고려하면서 세부 사항을 짜맞춰 연결하는 것이 이 과제에 해당함. UDF, 외부 매개변수 등의 경우에는 코드로부터 계보를 유추하는 것이 쉽지 않기 때문 
  - 팀 지식 수집하기 
    - 팀 지식의 네 가지 범주 
      - 주석, 문서, 속성 설명 형식의 사용자 정의 메타데이터
      - 비즈니스 직관적 계층 구조(business-intuitive hierarchy)에서 데이터 개체 및 메트릭을 연결하고 구성하기 위한 비즈니스 분류법 또는 어휘
      - 규정 준수, 개인 식별 가능 정보(PII, Personally identifiable information) 데이터 필드, 데이터 암호화 요구 사항 등과 같은 측면의 데이터 세트 상태
      - 가장 인기 있는 테이블, 쿼리, 기타 형태의 ML 증강 메타데이터(ML-augmented metadata) 
- 구현 패턴
  - 메타데이터 카탈로그 서비스에 대한 자동화 수준 
    - 소스 특화 커넥터 패턴 : 서로 다른 데이터 소스에 연결하고 데이터와 연결된 메타데이터 정보를 추출하는 작업을 간소화함
    - 계보 상관 패턴 : 소스 테이블과 대상 테이블을 상관시키는 변환 계보를 추출하는 작업을 자동화함
    - 팀 지식 패턴 : 비즈니스 문맥 수집과 데이터 사용자 간의 지식 공유를 단순화함 
  - 메타데이터 카탈로그 서비스는 금융산업규제당국(finra)의 Herd, 우버의 Databook, 링크드인의 WhereHows와 Data Hub, 넷플릭스의 Metacat, 아파치의 Atlas 프로젝트, AWS Glue 같은 클라우드 서비스가 있음 
  - 소스 특화 커넥터 패턴
    - 소스 특화 커넥터 패턴은 기술 메타데이터 집계를 위해 소스에서 메타데이터를 추출함
    - 데이터 세트는 URN(Uniform Resource Name) 기반 이름을 사용해 식별됨 
    - 두 가지 구성 요소(building block)
      - 커스텀 추출기
        - 소스 특화 커넥터는 메타데이터를 연결하고 지속적으로 가져오는 데 사용됨. 커스텀 추출기를 RDBMS, Hive, 깃허브 등의 데이터스토어에 연결하기 위해 자격 증명을 인증하려면 적절한 액세스 권한이 필요함 
        - 추출기가 소스에 연결되면 데이터 세트의 형식, 스키마, 관련 속성을 결정하는 분류자(classifier)를 구현해 세부 정보를 수집함 
      - 연합 지속성(federated persistence)
        - 메타데이터 세부 정보는 정규화된 방식으로 유지됨 
  - 계보 상관 패턴(lineage correlation pattern) 
    - 데이터 및 작업에 걸친 운영 메타데이터를 연결해 실행 통계와 결합함 
    - 작업 실행 레코드를 계보와 결합함으로써 데이터 신선도, 서비스 수준 협약(SLA, Service Level Agreement), 영향을 받는 특정 테이블의 다운스트림 작업, 사용량에 따른 파이프라인 내의 테이블 순위 등에 관한 질문에 답변할 수 있음 
      - 쿼리 구문 분석
      - 파이프라인 상관관계
      - 실행 통계를 통한 계보 보강 
    - 아파치 Atlas는 Sqoop, Hive, Kafka, Storm 등 여러 Hadoop 에코시스템 구성 요소에 걸쳐 계보를 추출함. Atlas는 Hadoop job ID가 주어지면 job history 노드에서 job conf 쿼리를 수집함. Sqoop 작업에도 비슷한 접근법이 적용돼 있음. 
    - Atlas는 테이블 수준 계보 외에도 다음과 같은 유형의 종속성을 추적해 열 수준 계보를 지원함
      - 단일 종속성 : 출력 열의 값이 입력 열과 동일함 
      - 표현 종속성 : 출력 열은 런타임 시 입력 열의 일부 표현식(Hive SQL 표현식)에 의해 변환됨
      - 스크립트 종속성 : 출력 열은 사용자가 제공한 스크립트에 의해 변환됨 
      - 강점은 종속성을 재구성하는 간섭 없는 방법을 제공함. 단점은 계보가 쿼리 유형을 100% 커버하지 못하고 대략적이라는 것 
  - 팀 지식 패턴
    - 팀 지식의 세 가지 주요 유형
      - 데이터 문서 : 속성 의미, 열거형, 데이터 설명의 세부 정보가 포함됨
      - 비즈니스 분류법 및 태그 : 비즈니스 영역과 주제 영역에 따라 데이터를 분류하는 분려법으로, 비즈니스 내에서 사용되는 개념이 포함됨 
      - 플리거블 검증(pluggable validation) : 테이블 소유자는 테이블에 대한 감사 정보를 메타데이터로 제공할 수 있음. 테이블 작성에 사용할 열 기본값과 검증 규칙을 제공할 수 있음 

## 검색서비스
- 인사이트를 개발하는 반복적인 프로세스 중 연관 데이터 세트(테이블, 뷰, 스키마, 파일, 스트림, 이벤트)와 아티팩트(지표, 대시보드, 모델, ETL, 임시 쿼리)를 찾는 것에 초점을 맞춤 
- 검색 서비스를 통해 데이터 사용자는 키워드, 와일드카드 검색, 비즈니스 용어 등을 사용해 원하는 것을 표현함. 
- 소스 발견, 데이터 세트 및 아티팩트 인덱싱, 결과 순위 지정, 액세스 거버넌스(access governance) 보장, 지속적인 변경 관리 등의 어려운 업무를 보이지 않는 곳에서 수행함 
- 데이터 세트 및 아티팩트 인덱싱
  - 인덱싱의 두 가지 작업
    - 데이터 세트와 아티팩트의 소스 찾기
    - 해당 소스를 조사해 스키마와 메타데이터 속성 같은 세부 정보 수집 
  - 접근 제어하기 
    - 데이터 세트 및 아티팩트 소스에 안전하게 연결
    - 검색 결과에 대한 접근 제한 
- 검색 서비스를 구축하는 데는 세 가지 주요 모듈 
  - 인덱서 모듈 
    - 사용 가능한 데이터 세트와 아티팩트를 발견하고, 스키마 및 메타데이터 속성을 추출하고, 카탈로그에 추가함. 이 모듈은 변경 내용을 추적하고 세부 정보를 지속적으로 업데이트함 
  - 순위 모듈 : 관련성과 인기도의 조합에 따라 검색 결과의 순위를 매기는 역할을 함
  - 액세스 모듈 : 데이터 사용자에게 표시되는 검색 결과가 접근 제어 정책을 준수하도록 함 
- 요구 사항 순위 매기기 
  - 데이터 세트와 아티팩트에 관련된 메타데이터의 범주
  - |메타데이터 범주|속성 예|
    |:---:|:---:|
    |기본|크기,형식,최종 수정, 가명, 접근 제어 목록
    |콘텐츠 기반|스키마,기록 수,데이터 핑거프린트,키 필드
    |계보|읽기 작업,쓰기 작업, 다운스트림 데이터 세트, 업스트림 데이터 세트
    |사용자 정의|태그, 카테고리
    |사람|소유자,팀 접근, 팀 업데이트
    |시간|변경 히스토리 
  - 접근 제어 요구 사항
    - 사용자별 정책은 역할 기반 접근 제어(RBAC, Role-Based Access Control), 속성별 정책은 속성 기반 접근 제어(ABAC, Attribute-Based Access Control), 사용자 그룹에 대한 가시성 제한은 RBAC 정책이며 데이터 태그 또는 개인 식별 정보(PII)에 대해 정의된 정책은 ABAC 정책 
    - 다른 특수 처리 요구 사항이 필요할 수 있음 
      - 행 또는 열 값의 마스킹 
      - 데이터 세트와 아티팩트를 특정 타임스탬프까지 볼 수 없도록 하는 시간 변동 정책(분기별 결과가 공식적으로 발표된 날짜까지 표를 볼 수 없음) 
  - 비기능 요구 사항
    - 비기능 요구 사항(NFR,Nonfunctional Requirement)
      - 검색 응답 시간 : 검색 서비스가 초 단위로 검색 쿼리에 응답하도록 하는 것이 중요함 
      - 대규모 인덱 지원을 위한 확장 : 기업이 성장함에 따라 수천 개의 데이터 세트와 아티팩트를 지원하도록 검색 서비스를 확장하는 것이 중요함 
      - 새로운 소스에 대한 손쉬운 온보딩 : 데이터 소스 소유자가 검색 서비스에 소스를 추가할 때의 UX를 단순화해야 함 
      - 자동 모니터링과 알림 : 서비스 상태는 모니터링하기 쉬워야 함. 프로더션 중 문제가 발생하면 자동 경고가 생성돼야 함 
- 구현 패턴
  - 기존 작업 지도에 따라 검색 서비스에 대한 자동화 수준은 세 가지 
    - 푸시 풀 인덱서 패턴 : 사용 가능한 데이터 세트와 아티팩트를 발견하고 지속적으로 업데이트함 
    - 하이브리드 검색 순위 패턴 : 데이터 사용자가 데이터 프로젝트의 요구 사항에 맞는 가장 관련성 높은 데이터 세트와 아티팩트를 찾을 수 있도록 결과의 순위를 매김 
    - 카탈로그 접근 제어 패턴 : 데이터 사용자 및 기타 특성에 따라 검색 서비스에 표시되는 데이터 세트와 아티팩트에 대한 접근을 제어함 
  - 푸시 풀 인덱서 패턴
    - 기업의 사일로 전체에서 사용 가능한 데이터 세트와 아티팩트를 발견하고 업데이트함 
    - 데이터 세트를 인덱싱할 수 있는 넷플릭스의 오픈소스 Metacat 카탈로그
      - Metacat은 데이터 세트 세부 정보를 추출하기 위해서뿐 아니라 데이터 소스가 Kafka와 같은 이벤트 버스에 업데이트를 게시하는 푸시 알림 모델에서도 풀 모델을 사용함. 데이터 소스는 명시적 REST API를 호출해 변경 이벤트를 게시할 수도 있음. Metacat에서는 변경 사항이 아마존 SNS에도 게시됨. SNS에 이벤트를 게시하면 데이터 플랫폼의 다른 시스템이 이러한 메타데이터 또는 데이터 변경에 따라 반응을 할 수 있음 
      - 강점 
        - 인덱스 업데이트가 시기적절함. 새 소스는 주기적으로 크롤링되고 변경 이벤트 처리를 위해 이벤트 버스에 푸시됨 
        - 다양한 범주의 메타데이터 속성을 추출하고 업데이트하기 위한 확장 가능한 패턴
        - 푸시 및 풀 방식의 조합을 고려할 때 많은 소스를 지원하도록 확장 가능함 
      - 약점
        - 다양한 소스 유형에 대한 구성과 배포가 어려울 수 있음 
        - 풀을 통해 세부 정보에 접근하려면 소스 권한이 필요한데, 규제된 소스에는 우려 사항이 될 수 있음 
  - 하이브리드 검색 순위 패턴
    - 문자열 입력이 주어지면 순위 패턴이 데이터 세트와 아티팩트의 목록을 생성함. 이 목록은 테이블 이름, 비즈니스 어휘 개념, 분류 태그 등의 문자열로 구성될 수 있음 
    - 이 패턴의 성공 기준은 가장 관련성 높은 결과가 목록의 상위 다섯 건에 들어있는지 여부 
    - 하이브리드 검색 순위 패턴의 예로는 아문센(Amundsen) 오픈소스 프로젝트 
      - 아문센은 데이터 세트와 아티팩트를 인덱싱함. 입력 구문 분석에서는 정확한 매칭 개선을 위해 자동 완성(type-ahead) 기능을 구현함. 입력 문자열은 와일드카드와 키워드, 범주, 비즈니스 어휘 등을 지원함 
      - 아문센은 얇은 Elasticsearch 프록시 계층을 구현해 카탈로그와 상호 작용함으로써 퍼지 검색을 가능하게 함. 
      - 메타데이터는 Neo4j에서 유지됨. 인덱스 구축을 위해서는 데이터 수집 라이브러리를 사용함 
  - 카탈로그 제어 패턴
    - 메타데이터 카탈로그에 접근 제어를 시행하고 세분화된 권한 부여 및 접근 제어를 위한 중앙 집중식 접근 방식을 제공함 
    - 카탈로그 접근 제어 패턴의 세 단계 
      - 분류
      - 정의
        - 정책 정의는 크게 두 가지의 광범위한 버킷으로 나뉨. 
        - 역할 기반 접근 제어 : RBAC,Role-Based Access Control, 사용자를 기반으로 정책이 정의됨 
        - 속성 기반 접근 제어 : ABAC,Attriubte-Based Access Control, 사용자 정의 태그, IP 주소를 기반으로 하는 지리적 태그, 시간 기반 태그 등과 같은 속성을 기반으로 정책이 정의됨 
      - 시행 
        - 검색 결과에서 접근 제어 정책을 시행하는 세 가지 방법
        - 모든 사용자를 위한 기본 메타데이터 : 검색 쿼리에 대한 응답 결과로 기본 메타데이터(이름,설명,소유자,업데이트 날짜, 사용자 정의 태그 등)를 모든 사용자엑 접근 권한 여부에 관계없이 표시함 
        - 선택적 고급 메타데이터 : 선별된 사용자가 접근 제어 정책에 따라 열 통계 및 데이터 미리 보기와 같은 고급 메타데이터를 가져옴 
        - 열 및 행 마스킹 ; 접근 제어에 따라 동일한 데이터 세트의 열 개수는 물론 데이터 미리 보기의 행이 달라짐 
    - 세분화된 권한 부여와 접근 제어를 위해 널리 사용되는 오픈소스 솔루션의 예로 아파치 Ranger 
      - Atlas 카탈로그와 모든 Hadoop 에코시스템에 대한 보안 정책 구현을 위한 중앙 집중식 프레임워크를 제공함 
      - 개별 사용자, 그룹, 접근 유형, 사용자 정의 태그, IP 주소와 같은 동적 태그 등을 기반으로 한 RBAC 및 ABAC 정책을 지원함 
    - 강점
      - 카탈로그 수준의 중장 집중식 접근 제어 정책을 통해 쉽게 관리할 수 있음 
      - 다양한 사용자 및 유스 케이스에 따라 조정 가능한 접근 제어 기능을 제공함 
    - 약점
      - 카탈로그 접근 제어 정책이 데이터 원본 정책과 동기화되지 않을 수 있음

# 피처 저장소 서비스 
- 요구 사항 정의
  - 피처 연산
    - 피처 비닝(feature binning) : 연속 피처를 개별 피처로 변환
    - 피처 해싱(feature hashing) : 원-핫 인코딩된 피처의 메모리 풋프린트(memory footprint)를 줄이기 위함 
    - Spark는 대규모 데이터 세트로 작업하는 사용자 간의 데이터 랭글링에 선호됨. 작은 데이터 세트로 작업하는 사용자는 Numpy, pandas와 같은 프레임워크를 선호함. 피처 엔지니어링 작업은 노트북(notebook), 파이썬 파일 또는 .jar 파일을 사용해 빌드되고 samza, Spark, Flink, Beam과 같은 연산 프레임워크에서 실행됨 
- 구현 패턴
  - 하이브리드 피처 연산 패턴 : 피처 연산을 위한 일괄 처리 및 스트림 처리를 결합하는 패턴을 정의함 
  - 피처 레지스트리 패턴 : 학습자 추론을 위한 기능을 제공하는 패턴을 정의함 
- 하이브리드 피처 연산 패턴 
  - 세 가지 구성 요소 
    - 일괄 처리 연산 파이프라인 
      - 전통적인 일괄 처리 작업에서는 몇 시간마다 또는 매일 ETL 작업으로 실행돼 과거 피처 값을 계산함 
    - 스트리밍 연산 파이프라인
      - 실시간 메시지 버스의 데이터 이벤트에 대해 수행되는 스트리밍 분석을 통해 낮은 지연 시간으로 피처 값을 계산함 
    - 피처 사양 
      - 일관성을 보장하기 위해 데이터 사용자는 새로운 피처에 대한 파이프라인을 생성하는 대신 도메인 특화 언어(DSL, Domain-Specific Language)를 사용해 피처 사양을 정의함 
  - 우버의 Michelangelo
    - 아파치 Spark와 Samza의 조합을 구현함. Spark는 일괄 처리 피처를 연산하는 데 사용되며 결과는 Hive에서 유지됨. 일괄 처리 작업은 피처 그룹을 연산하고, 이를 컬럼당 피처로서 단일 Hive 테이블에 씀 
    - 스트리밍 파이프라인의 경우 Kafka 토픽은 Samza 스트리밍 작업과 함께 소비돼 Cassandra에서 키-값 형식으로 유지되는 준실시간 피처 값을 생성함 
    - 히스토리 피처의 대량 사전 연산 및 과거 피처의 로딩이 정기적으로 Hive에서 Cassandra로 이뤄짐 
  - 강점 
    - 일괄 처리 및 스트리밍 타임 윈도우에 걸쳐 최적의 피처 연산 성능을 제공함 
    - 피처를 정의하는 DSL은 학습과 추론을 위한 파이프라인 구현 불일치에 관련된 모순을 방지함 
  - 약점 
    - 프로덕션 환경에서 구현되고 관리하는 것은 쉽지 않음. 데이터 플랫폼이 상당히 성숙해야 함 
- 피처 레지스트리 패턴 
  - 피처를 쉽게 검색하고 관리할 수 있음 
  - Hopsworks 피처 저장소 
    - 사용자가 피처 저장소를 SQL 또는 프로그래밍 방식으로 쿼리하면 피처 저장소는 피처를 데이터프레임으로 변환함 
    - Hopworks 피처 저장소의 피처 그룹 및 학습 데이터 세트는 Spark/Numpy/pandas 작업에 연결돼 있어 필요할 때 피처를 재현하고 재연산할 수 있음 
  - 강점 
    - 학습 데이터 세트와 피처 값의 성능 기준에 맞는 성능을 제공함 
    - 데이터 사용자의 피처 분석 시간을 단축함 
  - 약점 
    - 수백 개의 모델을 제공하는 동안 잠재적인 성능 병목 현상이 나타남
    - 피처가 계속 증가해 피처 분석을 위한 확장을 지속함 

# 데이터 이동 서비스 
- 원시 데이터를 전문 쿼리 엔진으로 이동
  - 점점 더 많은 쿼리 처리 엔진이 다양한 유형의 쿼리 및 데이터 워크로드에 최적화되고 있음 
  - 시계열 데이터 세트의 데이터 분할(slice-and-dice) 분석의 경우 데이터는 Druid와 Pinot 같은 전문 분석 솔루션으로 복사됨 
- 데이터 품질 검증 
  - 실제 배포 환경에서는 소스 오류, 어댑터 실패, 집계 문제 등과 같은 다양한 이유로 품질 오류가 발생할 수 있음
  - 데이터 이동 중 데이터 패리티(data parity) 모니터링은 데이터 품질 오류를 발견하지 못하거나 비즈니스 지표 및 ML 모델의 정확성에 영향을 미치지 않도록 하기 위해 반드시 필요함 
- 요구 사항 정의
  - 데이터 이동 서비스의 네 가지 주요 모듈 
    - 수집 모듈 : 소스에서 대상 데이터스토어로 데이터를 한 번 또는 지속적으로 복사하는 것을 담당함 
    - 변환 모듈 : 소스에서 대상으로 복사되는 데이터의 변환을 담당함 
    - 규정 준수 모듈 : 분석 목적으로 데이터를 이동함으로써 규정 준수 요구 사항을 충족함 
    - 검증 모듈 : 소스와 대상 간의 데이터 패리티를 보장함 
수집 요구 사항 
  - 요구 사항 수집의 일부로 수집할 데이터스토어 범주
    - |데이터스토어 범주|인기 있는 예시|
      |:---:|:---:|
      |트랜잭션 데이터베이스|Oracle, SQL Server, MySQL|
      |NoSQL 데이터스토어|Cassandra, Neo4j, MongoDB|
      |파일 시스템|Hadoop FileSystem, NFS appliance, Samba|
      |데이터 웨어하우스|Vertica, Oracle Exalogic, AWS Redshift|
      |오브젝트 저장소|AWS S3|
      |메시징 프레임워크|Kafka, JMS|
      |이벤트 로그|Syslog,NGNIX logs|
  - 데이터 규모
    - 데이터 엔지니어가 이해해야 하는 구모의 주요 측면
      - 행의 개수로 볼 때 테이블의 크기가 얼마나 큰가(즉, 수천 개의 행이 있는지, 수십억 개의 행이 있는지)?
      - TB 단위로 표의 대략적인 크기는 얼마인가?
      - 지속적으로 복사해야 하는 테이블의 수는 얼마인가?
    - 삽입, 업데이트, 삭제 횟수와 관련해 테이블이 빠르게 변경되는지 여부를 추정하는 변화율 
- 규정 준수 요구 사항 
  - 구정 준수에 대한 여러 측면을 고려해야 함
  - 매슬로우의 욕구 계층 구조(역피라미드) 
    - 삼각형의 맨 아래에는 규정 준스를 위한 3A인 인증(authentication), 접근 제어(access control), 감사 추적(audit tracking)이 있음 
    - 그 위에 암호화 및 마스킹과 관련해 개인 식별 정보(PII)를 처리할 때 고려해야할 사항이 있음 
    - 다음은 SOX,PCI 등과 같은 규정 주수 관련 요구 사항 
    - 맨 위에는 CCPA, GDPR 등의 법률에 따른 데이터 권한 준수가 있음 
- 구현 패턴
  - 데이터 이동 서비스는 수집, 변환, 규정 준수, 검증 모듈이라는 네 가지 주요 작업을 수행함 
  - 데이터 이동 서비스의 다양한 자동화 수준
    - 일괄 수집 패턴
      - 일괄 수집(batch ingestion)은 빅데이터 진화 초기에 널리 사용됐던 전통적인 패턴이며, 일회성 및 예약된 데이터 이동 모두에 적용됨.
      - 일괄 처리(batch)라는 용어는 소스에 대한 업데이트가 함께 그룹화된 다음 주기적으로 대상으로 이동됨을 의미함 
      - 일괄 수집은 일반적으로 실시간 업데이트 요구가 없는 대규모 소스의 데이터 이동에 사용됨. 6~24시간 단위로 예약됨 
      - 일괄 수집 패턴에는(MapReduce의)지도 단계를 이용해 소스 데이터 개체를 분할함으로써 대상 데이터 개체로 병렬 복사하는 것이 포함됨 
      - 일괄 수집 패턴의 세 단계
        - 파티션 단계 : 복사할 소스 테이블은 데이터 이동을 병렬화하기 위해 더 작은 청크(chunk)로 논리적으로 분할됨 
        - 지도 단계 : 각 청크는 매퍼(mapper, MapReduce의 용어)에 할당됨. 매퍼는 쿼리를 실행해 소스 테이블에서 데이터를 읽고 대상에 복사함. 더 많은 매퍼를 사용하면 동시 데이터 전송 작업 수가 많아져 작업 완료 속도가 빨라질 수 있음 .데이터베이스의 로드(load)도 증가해 잠재적으로 소스가 포화될 수 있음. 증분 테이블 복사의 경우, 매퍼는 마지막 업데이트 이후 소스 테이블에 대한 삽입, 업데이트, 삭제를 처리함 
        - 축소 단계 : 매퍼의 출력은 스테이징 파일로 저장되고 리듀서에 의해 대상 데이터스토어의 단일 구체화 뷰로 결합됨. 리듀서는 변환 기능을 구현할 수도 있음 
      - 아파치 Sqoop
        - 일반적으로 관계형 데이터베이스와 파일 시스템 간에 HDFS와 아파치 Hive로 대량의 데이터를 이동할 때 사용됨. 클라이언트-서버모델로 구현됨.
        - 클라이언트는 소스 및 대상 데이터스토어에 설치되고 데이터 이동은 클라이언트와 대응하는 Sqoop 서버에 의해 MapReduce 작업으로 오케스트레이션됨 
        - 데이터스토어에 연결하기 위한 기술 특화 어댑터는 클라이언트에 설치됨(최신 Sqoop2 버전에서는 드라이버가 서버에 설치됨). 데이터 이동은 소스 클라이언트의 매퍼가 소스에서 데이터를 전송하는 동안 대상 클라이언트의 리듀서가 데이터를 복사 및 변환하는 MapReduce 작업 
      - 강점
        - 광범위한 소스 및 대상 데이터스토어에 적용할 수 있는 전통적인 데이터 이동 패턴. 데이터 소스 소유자가 소스 데이터스토어를 온보딩, 관리, 유지 관리 하는 데 최소한의 노력만 필요함 
        - 매일 수천 개의 예약된 데이터 이동으로 확장할 수 있음. MapReduce를 활용해 장애 복구를 구현함
        - 기본적으로 복사 후 데이터 유효성 검사를 지원함 
      - 약점
        - 준실시간 데이터 새로 고침을 지원하지 않음 
        - 소스 데이터스토어의 성능에 잠재적으로 영향을 미칠 수 있음. 제한 규정 준수 상태의 소스 데이터스토어를 연결하는 데 사용되는 JDBC 연결과 관련된 잠재적인 규정 준수 문제가 있음 
        - 영구 삭제(hard delete)가 수반되는 증분 테이블의 새로 고침 및 데이터 변환 기능에 대한 지원이 제한적 
    - 지속적 변화 수집 패턴 / 변경 데이터 캡처 수집 패턴
      - 조직이 성숙해지면 일괄 수집을 넘어 변경 데이터 캡처(CDC, Change Data Capture) 패턴으로 이동함 
      - 짧은 지연 시간(몇 초 또는 몇 분)으로 대상에서 소스 업데이트가 필요한 지속적인 데이터 이동에 적용 가능함. CDC는 소스에서 모든 변경 이벤트(업데이트,삭제,삽입)를 캡처하고 대상에 업데이트를 적용함 
      - CDC 패턴은 일반적으로 CDC 패턴을 사용해 연속 업데이트가 수행되는 동안, 소스 테이블을 처음으로 전체 복사할 때 사용되는 일괄 수집과 함께 사용됨 
      - CDC 수집 패턴
        - 1.CDC 이벤트 생성
          - CDC 어댑터는 소스 데이터베이스에 설치되고 구성됨. 이 어댑터는 사용자 지정 테이블에 대한 삽입, 업데이트, 삭제를 추적하기 위한 소스 데이터스토어 특화 소프트웨어 
        - 2. 이벤트 버스에 게시된 CDC
          - CDC는 이벤트 버스에 게시되며 하나 이상의 분석 유스 케이스에서 사용할 수 있음. 버스의 이벤트는 내구성이 뛰어나며 오류가 발생한 경우 재생 가능함 
        - 3. 이벤트 병합
          - 각 이벤트(삽입,삭제,업데이트)는 대상 테이블에 적용됨. 최종 결과는 소스 테이블보다 짧은 지연 시간이 있는 테이블의 구체화 뷰. 대상 테이블에 해당하는 메타데이터는 새로 고침 타임스탬프와 기타 속성을 반영하기 위해 데이터 카탈로그에 업데이트됨 
      - CDC 수집 패턴 중에는 병합 단계를 거치지 않고 직접 이벤트를 사용할 수 있는 변형도 있음. 이 변형 패턴은 일반적으로 원시 CDC 이벤트가 비즈니스 특정 이벤트로 변환되는 시나리오에 적용됨 
      - CDC 이벤트를 시간 기반 저널(time-based journal)로 저장하는 것. 일반적으로 리스크 및 사기(fraud) 탐지 분석에 유용함 
      - 아파치 Kafka와 결합된 Debezium
        - Debezium은 지연 시간이 짧은 CDC 어댑터
        - 데이터베이스 기술에 관계없이 표준화된 이벤트 모델에서 커밋된 데이터베이스 변경 사항을 캡처함.
        - 이벤트는 변경된 내용, 시기 및 위치를 설명함. 이벤트는 아파치 Kafka에 하나 이상의 Kafka 토픽(일반적으로 데이터베이스 테이블당 하나의 토픽)으로 게시됨 
        - Kafka는 모든 이벤트가 복제되고 완전히 정렬되도록 보장하며, 많은 소비자가 업스트림 시스템에 거의 영향을 주지 않으면서 동일한 데이터 변경 이벤트를 독립적으로 사용할 수 있게 함 . 병합 프로세스 중에 오류가 발생하는 경우 중단된 지점에서 정확히 다시 시작할 수 있음 
        - 이벤트는 정확히 한 번(exactly-once) 또는 최소한 한 번(at-least-once) 정확하게 전달됨. 각 데이터베이스/테이블에 대한 모든 데이터 변경 이벤트는 업스트림 데이터베이스에서 발생한 것과 동일한 순서로 전달됨 
        - CDC 레코드를 구체화된 대상 테이블로 병합하기 위해 널리 사용되는 접근 방식은 MapReduce를 사용하는 일괄 처리 지향적 방식 또는 Spark와 같은 기술을 사용하는 스트리밍 지향적 방식
      - 아파치 Gobblin(인기 있는 오픈소스 솔루션으로는 MapReduce를 사용함), Spark를 사용하는 우버의 Marmaray
        - Gobblin의 병합 구현에는 역직렬화/추출, 포맷 변환, 품질 검증, 대상에 대한 쓰기가 포함됨. Gobblin과 Marmaray는 모두 어떤 소스에서 어떤 대사응로든 데이터를 이동을 할 수 있도록 설계됨 
      - 강점
        - CDC 패턴은 소스 데이터스토어에 미치는 성능 영향을 최소화하면서 대상을 업데이트하는 지연 시간이 짧은 솔루션
        - CDC 어댑터는 광범위한 데이터스토어에 사용할 수 있음 
        - 데이터 이동 과정에서 필터링 또는 데이터 변환을 지원함
        - 증분 수집(incremental ingestion)을 사용해 대형 테이블을 지원함 
      - 약점
        - CDC 어댑터의 최적 구성 옵션을 선택하는 데 필요한 전문 지식이 없으면 온보딩이 쉽지 않음 
        - Hadoop MapReduce 대신 Spark를 사용하는 병합 구현에서는 약 10억 행 이상의 매우 큰 테이블에서 문제가 발생할 수 있음 
        - 증분 변경 내용을 추적하려면 CDC 열이 있는 테이블이 필요함
        - 필터링 또는 데이터 변환을 제한적으로 지원함 
      - 이 접근 방식은 빠르게 이동하는 대용량 데이터에 적합하며, 널리 사용되고 가장 인기 있는 접근법 중 하나. 오류 없는 업데이트 추적 및 대규모 업데이트 병합을 보장하려면 소스 팀과 데이터 엔지니어링 팀 간의 운영 성숙도가 필요함 
    - 이벤트 수집 패턴 (이벤트 집계 패턴)
      - 사기 탐지, 알림, IoT 등을 위해 실시간으로 지속적인 이벤트를 집계해야 하는 애플리케이션 이벤트뿐만 아니라 로그 파일을 집계하는 일반적인 패턴 
      - 웹 액세스 로그, 광고 로그, 감사 로그, Syslog, 센서 데이터 등 로그의 수가 증가함에 따라 적용 범위가 넓어짐 
      - 여러 소스에서 집계하고, 단일 스트림으로 통합하고, 이를 일괄 처리 또는 스트리밍 분석에 사용할 수 있도록 하는 작업이 포함됨 
        - 이벤트 전달
          - 에지 노드, 로그 서버, IoT 센서 등으로부터의 이벤트 및 로그가 집계 단계로 전달됨. 로그를 실시간으로 푸시하기 위해 경량 클라이언트가 설치됨 
        - 이벤트 집계 
          - 여러 소스의 이벤트가 정규화되고 변환돼 하나 이상의 대상에서 사용할 수 있음. 집계는 스트리밍 데이터 흐름을 기반으로 함. 이벤트 스트림은 버퍼링돼 주기적으로 데이터스토어 대상에 업로드됨 
      - 아파치 Flume
        - 데이터 이동 작업의 일부로, 구성 파일에서는 이벤트 소스와 데이터가 집계되는 대상을 정의함 
        - Flume의 소스 구성 요소는 소스에서 로그 파일과 이벤트를 가져와 데이터가 처리되는 집계 에이전트로 보냄. 로그 집계 처리는 메모리에 저장되고 대상으로 스트리밍됨 
        - Flume은 기본적으로 웹 서버에서 생성된 대량의 로그 파일을 Hadoop으로 빠르고 안정적으로 스트리밍할 수 있도록 설계됐으며, Kafka 브로커, 페이스북, 트위터와 같은 소스의 데이터를 포함해 이벤트 데이터를 처리하도록 진화했음 
      - Fluent Bit과 Fluentd, 오픈소스 로그 수집기(log collec색) 및 로그 집계기(log aggregator)로 널리 사용됨 
      - 강점 
        - 이벤트 집계 패턴은 로그와 이벤트에 최적화된 실시간 솔루션. 신뢰성, 가용성이 높고 횡적 확장성이 뛰어남 
        - 소스 성능에 미치는 영향을 최소화함
        - 확장성과 커스터마이징이 용이하며 운영 오버헤드를 최소화함
        - 데이터 이동 프로세스 중 필터링과 데이터 변환을 지원함
        - 대량의 로그 및 이벤트 데이터를 처리하도록 확장됨 
      - 약점 
        - 소스 이벤트에 대한 정렬을 보장하지 않음
        - 메시지를 정확히 한 번만 전달하지 않고 최소 한 번 전달하기 때문에 대상에서 중복 이벤트를 처리해야 함 
      - 로그 및 이벤트 데이터에 최적화돼 있음 

# 클릭스트림 추적 서비스
- 클릭스트림 데이터로 알려진 행동 데이터를 수집, 분석, 집계하는 것. 클릭스트림은 애플리케이션 또는 웹 사이트 내에서 방문자의 행동을 나타내는 일련의 이벤트 
- 클릭, 보기 및 페이지 로드 시간, 방문자가 사용하는 브라우저 또는 장치 등과 같은 관련 컨텍스트가 포함됨. 클릭스트림 데이터는 고객 트래픽 분석, 마케팅 캠페인 관리, 시장 세분화, 세일즈 퍼널 분석(sales funnel analysis) 등과 같은 비즈니스 프로세스 인사이트에 중요함 
- A/B 테스트는 클릭스트림 데이터 스트림을 사용해 비즈니스 상승 효과를 계산하거나 제품 또는 웹 사이트의 새로운 변경 사항에 대한 사용자 피드백을 캡처함 
- 세 가지 중요한 문제점 
  - 데이터 사용자는 분석 요구 사항에 따라 제품 및 웹 페이지에 새로운 추적 비콘(tracking beacon)을 지속적으로 추가해야함. 이러한 비콘을 추가하는 것은 셀프서비스가 아니며 계측 비콘을 추가할 위치, 사용할 계측 라이브러리, 사용할 이벤트 분류를 결정하기 위한 전문 지식이 필요함 
  - 클릭스트림 데이터는 인사이트 생성에 사용되기 전에 집계, 필터링, 보강돼야 함 
  - 클릭스트림 분석은 트랜잭션 기록과 실시간 클릭스트림 데이터에 대한 액세스를 필요로 함 
- 여정 지도
  - 마케팅 캠페인에서는 최적화를 위한 다양한 목표가 존재함. 판매 수익 증대, 고객 유지 개선, 브랜드 범위 확대 등이 그 예. 
  - 인사이트는 웹 추적 이벤트(클릭,뷰,전환), 광고 추적 이벤트(광고 노출, 비용), 인벤토리 데이터베이스(제품, 재고,마진),고객 주문 추적(고객, 주문, 크레딧)으로 구성된 원시 데이터에서 추출해야 함 
  - 웹 트래픽 분석은 트래픽을 가져오는 소스, 인기 키워드, 다른 트래픽 소스 방문자로부터의 전환율, 캠페인에 연결된 코호트 분석 등에 대한 인사이트를 제공함 
  - 클릭스트림 유스 케이스의 세 가지 구성 요소 
    - 고객의 클릭과 뷰를 캡처하기 위해 제품과 웹 페이지에 추적 코드를 추가
    - 비콘에서 데이터를 수집한 뒤 집계, 상관, 정리, 보강
    - 실시간 클릭스트림 이벤트와 데이터 레이크의 기록 데이터를 결합해 인사이트 생성 
- 클릭 시간 지표 최소화
  - 클릭 시간 지표에는 계측 관리, 수집된 이벤트 보강, 데이터 소비에 대한 분석 시간이 포함됨 
  - 계측 관리 
    - 클릭스트림 이벤트를 생성하려면 제품 도는 웹 페이지 내에 계측 비콘이 필요함. 비콘은 일반적으로 모든 요청에 대해 페이지로 로드되는 자바스크립트 추적기로 구현되고 뷰, 클릭 및 기타 동작에 대한 세부 정보와 함께 수집기 서비스로 JSON POST 요청을 보냄 
  - 이벤트 보강
    - 봇 필터링 : 봇에 의해 트리거된 이벤트는 방문자당 고객 인터랙션 및 전환과 관련된 주요 지표를 왜곡하기 때문에 필터링이 필요함 
    - 세션화
      - 원시 클릭스트림 이벤트는 고객 행동을 더 잘 이해하기 위해 세션으로 쪼개짐. 세션은 두 개 이상의 장치 및 사용자 간의 짧은 대화형 정보 교환
      - 세션을 사용하면 구매 빈도가 가장 높은 경로, 사용자가 특정 페이지로 이동하는 방법, 사용자가 이탈하는 시기와 이유, 일부 획득 유입 경로가 다른 페이지보다 효율적인지 등의 질문에 답할 수 있음 
    - 풍부한 컨텍스트
      - 효과적으로 인사이트를 추출하기 위해 클릭스트림 이벤트는 기기 유형, 브라우저 유형, OS 버전과 같은 사용자 에이전트 세부 정보를 추가 컨텍스트로 사용해 보강됨 
  - 인사이트 쌓기
    - 실시간 대시보드는 E2E 고객 여정, 고객 360 프로필, 개인화 등을 파악하는 데 사용됨. 실시간으로 사용자 행동을 추적하면 추천 내용을 업데이트하고, 고급 A/B 테스트를 수행하거나 고객에게 알림을 보낼 수 있음 
    - 고객 ID가 상호 연결돼야 함(이를 ID 스티칭-identity stitching), ID 스티칭 시에는 정확하게 일치하는 프로필을 가지기 위해 가능한 한 많은 식별자와 고객을 일치시킴
    - 단일 파이프라인의 모든 이벤트를 추적하면 IP 주소를 매칭해서 고객 이벤트를 상호 연관시킬 수 있음. 고객이 이메일을 열때 쿠키 ID를 사용한 다음 쿠키가 이메일 주소 해시 코드를 추적하도록 하는 것 
    - 고객의 온라인 여정 지도는 구매 결정에 영향을 미치는 다양한 접점과 채널로 인해 매우 복잡함. 기업의 자체 웹 사이트만을 사용해 고객 행동을 추적하는 것은 라스트 터치 어트리뷰션 모델(last-touch attribution model - 고객의 마지막 접점에만 크레딧을 부여하는 모델)을 사용하는 것과 유사하고 완전한 그림을 제공하지 않음
- 요구 사항 정의
  - 계측 요구 체크리스트
    - 이벤트에서 캡처된 속성 : 이벤트 속성, 즉 누구인지, 무엇인지, 어디인지와 도메인 세부 정보 및 이벤트 유형(페이지 뷰, 클릭 등)을 정의함 
    - 클라이언트 측 이벤트 수집 : 모바일 클라이언트, 데스크톱 응용프로그램, 웹 응용프로그램의 인벤토리를 수집함 
    - 타사 소스 수집 : 구글,페이스북 픽셀, 광고 대행사 등 타사 소스의 로그 데이터와 통계를 집계할 필요가 있는지 판단함. 각 에이전시에 해당하는 웹훅(webhook)을 식별함 
    - 서버 측 이벤트 수집 : 백엔드 애플리케이션 서버에서 이벤트를 캡처해야 하는지 여부를 결정함 
    - 속도와 피드 : 비콘 수, 이벤트 생성 비율, 이벤트 보존 기간에 대한 대략적인 추정치를 가져옴 
  - 보강 요구 사항 체크리스트
    - 봇 필터링 : 실제 사용자 활동 중에서 봇 트래픽을 필터링함 
    - 사용자 에이전트 구문 분석 : 브라우저 유형과 모바일인지 데스크톱인지 등의 추가 세부 정보가 클릭스트림 이벤트와 연결됨 
    - IP2Geo : 위치를 추적해 지역 간 제품 사용 방식의 차이를 더 잘 이해할 수 있음 
    - 세션화 : 특정 세션 및 세션 전체에서 사용자의 활동을 분석하는 유스 케이스에 활용됨 
    - 다양한 시간대에 걸친 이벤트 데이터 요약 : 개별 이벤트 세부 정보와 이에 대한 장기간의 사용자 활동 추세를 확인해야 하는 다양한 요구 사항이 있는 유스 케이스에서 활용됨 
    - 개인정보 필터링 : 사용자 개인정보 보호 규정 준수를 따라 IP 주소 제거가 필요한 유스 케이스 등에 사용됨 
    - 사용자를 식별하는 데 사용되는 다양한 옵션
      - 계정 로그인(사용자의 작은 하위 집합)
      - 쿠키 식별(크로스 디바이스 환경에서는 작동하지 않으며 삭제, 만료, 차단됨)
      - 디바이스 핑거프린팅(사용자를 식별하는 확률적 방법)
      - IP 일치(동적 IP와 공유 IP에서는 식별에 문제가 있음)등이 있음 
- 구현 패턴
  - 계측 패턴 : 제품 및 마케팅 웹 페이지 내에서 추적 비콘 관리를 단순화함
    - 제품 및 웹 페이지에서 계측 비콘 관리를 단순화함. 가용한 비콘을 업데이트, 추가, 나열해 데이터 사용자가 셀프서비스로 사용할 수 있도록 함 
    - 이벤트 수집 : 이벤트는 웹 페이지, 모바일 앱, 데스크톱 앱, 백엔드 서버에 생성됨 
    - 이벤트 확인 : 스키마 속성 및 데이터에 대한 이벤트는 엔디포인트에서 확인됨 
    - 대상에 대한 프록시 이벤트 : 이벤트가 다수의 태그를 사이트에 로드하지 않고 다수의 프로바이더에게 전달됨 
    - Segemnt와 RudderStack 
      - Segement는 게시자-구독자 접근 방식을 사용해 클릭스트림 이벤트에 대한 프록시를 구현함. 이벤트는 메시지 버스(Kafka)에 추가됨. 이메일 도구, 웹 분석과 기타 배포된 솔루션에 대한 프로바이더가 구독자로 추가됨 
  - 보강 패턴 : 클릭스트림 이벤트의 정리 및 보강을 자동화함
    - 보강 패턴은 원시 이벤트를 분석, 필터링하고 개선함. 패턴은 규칙 기반이며 더 간편한 추론(휴리스틱)을 위해 데이터 사용자에 의한 확장이 가능해야 함 
    - 봇 필터링 패턴 : 인간 사용자와 봇을 구분하는 규칙을 정의함 
    - 세션화 패턴 
      - 일반적으로 접근하는 방식은 이벤트가 도착하지 않고 통과하는 지연 시간(일반적으로 30분)을 통한 것
      - 세션화 시에는 클릭스트림 이벤트에 대해 SQL 쿼리가 지속적으로 실행되며 세션 마커를 생성함 
      - AWS Kinesis는 슬라이딩 윈도우, 텀블링 윈도우, 스태거 윈도우라는 세 가지 유형의 윈도우 쿼리 함수를 제공함 
    - 사용자 컨텍스트 보강 패턴
      - 클릭스트림 이벤트에는 지리적 위치와 브라우저 버전 같은 사용자 에이전트 세부 정보를 추가해 컨텍스트를 보강함 
      - Divolte Collector로서, 비콘을 수집하고 이벤트를 보강함 
  - 소비 패턴 : 이벤트 처리를 자동화해서 다양한 유스 케이스에 대한 실시간 인사이트를 생성함 
    - 마케팅 캠페인이 어떻게 퍼포먼스를 내고 있는지, 실험이 리텐션, 성장, 교차 판매에 어떻게 영향을 미치고 있는지 등과 관련된 ML 모델과 실시간 대시보드의 강화를 위해 클릭스트림 데이터 소비에 초점을 맞춤
    - 일괄 처리 지표와 상호 관련된 스트리밍 데이터를 결합하며, CEP(Complex Event Processing - 복합 이벤트 처리)라고 함 
    - CEP 패턴은 윈도우 설정 기능을 사용하며 일괄 처리 중 또는 일괄 처리 간의 이벤트 전반에 걸친 패턴의 일반적인 검색 및 상관관계를 포함하고 있음 
      - 아파치 NiFi 및 Pulsar 같은 메시지 처리 프레임워크를 사용해 타임스탬프로 식별된 개별 이벤트 처리가 가능함 
      - 아파치 Druid 및 Pinot와 우버의 M3 같은 시계열 데이터스토어 형태의 서빙 레이어를 사용해 레코드 수준 업데이트와 일괄 벌크 로드(batch bulk load)를 모두 처리 가능함 
    - 아파치 Pulsar
      - 지리적 복제, 멀티테넌시, 유니파이드 큐, 스트리밍 기능을 갖추고 있으며, 계층화된 아키텍처 기반으로 구촉된 강력한 발행 구독(pub-sub)모델 
    - 시계열 서빙 레이어의 아파치 Druid
      - Druid는 각 열이 개별적으로 저장되는 열 지향 저장소를 구현함 
      - 빠른 스캔, 순위, 그룹화를 지원하는 특정 쿼리에 필요한 열만 읽을 수 있음. Druid는 빠른 검색 및 필터링을 위해 문자열 값에 대해 반전된 인덱스를 생성하고 진화하는 스키마와 중첩된 데이터를 우하하게 처리함 
      - 여러 데이터 작업자에 걸쳐 샤딩(sharding)해서 시간을 기준으로 데이터를 지능적으로 분할함. 시간 기반 쿼리는 전통적인 데이터베이스보다 훨씬 빠름 
      - 네이티브 JSON 기반 언어 외에도 Druid는 HTTP 또는 JDBC를 통해 SQL을 지원함. 초당 수백만 개의 이벤트를 수집하고 수년간의 데이터를 유지하며 1초 미만의 쿼리를 제공하도록 확정할 수 있음. 서버를 추가하거나 제거하는 것만으로 규모를 확장하거나 축소하면 Druid가 자동으로 재조정됨 
    
# 셀프서비스 데이터 준비
## 데이터 레이크 관리 서비스
- 데이터 레이크는 페타바이트 규모의 정형, 반정형, 비정형 데이터를 집계하기 위한 중앙 데이터스토어가 됐음, 데이터의 버전 관리 및 롤백을 지원해야 함 
- 복제본 간의 일관성 보장, 기본 데이터의 스키마 진화, 부분 업데이트 지원, 기존 데이터 업데이트를 위한 ACID 일관성 등과 같은 데이터 수명주기 관리 작업들이 있음 
- 데이터 레이크가 중앙 데이터 웨어하우스로 인기를 얻기는 했지만, 전통적인 데이터 수명주기 관리 작업에 대한 지원은 부족함
- 고충 
  - 원시 데이터 수명주기 작업에 자동화된 API가 없고 재현성 및 롤백, 데이터 제공 계층 프로비저닝 등에 대한 엔지니어링 전문 지식이 필요함 
  - 동시 읽기-쓰기 작업에 대한 레이크의 일관성 부족을 수용하기 위해 애플리케이션을 이용한 대체 해결 방법이 필요함 
  - 규정 준수를 위해 고객의 기록을 삭제하는 것과 같은 증분 업데이트의 최적화 수준이 매우 낮음 
  - 스트림 일괄 처리를 결합한 통합 데이터 관리가 불가능함 
- 대체 방안들은 일괄 처리 및 스트림(람다 아키텍처라고 함)에 대해 별도의 처리 코드 경로를 필요로 하거나 모든 데이터를 이벤트(카파 아키텍처라고 함)로 변환해야 하는데, 이는 대규모 관리가 쉽지 않음 
- 레이크의 원시 데이터 수명주기 관리와 관련된 문제점
- |원시 수명주기 작업|문제점|적용 대안|
  |:---:|:---:|:---:|
  |작업 실패로 인해 탐색, 모델 학습, 손상 해결에 필요한 데이터 버전 관리|스냅샷을 생성하고 복원하는 명확한 프로세스가 없음.특정 시점에서 특정 테이블 속성의 값을 쉽게 얻을 수 있는 방법이 없음. 실패한 작업/트랜잭션을 버전 또는 타임스탬프에 따라 롤백할 수 있는 방법이 없음|스냅샷은 정책을 기반으로 생성됨.모델의 재현성을 위해 데이터의 복사본이 여러 개 생성되므로 스토리지 비용이 증가함. 기록 데이터에 액세스하기 위해 전체 스냅샷이 샌드박스 네임스페이스에 복원되고 분석을 위해 액세스할 수 있게 됨 
  |소스 데이터 세트의 변경 사항을 관리하기 위한 스키마 진화|스키마가 진화하면 다운스트림 분석이 작동하지 않을 수 있음.레이크 수집 시 데이터 세트 스키마의 검증 지원이 없음|소스 데이터 세트와 다운스트림 분석간에 격리 데이터 레이어를 생성함. 이는 완전한 것이 아니며, 모든 스키마 변경에 대해 작동하지 않음
  |레이크 데이터를 웹 애플리케이션 및 분석에 효율적으로 노출하기 위한 데이터 서비스 계층|처리된 레이크 데이터에 대한 읽기-쓰기는 키-값, 그래프,문서,시계열과 같은 모든 데이터 모델에 효율적이지 않을 수 있음|관계형 모델에 맞게 애플리케이션의 데이터 모델을 수정함 
  |데이터 액세스 및 사용에 대한 중앙 집중식 추적.|여러 사용자와 서비스에 걸친 데이터 세트 업데이트 및 액세스를 추적하기 어려움. 중앙 집중식 감사 기능이 부족하면 액세스 제어와 관련된 시각지대가 생김|애드혹 스크립트 및 감사 모니터링|
- 데이터 업데이트 관리
  - 데이터 레이크는 ACID 데이터베이스가 제공하는 것과 동일한 무결성 보장을 제공하지 않음. 분리로 인해 쓰기 작업이 데이터를 업데이트하는 동안 부분 데이터를 가져오는 영향 판독기가 누락됨. 동시 쓰기 작업은 데이터를 손상시킬 수 있음 
  - 업데이트 누락 시 재시도를 하거나, 사용 중인 애플리케이션이 손상된 데이터를 읽는 것을 방지하기 위해 실행 중에 데이터를 사용하지 못하도록 제한하는 블랙아웃(blackout) 시간을 부여하는 것. 완료 및 오류발생 시 롤백을 위해 업데이트를 수동으로 추적하는 것 
- 데이터 레이크 관리 시간 최소화
  - 네임스페이스 영역
    - 데이터 레이크 내에서 영역(zone)은 데이터의 논리적 및 물리적 분리를 허용함. 네임스페이스는 현재 워크플로우, 데이터 파이프라인 프로세스, 데이터 세트 속성을 기반으로 다양한 영역으로 구성됨 
    - 브론즈 존 : 트랜잭션 데이터스토어에서 수집된 원시 데이터를 위한 영역으로 원시 데이터 및 장기 보존을 위한 매립장이라고 할 수 있음. 민감한 데이터는 암호화되고 토큰화됨
    - 실버 존 : 필터링, 정리, 증강된 데이터가 있는 중간 데이터가 포함된 스테이징 영역 
    - 골드 존 : 비즈니스 수준으로 집계되고 지표와 함께 사용할 준비가 된 정제된 데이터를 포함함 
- 지원되는 파일 형식
  - 데이터 형식은 포맷의 견고성(즉, 데이터 손상 시나리오에 대해 포맷이 얼마나 잘 테스트됐는지)과 널리 사용되는 SQL 엔진 및 분석 플랫폼과의 상호 운용성에 대한 부분에서 균형을 맞춰야 함 
    - 표현성 : 포맷이 지도, 레코드, 목록, 중첩된 데이터 구조 등과 같은 복잡한 데이터 구조를 표현할 수 있는가?
    - 견고성 : 포맷이 잘 정의돼 있고 쉽게 이해할 수 있는가? 손상 시나리오와 기타 예외 케이스에 대해 테스트가 잘됐는가? 견고성의 다른 중요한 측면은 포맷의 단순성. 형식이 복잡할수록 직렬화 및 역직렬화 드라이버에서 버그가 발생할 가능성이 높아짐
    - 공간 효율성 : 데이터의 간결한 표현은 언제나 최적화의 기준이 됨. 공간 효율성은 데이터를 이진으로 표현하는 능력과 데이터를 압축하는 능력이라는 두 가지 요소를 기반으로함 
    - 액세스 최적화 : 응용프로그램 쿼리에 대한 응답으로 액세스되는 데이터양(바이트)을 최소화함.이는 쿼리 유형에 따라 크게 달라지며, 어디에나 적용 가능한 방법은 없음(select * 쿼리 vs 제한된 수의 열 값을 기반으로 필터링하는 쿼리). 액세스 최적화의 또 다른 고려 사항은 병렬 실행을 위한 파일을 분할하는 기능 
  - 주요 포맷
    - 텍스트 파일 : 가장 오래된 형식 중 하나. 사람이 읽을 수 있고 상호 운용이 가능하지만, 공간과 접근 최적화 측면에서 상당히 비효율적
    - CSV/TSV : 이 형식에는 비효율적인 이진 표현과 액세스에 관련된 제한이 있음. 또한 복잡한 데이터 구졸르 이 형식으로 표현하기는 어려움 
    - JSON : 이 형식은 애플리케이션 개발자에게 가장 표현성이 있고 범용적인 형식 중 하나. 이 목록의 다른 형식과 비교하면 공간 및 액세스 측면 모두에서 최적화되지 않았음 
    - SequenceFile : Hadoop에서 가장 오래된 파일 형식 중 하나. 데이터는 키-값 쌍으로 표시됌. 자바가 쓰기 가능한 인터페이스를 사용해 Hadoop에 액세스하는 유일한 방법이었을 때 인기가 있었음.가장 큰 문제는 상호 운용성이었고, 일반적인 정의가 없었음 
    - Avro : 스키마가 파일 헤더와 함께 저장된다는 점을 제외하면 SequenceFile과 유사함. 형식은 표현성이 있고 상호 운용이 가능함. 이진 표현에는 오버헤드가 있으며, 최적화가 최고로 잘된 것은 아님. 전반적으로 범용 워크로드에 적합함
    - ORCFile : 고급 사용 데이터베이스에서 사용되는 열 기반 포맷. Hadoop 에코시스템에서 이 포맷은 RCfile 포맷의 후속 포맷으로 여겨지고 있는데, 이는 데이터를 문자열로 저장하는 데 비효율적이었음. ORCFile은 강력한 Hortonworks 지원과 최근의 흥미로운 발전을 통해 PPD(Push Predicate Down)와 향상된 압축 기능을 제공함 
    - Parquet : ORCFile과 유사하며 클라우데라의 지원을 받음. Parquet는 구글 Dremel논문의 최적화를 구현함
  - 인코딩과 함께 사용할 수 있는 다양한 압축 기술로 zlib, gzip, LZO, Snappy 등이 널리 사용됨 
