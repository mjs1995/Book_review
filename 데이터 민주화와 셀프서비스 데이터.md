# 서평

# 소개
- 데이터 민주화란 데이터에 쉽게 접근할 수 있도록 기반을 만들어 데이터를 잘 아는 사람부터 잘 모르는 사람까지 누구나 데이터를 쉽게 사용해 인사이트를 도출할 수 있도록 한느 것 
- 셀프서비스 데이터란 데이터 엔지니어나 데이터 과학자가 관여하지 않더라도 마케터, 사업 담당자, 서비스 운영 담당자 등 조직 내 모든 사람이 스스로 데이터에 접근해 인사이트를 추출할 수 있도록 만들어진 데이터 기반을 의미함 
- 원시 데이터에서 인사이트로의 여정 지도 
  - 전통적인 데이터 웨어하우스와 현재의 빅데이터 시대에서 인사이트를 추출하는 방식의 주요 차이점 
  - ||데이터 웨어하우징 시대의 인사이트 추출|빅데이터 시대의 인사이트 추출
    |:---:|:---:|:---:|
    |데이터 형식|정형 데이터|정형,반정형,비정형 데이터
    |데이터 특성|대용량 데이터|데이터의 4V:볼륨,속도,다양성,진시성
    |데이터 카탈로그 작성|데이터를 집계할 때 정의됨|데이터를 읽을 때 정의됨
    |인사이트의 신선함|인사이트는 주로 소급형(비드니스 마지막 주 기준 지표)|인사이트는 소급형,대화형,실시간,예측의 조합
    |쿼리 처리 방식|단일 솔루션으로 결합된쿼리 프로세서와 데이터 스토리지|쿼리 처리와 데이터 스토리지가 분리됨
    |데이터 서비스|단일 솔루션으로 통합|작업에 적합한 도구를 선택하는 데 많은 치환을 허용하는 믹스 앤 매치(mix-and-match)방식
  - 발견
    - 모든 인사이트 도출 프로젝트는 사용 가능한 데이터 세트와 개발 산출물을 발견하고, 인사이트를 발전시키는 데 필요한 추가 데이터를 수집하는 것부터 시작함
    - 데이터 세트의 메타데이터 세부 정보 발견
      - 마일스톤은 데이터가 생성된 위치, 데이터 속성이 생성된 방법 등 메타데이터 속성을 이해하는 것 
      - 메타데이터를 수집하고 상호 연결이 가능하려면 데이터스토어, 수집 프레임워크, 스케줄러, 메타데이터 카탈로그, 규정 준수 프레임워크 등에 접근이 필요함
      - 마일스톤을 완료하는 데 걸리는 시간은 해석시간(time to interpret)을 지표로 추적함 
    - 사용 가능한 데이터 세트 및 아티팩트 검색
      - 마일스톤은 모든 관련 데이터 세트와 아티팩트, 예를 들어 뷰, 파일, 스트림, 이벤트, 지표, 대시보드, ETL, 임시 쿼리를 찾는 것이라고 할 수 있음 
      - 탐색 시간 지표(time to find)로 추적됨 
    - ML 모델에서의 기능 재사용 또는 생성
      - 피처화 시간(time to featurize) 지표로 추적함 
    - 누락된 데이터 집계
      - 비즈니스 대시보드를 만들려면 식별된 데이터 세트(고객 활동 및 결제 청구 기록)를 결합해 리텐션 리스크(retention risk)에 대한 인사이트를 생성
      - 데이터 가용성 확보 시간(time to data availability)
    - 클릭스트림 이벤트 관리
      - 클릭, 뷰와 이전 애플리케이션 페이지, 방문자 기기 유형 등 연관된 맥락까지의 고객 활동을 분석해야 함
      - 클릭스트림 데이터(clickstream data)는 우선 수집, 필터링되고 보강돼야 인사이트 생성에 사용할 수 있음 
      - 클릭 시간(time to click)지표로 추적함 
  - 준비
    - 준비 단계에서는 인사이트 추출을 위해 실제 비즈니스 로직 구축용 데이터를 준비하는데 집중함. 준비는 데이터 집계, 정리, 표준화, 변환, 비정규화를 포함하는 반복적이고 시간 집약적인 작업이며 여러 가지 도구와 프레임워크를 포함함
    - 규제 준수 요건을 충족하기 위해 데이터 거버넌스(data governance)를 보장함 
  - 중앙 저장소 내의 집계 데이터 관리 
    - 비즈니스 대시보드는 과거 일괄 처리 데이터 스트리밍 행동 데이터 이벤트를 결합해야 함. 데이터는 데이터 모델과 온디스크 형식을 고려해 효율적으로 유지 관래돼야 함
    - 데이터 레이크 관리 시간(time to data lake management) 지표에 의해 추적됨 
  - 데이터의 구조화, 정리, 보강, 유효성 검사
    - 랭글링 시간(time to wrangle) 지표로 추적함 
  - 데이터 권한 규정 준수 보장
    - 규정 준수(compliance)는 고객 경험을 인사이트로 더 잘 제공하는 것과 고객 동의 내에서 데이터가 사용되도록 보장하는 것 사이의 균형 조정 행위 
    - 규정 준수 시간(time to comply) 지표로 추적함 
  - 구축
    - 인사이트를 추출하는 데 필요한 실제 로직을 작성하는 데 집주앟ㅁ
    - 데이터 액세스 및 분석을 위한 최상의 접근 방식 결정 
      - 구축 단계의 출발점은 인사이트 로직을 작성하고 실행 전략을 결정하는 것 
      - 장기간 실행되는 일괄 처리(batch) 프로세스는 Hive 또는 Spark에 있는 반면 짧은 대화형 쿼리는 Presto 클러스터에서 실행됨 
      - 가상화 시간(time to virtualize)지표로 추적함
    - 변환 로직 작성
      - 대시보드 또는 모델 인사이트의 실제 로직은 ETL, ELT 또는 스트리밍 분석 패턴으로 작성됨. 비즈니스 로직은 변화에 대한 관리가 용이할 뿐만 아니라 실행성과 확장성이 있는 실제 코드로 번역돼야 하며 가용성, 품질, 변경 관리를 위해 모니터링돼야 함 
      - 변환 시간(time to transform) 지표로 추적함
    - 모델 학습
      - 학습은 CPU와 GPU 같은 전문 하드웨어가 조합된 서버로 구성된 팜(farm)에서 운영됨 
      - 학습 시간(time to train) 지표에 의 추적됨 
    - ML 모델 변경 사항의 지속적인 통합 
      - ML 모델 파이프라인은 소스 스키마 변경, 형상 로직, 종속 데이터 세트, 데이터 처리 설정, 모델 알고리즘을 통해 지속적으로 진화함 
      - 통합 시간(time to integrate) 지표에 의해 추적됨 
    - 인사이트 A/B 테스트
      - 버킷 테스트, 분할 테스트 또는 통제된 실험이라고 알려진 A/B 테스트는 데이터 중심 의사 결정을 위한 표준 접근 방식이 되고 있음 
      - A/B 테스트 시간(time to A/B test)
  - 운영화
    - 여정 지도의 운영화 단계에서는 인사이트가 프로덕션에 배포됨
    - 쿼리 검증 및 최적화
      - 어디에나 만능으로 적용되는 쿼리의 최적 조절 값은 없고 데이터 모델, 쿼리 유형, 클러스터 크기, 동시 쿼리 로드 등에 따라 달라짐. 쿼리 최적화는 지속적인 활동. 
      - 최적화 시간(time to optimize) 지표에 의해 추적됨 
    - 파이프라인 오케스트레이션 
      - 오케스트레이션은 파이프라인 서비스 수준 계약(SLA, Service Level Agreement)을 보장하고 기본 리소스의 효율적인 활용을 보장하는 균형 조정 행위 
      - 파이프라인은 데이터 수집, 준비, 변환, 학습, 배포 전반에 걸쳐 서비스를 호출함. 데이터 사용자가 이러한 서비스 전반에서 정확성, 견고성, 적시성을 모니터링하고 디버깅하는 것이 중요함 
      - 파이프라인 오케스트레이션은 멀티테넌트(multitenant)로, 여러 팀과 비즈니스 유즈 케이스를 지원함 
      - 오케스트레이션 시간(time to orchestrate) 지표에 의해 추적됨 
    - ML 모델 배포 
      - 배포 시간(time to deploy) 지표 
    - 인사이트 품질 모니터링
      - 인사이트 품질 확보 시간(time to insight quality) 지표 
    - 지속적인 비용 모니터링
      - 비용 관리는 종래의 종량제 모델과 달리 사용량에 따라 선형적으로 비용이 증가하는 클라우드에서 특히 중요함 
      - 비용 최적화 시간(time to optimize cost) 지표로 추적됨 
- 인사이트 시간 스코어가드 정의
  - 인사이트 시간(time to insight)은 원시 데이터에서 인사이트까지의 전체 여정을 완료하는 데 걸리는 시간을 측정하는 전반적인 지표 
  - 각 마일스톤의 척도를 합치면 전체 인사이트 시간 척도가 됨 
  - 인사이트 시간 스코어가드(scorecard)를 사용함. 전체 여정 지도에서 가장 시간이 많이 걸리는 마일스톤을 찾는 것이 이 활동의 목표 
    - 해석 시간(time to intepret) : 데이터 세트의 메타데이터 세부 정보를 인사이트 개발에 사용하기 전에 해석하는 마일스톤에 연관된 지표 
    - 탐색 시간(time to find) : 검색 관련 데이터 세트와 아티팩트의 마일스톤에 연관된 지표 
    - 피처화 시간(time to featurize) : ML 모델 학습에 필요한 기능 관리 마일스톤과 연관된 지표 
    - 데이터 가용성 확보 시간(time to data availability) : 사일로 간에 데이터를 이동하는 마일스톤과 연관된 지표 
    - 클릭 시간(time to click) : 클릭스트림 데이터 이벤트의 수집, 관리, 분석 마일스톤과 연관된 지표 
    - 데이터 레이크 관리 시간(time to data lake management) : 중앙 저장소에서 데이터를 관리하는 마일스톤과 연관된 지표 
    - 랭글링 시간(time to wrangle) : 데이터 구조화, 정리, 보강, 검증의 마일스톤과 연관된 지표 
    - 규정 준수 시간(time to comply) : 데이터 권한 규정 준수를 보장하는 마일스톤과 연관된 지표 
    - 가상화 시간(time to virtualize) : 데이터 구축, 분석의 접근 방식을 선택하는 마일스톤과 연관된 지표 
    - 변환 시간(time to transform) : 데이터 및 ML 파이프라인에서 변환 로직을 구현하는 마일스톤과 연관된 지표 
    - 학습 시간(time to train) : ML 모델 학습 마일스톤과 관련된 지표 
    - 통합 시간(time to integrate) : ML 파이프라인의 코드, 데이터, 설정의 변경을 통합하는 마일스톤과 연관된 지표 
    - A/B 테스트 시간(time to A/B test) : A/B 테스트의 마일스톤과 연관된 지표 
    - 최적화 시간(time to optimize) : 쿼리 및 빅데이터 프로그램을 최적화하는 마일스톤과 연관된 지표 
    - 오케스트레이션 시간(time to orchestrate) : 프로덕션의 파이프라인 조정 마일스톤과 연관된 지표 
    - 배포 시간(time to deploy) : 프로덕션에 인사이트를 배포하는 마일스톤과 연관된 지표 
    - 인사이트 품질 확보 시간(time to insight quality) : 생성된 인사이트의 정확성을 보장하는 마일스톤과 연관된 지표 
    - 비용 최적화 시간(time to optimize cost) : 비용을 최적화하는 마일스톤과 연관된 지표 
- 셀프서비스 로드맵 실행 
  - 현재 스코어카드를 정의하는 것부터 시작
  - 데이터 사용자에 대한 설문 조사를 기반으로 여정 지도를 가장 많이 늦추는 두 세가지 지표를 식별하고 현재 작업이 구현되는 방식에 대한 기술적 분석을 수행하라. 지표의 중요도는 현재 프로세스, 데이터 사용자 기술, 기술 구성 요소, 데이터 속성, 유스 케이스 요구 사항에 따라 기업마다 다르다는 것을 인식하라
  - 각 지표는 매슬로우의 구현 패턴 계층부터 시작하라. 각 장은 하나의 지표에 대한 자동화 단계가 증가하는 패턴을 다룸 
  - 각 분기마다 지표 우선순위를 전념하고 셀프서비스화에 집중하면서 단계별 기기, 걷기, 달리기 전략을 따르자 

# 셀프서비스 데이터 발견 
## 메타데이터 카탈로그 서비스 
- 빅데이터 시대 이전에는 데이터를 중앙 웨어하우스에 추가하기 전에 먼저 분류함 
- 쓰기스키마(schema-on-write) : 스키마, 계보, 소유자, 비즈니스 분류법 등을 포함한 메타데이터 세부 정보를 먼저 카탈로그화했음. 
- 읽기스키마(schema-on-read) : 오늘날 데이터 레이크의 접근 방식에는 머저 데이터를 집계한 뒤 데이터 사용 시에 데이터 세부 정보를 추론함 
- 데이터 세트 이해하기
  - 데이터 과학자는 새로운 모델을 구축하거나 새로운 측정 기준을 수립하거나 임시 분석을 수행하는 첫 번째 단계로 데이터의 출처, 사용 방법, 지속 방법 등에 대한 세부 정보를 이해해야 함 
  - 메타데이터 카탈로그는 질문에 대한 단일 진실 공급원(SSOT, Single Source Of Truth) 
- 데이터 세트 분석하기
  - 데이터 과학자는 데이터 세트 속성과 쿼리 유형을 기반으로 작업에 적합한 도구를 사용하며 ,하나의 데이터 세트를 Pig, Spark, Presto, Hive 등 여러 쿼리 엔진에서 번갈아가며 사용할 수 있음 
- 지식 확장하기 
  - 팀지식 : 데이터 과학자는 프로젝트를 위해 서로 다른 데이터 세트로 작업하면서 비즈니스 어휘, 데이터 품질 등에 대한 추가 세부 정보를 발견함 
- 해석 시간 최소화
  - 해석 시간은 데이터 과학자가 인사이트를 구축하기 전에 데이터 세트의 세부 정보를 이해하는 데 걸리는 시간을 말함 
  - 기술 메타데이터 추출하기
    - 기술 메타데이터는 데이터 세트의 논리적, 물리적 메타데이터 세부 정보로 구성됨 
    - 물리적 메타데이터는 생성 및 수정 타임스탬프, 물리적 위치 및 형식, 스토리지 계층, 보존 세부 정보와 같은 물리적 레이아웃과 지속성에 관련된 세부 정보를 포함함
    - 논리적 메타데이터에는 데이터 세트 스키마, 데이터 원본 세부 정보, 데이터 세트를 생성하는 프로세스 ,데이터 세트의 소유자 및 사용자가 포함됨 
    - 기술 메타데이터는 여러 소스 간 연관 관계를 고려하지 않고 각각의 데이터 소스를 크롤링 해서 추출함 
    - 메타데이터를 수집하는 데 세 가지 주요 과제 
      - 형식 차이 
      - 스키마 유추
      - 변경 추적 
- 운영 메타데이터 추출하기 
  - 두 가지 주요 버킷 
    - 계보(lineage)
      - 데이터 세트가 어떻게 생성됐는지와 다른 데이터 세트에 대한 종속성을 추적함 
      - 특정 데이터 세트의 계보는 모든 종속 입력 테이블, 파생 테이블, 출력 모델 및 대시보드를 포함함 
      - 최종 출력 도출을 위해 변환 로직을 구현하는 작업이 포함됨 
    - 데이터 프로파일링 통계
      - 가용성 및 품질 통계
      - 데이터 세트의 열 수준 및 설정 수준 특성을 포착함 
      - 완료 시간, 처리된 데이터 ,파이프라인과 관련된 오류를 포착하는 실행 통계도 포함됨 
  - 서로 다른 다양한 유형의 데이터베이스, 스케줄러, 쿼리 엔진, BI(비즈니스 인텔리전스) 툴로 인해 서로 다른 처리 프레임워크, 데이터 플랫폼, 스케줄링 시스템에 걸친 전반적인 데이터 흐름과 계보를 이해하는 것은 어려운 과제. 처리 프레임워크의 다양성을 고려하면서 세부 사항을 짜맞춰 연결하는 것이 이 과제에 해당함. UDF, 외부 매개변수 등의 경우에는 코드로부터 계보를 유추하는 것이 쉽지 않기 때문 
  - 팀 지식 수집하기 
    - 팀 지식의 네 가지 범주 
      - 주석, 문서, 속성 설명 형식의 사용자 정의 메타데이터
      - 비즈니스 직관적 계층 구조(business-intuitive hierarchy)에서 데이터 개체 및 메트릭을 연결하고 구성하기 위한 비즈니스 분류법 또는 어휘
      - 규정 준수, 개인 식별 가능 정보(PII, Personally identifiable information) 데이터 필드, 데이터 암호화 요구 사항 등과 같은 측면의 데이터 세트 상태
      - 가장 인기 있는 테이블, 쿼리, 기타 형태의 ML 증강 메타데이터(ML-augmented metadata) 
- 구현 패턴
  - 메타데이터 카탈로그 서비스에 대한 자동화 수준 
    - 소스 특화 커넥터 패턴 : 서로 다른 데이터 소스에 연결하고 데이터와 연결된 메타데이터 정보를 추출하는 작업을 간소화함
    - 계보 상관 패턴 : 소스 테이블과 대상 테이블을 상관시키는 변환 계보를 추출하는 작업을 자동화함
    - 팀 지식 패턴 : 비즈니스 문맥 수집과 데이터 사용자 간의 지식 공유를 단순화함 
  - 메타데이터 카탈로그 서비스는 금융산업규제당국(finra)의 Herd, 우버의 Databook, 링크드인의 WhereHows와 Data Hub, 넷플릭스의 Metacat, 아파치의 Atlas 프로젝트, AWS Glue 같은 클라우드 서비스가 있음 
  - 소스 특화 커넥터 패턴
    - 소스 특화 커넥터 패턴은 기술 메타데이터 집계를 위해 소스에서 메타데이터를 추출함
    - 데이터 세트는 URN(Uniform Resource Name) 기반 이름을 사용해 식별됨 
    - 두 가지 구성 요소(building block)
      - 커스텀 추출기
        - 소스 특화 커넥터는 메타데이터를 연결하고 지속적으로 가져오는 데 사용됨. 커스텀 추출기를 RDBMS, Hive, 깃허브 등의 데이터스토어에 연결하기 위해 자격 증명을 인증하려면 적절한 액세스 권한이 필요함 
        - 추출기가 소스에 연결되면 데이터 세트의 형식, 스키마, 관련 속성을 결정하는 분류자(classifier)를 구현해 세부 정보를 수집함 
      - 연합 지속성(federated persistence)
        - 메타데이터 세부 정보는 정규화된 방식으로 유지됨 
  - 계보 상관 패턴(lineage correlation pattern) 
    - 데이터 및 작업에 걸친 운영 메타데이터를 연결해 실행 통계와 결합함 
    - 작업 실행 레코드를 계보와 결합함으로써 데이터 신선도, 서비스 수준 협약(SLA, Service Level Agreement), 영향을 받는 특정 테이블의 다운스트림 작업, 사용량에 따른 파이프라인 내의 테이블 순위 등에 관한 질문에 답변할 수 있음 
      - 쿼리 구문 분석
      - 파이프라인 상관관계
      - 실행 통계를 통한 계보 보강 
    - 아파치 Atlas는 Sqoop, Hive, Kafka, Storm 등 여러 Hadoop 에코시스템 구성 요소에 걸쳐 계보를 추출함. Atlas는 Hadoop job ID가 주어지면 job history 노드에서 job conf 쿼리를 수집함. Sqoop 작업에도 비슷한 접근법이 적용돼 있음. 
    - Atlas는 테이블 수준 계보 외에도 다음과 같은 유형의 종속성을 추적해 열 수준 계보를 지원함
      - 단일 종속성 : 출력 열의 값이 입력 열과 동일함 
      - 표현 종속성 : 출력 열은 런타임 시 입력 열의 일부 표현식(Hive SQL 표현식)에 의해 변환됨
      - 스크립트 종속성 : 출력 열은 사용자가 제공한 스크립트에 의해 변환됨 
      - 강점은 종속성을 재구성하는 간섭 없는 방법을 제공함. 단점은 계보가 쿼리 유형을 100% 커버하지 못하고 대략적이라는 것 
  - 팀 지식 패턴
    - 팀 지식의 세 가지 주요 유형
      - 데이터 문서 : 속성 의미, 열거형, 데이터 설명의 세부 정보가 포함됨
      - 비즈니스 분류법 및 태그 : 비즈니스 영역과 주제 영역에 따라 데이터를 분류하는 분려법으로, 비즈니스 내에서 사용되는 개념이 포함됨 
      - 플리거블 검증(pluggable validation) : 테이블 소유자는 테이블에 대한 감사 정보를 메타데이터로 제공할 수 있음. 테이블 작성에 사용할 열 기본값과 검증 규칙을 제공할 수 있음 

## 검색서비스
- 인사이트를 개발하는 반복적인 프로세스 중 연관 데이터 세트(테이블, 뷰, 스키마, 파일, 스트림, 이벤트)와 아티팩트(지표, 대시보드, 모델, ETL, 임시 쿼리)를 찾는 것에 초점을 맞춤 
- 검색 서비스를 통해 데이터 사용자는 키워드, 와일드카드 검색, 비즈니스 용어 등을 사용해 원하는 것을 표현함. 
- 소스 발견, 데이터 세트 및 아티팩트 인덱싱, 결과 순위 지정, 액세스 거버넌스(access governance) 보장, 지속적인 변경 관리 등의 어려운 업무를 보이지 않는 곳에서 수행함 
- 데이터 세트 및 아티팩트 인덱싱
  - 인덱싱의 두 가지 작업
    - 데이터 세트와 아티팩트의 소스 찾기
    - 해당 소스를 조사해 스키마와 메타데이터 속성 같은 세부 정보 수집 
  - 접근 제어하기 
    - 데이터 세트 및 아티팩트 소스에 안전하게 연결
    - 검색 결과에 대한 접근 제한 
- 검색 서비스를 구축하는 데는 세 가지 주요 모듈 
  - 인덱서 모듈 
    - 사용 가능한 데이터 세트와 아티팩트를 발견하고, 스키마 및 메타데이터 속성을 추출하고, 카탈로그에 추가함. 이 모듈은 변경 내용을 추적하고 세부 정보를 지속적으로 업데이트함 
  - 순위 모듈 : 관련성과 인기도의 조합에 따라 검색 결과의 순위를 매기는 역할을 함
  - 액세스 모듈 : 데이터 사용자에게 표시되는 검색 결과가 접근 제어 정책을 준수하도록 함 
- 요구 사항 순위 매기기 
  - 데이터 세트와 아티팩트에 관련된 메타데이터의 범주
  - |메타데이터 범주|속성 예|
    |:---:|:---:|
    |기본|크기,형식,최종 수정, 가명, 접근 제어 목록
    |콘텐츠 기반|스키마,기록 수,데이터 핑거프린트,키 필드
    |계보|읽기 작업,쓰기 작업, 다운스트림 데이터 세트, 업스트림 데이터 세트
    |사용자 정의|태그, 카테고리
    |사람|소유자,팀 접근, 팀 업데이트
    |시간|변경 히스토리 
  - 접근 제어 요구 사항
    - 사용자별 정책은 역할 기반 접근 제어(RBAC, Role-Based Access Control), 속성별 정책은 속성 기반 접근 제어(ABAC, Attribute-Based Access Control), 사용자 그룹에 대한 가시성 제한은 RBAC 정책이며 데이터 태그 또는 개인 식별 정보(PII)에 대해 정의된 정책은 ABAC 정책 
    - 다른 특수 처리 요구 사항이 필요할 수 있음 
      - 행 또는 열 값의 마스킹 
      - 데이터 세트와 아티팩트를 특정 타임스탬프까지 볼 수 없도록 하는 시간 변동 정책(분기별 결과가 공식적으로 발표된 날짜까지 표를 볼 수 없음) 
  - 비기능 요구 사항
    - 비기능 요구 사항(NFR,Nonfunctional Requirement)
      - 검색 응답 시간 : 검색 서비스가 초 단위로 검색 쿼리에 응답하도록 하는 것이 중요함 
      - 대규모 인덱 지원을 위한 확장 : 기업이 성장함에 따라 수천 개의 데이터 세트와 아티팩트를 지원하도록 검색 서비스를 확장하는 것이 중요함 
      - 새로운 소스에 대한 손쉬운 온보딩 : 데이터 소스 소유자가 검색 서비스에 소스를 추가할 때의 UX를 단순화해야 함 
      - 자동 모니터링과 알림 : 서비스 상태는 모니터링하기 쉬워야 함. 프로더션 중 문제가 발생하면 자동 경고가 생성돼야 함 
- 구현 패턴
  - 기존 작업 지도에 따라 검색 서비스에 대한 자동화 수준은 세 가지 
    - 푸시 풀 인덱서 패턴 : 사용 가능한 데이터 세트와 아티팩트를 발견하고 지속적으로 업데이트함 
    - 하이브리드 검색 순위 패턴 : 데이터 사용자가 데이터 프로젝트의 요구 사항에 맞는 가장 관련성 높은 데이터 세트와 아티팩트를 찾을 수 있도록 결과의 순위를 매김 
    - 카탈로그 접근 제어 패턴 : 데이터 사용자 및 기타 특성에 따라 검색 서비스에 표시되는 데이터 세트와 아티팩트에 대한 접근을 제어함 
  - 푸시 풀 인덱서 패턴
    - 기업의 사일로 전체에서 사용 가능한 데이터 세트와 아티팩트를 발견하고 업데이트함 
    - 데이터 세트를 인덱싱할 수 있는 넷플릭스의 오픈소스 Metacat 카탈로그
      - Metacat은 데이터 세트 세부 정보를 추출하기 위해서뿐 아니라 데이터 소스가 Kafka와 같은 이벤트 버스에 업데이트를 게시하는 푸시 알림 모델에서도 풀 모델을 사용함. 데이터 소스는 명시적 REST API를 호출해 변경 이벤트를 게시할 수도 있음. Metacat에서는 변경 사항이 아마존 SNS에도 게시됨. SNS에 이벤트를 게시하면 데이터 플랫폼의 다른 시스템이 이러한 메타데이터 또는 데이터 변경에 따라 반응을 할 수 있음 
      - 강점 
        - 인덱스 업데이트가 시기적절함. 새 소스는 주기적으로 크롤링되고 변경 이벤트 처리를 위해 이벤트 버스에 푸시됨 
        - 다양한 범주의 메타데이터 속성을 추출하고 업데이트하기 위한 확장 가능한 패턴
        - 푸시 및 풀 방식의 조합을 고려할 때 많은 소스를 지원하도록 확장 가능함 
      - 약점
        - 다양한 소스 유형에 대한 구성과 배포가 어려울 수 있음 
        - 풀을 통해 세부 정보에 접근하려면 소스 권한이 필요한데, 규제된 소스에는 우려 사항이 될 수 있음 
  - 하이브리드 검색 순위 패턴
    - 문자열 입력이 주어지면 순위 패턴이 데이터 세트와 아티팩트의 목록을 생성함. 이 목록은 테이블 이름, 비즈니스 어휘 개념, 분류 태그 등의 문자열로 구성될 수 있음 
    - 이 패턴의 성공 기준은 가장 관련성 높은 결과가 목록의 상위 다섯 건에 들어있는지 여부 
    - 하이브리드 검색 순위 패턴의 예로는 아문센(Amundsen) 오픈소스 프로젝트 
      - 아문센은 데이터 세트와 아티팩트를 인덱싱함. 입력 구문 분석에서는 정확한 매칭 개선을 위해 자동 완성(type-ahead) 기능을 구현함. 입력 문자열은 와일드카드와 키워드, 범주, 비즈니스 어휘 등을 지원함 
      - 아문센은 얇은 Elasticsearch 프록시 계층을 구현해 카탈로그와 상호 작용함으로써 퍼지 검색을 가능하게 함. 
      - 메타데이터는 Neo4j에서 유지됨. 인덱스 구축을 위해서는 데이터 수집 라이브러리를 사용함 
  - 카탈로그 제어 패턴
    - 메타데이터 카탈로그에 접근 제어를 시행하고 세분화된 권한 부여 및 접근 제어를 위한 중앙 집중식 접근 방식을 제공함 
    - 카탈로그 접근 제어 패턴의 세 단계 
      - 분류
      - 정의
        - 정책 정의는 크게 두 가지의 광범위한 버킷으로 나뉨. 
        - 역할 기반 접근 제어 : RBAC,Role-Based Access Control, 사용자를 기반으로 정책이 정의됨 
        - 속성 기반 접근 제어 : ABAC,Attriubte-Based Access Control, 사용자 정의 태그, IP 주소를 기반으로 하는 지리적 태그, 시간 기반 태그 등과 같은 속성을 기반으로 정책이 정의됨 
      - 시행 
        - 검색 결과에서 접근 제어 정책을 시행하는 세 가지 방법
        - 모든 사용자를 위한 기본 메타데이터 : 검색 쿼리에 대한 응답 결과로 기본 메타데이터(이름,설명,소유자,업데이트 날짜, 사용자 정의 태그 등)를 모든 사용자엑 접근 권한 여부에 관계없이 표시함 
        - 선택적 고급 메타데이터 : 선별된 사용자가 접근 제어 정책에 따라 열 통계 및 데이터 미리 보기와 같은 고급 메타데이터를 가져옴 
        - 열 및 행 마스킹 ; 접근 제어에 따라 동일한 데이터 세트의 열 개수는 물론 데이터 미리 보기의 행이 달라짐 
    - 세분화된 권한 부여와 접근 제어를 위해 널리 사용되는 오픈소스 솔루션의 예로 아파치 Ranger 
      - Atlas 카탈로그와 모든 Hadoop 에코시스템에 대한 보안 정책 구현을 위한 중앙 집중식 프레임워크를 제공함 
      - 개별 사용자, 그룹, 접근 유형, 사용자 정의 태그, IP 주소와 같은 동적 태그 등을 기반으로 한 RBAC 및 ABAC 정책을 지원함 
    - 강점
      - 카탈로그 수준의 중장 집중식 접근 제어 정책을 통해 쉽게 관리할 수 있음 
      - 다양한 사용자 및 유스 케이스에 따라 조정 가능한 접근 제어 기능을 제공함 
    - 약점
      - 카탈로그 접근 제어 정책이 데이터 원본 정책과 동기화되지 않을 수 있음

# 피처 저장소 서비스 
- 요구 사항 정의
  - 피처 연산
    - 피처 비닝(feature binning) : 연속 피처를 개별 피처로 변환
    - 피처 해싱(feature hashing) : 원-핫 인코딩된 피처의 메모리 풋프린트(memory footprint)를 줄이기 위함 
    - Spark는 대규모 데이터 세트로 작업하는 사용자 간의 데이터 랭글링에 선호됨. 작은 데이터 세트로 작업하는 사용자는 Numpy, pandas와 같은 프레임워크를 선호함. 피처 엔지니어링 작업은 노트북(notebook), 파이썬 파일 또는 .jar 파일을 사용해 빌드되고 samza, Spark, Flink, Beam과 같은 연산 프레임워크에서 실행됨 
- 구현 패턴
  - 하이브리드 피처 연산 패턴 : 피처 연산을 위한 일괄 처리 및 스트림 처리를 결합하는 패턴을 정의함 
  - 피처 레지스트리 패턴 : 학습자 추론을 위한 기능을 제공하는 패턴을 정의함 
- 하이브리드 피처 연산 패턴 
  - 세 가지 구성 요소 
    - 일괄 처리 연산 파이프라인 
      - 전통적인 일괄 처리 작업에서는 몇 시간마다 또는 매일 ETL 작업으로 실행돼 과거 피처 값을 계산함 
    - 스트리밍 연산 파이프라인
      - 실시간 메시지 버스의 데이터 이벤트에 대해 수행되는 스트리밍 분석을 통해 낮은 지연 시간으로 피처 값을 계산함 
    - 피처 사양 
      - 일관성을 보장하기 위해 데이터 사용자는 새로운 피처에 대한 파이프라인을 생성하는 대신 도메인 특화 언어(DSL, Domain-Specific Language)를 사용해 피처 사양을 정의함 
  - 우버의 Michelangelo
    - 아파치 Spark와 Samza의 조합을 구현함. Spark는 일괄 처리 피처를 연산하는 데 사용되며 결과는 Hive에서 유지됨. 일괄 처리 작업은 피처 그룹을 연산하고, 이를 컬럼당 피처로서 단일 Hive 테이블에 씀 
    - 스트리밍 파이프라인의 경우 Kafka 토픽은 Samza 스트리밍 작업과 함께 소비돼 Cassandra에서 키-값 형식으로 유지되는 준실시간 피처 값을 생성함 
    - 히스토리 피처의 대량 사전 연산 및 과거 피처의 로딩이 정기적으로 Hive에서 Cassandra로 이뤄짐 
  - 강점 
    - 일괄 처리 및 스트리밍 타임 윈도우에 걸쳐 최적의 피처 연산 성능을 제공함 
    - 피처를 정의하는 DSL은 학습과 추론을 위한 파이프라인 구현 불일치에 관련된 모순을 방지함 
  - 약점 
    - 프로덕션 환경에서 구현되고 관리하는 것은 쉽지 않음. 데이터 플랫폼이 상당히 성숙해야 함 
- 피처 레지스트리 패턴 
  - 피처를 쉽게 검색하고 관리할 수 있음 
  - Hopsworks 피처 저장소 
    - 사용자가 피처 저장소를 SQL 또는 프로그래밍 방식으로 쿼리하면 피처 저장소는 피처를 데이터프레임으로 변환함 
    - Hopworks 피처 저장소의 피처 그룹 및 학습 데이터 세트는 Spark/Numpy/pandas 작업에 연결돼 있어 필요할 때 피처를 재현하고 재연산할 수 있음 
  - 강점 
    - 학습 데이터 세트와 피처 값의 성능 기준에 맞는 성능을 제공함 
    - 데이터 사용자의 피처 분석 시간을 단축함 
  - 약점 
    - 수백 개의 모델을 제공하는 동안 잠재적인 성능 병목 현상이 나타남
    - 피처가 계속 증가해 피처 분석을 위한 확장을 지속함 

# 데이터 이동 서비스 
- 원시 데이터를 전문 쿼리 엔진으로 이동
  - 점점 더 많은 쿼리 처리 엔진이 다양한 유형의 쿼리 및 데이터 워크로드에 최적화되고 있음 
  - 시계열 데이터 세트의 데이터 분할(slice-and-dice) 분석의 경우 데이터는 Druid와 Pinot 같은 전문 분석 솔루션으로 복사됨 
- 데이터 품질 검증 
  - 실제 배포 환경에서는 소스 오류, 어댑터 실패, 집계 문제 등과 같은 다양한 이유로 품질 오류가 발생할 수 있음
  - 데이터 이동 중 데이터 패리티(data parity) 모니터링은 데이터 품질 오류를 발견하지 못하거나 비즈니스 지표 및 ML 모델의 정확성에 영향을 미치지 않도록 하기 위해 반드시 필요함 
- 요구 사항 정의
  - 데이터 이동 서비스의 네 가지 주요 모듈 
    - 수집 모듈 : 소스에서 대상 데이터스토어로 데이터를 한 번 또는 지속적으로 복사하는 것을 담당함 
    - 변환 모듈 : 소스에서 대상으로 복사되는 데이터의 변환을 담당함 
    - 규정 준수 모듈 : 분석 목적으로 데이터를 이동함으로써 규정 준수 요구 사항을 충족함 
    - 검증 모듈 : 소스와 대상 간의 데이터 패리티를 보장함 
수집 요구 사항 
  - 요구 사항 수집의 일부로 수집할 데이터스토어 범주
    - |데이터스토어 범주|인기 있는 예시|
      |:---:|:---:|
      |트랜잭션 데이터베이스|Oracle, SQL Server, MySQL|
      |NoSQL 데이터스토어|Cassandra, Neo4j, MongoDB|
      |파일 시스템|Hadoop FileSystem, NFS appliance, Samba|
      |데이터 웨어하우스|Vertica, Oracle Exalogic, AWS Redshift|
      |오브젝트 저장소|AWS S3|
      |메시징 프레임워크|Kafka, JMS|
      |이벤트 로그|Syslog,NGNIX logs|
  - 데이터 규모
    - 데이터 엔지니어가 이해해야 하는 구모의 주요 측면
      - 행의 개수로 볼 때 테이블의 크기가 얼마나 큰가(즉, 수천 개의 행이 있는지, 수십억 개의 행이 있는지)?
      - TB 단위로 표의 대략적인 크기는 얼마인가?
      - 지속적으로 복사해야 하는 테이블의 수는 얼마인가?
    - 삽입, 업데이트, 삭제 횟수와 관련해 테이블이 빠르게 변경되는지 여부를 추정하는 변화율 
- 규정 준수 요구 사항 
  - 구정 준수에 대한 여러 측면을 고려해야 함
  - 매슬로우의 욕구 계층 구조(역피라미드) 
    - 삼각형의 맨 아래에는 규정 준스를 위한 3A인 인증(authentication), 접근 제어(access control), 감사 추적(audit tracking)이 있음 
    - 그 위에 암호화 및 마스킹과 관련해 개인 식별 정보(PII)를 처리할 때 고려해야할 사항이 있음 
    - 다음은 SOX,PCI 등과 같은 규정 주수 관련 요구 사항 
    - 맨 위에는 CCPA, GDPR 등의 법률에 따른 데이터 권한 준수가 있음 
- 구현 패턴
  - 데이터 이동 서비스는 수집, 변환, 규정 준수, 검증 모듈이라는 네 가지 주요 작업을 수행함 
  - 데이터 이동 서비스의 다양한 자동화 수준
    - 일괄 수집 패턴
      - 일괄 수집(batch ingestion)은 빅데이터 진화 초기에 널리 사용됐던 전통적인 패턴이며, 일회성 및 예약된 데이터 이동 모두에 적용됨.
      - 일괄 처리(batch)라는 용어는 소스에 대한 업데이트가 함께 그룹화된 다음 주기적으로 대상으로 이동됨을 의미함 
      - 일괄 수집은 일반적으로 실시간 업데이트 요구가 없는 대규모 소스의 데이터 이동에 사용됨. 6~24시간 단위로 예약됨 
      - 일괄 수집 패턴에는(MapReduce의)지도 단계를 이용해 소스 데이터 개체를 분할함으로써 대상 데이터 개체로 병렬 복사하는 것이 포함됨 
      - 일괄 수집 패턴의 세 단계
        - 파티션 단계 : 복사할 소스 테이블은 데이터 이동을 병렬화하기 위해 더 작은 청크(chunk)로 논리적으로 분할됨 
        - 지도 단계 : 각 청크는 매퍼(mapper, MapReduce의 용어)에 할당됨. 매퍼는 쿼리를 실행해 소스 테이블에서 데이터를 읽고 대상에 복사함. 더 많은 매퍼를 사용하면 동시 데이터 전송 작업 수가 많아져 작업 완료 속도가 빨라질 수 있음 .데이터베이스의 로드(load)도 증가해 잠재적으로 소스가 포화될 수 있음. 증분 테이블 복사의 경우, 매퍼는 마지막 업데이트 이후 소스 테이블에 대한 삽입, 업데이트, 삭제를 처리함 
        - 축소 단계 : 매퍼의 출력은 스테이징 파일로 저장되고 리듀서에 의해 대상 데이터스토어의 단일 구체화 뷰로 결합됨. 리듀서는 변환 기능을 구현할 수도 있음 
      - 아파치 Sqoop
        - 일반적으로 관계형 데이터베이스와 파일 시스템 간에 HDFS와 아파치 Hive로 대량의 데이터를 이동할 때 사용됨. 클라이언트-서버모델로 구현됨.
        - 클라이언트는 소스 및 대상 데이터스토어에 설치되고 데이터 이동은 클라이언트와 대응하는 Sqoop 서버에 의해 MapReduce 작업으로 오케스트레이션됨 
        - 데이터스토어에 연결하기 위한 기술 특화 어댑터는 클라이언트에 설치됨(최신 Sqoop2 버전에서는 드라이버가 서버에 설치됨). 데이터 이동은 소스 클라이언트의 매퍼가 소스에서 데이터를 전송하는 동안 대상 클라이언트의 리듀서가 데이터를 복사 및 변환하는 MapReduce 작업 
      - 강점
        - 광범위한 소스 및 대상 데이터스토어에 적용할 수 있는 전통적인 데이터 이동 패턴. 데이터 소스 소유자가 소스 데이터스토어를 온보딩, 관리, 유지 관리 하는 데 최소한의 노력만 필요함 
        - 매일 수천 개의 예약된 데이터 이동으로 확장할 수 있음. MapReduce를 활용해 장애 복구를 구현함
        - 기본적으로 복사 후 데이터 유효성 검사를 지원함 
      - 약점
        - 준실시간 데이터 새로 고침을 지원하지 않음 
        - 소스 데이터스토어의 성능에 잠재적으로 영향을 미칠 수 있음. 제한 규정 준수 상태의 소스 데이터스토어를 연결하는 데 사용되는 JDBC 연결과 관련된 잠재적인 규정 준수 문제가 있음 
        - 영구 삭제(hard delete)가 수반되는 증분 테이블의 새로 고침 및 데이터 변환 기능에 대한 지원이 제한적 
    - 지속적 변화 수집 패턴 / 변경 데이터 캡처 수집 패턴
      - 조직이 성숙해지면 일괄 수집을 넘어 변경 데이터 캡처(CDC, Change Data Capture) 패턴으로 이동함 
      - 짧은 지연 시간(몇 초 또는 몇 분)으로 대상에서 소스 업데이트가 필요한 지속적인 데이터 이동에 적용 가능함. CDC는 소스에서 모든 변경 이벤트(업데이트,삭제,삽입)를 캡처하고 대상에 업데이트를 적용함 
      - CDC 패턴은 일반적으로 CDC 패턴을 사용해 연속 업데이트가 수행되는 동안, 소스 테이블을 처음으로 전체 복사할 때 사용되는 일괄 수집과 함께 사용됨 
      - CDC 수집 패턴
        - 1.CDC 이벤트 생성
          - CDC 어댑터는 소스 데이터베이스에 설치되고 구성됨. 이 어댑터는 사용자 지정 테이블에 대한 삽입, 업데이트, 삭제를 추적하기 위한 소스 데이터스토어 특화 소프트웨어 
        - 2. 이벤트 버스에 게시된 CDC
          - CDC는 이벤트 버스에 게시되며 하나 이상의 분석 유스 케이스에서 사용할 수 있음. 버스의 이벤트는 내구성이 뛰어나며 오류가 발생한 경우 재생 가능함 
        - 3. 이벤트 병합
          - 각 이벤트(삽입,삭제,업데이트)는 대상 테이블에 적용됨. 최종 결과는 소스 테이블보다 짧은 지연 시간이 있는 테이블의 구체화 뷰. 대상 테이블에 해당하는 메타데이터는 새로 고침 타임스탬프와 기타 속성을 반영하기 위해 데이터 카탈로그에 업데이트됨 
      - CDC 수집 패턴 중에는 병합 단계를 거치지 않고 직접 이벤트를 사용할 수 있는 변형도 있음. 이 변형 패턴은 일반적으로 원시 CDC 이벤트가 비즈니스 특정 이벤트로 변환되는 시나리오에 적용됨 
      - CDC 이벤트를 시간 기반 저널(time-based journal)로 저장하는 것. 일반적으로 리스크 및 사기(fraud) 탐지 분석에 유용함 
      - 아파치 Kafka와 결합된 Debezium
        - Debezium은 지연 시간이 짧은 CDC 어댑터
        - 데이터베이스 기술에 관계없이 표준화된 이벤트 모델에서 커밋된 데이터베이스 변경 사항을 캡처함.
        - 이벤트는 변경된 내용, 시기 및 위치를 설명함. 이벤트는 아파치 Kafka에 하나 이상의 Kafka 토픽(일반적으로 데이터베이스 테이블당 하나의 토픽)으로 게시됨 
        - Kafka는 모든 이벤트가 복제되고 완전히 정렬되도록 보장하며, 많은 소비자가 업스트림 시스템에 거의 영향을 주지 않으면서 동일한 데이터 변경 이벤트를 독립적으로 사용할 수 있게 함 . 병합 프로세스 중에 오류가 발생하는 경우 중단된 지점에서 정확히 다시 시작할 수 있음 
        - 이벤트는 정확히 한 번(exactly-once) 또는 최소한 한 번(at-least-once) 정확하게 전달됨. 각 데이터베이스/테이블에 대한 모든 데이터 변경 이벤트는 업스트림 데이터베이스에서 발생한 것과 동일한 순서로 전달됨 
        - CDC 레코드를 구체화된 대상 테이블로 병합하기 위해 널리 사용되는 접근 방식은 MapReduce를 사용하는 일괄 처리 지향적 방식 또는 Spark와 같은 기술을 사용하는 스트리밍 지향적 방식
      - 아파치 Gobblin(인기 있는 오픈소스 솔루션으로는 MapReduce를 사용함), Spark를 사용하는 우버의 Marmaray
        - Gobblin의 병합 구현에는 역직렬화/추출, 포맷 변환, 품질 검증, 대상에 대한 쓰기가 포함됨. Gobblin과 Marmaray는 모두 어떤 소스에서 어떤 대사응로든 데이터를 이동을 할 수 있도록 설계됨 
      - 강점
        - CDC 패턴은 소스 데이터스토어에 미치는 성능 영향을 최소화하면서 대상을 업데이트하는 지연 시간이 짧은 솔루션
        - CDC 어댑터는 광범위한 데이터스토어에 사용할 수 있음 
        - 데이터 이동 과정에서 필터링 또는 데이터 변환을 지원함
        - 증분 수집(incremental ingestion)을 사용해 대형 테이블을 지원함 
      - 약점
        - CDC 어댑터의 최적 구성 옵션을 선택하는 데 필요한 전문 지식이 없으면 온보딩이 쉽지 않음 
        - Hadoop MapReduce 대신 Spark를 사용하는 병합 구현에서는 약 10억 행 이상의 매우 큰 테이블에서 문제가 발생할 수 있음 
        - 증분 변경 내용을 추적하려면 CDC 열이 있는 테이블이 필요함
        - 필터링 또는 데이터 변환을 제한적으로 지원함 
      - 이 접근 방식은 빠르게 이동하는 대용량 데이터에 적합하며, 널리 사용되고 가장 인기 있는 접근법 중 하나. 오류 없는 업데이트 추적 및 대규모 업데이트 병합을 보장하려면 소스 팀과 데이터 엔지니어링 팀 간의 운영 성숙도가 필요함 
    - 이벤트 수집 패턴 (이벤트 집계 패턴)
      - 사기 탐지, 알림, IoT 등을 위해 실시간으로 지속적인 이벤트를 집계해야 하는 애플리케이션 이벤트뿐만 아니라 로그 파일을 집계하는 일반적인 패턴 
      - 웹 액세스 로그, 광고 로그, 감사 로그, Syslog, 센서 데이터 등 로그의 수가 증가함에 따라 적용 범위가 넓어짐 
      - 여러 소스에서 집계하고, 단일 스트림으로 통합하고, 이를 일괄 처리 또는 스트리밍 분석에 사용할 수 있도록 하는 작업이 포함됨 
        - 이벤트 전달
          - 에지 노드, 로그 서버, IoT 센서 등으로부터의 이벤트 및 로그가 집계 단계로 전달됨. 로그를 실시간으로 푸시하기 위해 경량 클라이언트가 설치됨 
        - 이벤트 집계 
          - 여러 소스의 이벤트가 정규화되고 변환돼 하나 이상의 대상에서 사용할 수 있음. 집계는 스트리밍 데이터 흐름을 기반으로 함. 이벤트 스트림은 버퍼링돼 주기적으로 데이터스토어 대상에 업로드됨 
      - 아파치 Flume
        - 데이터 이동 작업의 일부로, 구성 파일에서는 이벤트 소스와 데이터가 집계되는 대상을 정의함 
        - Flume의 소스 구성 요소는 소스에서 로그 파일과 이벤트를 가져와 데이터가 처리되는 집계 에이전트로 보냄. 로그 집계 처리는 메모리에 저장되고 대상으로 스트리밍됨 
        - Flume은 기본적으로 웹 서버에서 생성된 대량의 로그 파일을 Hadoop으로 빠르고 안정적으로 스트리밍할 수 있도록 설계됐으며, Kafka 브로커, 페이스북, 트위터와 같은 소스의 데이터를 포함해 이벤트 데이터를 처리하도록 진화했음 
      - Fluent Bit과 Fluentd, 오픈소스 로그 수집기(log collec색) 및 로그 집계기(log aggregator)로 널리 사용됨 
      - 강점 
        - 이벤트 집계 패턴은 로그와 이벤트에 최적화된 실시간 솔루션. 신뢰성, 가용성이 높고 횡적 확장성이 뛰어남 
        - 소스 성능에 미치는 영향을 최소화함
        - 확장성과 커스터마이징이 용이하며 운영 오버헤드를 최소화함
        - 데이터 이동 프로세스 중 필터링과 데이터 변환을 지원함
        - 대량의 로그 및 이벤트 데이터를 처리하도록 확장됨 
      - 약점 
        - 소스 이벤트에 대한 정렬을 보장하지 않음
        - 메시지를 정확히 한 번만 전달하지 않고 최소 한 번 전달하기 때문에 대상에서 중복 이벤트를 처리해야 함 
      - 로그 및 이벤트 데이터에 최적화돼 있음 

# 클릭스트림 추적 서비스
- 클릭스트림 데이터로 알려진 행동 데이터를 수집, 분석, 집계하는 것. 클릭스트림은 애플리케이션 또는 웹 사이트 내에서 방문자의 행동을 나타내는 일련의 이벤트 
- 클릭, 보기 및 페이지 로드 시간, 방문자가 사용하는 브라우저 또는 장치 등과 같은 관련 컨텍스트가 포함됨. 클릭스트림 데이터는 고객 트래픽 분석, 마케팅 캠페인 관리, 시장 세분화, 세일즈 퍼널 분석(sales funnel analysis) 등과 같은 비즈니스 프로세스 인사이트에 중요함 
- A/B 테스트는 클릭스트림 데이터 스트림을 사용해 비즈니스 상승 효과를 계산하거나 제품 또는 웹 사이트의 새로운 변경 사항에 대한 사용자 피드백을 캡처함 
- 세 가지 중요한 문제점 
  - 데이터 사용자는 분석 요구 사항에 따라 제품 및 웹 페이지에 새로운 추적 비콘(tracking beacon)을 지속적으로 추가해야함. 이러한 비콘을 추가하는 것은 셀프서비스가 아니며 계측 비콘을 추가할 위치, 사용할 계측 라이브러리, 사용할 이벤트 분류를 결정하기 위한 전문 지식이 필요함 
  - 클릭스트림 데이터는 인사이트 생성에 사용되기 전에 집계, 필터링, 보강돼야 함 
  - 클릭스트림 분석은 트랜잭션 기록과 실시간 클릭스트림 데이터에 대한 액세스를 필요로 함 
- 여정 지도
  - 마케팅 캠페인에서는 최적화를 위한 다양한 목표가 존재함. 판매 수익 증대, 고객 유지 개선, 브랜드 범위 확대 등이 그 예. 
  - 인사이트는 웹 추적 이벤트(클릭,뷰,전환), 광고 추적 이벤트(광고 노출, 비용), 인벤토리 데이터베이스(제품, 재고,마진),고객 주문 추적(고객, 주문, 크레딧)으로 구성된 원시 데이터에서 추출해야 함 
  - 웹 트래픽 분석은 트래픽을 가져오는 소스, 인기 키워드, 다른 트래픽 소스 방문자로부터의 전환율, 캠페인에 연결된 코호트 분석 등에 대한 인사이트를 제공함 
  - 클릭스트림 유스 케이스의 세 가지 구성 요소 
    - 고객의 클릭과 뷰를 캡처하기 위해 제품과 웹 페이지에 추적 코드를 추가
    - 비콘에서 데이터를 수집한 뒤 집계, 상관, 정리, 보강
    - 실시간 클릭스트림 이벤트와 데이터 레이크의 기록 데이터를 결합해 인사이트 생성 
- 클릭 시간 지표 최소화
  - 클릭 시간 지표에는 계측 관리, 수집된 이벤트 보강, 데이터 소비에 대한 분석 시간이 포함됨 
  - 계측 관리 
    - 클릭스트림 이벤트를 생성하려면 제품 도는 웹 페이지 내에 계측 비콘이 필요함. 비콘은 일반적으로 모든 요청에 대해 페이지로 로드되는 자바스크립트 추적기로 구현되고 뷰, 클릭 및 기타 동작에 대한 세부 정보와 함께 수집기 서비스로 JSON POST 요청을 보냄 
  - 이벤트 보강
    - 봇 필터링 : 봇에 의해 트리거된 이벤트는 방문자당 고객 인터랙션 및 전환과 관련된 주요 지표를 왜곡하기 때문에 필터링이 필요함 
    - 세션화
      - 원시 클릭스트림 이벤트는 고객 행동을 더 잘 이해하기 위해 세션으로 쪼개짐. 세션은 두 개 이상의 장치 및 사용자 간의 짧은 대화형 정보 교환
      - 세션을 사용하면 구매 빈도가 가장 높은 경로, 사용자가 특정 페이지로 이동하는 방법, 사용자가 이탈하는 시기와 이유, 일부 획득 유입 경로가 다른 페이지보다 효율적인지 등의 질문에 답할 수 있음 
    - 풍부한 컨텍스트
      - 효과적으로 인사이트를 추출하기 위해 클릭스트림 이벤트는 기기 유형, 브라우저 유형, OS 버전과 같은 사용자 에이전트 세부 정보를 추가 컨텍스트로 사용해 보강됨 
  - 인사이트 쌓기
    - 실시간 대시보드는 E2E 고객 여정, 고객 360 프로필, 개인화 등을 파악하는 데 사용됨. 실시간으로 사용자 행동을 추적하면 추천 내용을 업데이트하고, 고급 A/B 테스트를 수행하거나 고객에게 알림을 보낼 수 있음 
    - 고객 ID가 상호 연결돼야 함(이를 ID 스티칭-identity stitching), ID 스티칭 시에는 정확하게 일치하는 프로필을 가지기 위해 가능한 한 많은 식별자와 고객을 일치시킴
    - 단일 파이프라인의 모든 이벤트를 추적하면 IP 주소를 매칭해서 고객 이벤트를 상호 연관시킬 수 있음. 고객이 이메일을 열때 쿠키 ID를 사용한 다음 쿠키가 이메일 주소 해시 코드를 추적하도록 하는 것 
    - 고객의 온라인 여정 지도는 구매 결정에 영향을 미치는 다양한 접점과 채널로 인해 매우 복잡함. 기업의 자체 웹 사이트만을 사용해 고객 행동을 추적하는 것은 라스트 터치 어트리뷰션 모델(last-touch attribution model - 고객의 마지막 접점에만 크레딧을 부여하는 모델)을 사용하는 것과 유사하고 완전한 그림을 제공하지 않음
- 요구 사항 정의
  - 계측 요구 체크리스트
    - 이벤트에서 캡처된 속성 : 이벤트 속성, 즉 누구인지, 무엇인지, 어디인지와 도메인 세부 정보 및 이벤트 유형(페이지 뷰, 클릭 등)을 정의함 
    - 클라이언트 측 이벤트 수집 : 모바일 클라이언트, 데스크톱 응용프로그램, 웹 응용프로그램의 인벤토리를 수집함 
    - 타사 소스 수집 : 구글,페이스북 픽셀, 광고 대행사 등 타사 소스의 로그 데이터와 통계를 집계할 필요가 있는지 판단함. 각 에이전시에 해당하는 웹훅(webhook)을 식별함 
    - 서버 측 이벤트 수집 : 백엔드 애플리케이션 서버에서 이벤트를 캡처해야 하는지 여부를 결정함 
    - 속도와 피드 : 비콘 수, 이벤트 생성 비율, 이벤트 보존 기간에 대한 대략적인 추정치를 가져옴 
  - 보강 요구 사항 체크리스트
    - 봇 필터링 : 실제 사용자 활동 중에서 봇 트래픽을 필터링함 
    - 사용자 에이전트 구문 분석 : 브라우저 유형과 모바일인지 데스크톱인지 등의 추가 세부 정보가 클릭스트림 이벤트와 연결됨 
    - IP2Geo : 위치를 추적해 지역 간 제품 사용 방식의 차이를 더 잘 이해할 수 있음 
    - 세션화 : 특정 세션 및 세션 전체에서 사용자의 활동을 분석하는 유스 케이스에 활용됨 
    - 다양한 시간대에 걸친 이벤트 데이터 요약 : 개별 이벤트 세부 정보와 이에 대한 장기간의 사용자 활동 추세를 확인해야 하는 다양한 요구 사항이 있는 유스 케이스에서 활용됨 
    - 개인정보 필터링 : 사용자 개인정보 보호 규정 준수를 따라 IP 주소 제거가 필요한 유스 케이스 등에 사용됨 
    - 사용자를 식별하는 데 사용되는 다양한 옵션
      - 계정 로그인(사용자의 작은 하위 집합)
      - 쿠키 식별(크로스 디바이스 환경에서는 작동하지 않으며 삭제, 만료, 차단됨)
      - 디바이스 핑거프린팅(사용자를 식별하는 확률적 방법)
      - IP 일치(동적 IP와 공유 IP에서는 식별에 문제가 있음)등이 있음 
- 구현 패턴
  - 계측 패턴 : 제품 및 마케팅 웹 페이지 내에서 추적 비콘 관리를 단순화함
    - 제품 및 웹 페이지에서 계측 비콘 관리를 단순화함. 가용한 비콘을 업데이트, 추가, 나열해 데이터 사용자가 셀프서비스로 사용할 수 있도록 함 
    - 이벤트 수집 : 이벤트는 웹 페이지, 모바일 앱, 데스크톱 앱, 백엔드 서버에 생성됨 
    - 이벤트 확인 : 스키마 속성 및 데이터에 대한 이벤트는 엔디포인트에서 확인됨 
    - 대상에 대한 프록시 이벤트 : 이벤트가 다수의 태그를 사이트에 로드하지 않고 다수의 프로바이더에게 전달됨 
    - Segemnt와 RudderStack 
      - Segement는 게시자-구독자 접근 방식을 사용해 클릭스트림 이벤트에 대한 프록시를 구현함. 이벤트는 메시지 버스(Kafka)에 추가됨. 이메일 도구, 웹 분석과 기타 배포된 솔루션에 대한 프로바이더가 구독자로 추가됨 
  - 보강 패턴 : 클릭스트림 이벤트의 정리 및 보강을 자동화함
    - 보강 패턴은 원시 이벤트를 분석, 필터링하고 개선함. 패턴은 규칙 기반이며 더 간편한 추론(휴리스틱)을 위해 데이터 사용자에 의한 확장이 가능해야 함 
    - 봇 필터링 패턴 : 인간 사용자와 봇을 구분하는 규칙을 정의함 
    - 세션화 패턴 
      - 일반적으로 접근하는 방식은 이벤트가 도착하지 않고 통과하는 지연 시간(일반적으로 30분)을 통한 것
      - 세션화 시에는 클릭스트림 이벤트에 대해 SQL 쿼리가 지속적으로 실행되며 세션 마커를 생성함 
      - AWS Kinesis는 슬라이딩 윈도우, 텀블링 윈도우, 스태거 윈도우라는 세 가지 유형의 윈도우 쿼리 함수를 제공함 
    - 사용자 컨텍스트 보강 패턴
      - 클릭스트림 이벤트에는 지리적 위치와 브라우저 버전 같은 사용자 에이전트 세부 정보를 추가해 컨텍스트를 보강함 
      - Divolte Collector로서, 비콘을 수집하고 이벤트를 보강함 
  - 소비 패턴 : 이벤트 처리를 자동화해서 다양한 유스 케이스에 대한 실시간 인사이트를 생성함 
    - 마케팅 캠페인이 어떻게 퍼포먼스를 내고 있는지, 실험이 리텐션, 성장, 교차 판매에 어떻게 영향을 미치고 있는지 등과 관련된 ML 모델과 실시간 대시보드의 강화를 위해 클릭스트림 데이터 소비에 초점을 맞춤
    - 일괄 처리 지표와 상호 관련된 스트리밍 데이터를 결합하며, CEP(Complex Event Processing - 복합 이벤트 처리)라고 함 
    - CEP 패턴은 윈도우 설정 기능을 사용하며 일괄 처리 중 또는 일괄 처리 간의 이벤트 전반에 걸친 패턴의 일반적인 검색 및 상관관계를 포함하고 있음 
      - 아파치 NiFi 및 Pulsar 같은 메시지 처리 프레임워크를 사용해 타임스탬프로 식별된 개별 이벤트 처리가 가능함 
      - 아파치 Druid 및 Pinot와 우버의 M3 같은 시계열 데이터스토어 형태의 서빙 레이어를 사용해 레코드 수준 업데이트와 일괄 벌크 로드(batch bulk load)를 모두 처리 가능함 
    - 아파치 Pulsar
      - 지리적 복제, 멀티테넌시, 유니파이드 큐, 스트리밍 기능을 갖추고 있으며, 계층화된 아키텍처 기반으로 구촉된 강력한 발행 구독(pub-sub)모델 
    - 시계열 서빙 레이어의 아파치 Druid
      - Druid는 각 열이 개별적으로 저장되는 열 지향 저장소를 구현함 
      - 빠른 스캔, 순위, 그룹화를 지원하는 특정 쿼리에 필요한 열만 읽을 수 있음. Druid는 빠른 검색 및 필터링을 위해 문자열 값에 대해 반전된 인덱스를 생성하고 진화하는 스키마와 중첩된 데이터를 우하하게 처리함 
      - 여러 데이터 작업자에 걸쳐 샤딩(sharding)해서 시간을 기준으로 데이터를 지능적으로 분할함. 시간 기반 쿼리는 전통적인 데이터베이스보다 훨씬 빠름 
      - 네이티브 JSON 기반 언어 외에도 Druid는 HTTP 또는 JDBC를 통해 SQL을 지원함. 초당 수백만 개의 이벤트를 수집하고 수년간의 데이터를 유지하며 1초 미만의 쿼리를 제공하도록 확정할 수 있음. 서버를 추가하거나 제거하는 것만으로 규모를 확장하거나 축소하면 Druid가 자동으로 재조정됨 
    
# 셀프서비스 데이터 준비
## 데이터 레이크 관리 서비스
- 데이터 레이크는 페타바이트 규모의 정형, 반정형, 비정형 데이터를 집계하기 위한 중앙 데이터스토어가 됐음, 데이터의 버전 관리 및 롤백을 지원해야 함 
- 복제본 간의 일관성 보장, 기본 데이터의 스키마 진화, 부분 업데이트 지원, 기존 데이터 업데이트를 위한 ACID 일관성 등과 같은 데이터 수명주기 관리 작업들이 있음 
- 데이터 레이크가 중앙 데이터 웨어하우스로 인기를 얻기는 했지만, 전통적인 데이터 수명주기 관리 작업에 대한 지원은 부족함
- 고충 
  - 원시 데이터 수명주기 작업에 자동화된 API가 없고 재현성 및 롤백, 데이터 제공 계층 프로비저닝 등에 대한 엔지니어링 전문 지식이 필요함 
  - 동시 읽기-쓰기 작업에 대한 레이크의 일관성 부족을 수용하기 위해 애플리케이션을 이용한 대체 해결 방법이 필요함 
  - 규정 준수를 위해 고객의 기록을 삭제하는 것과 같은 증분 업데이트의 최적화 수준이 매우 낮음 
  - 스트림 일괄 처리를 결합한 통합 데이터 관리가 불가능함 
- 대체 방안들은 일괄 처리 및 스트림(람다 아키텍처라고 함)에 대해 별도의 처리 코드 경로를 필요로 하거나 모든 데이터를 이벤트(카파 아키텍처라고 함)로 변환해야 하는데, 이는 대규모 관리가 쉽지 않음 
- 레이크의 원시 데이터 수명주기 관리와 관련된 문제점
- |원시 수명주기 작업|문제점|적용 대안|
  |:---:|:---:|:---:|
  |작업 실패로 인해 탐색, 모델 학습, 손상 해결에 필요한 데이터 버전 관리|스냅샷을 생성하고 복원하는 명확한 프로세스가 없음.특정 시점에서 특정 테이블 속성의 값을 쉽게 얻을 수 있는 방법이 없음. 실패한 작업/트랜잭션을 버전 또는 타임스탬프에 따라 롤백할 수 있는 방법이 없음|스냅샷은 정책을 기반으로 생성됨.모델의 재현성을 위해 데이터의 복사본이 여러 개 생성되므로 스토리지 비용이 증가함. 기록 데이터에 액세스하기 위해 전체 스냅샷이 샌드박스 네임스페이스에 복원되고 분석을 위해 액세스할 수 있게 됨 
  |소스 데이터 세트의 변경 사항을 관리하기 위한 스키마 진화|스키마가 진화하면 다운스트림 분석이 작동하지 않을 수 있음.레이크 수집 시 데이터 세트 스키마의 검증 지원이 없음|소스 데이터 세트와 다운스트림 분석간에 격리 데이터 레이어를 생성함. 이는 완전한 것이 아니며, 모든 스키마 변경에 대해 작동하지 않음
  |레이크 데이터를 웹 애플리케이션 및 분석에 효율적으로 노출하기 위한 데이터 서비스 계층|처리된 레이크 데이터에 대한 읽기-쓰기는 키-값, 그래프,문서,시계열과 같은 모든 데이터 모델에 효율적이지 않을 수 있음|관계형 모델에 맞게 애플리케이션의 데이터 모델을 수정함 
  |데이터 액세스 및 사용에 대한 중앙 집중식 추적.|여러 사용자와 서비스에 걸친 데이터 세트 업데이트 및 액세스를 추적하기 어려움. 중앙 집중식 감사 기능이 부족하면 액세스 제어와 관련된 시각지대가 생김|애드혹 스크립트 및 감사 모니터링|
- 데이터 업데이트 관리
  - 데이터 레이크는 ACID 데이터베이스가 제공하는 것과 동일한 무결성 보장을 제공하지 않음. 분리로 인해 쓰기 작업이 데이터를 업데이트하는 동안 부분 데이터를 가져오는 영향 판독기가 누락됨. 동시 쓰기 작업은 데이터를 손상시킬 수 있음 
  - 업데이트 누락 시 재시도를 하거나, 사용 중인 애플리케이션이 손상된 데이터를 읽는 것을 방지하기 위해 실행 중에 데이터를 사용하지 못하도록 제한하는 블랙아웃(blackout) 시간을 부여하는 것. 완료 및 오류발생 시 롤백을 위해 업데이트를 수동으로 추적하는 것 
- 데이터 레이크 관리 시간 최소화
  - 네임스페이스 영역
    - 데이터 레이크 내에서 영역(zone)은 데이터의 논리적 및 물리적 분리를 허용함. 네임스페이스는 현재 워크플로우, 데이터 파이프라인 프로세스, 데이터 세트 속성을 기반으로 다양한 영역으로 구성됨 
    - 브론즈 존 : 트랜잭션 데이터스토어에서 수집된 원시 데이터를 위한 영역으로 원시 데이터 및 장기 보존을 위한 매립장이라고 할 수 있음. 민감한 데이터는 암호화되고 토큰화됨
    - 실버 존 : 필터링, 정리, 증강된 데이터가 있는 중간 데이터가 포함된 스테이징 영역 
    - 골드 존 : 비즈니스 수준으로 집계되고 지표와 함께 사용할 준비가 된 정제된 데이터를 포함함 
- 지원되는 파일 형식
  - 데이터 형식은 포맷의 견고성(즉, 데이터 손상 시나리오에 대해 포맷이 얼마나 잘 테스트됐는지)과 널리 사용되는 SQL 엔진 및 분석 플랫폼과의 상호 운용성에 대한 부분에서 균형을 맞춰야 함 
    - 표현성 : 포맷이 지도, 레코드, 목록, 중첩된 데이터 구조 등과 같은 복잡한 데이터 구조를 표현할 수 있는가?
    - 견고성 : 포맷이 잘 정의돼 있고 쉽게 이해할 수 있는가? 손상 시나리오와 기타 예외 케이스에 대해 테스트가 잘됐는가? 견고성의 다른 중요한 측면은 포맷의 단순성. 형식이 복잡할수록 직렬화 및 역직렬화 드라이버에서 버그가 발생할 가능성이 높아짐
    - 공간 효율성 : 데이터의 간결한 표현은 언제나 최적화의 기준이 됨. 공간 효율성은 데이터를 이진으로 표현하는 능력과 데이터를 압축하는 능력이라는 두 가지 요소를 기반으로함 
    - 액세스 최적화 : 응용프로그램 쿼리에 대한 응답으로 액세스되는 데이터양(바이트)을 최소화함.이는 쿼리 유형에 따라 크게 달라지며, 어디에나 적용 가능한 방법은 없음(select * 쿼리 vs 제한된 수의 열 값을 기반으로 필터링하는 쿼리). 액세스 최적화의 또 다른 고려 사항은 병렬 실행을 위한 파일을 분할하는 기능 
  - 주요 포맷
    - 텍스트 파일 : 가장 오래된 형식 중 하나. 사람이 읽을 수 있고 상호 운용이 가능하지만, 공간과 접근 최적화 측면에서 상당히 비효율적
    - CSV/TSV : 이 형식에는 비효율적인 이진 표현과 액세스에 관련된 제한이 있음. 또한 복잡한 데이터 구졸르 이 형식으로 표현하기는 어려움 
    - JSON : 이 형식은 애플리케이션 개발자에게 가장 표현성이 있고 범용적인 형식 중 하나. 이 목록의 다른 형식과 비교하면 공간 및 액세스 측면 모두에서 최적화되지 않았음 
    - SequenceFile : Hadoop에서 가장 오래된 파일 형식 중 하나. 데이터는 키-값 쌍으로 표시됌. 자바가 쓰기 가능한 인터페이스를 사용해 Hadoop에 액세스하는 유일한 방법이었을 때 인기가 있었음.가장 큰 문제는 상호 운용성이었고, 일반적인 정의가 없었음 
    - Avro : 스키마가 파일 헤더와 함께 저장된다는 점을 제외하면 SequenceFile과 유사함. 형식은 표현성이 있고 상호 운용이 가능함. 이진 표현에는 오버헤드가 있으며, 최적화가 최고로 잘된 것은 아님. 전반적으로 범용 워크로드에 적합함
    - ORCFile : 고급 사용 데이터베이스에서 사용되는 열 기반 포맷. Hadoop 에코시스템에서 이 포맷은 RCfile 포맷의 후속 포맷으로 여겨지고 있는데, 이는 데이터를 문자열로 저장하는 데 비효율적이었음. ORCFile은 강력한 Hortonworks 지원과 최근의 흥미로운 발전을 통해 PPD(Push Predicate Down)와 향상된 압축 기능을 제공함 
    - Parquet : ORCFile과 유사하며 클라우데라의 지원을 받음. Parquet는 구글 Dremel논문의 최적화를 구현함
  - 인코딩과 함께 사용할 수 있는 다양한 압축 기술로 zlib, gzip, LZO, Snappy 등이 널리 사용됨 
- 서빙 레이어 
  - 반정형 데이터의 경우 키-값, 그래프, 문서 등과 같은 다양한 데이터 모델이 있음. 데이터 모델에 따라 최적의 성능과 확장을 위해서는 적절한 데이터스토어를 활용해야 함 
  - NoSQL은 확장성, 가용성, 성능 대신 트랜잭션 SQL 기능의 절충을 고려할 때 비SQL로 강조되는 경우가 많음(CAP정리가 전형적으로 등장함. CAP 정리 또는 브루어의 정리는 일관성,가용성,분할내성이라는 세 가지 조건을 모두 만족하는 분산 컴퓨터 시스템이 존재하지 않음을 증명한 정리). NoSQL은 SQL 충실도보다는 다양한 데이터 모델을 지원하는 것임을 인식하는 것이 중요함 
  - 키-값 데이터 모델 
    - 데이터 모델 중 가장 쉬움. 응용프로그램은 임의의 데이터 값 또는 블롭(blob) 집합으로 저장함(최대 크기에 제한이 있을 수 있음). 저장된 값이 불투명해 응용프로그램에서 스키마 해석을 수행해야 함. 키-값 저장소는 단순히 키로 값을 검색하거나 저장함. 대표적인 예로는 Riak, Redis, Memcache, Hazelcast, Aerospike, AWS DynamoDB 등이 있음 
  - 넓은 열 데이터 모델 
    - 넓은 열(wide-column) 데이터베이스는 관계형 데이터베이스와 유사하게 데이터를 행과 열로 구성함.논리적으로 연관된 열은 열 패밀리(column family)라는 그룹으로 나뉨. 열 패밀리 내에서 새 열을 동적으로 추가할 수 있으며 행은 드문드문할 수 있음(행에 모든 열에 대한 값이 있을 필요가 없음). Cassandra와 같은 구현을 사용하면 열 패밀리의 특정 열에 대한 인덱스를 생성해 행 키가 아닌 열 키로 데이터를 검색할 수 있음. 행에 대한 읽기 및 쓰기 작업은 일반적으로 단일 열 패밀리키에서 원자적이지만, 일부 구현은 다수의 열 패밀리에 걸쳐 전체 행에 대한 원자성을 제공함. 대표적인 예로는 Cassandra, HBase, Hypertable, Accumulo,구글 Bigtable 등이 있음 
  - 문서 데이터 모델 
    - 문서 필드는 키-값 저장소와 달리 이 필드의 값을 사용해 데이터를 쿼리하고 필터링하는 데 사용할 수 있음. 단일 문서는 RDBMS의 여러 관계형 테이블에서 분산될 수 있는 정보가 포함될 수 있음. MongoDB와 기타 구현은 전체 문서를 다시 작성하지 않고도 애플리케이션이 문서의 특정 필드 값을 수정할 수 있도록 내부 업데이트를 지원함. 단일 문서의 여러 필드에 대한 읽기 및 쓰기 작업은 원자적임. 저장할 데이터 필드가 각 요소 간에 다른 경우, 빈 열이 많을 수 있으므로 관계형 또는 열 지향 저장소가 최선이 아닐 수 있음. 문서 저장소는 모든 문서가 동일한 구조를 가질 필요가 없음. 대표적인 예로는 MongoDB, AWS DynamoDB(제한된 기능), Couchbase, CouchDB, Azure Cosmos DB 등이 있음 
  - 그래프 데이터 모델
    - 그래프 데이터베이스에는 노드와 에지라는 두 가지 정보가 저장됨. 노드는 엔티티이며 에지는 노드 간의 관계를 나타냄. 노드와 에지는 모두 테이블의 열과 유사하게 해당 노드 또는 에지에 대한 정보 제공 속성을 가질 수 있음. 에지는 관계의 특성을 나타내는 방향을 가질 수도 있음. 대표적인 예로는 Neo4j, OrientDB, Azure Cosmos DB, Giraph, 아마존 Neptune 등이 있음 
- 구현 패턴
  - 데이터 수명주기 패턴 : 기본 작업(primitive operation)과 증분 데이터 업데이트를 단순화함 
    - 데이터 사용자가 정책과 API를 통해 기본 작업을 실행할 수 있도록 하는 것이 이 패턴의 목표. 네임스페이스 생성, 데이터 제공 계층에의 데이터 저장, 파티션 생성, 감사 규칙 생성, 스키마 진화 처리, 데이터 버전 관리에 대한 정책이 포함됨. 데이터 업데이트는 기본 작업이며 데이터를 최적화하는 것이 목표 
    - 스키마 진화 
      - 다운스트림 분석이 변경의 영향을 받지 않도록 스키마 변경을 자동으로 관리하는 것이 목표. 진화하는 스키마에 대해 기존 쿼리를 재사용하고 쿼리 중의 스키마 불일치 오류를 방지하고자 하는 것 
      - 열 이름 변경, 테이블의 시작과 중간 또는 끝에 열 추가,열 제거, 열 순서 변경, 열 데이터 유형 변경 등 다양한 스키마 변경이 있음.이에 대한 접근법은 역방향 및 순방향 진화를 모두 처리할 수 있는 데이터 형식을 사용하는 것. 역방향 호환성을 통해 이전 스키마를 사용해서 생성된 데이터를 읽기 위해 새로운 스키마를 사용할 수 있으며, 순반향 호환성을 통해 새로운 스키마를 사용해서 생성된 데이터를 읽기 위해 이전 스키마를 사용할 수 있음.
      - 스키마 진화는 데이터 형식, 스키마 변경 유형, 기본 쿼리 엔진의 기능. 스키마 변경 유형이나 스키마에 따라 변경 내용이 다운스트림 분석에 지장을 줄 수 있음 
      - 아마존 Athena는 읽기 스키마 쿼리 엔진. Athena에서 테이블이 생성되면 데이터를 읽을 때 스키마를 적용하고, 기본 데이터를 변경하거나 다시 쓰지 않음. Parquet와 ORC는 인덱스 또는 이름으로 읽을 수 있는 열 데이터 스토리지 형식. 데이터를 이 형식 중 하나로 저장하면 Athena 쿼리를 실행하는 동안 스키마 불일치 오류가 발생하지 않음 
    - 데이터 버전 관리
      - 사용자가 특정 시점에 데이터를 쿼리할 수 있도록 시간 이동 기능을 구현하는 것이 이 패턴의 목표. 재현성, 롤백, 감사의 학습을 위해 필요함 
      - 데이터 브릭스 Delta는 이 패턴의 구현 사례이며 델타 테이블 또는 디렉터리에 기록하면 모든 작업이 자동으로 버전화됨. 다른 버전에 액세스하는 방법으로는 타임스탬프를 사용하거나 버전 번호를 사용하는 두 가지 방법이 있음 
    - 증분 업데이트
      - 데이터 레이크에서 증분 업데이트를 최적화하는 것을 목표로 함
      - Hudi(Hadoop Upsert Delete and Incremental)로, 몇 분 정도면 HDFS의 데이터에 변형을 적용할 수 있음. Hudi는 관련 파티션의 모든 Parquet 파일에서 Bloom 필터 인덱스를 로드하고 업데이트를 위해 수신되는 키를 기존 파일에 매핑함으로써 레코드를 업데이트 하거나 삽입해 태그를 지정함. Hudi는 파티션별로 삽입을 그룹화하고 새 필드를 할당한 후 로그 파일이 HDFS 블록 크기에 도달할 때까지 해당 로그 파일에 추가함
      - 스케줄러는 몇 분마다 시간 제한 압축 프로세스를 시작해 우선순위가 지정된 압축 목록을 생성함. 압축은 비동기식으로 실행됨. 모든 압축 반복에서 가장 많은 로그가 있는 파일이 먼저 압축되는 반면, Parquet 파일을 다시 쓰는 비용이 파일의 업데이트 수에 따라 상각되지 않기 때문에 작은 로그 파일이 마지막으로 압축됨 
    - 트랜잭션 패턴
      - 데이터 레이크에서 ACID(원자성Atomicity, 일관성Consistency, 격리Isolation, 내구성Durability) 트랜잭션 구현에 중점을 둠. Delta Lake, Iceberg, 아파치 ORC와 같은 몇 가지 구현 패턴이 있음 
- 고급 데이터 관리 패턴
  - 고급 데이터 관리 패턴은 단일 기존 테이블 내에서 스트리밍 이벤트 데이터를 결합함 
  - upsert(업데이트를 진행할 때 데이터가 있다면 업데이트를하고, 없다면 인서트를 하는 것)는 새로운 데이터 파티션에 게시하는 문제를 신속하게 해결할 수 있지만, 다운스트림 소비자들은 과거 시점 이후 어떤 데이터가 변경됐는지 알지 못함 
  - 필수 데이터 레이크 원시 요소와 이러한 요소들이 Delta Lake에서 구현되는 방법
    - 데이터가 기록되는 동안 일관된 데이터를 읽을 수 있는 기능 -> 작성자와 독서자 간의 스냅샷 격리
    - 처리량이 우수한 대형 테이블에서의 증분 읽기 기능 -> 확장성 있는 메타데이터 처리가 가능한 최적화된 파일 소스 
    - 잘못된 쓰기 시 롤백 기능 -> 시간 이동
    - 도착한 새 데이터를 따라 데이터의 과거 기록을 재생하는 기능 -> 동일한 파이프라인을 통해 백필된 과거 데이터 스트리밍
    - 다운스트림 처리를 지연시키지 않고 늦게 도착하는 데이터를 처리할 수 있는 기능 -> 늦게 도착한 데이터가 테이블에 추가될 때 스트리밍 

## 데이터 랭글링 서비스
- 데이터 구조화, 정리, 보강, 유효성 검사를 아우르느 데이터 랭글링에 집중할 준비가 됐음. 
- 랭글링(wrangling)은 오류, 이상값, 결측값, 대체값, 데이터 불균형, 데이터 인코딩을 선별하는 반복적인 프로세스.프로세스의 각 단계는 인사이트를 생성하기 위한 가장 탄탄한 데이터 값을 생성하는 것을 목표로 데이터가 다시 랭글링될(re-wrangled) 수 있는 새로운 잠재적 방법을 도출함 
- 여정 지도
  - 발견 
    - 메타데이터 카탈로그를 활용해 데이터와 스키마의 속성, 분석에 필요한 랭글링 변환을 이해함 
    - 레코드 매칭, 즉 데이터 세트끼리 식별자를 공유하지 않거나 식별자를 신뢰하기 어려운 경우에도 여러 데이터 세트 간의 관계를 찾는 작업이 포함됨 
  - 검증
    - 데이터 필드의 값이 1/0이 아닌 부울 참/거짓과 같은 구문 제약 조건을 준수하는지 확인하는 것을 포함해 여러 차원의 검증이 있음. 분포 제약은 데이터 속성의 값 범위를 검증함 
    - 교차 속성 검사는 교차 데이터베이스 참조 무결성(고객 데이터베이스에 업데이트된 신용카드가 구독 청구 데이터베이스에 올바르게 업데이트되고 있는지)을 검증함 
  - 구조화 
    - 데이터 형식은 다운스트림 분석 요구 사항에 일치하지 않을 수 있음 
  - 정리
    - 이상값, 결측값, NULL 값, 생성된 인사이트를 왜곡할 수 있는 불균형 데이터를 제거하는 것. 정리에는 데이터 품질 및 일관성에 대한 지식이 필요함. 다양한 데이터 값이 최종 분석에 어떤 영향을 미칠 수 있는지 알고 있어야 함. 데이터 세트 내 중복된 레코드의 제거가 있음 
  - 보강
    - 고객 프로파일 데이터 보강처럼 다른 데이터 세트와의 결합을 포함함 
- 데이터 큐레이팅
  - 랭글링에 대한 요구 사항을 바탕으로 대규모 데이터 변환 기능을 구축하는 데 초점을 맞춤 
  - 데이터의 반복적인 시각적 편집을 데이터세트에 적용시키는 랭글링 규칙으로 변환하는 시각적 분석 도구를 사용하는 것 
  - 데이터 큐레이션을 위한 시각적 분석 프레임워크의 주요 과제 
    - 대규모 데이터 세트를 위한 확장성
    - 유사 데이터 세트에 자동으로 적용되는 인텔리전스(수동 개입 감소)
    - 정확성, 데이터 품질 문제, 데이터 재형식화, 다양한 유형의 데이터 값 간 변환 규격 지원 
    - 사람의 입력을 통해 학습하고 데이터 변환 프로세스에 대화형 변환 이력을 활용
- 구현 패턴
  - 탐색적 데이터 분석 패턴 : 데이터 세트에 대한 이해를 촉진해 랭글링 변환을 정의함 
    - 필요한 데이터 랭글링 변환이 무엇인지 알아내기 위해 데이터 세트를 이해하고 요약하는 것에 중점을 둠 
    - 데이터 시각화 및 관련된 데이터 요약을 제공하는 몇 가지 구현 사례로는 Profiler, Data Wrangler, Trifacta. Rapid-Miner는 분석 프로세스의 설계를 위한 직관적인 그래픽 사용자 인터페이스를 제공하며 프로그래밍이 필요하지 않음 
  - 분석 변환 패턴 : 프로덕션 규모로 변환을 구현함
    - 시각적 분석과 드래그 앤 드롭 ETL 정의 프레임워크 
    - 시각적 분석은 데이터 시각화, 변환, 검증을 통합하는 대화형 시스템을 통해 랭글링 데이터를 가능하게 해줌. 구체화 시간을 크게 줄이고 수동 편집 대신 편집 가능한 강력한 변환의 사용을 촉진함 
    - 스탠포드의 Wrangler는 데이터 변환을 생성하기 위한 대화형 시스템. 시각화된 데이터의 직접 조작과 이와 관련된 변환의 자동 추론을 결합해서 해당 작업의 가능 여부를 반복적으로 탐색하고 그 효과를 미리 볼 수 있도록 함. Wrangler는 시맨틱 데이터 유형을 활용해 검증과 타입 변환을 지원함 
  - 자동화된 품질 시행 패턴 : 데이터 품질 추적 및 디버깅을 위한 모니터링을 운영함 

## 데이터 권한 거버넌스 서비스
- 데이터 권한의 다양한 고려 사항 
  - 데이터 권한 수집 
    - 개인 데이터 수집과 수집된 정보 범주에 대해 통지받을 권리
  - 데이터 권한 사용
    - 처리(데이터의 사용 방법)를 제한할 권리, 개인정보 판매를 거부할 권리, 정보가 판매되는 제3자의 신원
  - 데이터 권한 삭제
    - 애플리케이션과 공유된 개인 데이터 및 제3자와 공유된 데이터를 삭제할 권리 
  - 데이터 권한에 대한 액세스
    - 고객의 개인 데이터에 액세스할 수 있는 권리, 데이터가 부정확하거나 불완전한 경우 수정할 권리, 개인이 개인 데이터를 얻고 재사용할 수 있는 데이터 이식성에 대한 권리 
- 규정 준수 시간 최소화
  - 규정 준수 시간에는 데이터와 고객 선호의 수명주기를 추적하고 고객 데이터 권한 요청을 실행하고 고객 선호에 따라 올바른 데이터가 사용되는지 확인하는 데 소요되는 시간이 포함됨 
  - 고객 데이터 수명주기 추적
    - 어떻게 고객으로부터 데이터를 수집하는지, 데이터가 어떻게 저장되고 식별되는지, 고객 선호 사항이 어떻게 유지되는지, 데이터가 서드 파티 프로세스와 어떻게 공유되는지, 데이터가 다른 파이프라인에서 어떻게 변환되는지에 대한 추적이 포함됨 
  - 고객 데이터 권한 요청 실행 : 데이터의 수집,사용,삭제,액세스와 관련된 고객 데이터 권한 실행이 포함됨 
- 요구 사항 정의
  - 데이터 거버넌스의 요구의 맥락에서 주요 고려 사항
    - 레이크 및 트랜잭션 시스템에서의 데이터 관리 성숙도
    - 다양한 업종에 대한 규정 준수 요구 사항
    - 데이터 분석과 ML에 관련된 유스 케이스의 범주
    - 사용자 선호 설정과 데이터 요소의 세분화 
- 상호 운용성 체크리스트 (데이터 거버넌스 서비스의 상호 운용성을 위한 핵심 시스템, https:oreil.ly/x7uV0 )
  - 스토리지 시스템 : S3, HDFS, Kafka, 관계형 데이터베이스, NoSQL 저장소 등 
  - 데이터 형식 :Avro, JSON, Parquet, ORC 등
  - 테이블 관리 : Hive, Delta Lake, Iceberg 등
  - 처리 엔진 : Spark, Hive, Presto, TensorFlow 등
  - 메타데이터 카탈로그 : Atlas, Hive, Metastore 등
  - 데이터 프로세서로서의 서드 파티 공급 업체 : 이메일 캠페인 과리 도구, 고객 관계 관리 등 
- 비기능 요구 사항
  - 직관적인 데이터 이식성 
    - 고객이 데이터를 요청할 때는 쉽게 이식할 수 있고 광범위하게 적용할 수 있는 읽기 쉬운 형식으로 제공해야 함 
  - 급증하는 요청을 처리하도록 확장 : SaaS 애플리케이션에서는 수백만 명의 고객이 있을 수 있음. 서비스는 급증하는 고객 요청을 처리하고 적시에 완료할 수 있어야 함 
  - 고객이 데이터 권한을 적용하는 과정이 직관적임 : 고객은 데이터 권한을 시행하는 방법을 쉽게 찾을 수 있어야 함 
  - 시스템 확장 가능 : 새로운 빌딩 블록이 플랫폼에 추가되면 데이터 권한 거버넌스 서비스가 쉽게 운용될 수 있어야 함 
- 구현 패턴 
  - 민감한 데이터 발견 및 분류 패턴
    - 범위는 민감한 고객 데이터의 발견 및 분류
    - 아마존 Macie와 아파치 Atlas 계보 기반 분류 
    - 머신러닝을 사용해 AWS에서 민감한 데이터를 자동으로 검색, 분류, 보호하는 아마존 Macie 
      - Macie는 데이터를 이해하고 데이터 액세스를 추적함. Macie는 PII, 소스 코드, SSL 인증서, iOS 및 Android 앱 서명, OAuth API 키 등과 같은 민감한 데이터를 인식함 
      - 콘텐츠, 정규식, 파일 확장자, PII 분류자를 기준으로 데이터를 분류함. Macie는 각각 지정된 민감도 수준 점수가 있는 콘텐츠 유형 라이브러리를 제공함. Macie는 bzip, Snappy, LZO 등과 같은 여러 압축 및 아카이브 파일 형식을 지원함. 데이터 액세스 활동에 이상이 있는지 지속적으로 모니터링하고 경고를 생성함. 어떤 사용자가 어떤 데이터 개체 및 콘텐츠 가시성(개인 데이터, 자격 증명, 민감도)에 접근할 수 있는지, 과도하게 허용된 데이터가 있는지, 콘텐츠에 대한 무단 접근은 없는지 식별하고 이와 연관된 액세스 동작과 관련해서 패턴을 적용함 
    - 레이블 전파 패턴의 아파치 Atlas
      - 분류 전파를 사용하면 데이터 개체(테이블)와 연결된 분류가 데이터 계보를 기반으로 다른 관련 개체와 자동으로 연결될 수 있음 
  - 데이터 레이크 삭제 패턴
    - 고객과 관련된 데이터 레이크에서 데이터를 삭제하는 데 초점. 트랜잭션 데이터스토어의 데이터는 다운스트림 분석 및 인사이트를 위해 레이크에 수집됨 
    - 아파치 Gobblin
      - Gobblin은 데이터와 연관된 Hive 파티션을 추적함. 트랜잭션 소스 테이블에서 수집이 이뤄지는 동안 고객 데이터를 제거해야 하는 경우, 수집 파이프라인의 병합 프로세스 중에 해당 레코드가 삭제됨. 스트림 처리에도 적용됨. 레이크의 기록 데이터 레코드 정리는 API를 통해 트리거될 수 있음 
  - 유스 케이스 기반 액세스 제어 패턴 사용 
    - 고객의 선호에 따라 적절한 유스 케이스에 데이터가 사용되도록 하는 것 
    - 대역 외 제어(out-of-band control)
      - 파일, 개체, 테이블, 열에 대한 세분화된 액세스 제어를 사용해 달성함. 데이터 개체와 관련된 속성에 따라 특정 유스 케이스에 해당하는 팀으로 액세스가 제한됨 
    - 인바운드 제어(in-bound control)
      - 액세스 시점에 기저의 물리적 데이터에서 동적으로 생성된 논리 테이블 및 뷰를 사용해 달성함 
    - Atlas : 데이터 엔티티에 대해 메타데이터와 태그를 정의할 수 있는 카탈로그. 
    - Ranger : 데이터 엔티티에 대해 정의된 속성에 따라 액세스를 적용하는 중앙 집중식 보안 프레임워크를 제공함. 데이터 마스크 또는 행 필터링에 대해 열 수준 또는 행 수준의 속성 기반 액세스 제어를 정의할 수 있음 
    - 대역 외 제어 패턴의 AWS Data Lake Formation : AWS Redshift, EMR, Glue, Athena와 같은 AWS 서비스 전반에 걸쳐 액세스 정책을 적용해 사용자가 접근 권한이 있는 테이블과 열만 볼 수 있도록 하면서 모든 액세스에 대해 로깅과 감사가 가능하게 함 
    - 인바운드 제어 패턴을 위한 링크드인의 Dali
      - Dali의 디자인 원칙은 데이터를 코드처럼 취급하는 것. Dali는 Hadoop과 Spark에 대한 논리적 데이터 액세스 계층은 물론 스트르밍 플랫폼을 제공함
      - 유니온,필터와 기타 변환을 적용하는 여러 데이터 세트에 걸쳐 논리적 평면화 뷰를 생성하는 것을 포함해 여러 외부 스키마를 사용함으로써 물리적 스키마를 사용할 수 있음 
      - 주어진 데이터 세트, 메타데이터, 유스 케이스에 따라 데이터 세트 및 열 수준 변환(마스크,난독화 등)을 생성함 

# 셀프서비스 구축
## 데이터 가상화 서비스
- 데이터 세트와 연관된 다중언어(여러 프로그래밍 언어로 개발하는 것) 데이터 모델 
- 데이터 스토리지 지속성(data storage persistence)에서 쿼리 엔진을 분리하면 레이크에서 지속되는 데이터에 대한 쿼리를 서로 다른 쿼리 엔진이 실행할 수 있다는 점. 짧은 대화형 쿼리는 Presto 클러스터에서 실행되는 반면, 장기 실행 일괄 처리 프로세스는 Hive 또는 Spark에서 실행됨. 일반적으로 여러 처리 크러스터가 서로 다른 쿼리 워크로드 조합에 대해 구성됨. 올바른 클러스터 유형을 선택하는 것이 중요함
- 실시간 BI와 같은 유스 케이스가 증가함에 따라 레이크의 데이터가 실시간으로 애플리케이션 소스와 결합되는 부분 
- 처리 클러스터 선택
  - 클러스터는 구성(장기간 실행되는 메모리 집약적 쿼리나 단기간 실행되는 컴퓨팅 쿼리에 최적화됐는지), 의도된 유스 케이스(테스팅 혹은 SLA 중심인지), 비즈니스 조직에 대한 할당 등에 따라 달라짐 
  - 처리 클러스터 선택 시 로드 밸런싱 및 블루-그린 유지보수 스케줄과 같은 동적 속성도 고려해야 함 
    - 블루-그린(blue-green)배포는 애플리케이션 또는 마이크로서비스의 이전 버전에 있던 사용자 트래픽을 이전 버전과 거의 동일한 새 버전으로 점진적으로 이전하는 애플리케이션 릴리스 모델. 두 버전 모두 프로덕션 환경에서 실행 상태를 유지함 
- 사일로 간 데이터 결합
  - 전통적인 쿼리 최적화 도구에서는 카디널리티(한 테이블이 다른 테이블과 갖는 관계(일대일, 일대다, 다대다) 또는 특정 데이터 세트에서의 유니크한 값을 나타내는 지표로 사용되는 용어)와 데이터 레이아웃을 고려하는데, 데이터 사일로 간에서는 수행하기가 어려움. 애플리케이션 데이터스토어의 데이터는 일반적으로 반복 쿼리를 지원하기 위해 구체화 뷰로도 캐시됨 
- 데이터 가상화 서비스의 주요 기능
  - 클라이언트 측의 변경 없이 올바른 클러스터에 대한 쿼리 라우팅을 자동화함. 라우팅은 기존 클러스터에 대한 동적 로드(평균 대기 시간, 쿼리 실행 시간 분포 등)뿐만 아니라 정적 구성 속성(클러스터 노드 수 및 하드웨어 구성, 즉 CPU,디스크, 스토리지 등)을 추적하는 것을 기반으로 함 
  - 다중언어 데이터스토어 간에 상주하는 정형, 반정형, 비정형 데이터에 대한 쿼리 공식화를 간소화함
  - 애플리케이션 마이크로서비스는 물론 레이크의 여러 데이터스토어에 있는 데이터를 결합하기 위한 통합 쿼리를 지원함. 또한 애플리케이션 데이터스토어로 푸시되는 쿼리 수를 제한할 수 있음 
- 데이터 가상화 서비스 설계 시 고려해야할 몇 가지 핵심 비기능 요구 사항
  - 확장성(extensibility) : 서비스는 변화하는 환경에 맞게 확장 가능해야 하며, 새로운 도구와 프레임워크를 지원하기 위해 확장할 수 있어야 함 
  - 비용 : 가상화는 계산 비용이 많이 들기 때문에 관련 비용을 최적화하는 것이 중요함 
  - 디버깅 가능성 : 가상화 서비스에서 개발된 쿼리는 대규모로 실행되는 프로덕션 배포에서의 정확성과 성능을 위해 쉽게 모니터링하고 디버깅할 수 있어야 함 
- 구현 패턴 
  - 자동 쿼리 라우팅 패턴 : 작업에 적합한 도구 선택과 관련된 작업을 단순화함. 쿼리에 적합한 처리 환경을 선택하는 작업을 복잡하지 않게 숨김 
    - 데이터 사용자가 작업을 가상화 서비스에 제출하기만 하면 자동으로 쿼리를 처리 클러스터로 라우팅하는 것이 이 패턴의 목표
    - 쿼리와 사용 가능한 처리 클러스터를 매칭해주는 역할을 함 
    - 넷플릭스의 Genie는 오픈소스 구현의 한 예
      - 패턴의 변형은 데이터 카디널리티와 복잡성에 대한 쿼리를 분석하는 페이스북과 같은 웹 2.0(Web 2.0) 회사에 의해 내부적으로 구현됐음. 장기간 실행되는 리소스 집약적인 쿼리가 Hive 클러스터에서 실행되는 동안 단기간 실행되는 대화형 쿼리는 Presto 클러스터로 라우팅됨 
      - 데이터 사용자는 물론 다양한 시스템(스케줄러, 마이크로서비스, 파이썬 라이브러리 등)도 클러스터 자체에 대해 전혀 알지 못한 채 작업을 제출할 수 있음. 실행 단위는 하나의 Hadoop, Hive, Pig 작업 
      - 데이터 사용자는 Genie에게 클러스터 이름/ID 또는 프로덕션인지 테스팅인지 등의 속성을 제공해 선택할 처리 클러스터의 종류를 지정함 
      - Genie 노드는 적절한 애플리케이션 라이브러리를 사용해 각 작업에 대한 새 작업 디렉터리를 생성하고, 선택한 클러스터에 대한 Hadoop, Hive 및 Pig 구성을 포함한 모든 종속성을 스테이징한 다음, 해당 작업 디렉터리에서 Hadoop 클라이언트 프로세스를 분기처리함 
      - Genie에는 인벤토리 정리, 좀비 작업 탐지, 디스크 정리, 작업 모니터링 작업을 실행하는 리더(leader) 노드가 있음. 리더십 선택은 Zookeeper를 통해 지원되거나 속성을 통해 정적으로 리더가 되도록 단일 노드를 설정해 지원됨 
  - 단일 쿼리 언어 패턴 : 정형, 반정형, 비정형 데이터에 대한 쿼리 작성과 관련된 학습 곡선을 단순화함 
    - 통합 쿼리 언어와 프로그래밍 모델에 초점을 맞춤 
    - 패턴은 PartiQL(SQL 유사 통합 쿼리 언어), 아파치 Drill(반정형 데이터를 위한 프로그래밍 모델), 아파치 Beam(스트리밍 및 일괄 처리를 위한 통합 프로그래밍 모델)으로 설명됨 
    - PartiQL은 저장된 위치 또는 형식에 관계없이 데이터를 효율적으로 쿼리할 수 있는 SQL 호환 쿼리 언어 
      - PartiQl은 관계형 데이터베이스(트랜잭션과 분석 모두)의 정형 데이터, 개방형 데이터 형식의 반정형 및 중첩 데이터(아마존 S3), NoSQL의 스키마가 없는 데이터 또는 다른 행에 대해 다른 속성을 허용하는 문서 데이터베이스의 정형 데이터를 처리함 
      - SQL에 대한 최소 확장 기능을 제공해 정형 데이터 세트, 반정형 데이터 세트, 중첩 데이터 세트의 조합에 대한 직관적인 필터링, 결합, 집계, 기간 설정이 가능함. PartiQL 데이터 모델은 중첩 데이터를 데이터 추상화의 기본적인 부분으로 간주해 SQL의 표준 기능으로 자연스럽게 구성하면서 중첩 데이터에 포괄적이고 정확하게 액세스하고 쿼리하는 구문(syntax)과 의미론(semantics)를 제공함 
      - PartiQL 쿼리는 데이터베이스에 구애받지 않고 여러 데이터 형식 및 모델에서 작동함 
    - 아파치 Drill은 복잡한 데이터를 쉽게 처리할 수 있는 직관적인 SQL 확장의 예 
      - 중첩된 데이터에 대한 쿼리를 가능하게 할 뿐만 아니라 최신 애프릴케이션 및 비정형 데이터스토어에서 흔히 볼 수 있는 빠르게 진화하는 구조를 지원하는 JSON 데이터 모델을 제공함 
      - Drill(구를 Dremel에서 영감을 얻음)을 사용하면 MapReduce 루틴이나 ETL을 사용해 스키마를 수정하지 않고도 다양한 데이터 세트를 탐색, 시각화, 쿼리할 수 있음. Drill을 사용하면 NoSQL 데이터베이스, 아마존 S3 버킷 또는 Hadoop 디렉터리에 SQL 쿼리의 경로를 언급하는 것만으로도 데이터를 쿼리할 수 있음. 기존 SQL 쿼리 엔진과 달리 사용자가 직접 데이터를 쿼리할 수 있도록 쉬지 않고 스키마를 정의함 
      - 개발자는 데이터를 추출하기 위해 Hive와 같은 애플리케이션을 코딩하고 빌드할 필요가 없음 
    - 아파치 Beam은 일괄 처리와 스트림 처리를 통합함 
      - 일괄 처리 및 스트리밍 데이터 병렬 처리 파이프라인을 정의하기 위한 오픈소스 통합 모델. 데이터 사용자는 오픈소스 Beam SDK 중 하나를 사용해 파이프라인을 정의하는 프로그램을 구축함 
      - 파이프라인은 Beam이 지원하는 분산 처리 백엔드 중 하나에 의해 실행되며 아파치 Apex, 아파치 Flink, 아파치 Spark, 구글 Cloud Dataflow가 포함됨
  - 연합 쿼리 패턴 : 소스 간에 데이터 결합과 관련된 작업을 단순화함. 단일 쿼리 엔진을 사용해 액세스할 수 있는 단일 쿼리 엔진을 제공함 
    - 서로 다른 데이터스토어에 상주하는 데이터를 결합할 수 있음 
    - Parquet 파일의 경우, 전체 블록을 건너뛸 수 있고 문자열 비교를 딕셔너리 인코딩을 통해 더 저렴한 정수 비교로 바꿀 수 있음. 관계형 데이터 베이스의 경우 데이터 트래픽 양을 줄이기 위해 외부 데이터베이스로 푸시다운함 
    - Spark 쿼리 처리 엔진
      - Spark SQL 쿼리는 각 테이블의 여러 행이 동시에 처리되는 방식으로 여러 테이블에 동시에 액세스 할 수 있음. 테이블은 동일하거나 다른 데이터베이스에 있을 수 있음 
      - 데이터스토어에 지원하기 위해 Spark는 여러 데이터스토어에 대한 커넥터를 구현함. 서로 다른 소스의 데이터는 DataFrame 추상화를 사용해 결합할 수 있음 
      - DataFrame에 대한 연산이 시작되기 전에 논리적 계획이 생성됨. 쿼리 푸시다운은 데이터스토어에서 크고 복잡한 Spark 논리 계획을 처리할 수 있도록 함으로써, 이러한 성능 효율성을 활용 가능하게 하고 데이터스토어가 대부분의 실제 작업을 담당할 수 있도록 함 
        - 푸시다운(pushdown) : 스택의 어떤 작업이 한 요인 때문에 정지될 때 그 요인을 음식점의 식기 분출 기계처럼 밀어내리는 역할을 하는 것을 의미함 
    - Presto도 연합 쿼리를 지원함
      - Presto는 빅데이터 애드혹 쿼리를 처리 하기 위한 분산형 ANSI SQL 엔진 
      - SQL Server, Azure SQL Database, Azure SQL Data Warehouse, MySQL, Postgres, Cassandra, MongoDB, Kafka, Hive(HDFS, Cloud Object Stores) 등과 같은 연합 데이터 소스에 대한 빠른 대화형 분석을 실행하는 데 사용됨 
      - Presto는 단일 쿼리 내에서 여러 시스템의 데이터에 액세스함. 예를 들어 S3에 저장된 기록 로그 데이터와 MySQL에 저장된 실시간 고객 데이터를 결합할 수 있음 

## 데이터 변환 서비스 
- 주요 고충 사항
  - 데이터 사용자는 비즈니스 로직의 전문가이지만 대규모 로직을 구현하려면 엔지니어링 지원이 필요함. 데이터가 기하급수적으로 증가함에 따라 안정적이고 성능이 뛰어난 방식으로 로직을 구현하려면 분산 프로그래밍 모델이 필요함. 데이터 사용자가 비즈니스 로직을 설명한 다음 엔지니어에게 UAT(User Acceptance Testing - 사용자 승인 테스트)를 설명해야 하기 때문에 전체 프로세스가 느려지는 경우가 많음 
  - 실시간 비즈니스 로직 변환기를 구축해야할 필요성이 증가하고 있음. 기존의 변환 방식은 파일 읽기, 형식 변환, 다른 데이터 소스와의 결합 등을 포함하는 일괄 처리 방식을 지향하고 있음 
  - 프로덕션에서 변환을 실행하려면 가용성, 품질, 데이터 소스의 변경 관리, 처리 로직을 추적하기 위한 지속적인 지원이 필요함 
- 여정 지도 
  - 변환 서비스는 데이터 보고, 스토리텔링, 모델 생성 등과 관련된 작업을 통해 데이터 사용자를 지원함. 
  - 프로덕션 대시보드 및 ML 파이프라인
    - 데이터 분석가는 데이터에서 인사이트를 추출해 마케팅 퍼널, 제품 기능 사용 현황, 가입 및 로그인, A/B 테스트 등에 대한 일일 대시보드에 관한 비즈니스 매트릭스를 생성함. 변환을 위한 비즈니스 로직은 재무, 영업, 마케팅 등의 이해관계자와의 협업을 기반으로 함 
  - 변환 시간 최소화
    - 변환 시간에는 비즈니스 로직 변환을 정의, 실행, 운영하려는 시간이 포함됨 
    - 변환 구현 
      - 비즈니스 로직 정의 및 변환 로직 코드 코딩이 포함됨. 적절한 테스트 및 검증, 성능 최적화와 기타 소프트웨어 엔지니어링 측면이 포함됨 
    - 변환 실행 
      - 적절한 쿼리 처리 엔진을 선택함 
      - 변환 로직은 일괄 처리 또는 스트리밍으로 실행될 수 있으며 이는 다른 구현을 필요로 함 
      - 핵심 변환 로직을 넘어서 실행을 하려면 데이터를 읽고, 로직을 적용하고, 출력을 서빙 데이터베이스에 써야 함 
      - 실행 시간을 소모하게 만드는 과제 
        - 처리 기술이 너무 많아 데이터 사용자가 올바른 쿼리 처리 프레임워크를 선택하기가 어려움 
        - 실시간 처리와 달리 일괄 처리를 위해 서로 다른 버전의 변환 로직을 관리하는 것은 일관된 관리가 어려움 
        - 로직이 변경될 때마다 로직 변경에 대한 데이터 백필(data backfill)이 필요함 
    - 변환 작업
      - 변환은 일반적으로 SLA를 준수하면서 프로덕션에 배포됨. 프로덕션 운영은 완수 및 데이터 품질 위반에 대한 모니터링, 경고 및 사전 예방적 이상 탐지가 필요함 
- 요구사항 정의
  - 현재 상태 설문지
    - 현재 상태와 관련된 고려 사항
      - 변환 로직 구현을 위한 현재 상태
        - 수집해야 할 핵심 지표는 기존 변환의 로직을 수정하는 시간, 구현의 정확성을 검증하는 시간, 새로운 변환 구현을 최적화하는 시간. 이러한 통계 외에도 레이크에서 사용되는 다양한 데이터 형식을 나열함 
      - 변환 실행을 위한 현재 상태
        - 고려해야 할 주요 사항은 (기존의 일괄 처리 지향 변환 대신) 실시간 변환이 필요한 유스케이스의 수, 읽고 쓸 데이터스토어, 기존 처리 엔진, 기존 프로그래밍 모델(아파치 Beam), 평균 동시 요청 수 
      - 변환 운영을 위한 현재 상태
        - 고려해야 할 주요 지표는 탐지 시간, 프로덕션 이슈를 디버깅하는 시간, SLA 위반 사건 수, 변환 정확성과 관련된 이슈 
- 기능 요구 사항 
  - 자동화된 변환 코드 생성 : 데이터 사용자는 구현을 위한 코드 세부 사항에 대해 걱정하지 않고 변환을 위한 비즈니스 로직을 구체화할 수 있음 
  - 일괄 처리 및 스트림 실행 : 유스 케이스의 요구 사항에 따라 변환 로직을 일괄 처리 또는 스트리밍으로 실행할 수 있음. 실행은 성능이 뛰어난 방식으로 대규모로 이뤄짐 
  - 증분 처리 : 과거 호출에서 처리한 데이터를 기억하고 새로운 증분 데이터에 처리를 적용할 수 있음 
  - 자동화된 백필 처리 : 로직 변경 시 메트릭을 자동으로 다시 계산함 
  - 가용성 및 품질 문제 감지 : 가용성, 품질, 변경 관리를 모니터링 함 
- 비기능 요구 사항 
  - 데이터 변환 서비스를 설계할 때 고려해야 할 몇 가지 주요 비기능 요구 사항 
    - 데이터 연결성 : ETL 도구는 모든 데이터 소스와 통신할 수 있어야 함 
    - 확장성 : 증가하는 데이터 볼륨 및 속도에 맞춰 확장할 수 있음 
    - 직관성 : 변환 서비스는 광범위한 데이터 사용자를 고려해 사용이 쉬워야 함
- 구현 패턴
  - 변환 서비스에 대한 자동화 수준 세 가지. 각 수준은 현재 수동이거나 비효율적인 작업 조합을 자동화하는 것에 해당함 
  - 구현 패턴 : 변화하는 비즈니스 요구 사항에 따라 변환 로직의 사양 및 구현을 단순화하고 빠르게 발전시킴 
    - 비즈니스 로직의 구현을 단순화하는 데 집중함 
    - 상용 및 오픈소스 솔루션으로 Informatica PowerCenter, 마이크로소프트 SSIS, Pentaho Kettle, Talend 
      - 사용자는 DSL(도메인 특화 언어) 또는 드래그 앤 드롭 UI를 사용해 변환 로직을 지정함. 변환 로직은 추출, 필터링, 집계 등과 같은 표준화된 빌딩 블록으로 정의됨. 사양은 버전으로 제어되고 코드와 별도로 관리됨 
      - 사양은 자동으로 실행 코드로 변환됨. 코드는 특정 데이터스토어, 처리 엔진, 데이터 형식 등을 설명함 
    - GUI 기반 변환인 아파치 NiFi와 DSL 기반 변환인 Looker의 LookerML. GUI 기반 도구는 잘 구성된 변환 코드를 대체하기에는 좋지 않으며, 유연성이 부족하고 도구의 한계로 인해 사용자가 로직 구현을 위한 임시방편을 택해야 하는 경우가 종종 있음 
    - 아파치 NiFi
      - 데이터 변환을 설계, 제어, 모니터링하기 위한 풍부한 웹 기반 GUI를 제공함. NiFi는 기본적으로 소스(추출함수), 프로세서(변환 함수), 싱크(로드 함수)라는 세 가지 유형으로 구분된 250개 이상의 표준화된 함수를 제공함. 프로세서 기능의 예로는 데이터 향상, 검증, 필터링, 결합, 분할, 조정이 있음 
      - 파이썬, 셸, Spark에는 부가적인 프로세서를 추가할 수 있음. 프로세서는 데이터 처리에서 매우 동시적으로 구현되며, 병렬 프로그래밍의 고유한 복잡성을 사용자에게 숨김. 프로세서는 동시에 실행되며 로드에 대처하기 위해 여러 스레드에 걸쳐 있음 
      - 외부 소스에서 데이터를 가져오면 NiFi 데이터 흐름 내부의 FlowFile로 표시됨. FlowFile은 기본적으로 관련 메타 정보가 있는 원본 데이터에 대한 포인터. 
      - 프로세서의 세 가지 출력
        - 실패 : FlowFIle을 올바르게 처리할 수 없는 경우, 원본 FlowFIle이 출력으로 라우팅됨
        - 원본 : 들어오는 FlowFile이 처리되면 원본 FlowFile이 출력으로 라우팅됨 
        - 성공 : 성공적으로 처리된 FlowFile은 이 관계로 라우팅됨 
    - Gui 변환 모델링 솔루션에는 StreamSets와 Matilion ETL 등 
    - DSL 사양의 예는 SQL 쿼리를 구성하는 데 사용되는 Looker의 LookML
      - 차원,집계,계산,데이터 관계를 설명하는 언어. 변환 프로젝트는 Git 저장소를 통해 버전이 함께 제어되는 모델, 뷰 및 대시보드 파일의 모음. 모델 파일에는 사용할 테이블과 테이블을 조인하는방법에 대한 정보가 포함돼 있음 
      - 뷰 파일에는 각 테이블에 대한 (또는 조인이 허용되는 경우 여러 테이블에 걸쳐) 정보를 계산하는 방법에 관한 정보가 포함돼 있음. LookML은 구조를 콘텐츠와 분리하므로 쿼리 구조(테이블이 조인되는 방법)는 쿼리 콘텐츠(액세스할 열, 파생 필드, 계산할 집계 함수, 적용할 필터링 식)와 독립적 
      - LookML은 UI 드래그 앤 드롭 모델과 달리 자동 완성, 오류 강조 표시, 상황별 도움말, 오류 수정에 도움이 되는 유효성 검사기가 있는 IDE를 제공함. LookML은 불평등 조인, 다대다 데이터 관계, 다단계 집계 등과 같은 기능을 통해 고급 사용자를 위한 복잡한 데이터 처리를 지원함 
    - 함수형 프로그래밍과 하스켈의 강력한 타입 시스템을 활용하는 ETL/ELT 데이터 처리를 위한 선언적 라이브러리인 에어비앤비의 metrics DSL과 DBFunctor 
  - 실행 패턴 : 변환 로직의 실행을 통합해 신선도(freshness) 요구 사항에 따라 일괄 처리와 실시간 처리를 모두 허용함 
    - 데이터가 사용자 비즈니스 변환 로직을 실행할 수 있도록 셀프서비스를 만드는데 집중함
    - 시간 지연은 매일 또는 매시간 일괄 처리부터 초 또는 밀리초 지연에 이르는 스트리밍 패턴까지 다양함. 초기에는 Spark의 스트림 처리가 마이크로 배치로 구현됐고, 아파치 Flink를 통해 이벤트별 처리까지 발전했음 
    - 넷플릭스의 Keystone과 아파치 Storm은 셀프서비스 스트리밍 데이터 패턴의 예이며, 일괄 처리를 스트림 처리의 하위 집합으로 취급함 
    - 데이터는 이벤트로 처리됨. 데이터 세트는 제한되지 않고 윈도우 기능을 사용해 작동함. 일괄 처리의 경우 데이터(테이블)는 처리를 위해 메시지 버스에서 이벤트로 재생됨 
      - 데이터는 메시지 버스에서 이벤트로 표시됨. 테이블에 대한 업데이트는 열의 이전 값과 새 값을 갖는 변경 데이터 캡처(CDC) 이벤트로 나타낼 수 있음. 행동 데이터와 같은 특정 데이터 세트는 자연스럽게 이벤트로 취급될 수 있음 
      - 변환 로직은 데이터 이벤트에서 작동함. 변환은 상태 비저장 또는 상태 저장일 수 있음. 상태 비저장 처리의 예로는 원시 CDC 이벤트를 고객 생성, 송장 작성 등과 같은 비즈니스 객체로 변환할 때처럼 각 이벤트가 독립적으로 처리되는 경우를 들 수 있음. 상태 저장 처리는 카운트, 집계 등과 같은 이벤트 전반에 걸쳐 작동함 
    - 넷플릭스의 Kyeston 플랫폼
      - 소스에서 이벤트를 읽는 것, 처리 작업을 실행하는 것, 싱크 데이터스토어에 데이터를 쓰는 것을 단순화함. 로직 변경 처리를 위한 백필을 자동화하고 일괄 처리를 이벤트 스트림으로서 실행함. 데이터 사용자는 비즈니스 로직에 집중하고 데이터 엔지니어링 측면에 대해서는 걱정하지 않음 
  - 운영 패턴 : 프로덕션의 변환을 심리스(seamless)하게 추적해 SLA를 충족함. 이 패턴은 변환의 가용성과 품질을 보장하기 위한 모니터링과 경고를 제공함 

## 모델 학습 서비스 
- 자동화된 모델 학습 플랫폼의 주요 예시로는 구글의 TensorFlow Extended, 에어비앤비의 Bighead, 우버의 Michelangelo, 아마존의 SageMaker, 구글 Cloud의 AutoML 등 
- 모델 프로토 타이핑 : 데이터 과학자는 피처 조합, 모델 매개변수, 초매개변수 값을 포함하는 다양한 모델 순열을 탐색해 비즈니스 문제에 가장 적합한 모델을 찾음 
- 모델 디버깅
  - 데이터 품질, 잘못된 피처 파이프라인, 데이터 분포 왜곡, 모델 과적합 등과 같은 다양한 문제로 인해 모델이 프로덕션에서 제대로 작동하지 않을 수 있음. 그 대안으로서 모델에 의해 생성된 특정 추론을 검사해 정확성을 확인해야 함 
  - 모델 성능을 디버깅하려면 종속성, 생성된 방법, 탐색된 순열(순열 탐색 및 학습에 걸리는 시간이 상당하다는 것을 고려함)과 관련된 모델의 계보가 필요함 
- 요구 사항 정의 
  - 모델 학습 서비스는 셀프서비스여야 함. 사양 세부 정보를 지정하게 됨 
    - 모델 유형
    - 모델 및 초매개변수 값
    - 데이터 소스 참조
    - 피처 DSL(도메인 특화 언어) 표현 
    - 지속적 학습 일정(해당하는 경우)
  - 학습 오케스트레이션 
    - 모델 피처에 대한 훈련 데이터 세트를 생성하는 것, 학습을 위해 이기종 하드웨어 환경에 컴퓨팅 리소스를 할당하는 것, 학습 전략을 최적화하는 것이 포함됨 
    - 프레임워크의 다른 예로는 PyTorch, Keras, MXNet, Caffe2, Spark MLlib, Theano 등이 있음. 딥러닝이 아닌 경우 Spark MLlib 및 XGBoost가 인기 있는 선택지. 딥러닝의 경우에는 Caffe와 TensorFlow가 가장 널리 사용됨 
      - 회귀 모델을 사용해 수량 예측 
      - 분류 모델을 사용해 카테고리 예측 
      - 이상 탐지 모델을 사용해 특이값, 부정 행위, 새로운 값 예측 
      - 차원 축소 모델을 사용해 피처 및 관계 탐색 
      - 클러스터링 모델을 사용해 데이터 구조 발견 
    - 인기 있는 대체 분류법은 알고리즘을 지도 학습, 비지도 학습, 강화 학습으로 분류하는 학습 스타일 기반 분류법. 딥러닝은 회귀와 분류에 사용되는 지도 학습의 변형 
    - 다양한 모델 유형을 학습할 때 고려해야 할 사항 
      - 모델 학습에 사용되는 데이터양은 얼마나 되는가? 데이터가 슬라이딩 윈도우 묶음(sliding window batches)으로 분석되는가, 아니면 새 데이터 포인트에 대해 점진적으로 분석되는가?
      - 모델당 평균 피처 수는 얼마나 되는가? 훈련 데이터 표본 분포에 일반적으로 왜곡이 있는가?
      - 모델당 평균 매개변수 수는 얼마인가? 더 많은 매개변수는 더 많은 튜닝을 의미함 
      - 모델이 단일인가, 분할돼 있는가? 분할된 모델의 경우 파티션당 하나의 모델이 학습되고, 필요한 경우 상위 모델로 대체됨 
  - 튜닝 
    - 반복적인 프로세스로, 각 반복이 끝날 때 모델의 정확성을 평가함. 곡선 아래 영역(AUC - Area Under the Curve), 정밀도(precision), 재현율(recall), F1, 혼동 행렬(confusion matrix) 등을 사용해 측정됨 
- 구현 패턴 
  - 분산 학습 오케스트레이터 패턴 : 리소스 오케스트레이션, 작업 예약, 학습 워크플로우 최적화를 자동화함 
    - 리소스 오케스트레이션
      - 학습의 분포는 동일한 머신 내의 컴퓨팅 코어(CPU와 GPU) 또는 머신 간에 이뤄질 수 있음. 데이터 병렬 처리를 사용해 학습을 분포시키는 일반적인 접근 방식은 두가지가 있음. 동기화된 입력 데이터의 서로 다른 데이터 슬라이스에 대해 학습하는 모든 작업자와 학습을 동기화하고 각 단계에서 기울기를 집계하는 것. 모든 작업자가 입력에 대해 독립적으로 학습하는 비동기 학습 데이터 및 변수를 비동기적으로 업데이트 하는 것. 근본적인 동기화 학습 접근 방식은 코어가 모델 값을 축소하고 결과를 모든 프로세스에 배포하는 전체 축소 패턴 
    - 작업 오케스트레이션 : 학습을 위한 피처 데이터 세트는 연산하거나 피처 저장소에서 가져와야 함 
    - 학습 최적화 : 학습은 일반적으로 학습 데이터 세트 내의 데이터 샘플을 통해 실행됨 
    - 분산 학습 오케스트레이션 패턴의 구글 TensorFlow Extended
      - 학습 작업을 CPU와 GPU에 분산하기 위한 여러가지 전략(MirroredStrategy, TPUStrategy, MultiWorkerMirroredStrategy, CentralStorageStrategy, OneServerStrategy)를 구현함
      - 대량의 데이터 처리를 다루기 위해 Spark, Flink 또는 구글 Cloud DataFlow와 같은 분산 처리 프레임워크가 사용됨. 대부분의 TFX 컴포넌트는 아파치 Beam 위에서 실행되며 이는 여러 실행 엔진에서 실행할 수 있는 통합 프로그래밍 모델. TFX는 확장 가능하며 Airflow와 Kubeflow를 즉시 지원함. TFX에 다른 워크플로우 엔진을 추가할 수도 있음 
    - 분산 학습 오케스트레이터 패턴의 장점은 처리를 분산하고 가능할 때마다 최적화해 학습 속도를 높일 수 있다는것. 약점은 제한된 ML 라이브러리, 도구, 하드웨어와의 통합 
  - 자동 튜닝 패턴 : 모델 매개변수와 초매개변수를 자동으로 튜닝함. 이 패턴은 학습 반복의 결과를 추적하고 데이터 사용자에게 계보 반복과 이에 대한 결과 보고서를 제공함 
    - 원래 모델 매개변수와 초매개변수를 튜닝하는 맥락에서 정의됐음 
    - AutoGluon, Auto-WEKA, H2O AutoML, TPOT, Hyperopt
    - 데이터 과학자는 랜덤 포레스트, 그라디언트 부스팅 머신(gradient-boosting machine), 신경망 등 다양한 유형의 ML 알고리즘에 적용할 수 있는 목적 함수 및 값 경계를 지정할 수 있음 
    - ML 커뮤니티에서 AutoML로 알려져 있음. 이 패턴의 예로는 모델 구축, 학습, 배포 프로세스의 전체 워크플로우를 자동화하는 구글의 AutoML 서비스가 있음. 
    - 자동 튜닝 패턴의 강점은 학습 서비스가 최적의 튜닝 값을 찾을 때 데이터 과학자의 생산성이 향상된다는 것. 약점은 무차별 대입 순열을 탐색하기 위해 컴퓨팅 리소스가 필요하다는 것 
  - 데이터 인식 지속적 학습 패턴 : 지능적인 재시도를 위해 ML 파이프라인의 구성 요소와 관련된 메타데이터를 추적해 모델 재학습 프로세스를 자동화함. 또한 프로덕션에서 모델을 푸시하기 전에 유효성 검사를 자동화함 
    - 배포된 모델의 학습을 최적화해 데이터 변경 사항을 반영함 
    - 메타데이터 추적 
      - 메타데이터는 현재 모델, 파이프라인 구성 요소의 실행 통계, 학습 데이터 세트 속성과 관련된 세부 정보를 포착함. 각각의 실행에 대한 파이프라인 구성 요소의 실행통계는 디버깅, 재현성, 감사를 지원하기 위해 추적함 
    - 오케스트레이션
      - ML 파이프라인 구성 요소는 데이터 아티팩트의 가용성에 따라 비동기적으로 트리거됨 
    - 유효성 검사
      - 프로덕션을 시작하기 전에 모델을 평가함. 유효성 검사는 모델 유형에 따라 다른 기법을 사용해 구현됨. 유효성 검사는 데이터 세트의 개별 데이터 조각에 대한 모델 성능을 포함함 
      - 유효성 검사에서는 고품질을 보장하기 위해 업데이트된 모델의 품질을 확인하는 것 외에도 데이터 품질에 대한 사전 보호 조치를 적용하고 모델이 배포 환경과 호환되는지 확인해야 함 
    - TFX(TensorFlow Extended)
      - TFX는 메타데이터 추적을 위해 오픈소스 라이브러리인 MLMD(MLMetadata)를 구현해 ML 파이프라인에 대한 메타데이터를 정의, 저장, 쿼리함. MLMD는 메타데이터를 관계형 백엔드에 저장하며 모든 SQL 호환 데이터베이스로 확장할 수 있음. TFX 파이프라인은 DAG(유향 비순환 그래프)로 생성됨 
      - TFX ModelValidator의 유효성 검사를 위한 구성 요소는 Beam을 사용함으로써, 사용자가 정의한 기준을 사용해 비교를 수행하고 새 모델을 프로덕션으로 푸시할지 여부를 결정함 

## 지속적인 통합 서비스
- ML 모델 파이프라인은 소스 스키마 변경, 피처 로직, 종속 데이터 세트, 데이터 처리 구성, 모델 알고리즘, 모델 피처, 구성과 함께 지속적으로 진화함. 
- ML 파이프라인의 지속적 통합과 관련해서는 여러 가지 어려움이 존재함. 데이터, 코드, 구성과 관련된 ML 파이프라인 실험을 전체적으로 추적하는 것. 변경 사항을 확인하려면 테스트 환경에 배포할 수 있도록 ML 파이프라인을 패키징해야 함. 개발 또는 테스트 환경에서의 단위 및 통합 테스트는 프로덕션과 유사한 실제 데이터를 제공하지 않음 
- ETL 변경 사항 통합 
  - ETL 코드는 지속적으로 발전함. 일반적인 시나리오로는 Spark와 같은 데이터 처리 프레임워크의 새 버전으로 이동하는 것, 성능 향상을 위해 Hive에서 Spark로 재작성하는 것, 소스 스키마가 변경되는 것 등이 있음. ETL 변경은 포괄적인 단위, 기능, 회귀, 통합 테스트를 사용해 정확성을 검증해야 함 
  - 통합 프로세스의 첫 번째 단계로는 단위 테스트와 통합 테스트의 골든 테스트 묶음(golden test suite)을 실행함. 이는 샘플 입력-출력 데이터의 결과를 비교하며 스모크 테스트(smoke test)라고도 함 
- 실험 추적 
  - 데이터 세트 버전에 대한 단일 종단 간 뷰(single end-to-end view), 모델 및 파이프라인, 피처 파이프라인 및 모델과 관련된 코드를 생성하는 것이 포함됨 
- 요구 사항 정의
  - 실험 추적 모듈 : 코드, 구성, 데이터 세트와 관련된 ML 파이프라인 변경 사항의 E2E 표현으로 실험을 추적함. 이에 해당하는 테스트 및 모델 학습 결과도 기록됨 
    - ML 파이프라인에 영향을 미치는 변경 사항을 전체적으로 포착해 빌드-검증 프로세스에 통합할 수 있도록 하는 것 
    - 구성 매개변수 : 피처 파이프라인 및 ML 모델 내에서 사용되는 모든 구성 가능한 매개변수
    - 코드 버전 : 라이브러리, 프로그래밍 언어, 종속 코드 등의 버전
    - 데이터 세트 : ML 파이프라인의 일부로 사용되는 데이터 버전을 정의함. 버전 관리를 사용하면 스키마, 배포와 같은 데이터 속성을 추적할 수 있음 
  - 파이프라인 패키징 모듈 : 로컬 또는 클라우드에 배포할 ML 파이프라인의 재현 가능한 패키지를 생성함 
    - 기술 버킷
      - Azure, AWS 등과 같은 클라우드 공급자
      - Docker, Kubernetes 등과 같은 컨테이너 오케스트레이션 프레임워크
      - Artifactory, Jenkins, S3 등과 같은 아티팩트 저장소
      - Jenkins, CircleCI, Travis 등과 같은 CI 프레임워크
      - AWS KMS, HashiCorp Vault 등과 같은 시크릿 관리(secrets management) 
  - 자동화 모듈 테스트 : 버전 프로덕션 데이터를 사용해 최적의 테스트 실행을 조율함 
- 구현 패턴
  - 프로그래밍 가능한 추적 패턴 : ML 모델 실험을 위해 사용자 정의 측정 항목을 추적할 수 있음 
    - 추적되는 측정 항목의 일반적인 예
      - 학습 작업의 시작 및 종료 시간
      - 누가 비즈니스 컨텍스트의 모델과 세부 사항을 학습시켰는가?
      - 각 피처의 분포 및 상대적 중요성
      - 다양한 모델 유형에 대한 특수한 정확도 지표(ROC 곡선, PR 곡선과 이진 분류기에 대한 혼동 행렬)
      - 모델 시각화를 위한 통계 요약 
    - MLflow Tracking
      - 매개변수, 코드 버전, 지표, 출력 파일을 로깅하기 위한 API와 UI를 제공함. 데이터 사용자는 ETL 또는 모델 프로그램 내에서 매개변수, 지표, 아티팩트를 추적할 수 있음.
      - 결과는 로컬 파일 또는 서버에 기록됨. 데이터 사용자는 웹 UI를 사용해 여러 실행의 출력을 보고 비교할 수 있음 
  - 재현 가능한 프로젝트 패턴 : 모든 환경에서 배포가 가능하도록 실험을 패키지화해 테스트 및 모델 학습을 지원함
    - 재사용 가능한 데이터 과학 코드를 패키징하기 위한 표준 형식을 제공하는 MLflow 프로젝트
      - 각 프로젝트는 단순히 코드 또는 Git 저장소가 있는 디렉터리이며, 설명자(descriptor) 파일을 사용해 종속성과 코드 실행 방법을 지정함. MLflow 프로젝트는 MLproject라고 하는 간단한 YAML 파일로 정의됨. 프로젝트는 Conda 환경을 통해 종속성을 지정할 수 있음 
      - 강점은 ML 파이프라인의 모든 측면을 포착해 실험 결과를 재현할 수 있또록 하는 표준화된 접근 방식. 약점은 패턴이 프로덕션 배포에 필요한 리소스 확장 요구 사항을 고려하지 않는다는 것 
  - 테스트 검증 패턴 : 단위, 컴포넌트, 통합 테스트의 형태로 테스트함. 이는 일반적인 소프트웨어 엔지니어링 관행과 유사함 
- 지속적 통합 서비스의 목표는 최적의 ML 파이프라인을 찾기 위해 실험을 추적, 구축, 테스트하는 것

## A/B 테스트 서비스 
- A/B 테스트(버킷 테스트, 분할 테스트 또는 제어된 실험이라고도 함)는 제품 변경, 새로운 기능 또는 제품 성장과 관련된 가설을 통해 사용자 만족도를 평가하는 일반적인 접근 방식으로 자리매김하고 있음 
- ML 모델, 비즈니스 리포트, 실험 전반에 걸쳐 일관된 지표 정의가 적용되도록 하려면 A/B 테스트를 데이터 플랫폼의 일부로 통합하는 것이 중요함 
- 코하비와 톰케가 언급했듯이 A/B 테스트는 검색 엔진(구글,Bing,Yahoo!), 소매 업체(아마존,이베이,엣시), 소셜 네트워킹 서비스(페이스북,링크드인,트위터), 여행 서비스(익스피디아, 에어비앤비,부킹닷컴) 등 프론트엔드 사용자 인터페이스 변경부터 백엔드 알고리즘에 이르기까지 모든 곳에 사용됨. 
- A/B 테스트는 동일한 웹 페이지의 변형을 여러 방문자 세그먼트에 동시에 표시하고 어떤 변형이 더 많은 전환을 유도하는지 비교하는 방법
- 몇 가지 핵심이 되는 고충 사항
  - A/B 테스트 실험을 올바르게 구성하는 것은 쉽지 않은 일이고, 변이 모집단에 걸쳐 관심 지표에 통계적으로 유의미한 차이를 초래하는 불균형이 없는지 확인해야 함 
  - 대규모 A/B 테스트 실험을 실행하려면 성능이 뛰어나고 확장 가능한 방식으로 변형을 할당해 생성하고 제공해야 함 
  - A/B 테스트 실험 결과 분석은 계산해야 할 지표를 기반으로 함 
- 구글, 마이크로소프트, 넷플릭스, 링크드인, 우버, 에어비앤비와 같은 셀프서비스 실험 플랫폼을 사용함. 
- 몇 가지 오픈소스의 예로는 클라우데라의 Gertrude, 엣시의 Feature Flagging, 페이스북의 PlanOut이 있음. 인튜이트의 오픈소스 실험 플랫폼인 Wasabi
- 여정 지도
  - A/B 테스트 개념
    - 요인(factor, 변수-variable)
      - 종속 반응을 생성하기 위해 독립적으로 변경할 수 있는 변수. 요인에는 일반적으로 수준(level)이라는 할당된 값이 있음. 웹 페이지의 배경색을 변경하는 것이 요인 
    - 실험군(treatment, 변형variant)
      - 현재의 시스템은 챔피언으로 여겨지고 있는 반면, 실험군은 개선을 시도하는 수정이며 도전자로 알려져 있음. 실험군은 하나 이상의 요인에서 수준(또는 수주들)을 변경하는 것이 특징 
    - 실험 단위 : 실험 단위는 무작위로 실험군에 할당될 수 잇는 물리적 개체, 이는 실험 또는 분석이 행해지는 개체 
    - 샘플 : 동일한 대조군을 제공받는 사용자 그룹 
    - 전체 평가 기준(OEC,Overall Evaluation Criteria) : 실험이 달성하고자 하는 척도, 목적 또는 목표를 나타냄 
  - 구체적인 실험 단계
    - 가설 생성 - 기능 설계 및 구현 - 실험 설계 - 실험 실행 - 결과 분석 
- A/B 테스트 시간 최소화
  - A/B 테스트 시간에는 실험 설계, 대규모 실행(지표 분석 포함), 최적화가 포함됨 
  - 대규모 실행 : 애플리케이션에는 실험을 위해 REST 엔드포인트를 호출해 적격한 실험, 실험군, 요인을 결정하는 신 서비스 클라이언트(thin service client)가 필요함 
  - 실험 최적화 
    - 실험을 추적하기 위해 풍부한 계측 로그를 사용해 셀프서비스 분석을 생성하고 실험 문제를 해결함. 로그에는 고객 체험에 관련된 검증된 실험, 실험군, 페이지와 관련된 정보가 포함됨
    - 일반적인 주요 비즈니스 OEC는 획득(가망 고객을 가입자로 전환), 참여(고객이 제품을 사용하는 빈도와 각 방문에 소비하는 시간), 유지(고객별 전체 가입자 수 및 평생 가치)
    - 보조 지표(가입 수, 로그인 수 등)와 운영 지표(가용성, 페이지 성능 등)를 추적해 실험이 잘 진행되고 있는지 컨펌하거나 거부함 
- 구현 패턴
  - 실험 명세 패턴 : 실험 설계와 관련된 무작위화 및 실험 상호 작용 처리를 자동화함 
    - 실험 설계 턴키(turnkey)로 만드는 데 중점을 둬서 실험 소유자가 수명주기 동안 실험을 구성, 시작, 모니터링, 제어할 수 있도록 함 
  - 지표 정의 패턴 : 실험을 평가하기 위한 지표 분석을 단순화해 실험 소유자가 실험과 관련된 인사이트를 추출하는 데 걸리는 시간을 줄임
    - 실험 분석에 필요한 지표 정의를 단순화함. 일회성 및 불일치 지쵸플ㄹ 구현하는 대신 지표와 차원을 정의하는 DSL을 제공함 
    - DSL의 예로는 마이크로소프트 실험 플랫폼과 에어비앤비의 지표 민주화가 있음 
    - DSL은 지표 및 속성 카탈로그에 내장돼 있으며, 사용자 가입 상태와 같은 정적 속성에서 회원의 마지막 로그인 날짜와 같은 동적 속성에 이르기까지 다양함. 속성은 매일 일괄 계산되거나 실시간으로 생성됨
    - 지표 플랫폼의 좋은 예는 링크드인의 Unified Metrics Platform
  - 자동화된 실험 최적화 : 실험 상태를 추적하고 변형 간의 트래픽 할당을 자동으로 최적화함 
    - 사용자 전반에 걸쳐 변형 할당을 자동으로 최적화하고 실험이 통계적 유의성과 고객 경험에 부정적인 영향을 미치지 않도록 올바르게 추세를 유지하도록 하는 것을 목표로함 
    - 실험 지표에 대한 가장 효과적인 검사는 카이-제곱 테스트를 사용해 구성된 비율과 변형에서 관찰된 사용자 수의 비율을 비교하는 SRM(Sample Ratio Mismatch - 표본 비율 불일치)테스트. SRM이 감지되면 결과가 유효하지 않은 것으로 간주됨. 
    - 검증 매커니즘은 A/A 실험으로, 실험군 효과가 없는 경우 p-값이 균일하게 분포될 것으로 예상함 
    - 변형 할당의 자동 최적화를 위한 많은 알고리즘이 있음. 가장 널리 사용되는 접근 방식은 다중 선택(multi-armed bandit). 이를 수행하기 위해 e-탐욕 알고리즘, 톰슨 샘플링, 베이지안 추론 등과 같은 여러 기술이 적용됨 

# 셀프서비스 운영화
## 쿼리 최적화 서비스
- 반복적으로 실행되는 장기 실행 쿼리는 튜닝 대상
- 쿼리 튜닝 시 여러 가지 어려움 발생
  - Hadoop, Spark, Presto와 같은 쿼리 엔진에는 수많은 노브(Knob)가 있음. 튜닝할 노브와 노브의 영향을 이해하는 것은 대부분의 데이터 사용자에게 쉬운 일이 아니며, 쿼리 엔진의 내부 작동에 대한 갚은 이해가 필요함. 쿼리의 최적 노브 값은 데이터 모델, 쿼리 유형, 클러스터 크기, 동시 쿼리 로드 등에 따라 다름. 데이터의 규모를 고려하면, 다른 노브 값을 실험하기 위한 무차별 대입 방식도 실현 가능하지 않음 
  - 페타바이트 규모의 데이터를 고려할 때 분산 데이터 처리 모범 사례에 최적화된 쿼리를 작성하는 것은 대부분의 데이터 사용자에게 어려움. 쿼리 엔진과 데이터스토어는 구현에 특화된 쿼리 원시 요소를 갖고 있음. 이러한 기능을 활용하려면 많은 새로운 기술에 대한 학습 곡선(learning curve)이 필요함
  - 쿼리 최적화는 일회성 활동이 아니라 실행 패턴에 기반해 진행됨. 쿼리 실행 프로필은 분할, 메모리, CPU 할당 등의 측면에서 런타임 속성을 기반으로 튜닝해야 함. 쿼리 튜닝은 낮은 중단(low-hanging) 최적화를 목표로 초기 몇 번의 반복 후 이득이 감소하는 반복적인 프로세스 
- 최적화 시간은 사용자가 쿼리를 최적화하는 데 소요한 시간을 나타냄
  - 데이터 사용자가 튜닝에 소요한 시간 
  - 쿼리 처리를 완료하는데 걸리는 시간. 프로덕션 환경에서 튜닝된 쿼리는 훨씬 더 빠르게 실행돼 전체 인사이트 시간을 크게 개선할 수 있음 
- 노브는 데이터 파티셔닝을 위한 연속 런타임 프로파일링, 분산 작업자 간의 처리 불균형 등을 포함해 처리 클러스터 및 쿼리 작업과 관련이 있음. 쿼리 최적화는 최적화 시간, 쿼리를 실행하는 데 필요한 시간, 멀티테넌트 환경에서 처리하기 위한 기본 리소스 할당에 대한 사용자 생산성 보장 간의 균형을 유지하는 작업 
- 여정 지도
  - 클러스터 막힘 방지
    - 잘못 작성된 쿼리는 클러스터를 막고 다른 프로덕션 작업에 영향을 미칠 수 있음 
  - 런타임 쿼리 문제 해결 
    - 쿼리가 작동을 중지하고 OOM(Out Of Memory - 메모리 부족) 문제로 인해 실패할 수 있음. 오류, 중단 또는 폭주하는 쿼리, SLA 위반, 변경된 구성 또는 데이터 속성, 아니면 클러스터를 막는 불량 쿼리와 같은 여러 시나리오가 런타임에 발생할 수 있음.
    - 컨테이너 크기, 구성 설정, 네트워크 문제, 시스템 성능 저하, 잘못된 조인, 쿼리 로직의 버그, 최적화되지 않은 데이터 레이아웃 또는 파일 형식, 스케줄러 설정 등 디버깅해야 하는 다양한 문제가 존재할 수 있음 
  - 애플리케이션 속도 향상
    - 데이터 제품을 개발하려면 모델 생성 중에 대화형 임시 쿼리가 필요한데, 탐색 단계에서 실행한 빠른 쿼리의 도움을 받을 수 있음. 엔지니어링 팀은 현재 프로덕션에서 리소스를 많이 사용하고 오래 실행되는 상위 열 개 쿼리를 매주 검토하는 방식을 따르고 있음. 이러한 쿼리를 최적화 대상으로 지정하고 데이터 사용자와 협업하며, 필요한 경우 다시 작성함 
- 최적화 시간 최소화
  - 모니터링 통계 집계
    - 쿼리 성능을 전체적으로 이해하려면 소프트웨어 스택의 모든 계층에서 통계를 수집해야 함 
      - 인프라 수준(컴퓨팅, 스토리지, 네트워크, 메모리) 성능 
      - 운영체제 상태
      - 리소스 관리자의 컨테이너 수준 통계
      - 쿼리 클러스터 리소스 할당 및 활용
      - 파일 액세스
      - 파이프라인 및 애플리케이션 성능 
    - 모니터링 세부 정보는 과거 추세 및 이상 징후 분석을 위해 성능 카운터, 로그 형태로 기록되고 유지됨. 이슈 디버깅 지원을 위해 설정 및 데이터 스키마의 변경 관리가 기록됨 
    - 통계 집계는 큰 부담이 됨. 스택의 여러 계층에서 다양한 성능 카운터와 로그 메시지 형식을 관리해야함. 통계는 API를 활용해 수집되고 해석해야 하며 소프트웨어 버전 업그레이드로 업데이트해야 함 
  - 모니터링된 데이터 분석
  - 분석 결과로 시정 조치 실시 
  - 통게 분석
    - 집계된 통계를 분석해 쿼리 성능 향상에 가장 효과적인 노브 및 최적화의 우선순위를 지정해야 함 
    - 쉬와 그 연구진은 세가지 다른 워크로드인 Terasort(테라바이트 데이터 정렬), N-gram(N-gram 데이터의 반전된 목록 계산), PageRank(그래프의 페이지 순위 계산)에 대한 Hadoop의 노브 튜닝을 비교했음 
    - Ngram 작업의 경우 Map Task 개수와 관련된 구성 노브가 중요했고 PageRank 작업은 작업 개수 감소의 영향을 가장 많이 받았음 
    - 분석 접근법의 세 가지 범주
      - 쿼리 분석 : 언어 구조 검토, 관련 테이블의 카디널리티 검사, 인덱스/파티션의 적절한 사용이 포함됨 
      - 작업 분석 : 데이터 프로파일링, 작업 병렬화 ,데이터 압축, 런타임 실행 단계 분석, 데이터 처리의 왜곡, 맵 효율성, 실행자(excutor) 감소 등과 관련된 통계 검토를 포함함 
      - 클러스터 분석 : 작업 스케줄링, 크기 조정(하드웨어, 버퍼 풀 등), 컨테이너 설정, 실행 코어 수, 활용률 등과 관련된 통계를 포함함 
    - 핵심 도전 과제는 클러스터, 작업, 쿼리 속성 간의 상관관계를 분석해 주어진 설정에 중요한 노브의 우선순위와 순위를 결정하는 데 필요한 전문 지식. 분석은 처리를 적절하게 병렬화하기 위한 올바른 파티셔닝 키를 정의하는 측면에서 데이터 스키마 설계 또한 다룸 
  - 작업 최적화 
    - 쿼리 최적화에는 데이터 레이아웃, 인덱스 및 뷰, 노트 튜닝, 쿼리 계획 최적화와 같은 여러 요인이 포함됨 
    - 쿼리 최적화 맥락 측면에서의 계층 구조 
      - 물리적 데이터 레이아웃 자동화 - 인덱스 및 뷰 추천 - 노브 튜닝, 버퍼 풀 크기 등 - 계획 최적화 
    - 노브는 성능에 비선형적인 영향을 미치며 일정 수준의 전문 지식을 필요로 함. 쿼리 최적화는 전통적으로 스키마와 통계가 부족한 구조화되지 않은 데이터를 처리할 때 데이터 카디널리티에 의존해왔으며, 그 영향을 추정하는 것은 단순한 일이 아님 
- 요구 사항 정의
  - 현재 고충 설문지
    - 현재 상태를 파악하기 위한 세 가지 범주의 고려 사항
      - 기존 쿼리 워크로드 : 프로덕션에서 실행중인 임시, 예약, 이벤트 트리거 쿼리의 비율. 쿼리 처리에 관련된 데이터 스토어, 쿼리 엔진의 다양성과 쿼리 실행의 일반적인 동시성 수준을 이해해야함 
      - 최적화되지 않은 쿼리의 영향 : 평가할 주요 지표는 누락된 SLA 수, 처리 클러스터의 활용도 수준, 실패한 쿼리 수, 클러스터에서 쿼리가 예약될 때까지의 대기 시간, 쿼리 완료 시간의 차이(반복 쿼리를 완료하는 데 걸리는 시간)
      - 기존 튜닝 프로세스 : 쿼리 튜닝에 대한 사전 대응적 접근 방식, 코드 검토, 기본 시스템 이해와 관련된 전문 지식, 리소스 소비 쿼리의 주기적 검토가 포함됨 
  - 상호 운용 요구 사항 
    - 쿼리 작성에 사용되는 프로그래밍 언어(파이썬과 스칼라), 백엔드 데이터스토어(Cassandra, Neo4j, Druid 등), 스트리밍 및 일괄 처리 엔진(Spark, Flink, Hive), 클라우드 및 사내 배포 환경(EC2와 Docker)과 상호 운용돼야 함 
- 기능 요구 사항 
  - 정적 쿼리 인사이트 
    - 올바른 원시 요소, 테이블 카디널리티와 기타 휴리스틱을 기반으로 쿼리를 개선하기 위한 권장 사항. 이상적으로는 클러스터의 처리에 영향을 미칠 수 있는 잘못 작성된 쿼리를 실행할 수 없도록 해야 함 
  - 동적 쿼리 인사이트
    - 런타임 프로파일링, 전체 스택의 단일 창, 튜닝할 노브에 대한 권장 사항을 기반으로 함. 작업 프로파일링은 연속적이며 쿼리가 실행될 때마다 통계를 사용함
  - 쿼리 자동 튜닝
    - 일반적인 시나리오의 경우, 권장 사항을 표시하는 대신 쿼리를 자동으로 조정할 수 있음 
- 비기능적 요구 사항
  - 설명 가능성 : 서비스는 최적화 서비스에서 생성된 권장 사항의 추론을 이해할 수 있어야 함
  - 중단 최소화 : 자동 튜닝을 사용할 때 서비스는 오탐을 최소화하고 튜닝 결과로 인한 부정적인 영향이 없도록 해야 함
  - 비용 최적화 : 클라우드에서 쿼리 처리에 지출하는 비율이 높다는 점을 고려하면 최적화 서비스는 전체 비용 절감에 도움이 될 것
- 구현 패턴
  - 회피 패턴 : 잘못된 쿼리가 처리 클러스터를 방해하고 다른 쿼리에 영향을 미치지 않도록 함.
    - 잘모 작성한 쿼리가 처리 클러스터를 막는 것을 방지하는 린트(lint - 소스 코드를 분석해 프로그램 오류, 버그, 스타일 오류, 의심스러운 구조체에 플래그를 달아놓기 위한 도구들을 가리킴)역할을 함. 두 가지 유형의 오류를 방지하는 것을 목표로함 
      - 매우 큰 테이블에 대한 복잡한 조인과 같은 데이터 모델 및 카디널리티에 대한 이해 부족으로 인한 우발적 실수를 방지하는 것
      - 서로 다른 데이터스토어와 관련된 쿼리 구문 및 모범 사례의 잘못된 사용을 방지하는 것 
    - 데이터 세트에 대한 메타데이터 집계 : 메타데이터 서비스를 활용해 통계(카디널리티, 데이터 품질 등) 및 데이터 유형을 수집함 
    - 쿼리 구문 분석 : 쿼리를 원시 문자열에서 AST(Abstract Syntax Tree - 추상 구문 트리) 표현으로 변환함 
    - 추천 제공 : 쿼리 원시 요소, 모범 사례, 물리적 데이터 레이아웃, 인덱스 및 뷰 권장 사항을 포함해 쿼리에 규칙을 적용함 
    - 아파치 Calcite는 쿼리가 실행되기 전에 분석하는 데 도움이 되며, Hue는 잘못 작성된 쿼리 생성을 방지하는 IDE를 제공함 
    - 아파치 Calcite
      - 아파치 Hive, Storm, Flink, Druid 등과 같은 다수의 인기 있는 오픈소스 데이터 처리 시스템에 쿼리 처리, 최적화, 쿼리 언어 지원을 제공함. 
      - Calcite의 아키텍처
        - 다양한 쿼리 언어를 처리할 수 있는 퀄 ㅣ프로세서, Calcite는 ANSI 표준 SQL뿐만 아니라 다양한 SQL 언어 및 확장(스트리밍 또는 중첩된 데이터에 대한 쿼리 표현)을 지원함
        - 관계형, 반정형, 스트리밍 등의 이기종 데이터 모델 및 저장소에 대한 확장성과 지원을 위해 설계된 어댑터 아키텍처 
        - 수백 개의 최적화 규칙이 내장된 모듈식 확장형 쿼리 쵲거화 도구 
    - Hue
      - IDE 내의 잘못된 쿼리를 회피하는 예시를 제공함 
      - 넷플릭스의 Polynote, 노트북 확장 프로그램 등에유사한 기능이 있음 
      - 카디널리티 통계와 함께 테이블과 열을 자동으로 나열하고 필터링하는 메타데이터 검색을 제공함. 모든 SQL 언어에 대한 쿼리 편집 자동 완성 기능을 제공하고, 유효한 구문만 표시하거나 키워드, 추가 시각화, 쿼리 형식화, 매개변수화에 대한 구문 강조 표시를 제공함 
      - 강점은 프로덕션에서 상당한 디버깅 시간을 절약하고 프로덕션 배포에서 예기치 않은 상황을 방지한다는 것. 약점은 균일한 시행이 어렵고 일반적으로 팀 엔지니어링 문화에 따라 다르다는 것 
  - 운영 인사이트 패턴 : 쿼리 실행에서 런타임 프로파일링 통계 분석을 기반으로 한 인사이트를 제공함. 운영 인사이트는 전체 스택을 모니터링하기 위한 단일 창에서 노브에 대한 권장 사항에 이르기까지 다양함 
    - 소프트웨어 스택의 여러 계층에서 수집된 지표를 분석하는 데 초점을 맞추며, 실행 가능한 다양한 인사이트를 데이터 사용자에게 제공함 
    - 노브 튜닝을 권장하기 위한 수집된 통계에 대한 상관관계 모델 모음. 애플리케이션 성능을 상호 연관시켜 코드 비효율성, 클러스터 리소스와의 경합이나 하드웨어 장애, 또는 비효율성(느린 코드)과 관련된 애플리케이션 성능 문제를 분석함. 두 기간 간의 클러스터 활동, 집계된 클러스터 워크로드, 클러스터 사용량에 대한 요약 보고서, 차지백 보고서(chargeback report) 등을 분석해 클러스터 사용률을 상호 연관시키는 것이 있음 
    - 통계 수집 : 빅데이터 스택의 모든 계층에서 통계와 카운터를 가져옴 
    - 통계 연관 : 여러 스택의 통계를 연관시켜 파이프라인에 대한 E2E 보기를 생성함
    - 휴리스틱 적용 : 휴리스틱과 작업 전체의 수행 방법에 대한 진단 보고서를 생성함 
    - Sparklens와 Dr.Elephant는 운영 인사이트를 제공하는 인기 있는 오픈소스 프로젝트
    - Sparklens
      - 애플리케이션이 제공된 컴퓨팅 리소스를 얼마나 효율적으로 사용하고 있는지 분석하는 Spark 애플리케이션용 프로파일링 도구 
      - 모든 지표를 수집하고 내장된 Spark 스케줄러 시뮬레이터를 사용해 분석을 실행함. Sparklens는 병목 현상에 대한 애플리케이션 실행을 분석해 드라이버 작업, 데이터 왜곡, 작업자 태스크(worker task) 부족과 기타 여러 가지 휴리스틱에 휴리스틱 모델을 적용해 확장을 제한함 
      - 시행 착오를 통해 학습하는 대신 체계적인 방법을 사용해 실행 단계에서 무엇이 잘못될 수 있는지에 대한 상황별 정보를 제공해 개발자와 컴퓨팅 시간을 모두 절약함 
    - Dr.Elephant
      - Hadoop과 Spark를 위한 성능 모니터링 및 튜닝 도구. 작업의 측정 항목을 자동으로 수집하고 분석해 쉽게 사용할 수 있도록 간단하게 보여줌 
  - 자동 노브 튜닝 패턴 : 작업 노브 값을 자동으로 조정하는 작업을 수행함 
    - 쿼리 성능을 향상시키기 위해 자동 튜닝 작업을 호출하는 최적화 도구를 개발하는 것 
    - 강점은 시스템 내부를 거의 또는 전혀 이해하지 못하는 데이터 사용자가 쿼리 성능을 향상시킬 수 있으므로 생산성이 향상된다는 점. 약점은 잘못된 튜닝이 부정적인 영향을 미치거나 생산 중단을 일으킬 가능성이 있다는 것 
- 쿼리 엔진 및 데이터스토어에 수백 개의 노브가 있는 쿼리 튜닝에는 기본 소프트웨어 및 하드웨어 스택에 대한 깊은 전문 지식이 필요함 
  - 더 빠른 완료와 엄격한 SLA
    - 증가하는 데이터 볼륨을 고려했을 때, 특히 비즈니스상의 이유로 엄격한 타임 위도우 내에 쿼리를 완료해야 하는 경우 쿼리를 적시에 완료하도록 조정하는 것이 중요함 
  - 더 나은 자원 활용 : 분산된 하드웨어 리소스 간에 처리를 확장할 수 있는 기능이 핵심 
  - 성능 격리 : 처리클러스터를 여러 팀이 공유하는 멀티테넌트 배포의 경우 잘못 작성된 쿼리로 인해 시스템이 중단될 수 있음 
