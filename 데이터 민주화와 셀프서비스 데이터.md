# 서평

# 소개
- 데이터 민주화란 데이터에 쉽게 접근할 수 있도록 기반을 만들어 데이터를 잘 아는 사람부터 잘 모르는 사람까지 누구나 데이터를 쉽게 사용해 인사이트를 도출할 수 있도록 한느 것 
- 셀프서비스 데이터란 데이터 엔지니어나 데이터 과학자가 관여하지 않더라도 마케터, 사업 담당자, 서비스 운영 담당자 등 조직 내 모든 사람이 스스로 데이터에 접근해 인사이트를 추출할 수 있도록 만들어진 데이터 기반을 의미함 
- 원시 데이터에서 인사이트로의 여정 지도 
  - 전통적인 데이터 웨어하우스와 현재의 빅데이터 시대에서 인사이트를 추출하는 방식의 주요 차이점 
  - ||데이터 웨어하우징 시대의 인사이트 추출|빅데이터 시대의 인사이트 추출
    |:---:|:---:|:---:|
    |데이터 형식|정형 데이터|정형,반정형,비정형 데이터
    |데이터 특성|대용량 데이터|데이터의 4V:볼륨,속도,다양성,진시성
    |데이터 카탈로그 작성|데이터를 집계할 때 정의됨|데이터를 읽을 때 정의됨
    |인사이트의 신선함|인사이트는 주로 소급형(비드니스 마지막 주 기준 지표)|인사이트는 소급형,대화형,실시간,예측의 조합
    |쿼리 처리 방식|단일 솔루션으로 결합된쿼리 프로세서와 데이터 스토리지|쿼리 처리와 데이터 스토리지가 분리됨
    |데이터 서비스|단일 솔루션으로 통합|작업에 적합한 도구를 선택하는 데 많은 치환을 허용하는 믹스 앤 매치(mix-and-match)방식
  - 발견
    - 모든 인사이트 도출 프로젝트는 사용 가능한 데이터 세트와 개발 산출물을 발견하고, 인사이트를 발전시키는 데 필요한 추가 데이터를 수집하는 것부터 시작함
    - 데이터 세트의 메타데이터 세부 정보 발견
      - 마일스톤은 데이터가 생성된 위치, 데이터 속성이 생성된 방법 등 메타데이터 속성을 이해하는 것 
      - 메타데이터를 수집하고 상호 연결이 가능하려면 데이터스토어, 수집 프레임워크, 스케줄러, 메타데이터 카탈로그, 규정 준수 프레임워크 등에 접근이 필요함
      - 마일스톤을 완료하는 데 걸리는 시간은 해석시간(time to interpret)을 지표로 추적함 
    - 사용 가능한 데이터 세트 및 아티팩트 검색
      - 마일스톤은 모든 관련 데이터 세트와 아티팩트, 예를 들어 뷰, 파일, 스트림, 이벤트, 지표, 대시보드, ETL, 임시 쿼리를 찾는 것이라고 할 수 있음 
      - 탐색 시간 지표(time to find)로 추적됨 
    - ML 모델에서의 기능 재사용 또는 생성
      - 피처화 시간(time to featurize) 지표로 추적함 
    - 누락된 데이터 집계
      - 비즈니스 대시보드를 만들려면 식별된 데이터 세트(고객 활동 및 결제 청구 기록)를 결합해 리텐션 리스크(retention risk)에 대한 인사이트를 생성
      - 데이터 가용성 확보 시간(time to data availability)
    - 클릭스트림 이벤트 관리
      - 클릭, 뷰와 이전 애플리케이션 페이지, 방문자 기기 유형 등 연관된 맥락까지의 고객 활동을 분석해야 함
      - 클릭스트림 데이터(clickstream data)는 우선 수집, 필터링되고 보강돼야 인사이트 생성에 사용할 수 있음 
      - 클릭 시간(time to click)지표로 추적함 
  - 준비
    - 준비 단계에서는 인사이트 추출을 위해 실제 비즈니스 로직 구축용 데이터를 준비하는데 집중함. 준비는 데이터 집계, 정리, 표준화, 변환, 비정규화를 포함하는 반복적이고 시간 집약적인 작업이며 여러 가지 도구와 프레임워크를 포함함
    - 규제 준수 요건을 충족하기 위해 데이터 거버넌스(data governance)를 보장함 
  - 중앙 저장소 내의 집계 데이터 관리 
    - 비즈니스 대시보드는 과거 일괄 처리 데이터 스트리밍 행동 데이터 이벤트를 결합해야 함. 데이터는 데이터 모델과 온디스크 형식을 고려해 효율적으로 유지 관래돼야 함
    - 데이터 레이크 관리 시간(time to data lake management) 지표에 의해 추적됨 
  - 데이터의 구조화, 정리, 보강, 유효성 검사
    - 랭글링 시간(time to wrangle) 지표로 추적함 
  - 데이터 권한 규정 준수 보장
    - 규정 준수(compliance)는 고객 경험을 인사이트로 더 잘 제공하는 것과 고객 동의 내에서 데이터가 사용되도록 보장하는 것 사이의 균형 조정 행위 
    - 규정 준수 시간(time to comply) 지표로 추적함 
  - 구축
    - 인사이트를 추출하는 데 필요한 실제 로직을 작성하는 데 집주앟ㅁ
    - 데이터 액세스 및 분석을 위한 최상의 접근 방식 결정 
      - 구축 단계의 출발점은 인사이트 로직을 작성하고 실행 전략을 결정하는 것 
      - 장기간 실행되는 일괄 처리(batch) 프로세스는 Hive 또는 Spark에 있는 반면 짧은 대화형 쿼리는 Presto 클러스터에서 실행됨 
      - 가상화 시간(time to virtualize)지표로 추적함
    - 변환 로직 작성
      - 대시보드 또는 모델 인사이트의 실제 로직은 ETL, ELT 또는 스트리밍 분석 패턴으로 작성됨. 비즈니스 로직은 변화에 대한 관리가 용이할 뿐만 아니라 실행성과 확장성이 있는 실제 코드로 번역돼야 하며 가용성, 품질, 변경 관리를 위해 모니터링돼야 함 
      - 변환 시간(time to transform) 지표로 추적함
    - 모델 학습
      - 학습은 CPU와 GPU 같은 전문 하드웨어가 조합된 서버로 구성된 팜(farm)에서 운영됨 
      - 학습 시간(time to train) 지표에 의 추적됨 
    - ML 모델 변경 사항의 지속적인 통합 
      - ML 모델 파이프라인은 소스 스키마 변경, 형상 로직, 종속 데이터 세트, 데이터 처리 설정, 모델 알고리즘을 통해 지속적으로 진화함 
      - 통합 시간(time to integrate) 지표에 의해 추적됨 
    - 인사이트 A/B 테스트
      - 버킷 테스트, 분할 테스트 또는 통제된 실험이라고 알려진 A/B 테스트는 데이터 중심 의사 결정을 위한 표준 접근 방식이 되고 있음 
      - A/B 테스트 시간(time to A/B test)
  - 운영화
    - 여정 지도의 운영화 단계에서는 인사이트가 프로덕션에 배포됨
    - 쿼리 검증 및 최적화
      - 어디에나 만능으로 적용되는 쿼리의 최적 조절 값은 없고 데이터 모델, 쿼리 유형, 클러스터 크기, 동시 쿼리 로드 등에 따라 달라짐. 쿼리 최적화는 지속적인 활동. 
      - 최적화 시간(time to optimize) 지표에 의해 추적됨 
    - 파이프라인 오케스트레이션 
      - 오케스트레이션은 파이프라인 서비스 수준 계약(SLA, Service Level Agreement)을 보장하고 기본 리소스의 효율적인 활용을 보장하는 균형 조정 행위 
      - 파이프라인은 데이터 수집, 준비, 변환, 학습, 배포 전반에 걸쳐 서비스를 호출함. 데이터 사용자가 이러한 서비스 전반에서 정확성, 견고성, 적시성을 모니터링하고 디버깅하는 것이 중요함 
      - 파이프라인 오케스트레이션은 멀티테넌트(multitenant)로, 여러 팀과 비즈니스 유즈 케이스를 지원함 
      - 오케스트레이션 시간(time to orchestrate) 지표에 의해 추적됨 
    - ML 모델 배포 
      - 배포 시간(time to deploy) 지표 
    - 인사이트 품질 모니터링
      - 인사이트 품질 확보 시간(time to insight quality) 지표 
    - 지속적인 비용 모니터링
      - 비용 관리는 종래의 종량제 모델과 달리 사용량에 따라 선형적으로 비용이 증가하는 클라우드에서 특히 중요함 
      - 비용 최적화 시간(time to optimize cost) 지표로 추적됨 
- 인사이트 시간 스코어가드 정의
  - 인사이트 시간(time to insight)은 원시 데이터에서 인사이트까지의 전체 여정을 완료하는 데 걸리는 시간을 측정하는 전반적인 지표 
  - 각 마일스톤의 척도를 합치면 전체 인사이트 시간 척도가 됨 
  - 인사이트 시간 스코어가드(scorecard)를 사용함. 전체 여정 지도에서 가장 시간이 많이 걸리는 마일스톤을 찾는 것이 이 활동의 목표 
    - 해석 시간(time to intepret) : 데이터 세트의 메타데이터 세부 정보를 인사이트 개발에 사용하기 전에 해석하는 마일스톤에 연관된 지표 
    - 탐색 시간(time to find) : 검색 관련 데이터 세트와 아티팩트의 마일스톤에 연관된 지표 
    - 피처화 시간(time to featurize) : ML 모델 학습에 필요한 기능 관리 마일스톤과 연관된 지표 
    - 데이터 가용성 확보 시간(time to data availability) : 사일로 간에 데이터를 이동하는 마일스톤과 연관된 지표 
    - 클릭 시간(time to click) : 클릭스트림 데이터 이벤트의 수집, 관리, 분석 마일스톤과 연관된 지표 
    - 데이터 레이크 관리 시간(time to data lake management) : 중앙 저장소에서 데이터를 관리하는 마일스톤과 연관된 지표 
    - 랭글링 시간(time to wrangle) : 데이터 구조화, 정리, 보강, 검증의 마일스톤과 연관된 지표 
    - 규정 준수 시간(time to comply) : 데이터 권한 규정 준수를 보장하는 마일스톤과 연관된 지표 
    - 가상화 시간(time to virtualize) : 데이터 구축, 분석의 접근 방식을 선택하는 마일스톤과 연관된 지표 
    - 변환 시간(time to transform) : 데이터 및 ML 파이프라인에서 변환 로직을 구현하는 마일스톤과 연관된 지표 
    - 학습 시간(time to train) : ML 모델 학습 마일스톤과 관련된 지표 
    - 통합 시간(time to integrate) : ML 파이프라인의 코드, 데이터, 설정의 변경을 통합하는 마일스톤과 연관된 지표 
    - A/B 테스트 시간(time to A/B test) : A/B 테스트의 마일스톤과 연관된 지표 
    - 최적화 시간(time to optimize) : 쿼리 및 빅데이터 프로그램을 최적화하는 마일스톤과 연관된 지표 
    - 오케스트레이션 시간(time to orchestrate) : 프로덕션의 파이프라인 조정 마일스톤과 연관된 지표 
    - 배포 시간(time to deploy) : 프로덕션에 인사이트를 배포하는 마일스톤과 연관된 지표 
    - 인사이트 품질 확보 시간(time to insight quality) : 생성된 인사이트의 정확성을 보장하는 마일스톤과 연관된 지표 
    - 비용 최적화 시간(time to optimize cost) : 비용을 최적화하는 마일스톤과 연관된 지표 
- 셀프서비스 로드맵 실행 
  - 현재 스코어카드를 정의하는 것부터 시작
  - 데이터 사용자에 대한 설문 조사를 기반으로 여정 지도를 가장 많이 늦추는 두 세가지 지표를 식별하고 현재 작업이 구현되는 방식에 대한 기술적 분석을 수행하라. 지표의 중요도는 현재 프로세스, 데이터 사용자 기술, 기술 구성 요소, 데이터 속성, 유스 케이스 요구 사항에 따라 기업마다 다르다는 것을 인식하라
  - 각 지표는 매슬로우의 구현 패턴 계층부터 시작하라. 각 장은 하나의 지표에 대한 자동화 단계가 증가하는 패턴을 다룸 
  - 각 분기마다 지표 우선순위를 전념하고 셀프서비스화에 집중하면서 단계별 기기, 걷기, 달리기 전략을 따르자 

# 셀프서비스 데이터 발견 
## 메타데이터 카탈로그 서비스 
- 빅데이터 시대 이전에는 데이터를 중앙 웨어하우스에 추가하기 전에 먼저 분류함 
- 쓰기스키마(schema-on-write) : 스키마, 계보, 소유자, 비즈니스 분류법 등을 포함한 메타데이터 세부 정보를 먼저 카탈로그화했음. 
- 읽기스키마(schema-on-read) : 오늘날 데이터 레이크의 접근 방식에는 머저 데이터를 집계한 뒤 데이터 사용 시에 데이터 세부 정보를 추론함 
- 데이터 세트 이해하기
  - 데이터 과학자는 새로운 모델을 구축하거나 새로운 측정 기준을 수립하거나 임시 분석을 수행하는 첫 번째 단계로 데이터의 출처, 사용 방법, 지속 방법 등에 대한 세부 정보를 이해해야 함 
  - 메타데이터 카탈로그는 질문에 대한 단일 진실 공급원(SSOT, Single Source Of Truth) 
- 데이터 세트 분석하기
  - 데이터 과학자는 데이터 세트 속성과 쿼리 유형을 기반으로 작업에 적합한 도구를 사용하며 ,하나의 데이터 세트를 Pig, Spark, Presto, Hive 등 여러 쿼리 엔진에서 번갈아가며 사용할 수 있음 
- 지식 확장하기 
  - 팀지식 : 데이터 과학자는 프로젝트를 위해 서로 다른 데이터 세트로 작업하면서 비즈니스 어휘, 데이터 품질 등에 대한 추가 세부 정보를 발견함 
- 해석 시간 최소화
  - 해석 시간은 데이터 과학자가 인사이트를 구축하기 전에 데이터 세트의 세부 정보를 이해하는 데 걸리는 시간을 말함 
  - 기술 메타데이터 추출하기
    - 기술 메타데이터는 데이터 세트의 논리적, 물리적 메타데이터 세부 정보로 구성됨 
    - 물리적 메타데이터는 생성 및 수정 타임스탬프, 물리적 위치 및 형식, 스토리지 계층, 보존 세부 정보와 같은 물리적 레이아웃과 지속성에 관련된 세부 정보를 포함함
    - 논리적 메타데이터에는 데이터 세트 스키마, 데이터 원본 세부 정보, 데이터 세트를 생성하는 프로세스 ,데이터 세트의 소유자 및 사용자가 포함됨 
    - 기술 메타데이터는 여러 소스 간 연관 관계를 고려하지 않고 각각의 데이터 소스를 크롤링 해서 추출함 
    - 메타데이터를 수집하는 데 세 가지 주요 과제 
      - 형식 차이 
      - 스키마 유추
      - 변경 추적 
- 운영 메타데이터 추출하기 
  - 두 가지 주요 버킷 
    - 계보(lineage)
      - 데이터 세트가 어떻게 생성됐는지와 다른 데이터 세트에 대한 종속성을 추적함 
      - 특정 데이터 세트의 계보는 모든 종속 입력 테이블, 파생 테이블, 출력 모델 및 대시보드를 포함함 
      - 최종 출력 도출을 위해 변환 로직을 구현하는 작업이 포함됨 
    - 데이터 프로파일링 통계
      - 가용성 및 품질 통계
      - 데이터 세트의 열 수준 및 설정 수준 특성을 포착함 
      - 완료 시간, 처리된 데이터 ,파이프라인과 관련된 오류를 포착하는 실행 통계도 포함됨 
  - 서로 다른 다양한 유형의 데이터베이스, 스케줄러, 쿼리 엔진, BI(비즈니스 인텔리전스) 툴로 인해 서로 다른 처리 프레임워크, 데이터 플랫폼, 스케줄링 시스템에 걸친 전반적인 데이터 흐름과 계보를 이해하는 것은 어려운 과제. 처리 프레임워크의 다양성을 고려하면서 세부 사항을 짜맞춰 연결하는 것이 이 과제에 해당함. UDF, 외부 매개변수 등의 경우에는 코드로부터 계보를 유추하는 것이 쉽지 않기 때문 
  - 팀 지식 수집하기 
    - 팀 지식의 네 가지 범주 
      - 주석, 문서, 속성 설명 형식의 사용자 정의 메타데이터
      - 비즈니스 직관적 계층 구조(business-intuitive hierarchy)에서 데이터 개체 및 메트릭을 연결하고 구성하기 위한 비즈니스 분류법 또는 어휘
      - 규정 준수, 개인 식별 가능 정보(PII, Personally identifiable information) 데이터 필드, 데이터 암호화 요구 사항 등과 같은 측면의 데이터 세트 상태
      - 가장 인기 있는 테이블, 쿼리, 기타 형태의 ML 증강 메타데이터(ML-augmented metadata) 
- 구현 패턴
  - 메타데이터 카탈로그 서비스에 대한 자동화 수준 
    - 소스 특화 커넥터 패턴 : 서로 다른 데이터 소스에 연결하고 데이터와 연결된 메타데이터 정보를 추출하는 작업을 간소화함
    - 계보 상관 패턴 : 소스 테이블과 대상 테이블을 상관시키는 변환 계보를 추출하는 작업을 자동화함
    - 팀 지식 패턴 : 비즈니스 문맥 수집과 데이터 사용자 간의 지식 공유를 단순화함 
  - 메타데이터 카탈로그 서비스는 금융산업규제당국(finra)의 Herd, 우버의 Databook, 링크드인의 WhereHows와 Data Hub, 넷플릭스의 Metacat, 아파치의 Atlas 프로젝트, AWS Glue 같은 클라우드 서비스가 있음 
  - 소스 특화 커넥터 패턴
    - 소스 특화 커넥터 패턴은 기술 메타데이터 집계를 위해 소스에서 메타데이터를 추출함
    - 데이터 세트는 URN(Uniform Resource Name) 기반 이름을 사용해 식별됨 
    - 두 가지 구성 요소(building block)
      - 커스텀 추출기
        - 소스 특화 커넥터는 메타데이터를 연결하고 지속적으로 가져오는 데 사용됨. 커스텀 추출기를 RDBMS, Hive, 깃허브 등의 데이터스토어에 연결하기 위해 자격 증명을 인증하려면 적절한 액세스 권한이 필요함 
        - 추출기가 소스에 연결되면 데이터 세트의 형식, 스키마, 관련 속성을 결정하는 분류자(classifier)를 구현해 세부 정보를 수집함 
      - 연합 지속성(federated persistence)
        - 메타데이터 세부 정보는 정규화된 방식으로 유지됨 
  - 계보 상관 패턴(lineage correlation pattern) 
    - 데이터 및 작업에 걸친 운영 메타데이터를 연결해 실행 통계와 결합함 
    - 작업 실행 레코드를 계보와 결합함으로써 데이터 신선도, 서비스 수준 협약(SLA, Service Level Agreement), 영향을 받는 특정 테이블의 다운스트림 작업, 사용량에 따른 파이프라인 내의 테이블 순위 등에 관한 질문에 답변할 수 있음 
      - 쿼리 구문 분석
      - 파이프라인 상관관계
      - 실행 통계를 통한 계보 보강 
    - 아파치 Atlas는 Sqoop, Hive, Kafka, Storm 등 여러 Hadoop 에코시스템 구성 요소에 걸쳐 계보를 추출함. Atlas는 Hadoop job ID가 주어지면 job history 노드에서 job conf 쿼리를 수집함. Sqoop 작업에도 비슷한 접근법이 적용돼 있음. 
    - Atlas는 테이블 수준 계보 외에도 다음과 같은 유형의 종속성을 추적해 열 수준 계보를 지원함
      - 단일 종속성 : 출력 열의 값이 입력 열과 동일함 
      - 표현 종속성 : 출력 열은 런타임 시 입력 열의 일부 표현식(Hive SQL 표현식)에 의해 변환됨
      - 스크립트 종속성 : 출력 열은 사용자가 제공한 스크립트에 의해 변환됨 
      - 강점은 종속성을 재구성하는 간섭 없는 방법을 제공함. 단점은 계보가 쿼리 유형을 100% 커버하지 못하고 대략적이라는 것 
  - 팀 지식 패턴
    - 팀 지식의 세 가지 주요 유형
      - 데이터 문서 : 속성 의미, 열거형, 데이터 설명의 세부 정보가 포함됨
      - 비즈니스 분류법 및 태그 : 비즈니스 영역과 주제 영역에 따라 데이터를 분류하는 분려법으로, 비즈니스 내에서 사용되는 개념이 포함됨 
      - 플리거블 검증(pluggable validation) : 테이블 소유자는 테이블에 대한 감사 정보를 메타데이터로 제공할 수 있음. 테이블 작성에 사용할 열 기본값과 검증 규칙을 제공할 수 있음 
