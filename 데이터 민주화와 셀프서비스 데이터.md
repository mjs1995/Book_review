# 서평

# 소개
- 데이터 민주화란 데이터에 쉽게 접근할 수 있도록 기반을 만들어 데이터를 잘 아는 사람부터 잘 모르는 사람까지 누구나 데이터를 쉽게 사용해 인사이트를 도출할 수 있도록 한느 것 
- 셀프서비스 데이터란 데이터 엔지니어나 데이터 과학자가 관여하지 않더라도 마케터, 사업 담당자, 서비스 운영 담당자 등 조직 내 모든 사람이 스스로 데이터에 접근해 인사이트를 추출할 수 있도록 만들어진 데이터 기반을 의미함 
- 원시 데이터에서 인사이트로의 여정 지도 
  - 전통적인 데이터 웨어하우스와 현재의 빅데이터 시대에서 인사이트를 추출하는 방식의 주요 차이점 
  - ||데이터 웨어하우징 시대의 인사이트 추출|빅데이터 시대의 인사이트 추출
    |:---:|:---:|:---:|
    |데이터 형식|정형 데이터|정형,반정형,비정형 데이터
    |데이터 특성|대용량 데이터|데이터의 4V:볼륨,속도,다양성,진시성
    |데이터 카탈로그 작성|데이터를 집계할 때 정의됨|데이터를 읽을 때 정의됨
    |인사이트의 신선함|인사이트는 주로 소급형(비드니스 마지막 주 기준 지표)|인사이트는 소급형,대화형,실시간,예측의 조합
    |쿼리 처리 방식|단일 솔루션으로 결합된쿼리 프로세서와 데이터 스토리지|쿼리 처리와 데이터 스토리지가 분리됨
    |데이터 서비스|단일 솔루션으로 통합|작업에 적합한 도구를 선택하는 데 많은 치환을 허용하는 믹스 앤 매치(mix-and-match)방식
  - 발견
    - 모든 인사이트 도출 프로젝트는 사용 가능한 데이터 세트와 개발 산출물을 발견하고, 인사이트를 발전시키는 데 필요한 추가 데이터를 수집하는 것부터 시작함
    - 데이터 세트의 메타데이터 세부 정보 발견
      - 마일스톤은 데이터가 생성된 위치, 데이터 속성이 생성된 방법 등 메타데이터 속성을 이해하는 것 
      - 메타데이터를 수집하고 상호 연결이 가능하려면 데이터스토어, 수집 프레임워크, 스케줄러, 메타데이터 카탈로그, 규정 준수 프레임워크 등에 접근이 필요함
      - 마일스톤을 완료하는 데 걸리는 시간은 해석시간(time to interpret)을 지표로 추적함 
    - 사용 가능한 데이터 세트 및 아티팩트 검색
      - 마일스톤은 모든 관련 데이터 세트와 아티팩트, 예를 들어 뷰, 파일, 스트림, 이벤트, 지표, 대시보드, ETL, 임시 쿼리를 찾는 것이라고 할 수 있음 
      - 탐색 시간 지표(time to find)로 추적됨 
    - ML 모델에서의 기능 재사용 또는 생성
      - 피처화 시간(time to featurize) 지표로 추적함 
    - 누락된 데이터 집계
      - 비즈니스 대시보드를 만들려면 식별된 데이터 세트(고객 활동 및 결제 청구 기록)를 결합해 리텐션 리스크(retention risk)에 대한 인사이트를 생성
      - 데이터 가용성 확보 시간(time to data availability)
    - 클릭스트림 이벤트 관리
      - 클릭, 뷰와 이전 애플리케이션 페이지, 방문자 기기 유형 등 연관된 맥락까지의 고객 활동을 분석해야 함
      - 클릭스트림 데이터(clickstream data)는 우선 수집, 필터링되고 보강돼야 인사이트 생성에 사용할 수 있음 
      - 클릭 시간(time to click)지표로 추적함 
  - 준비
    - 준비 단계에서는 인사이트 추출을 위해 실제 비즈니스 로직 구축용 데이터를 준비하는데 집중함. 준비는 데이터 집계, 정리, 표준화, 변환, 비정규화를 포함하는 반복적이고 시간 집약적인 작업이며 여러 가지 도구와 프레임워크를 포함함
    - 규제 준수 요건을 충족하기 위해 데이터 거버넌스(data governance)를 보장함 
  - 중앙 저장소 내의 집계 데이터 관리 
    - 비즈니스 대시보드는 과거 일괄 처리 데이터 스트리밍 행동 데이터 이벤트를 결합해야 함. 데이터는 데이터 모델과 온디스크 형식을 고려해 효율적으로 유지 관래돼야 함
    - 데이터 레이크 관리 시간(time to data lake management) 지표에 의해 추적됨 
  - 데이터의 구조화, 정리, 보강, 유효성 검사
    - 랭글링 시간(time to wrangle) 지표로 추적함 
  - 데이터 권한 규정 준수 보장
    - 규정 준수(compliance)는 고객 경험을 인사이트로 더 잘 제공하는 것과 고객 동의 내에서 데이터가 사용되도록 보장하는 것 사이의 균형 조정 행위 
    - 규정 준수 시간(time to comply) 지표로 추적함 
  - 구축
    - 인사이트를 추출하는 데 필요한 실제 로직을 작성하는 데 집주앟ㅁ
    - 데이터 액세스 및 분석을 위한 최상의 접근 방식 결정 
      - 구축 단계의 출발점은 인사이트 로직을 작성하고 실행 전략을 결정하는 것 
      - 장기간 실행되는 일괄 처리(batch) 프로세스는 Hive 또는 Spark에 있는 반면 짧은 대화형 쿼리는 Presto 클러스터에서 실행됨 
      - 가상화 시간(time to virtualize)지표로 추적함
    - 변환 로직 작성
      - 대시보드 또는 모델 인사이트의 실제 로직은 ETL, ELT 또는 스트리밍 분석 패턴으로 작성됨. 비즈니스 로직은 변화에 대한 관리가 용이할 뿐만 아니라 실행성과 확장성이 있는 실제 코드로 번역돼야 하며 가용성, 품질, 변경 관리를 위해 모니터링돼야 함 
      - 변환 시간(time to transform) 지표로 추적함
    - 모델 학습
      - 학습은 CPU와 GPU 같은 전문 하드웨어가 조합된 서버로 구성된 팜(farm)에서 운영됨 
      - 학습 시간(time to train) 지표에 의 추적됨 
    - ML 모델 변경 사항의 지속적인 통합 
      - ML 모델 파이프라인은 소스 스키마 변경, 형상 로직, 종속 데이터 세트, 데이터 처리 설정, 모델 알고리즘을 통해 지속적으로 진화함 
      - 통합 시간(time to integrate) 지표에 의해 추적됨 
    - 인사이트 A/B 테스트
      - 버킷 테스트, 분할 테스트 또는 통제된 실험이라고 알려진 A/B 테스트는 데이터 중심 의사 결정을 위한 표준 접근 방식이 되고 있음 
      - A/B 테스트 시간(time to A/B test)
  - 운영화
    - 여정 지도의 운영화 단계에서는 인사이트가 프로덕션에 배포됨
    - 쿼리 검증 및 최적화
      - 어디에나 만능으로 적용되는 쿼리의 최적 조절 값은 없고 데이터 모델, 쿼리 유형, 클러스터 크기, 동시 쿼리 로드 등에 따라 달라짐. 쿼리 최적화는 지속적인 활동. 
      - 최적화 시간(time to optimize) 지표에 의해 추적됨 
    - 파이프라인 오케스트레이션 
      - 오케스트레이션은 파이프라인 서비스 수준 계약(SLA, Service Level Agreement)을 보장하고 기본 리소스의 효율적인 활용을 보장하는 균형 조정 행위 
      - 파이프라인은 데이터 수집, 준비, 변환, 학습, 배포 전반에 걸쳐 서비스를 호출함. 데이터 사용자가 이러한 서비스 전반에서 정확성, 견고성, 적시성을 모니터링하고 디버깅하는 것이 중요함 
      - 파이프라인 오케스트레이션은 멀티테넌트(multitenant)로, 여러 팀과 비즈니스 유즈 케이스를 지원함 
      - 오케스트레이션 시간(time to orchestrate) 지표에 의해 추적됨 
    - ML 모델 배포 
      - 배포 시간(time to deploy) 지표 
    - 인사이트 품질 모니터링
      - 인사이트 품질 확보 시간(time to insight quality) 지표 
    - 지속적인 비용 모니터링
      - 비용 관리는 종래의 종량제 모델과 달리 사용량에 따라 선형적으로 비용이 증가하는 클라우드에서 특히 중요함 
      - 비용 최적화 시간(time to optimize cost) 지표로 추적됨 
- 인사이트 시간 스코어가드 정의
  - 인사이트 시간(time to insight)은 원시 데이터에서 인사이트까지의 전체 여정을 완료하는 데 걸리는 시간을 측정하는 전반적인 지표 
  - 각 마일스톤의 척도를 합치면 전체 인사이트 시간 척도가 됨 
  - 인사이트 시간 스코어가드(scorecard)를 사용함. 전체 여정 지도에서 가장 시간이 많이 걸리는 마일스톤을 찾는 것이 이 활동의 목표 
    - 해석 시간(time to intepret) : 데이터 세트의 메타데이터 세부 정보를 인사이트 개발에 사용하기 전에 해석하는 마일스톤에 연관된 지표 
    - 탐색 시간(time to find) : 검색 관련 데이터 세트와 아티팩트의 마일스톤에 연관된 지표 
    - 피처화 시간(time to featurize) : ML 모델 학습에 필요한 기능 관리 마일스톤과 연관된 지표 
    - 데이터 가용성 확보 시간(time to data availability) : 사일로 간에 데이터를 이동하는 마일스톤과 연관된 지표 
    - 클릭 시간(time to click) : 클릭스트림 데이터 이벤트의 수집, 관리, 분석 마일스톤과 연관된 지표 
    - 데이터 레이크 관리 시간(time to data lake management) : 중앙 저장소에서 데이터를 관리하는 마일스톤과 연관된 지표 
    - 랭글링 시간(time to wrangle) : 데이터 구조화, 정리, 보강, 검증의 마일스톤과 연관된 지표 
    - 규정 준수 시간(time to comply) : 데이터 권한 규정 준수를 보장하는 마일스톤과 연관된 지표 
    - 가상화 시간(time to virtualize) : 데이터 구축, 분석의 접근 방식을 선택하는 마일스톤과 연관된 지표 
    - 변환 시간(time to transform) : 데이터 및 ML 파이프라인에서 변환 로직을 구현하는 마일스톤과 연관된 지표 
    - 학습 시간(time to train) : ML 모델 학습 마일스톤과 관련된 지표 
    - 통합 시간(time to integrate) : ML 파이프라인의 코드, 데이터, 설정의 변경을 통합하는 마일스톤과 연관된 지표 
    - A/B 테스트 시간(time to A/B test) : A/B 테스트의 마일스톤과 연관된 지표 
    - 최적화 시간(time to optimize) : 쿼리 및 빅데이터 프로그램을 최적화하는 마일스톤과 연관된 지표 
    - 오케스트레이션 시간(time to orchestrate) : 프로덕션의 파이프라인 조정 마일스톤과 연관된 지표 
    - 배포 시간(time to deploy) : 프로덕션에 인사이트를 배포하는 마일스톤과 연관된 지표 
    - 인사이트 품질 확보 시간(time to insight quality) : 생성된 인사이트의 정확성을 보장하는 마일스톤과 연관된 지표 
    - 비용 최적화 시간(time to optimize cost) : 비용을 최적화하는 마일스톤과 연관된 지표 
- 셀프서비스 로드맵 실행 
  - 현재 스코어카드를 정의하는 것부터 시작
  - 데이터 사용자에 대한 설문 조사를 기반으로 여정 지도를 가장 많이 늦추는 두 세가지 지표를 식별하고 현재 작업이 구현되는 방식에 대한 기술적 분석을 수행하라. 지표의 중요도는 현재 프로세스, 데이터 사용자 기술, 기술 구성 요소, 데이터 속성, 유스 케이스 요구 사항에 따라 기업마다 다르다는 것을 인식하라
  - 각 지표는 매슬로우의 구현 패턴 계층부터 시작하라. 각 장은 하나의 지표에 대한 자동화 단계가 증가하는 패턴을 다룸 
  - 각 분기마다 지표 우선순위를 전념하고 셀프서비스화에 집중하면서 단계별 기기, 걷기, 달리기 전략을 따르자 

# 셀프서비스 데이터 발견 
## 메타데이터 카탈로그 서비스 
- 빅데이터 시대 이전에는 데이터를 중앙 웨어하우스에 추가하기 전에 먼저 분류함 
- 쓰기스키마(schema-on-write) : 스키마, 계보, 소유자, 비즈니스 분류법 등을 포함한 메타데이터 세부 정보를 먼저 카탈로그화했음. 
- 읽기스키마(schema-on-read) : 오늘날 데이터 레이크의 접근 방식에는 머저 데이터를 집계한 뒤 데이터 사용 시에 데이터 세부 정보를 추론함 
- 데이터 세트 이해하기
  - 데이터 과학자는 새로운 모델을 구축하거나 새로운 측정 기준을 수립하거나 임시 분석을 수행하는 첫 번째 단계로 데이터의 출처, 사용 방법, 지속 방법 등에 대한 세부 정보를 이해해야 함 
  - 메타데이터 카탈로그는 질문에 대한 단일 진실 공급원(SSOT, Single Source Of Truth) 
- 데이터 세트 분석하기
  - 데이터 과학자는 데이터 세트 속성과 쿼리 유형을 기반으로 작업에 적합한 도구를 사용하며 ,하나의 데이터 세트를 Pig, Spark, Presto, Hive 등 여러 쿼리 엔진에서 번갈아가며 사용할 수 있음 
- 지식 확장하기 
  - 팀지식 : 데이터 과학자는 프로젝트를 위해 서로 다른 데이터 세트로 작업하면서 비즈니스 어휘, 데이터 품질 등에 대한 추가 세부 정보를 발견함 
- 해석 시간 최소화
  - 해석 시간은 데이터 과학자가 인사이트를 구축하기 전에 데이터 세트의 세부 정보를 이해하는 데 걸리는 시간을 말함 
  - 기술 메타데이터 추출하기
    - 기술 메타데이터는 데이터 세트의 논리적, 물리적 메타데이터 세부 정보로 구성됨 
    - 물리적 메타데이터는 생성 및 수정 타임스탬프, 물리적 위치 및 형식, 스토리지 계층, 보존 세부 정보와 같은 물리적 레이아웃과 지속성에 관련된 세부 정보를 포함함
    - 논리적 메타데이터에는 데이터 세트 스키마, 데이터 원본 세부 정보, 데이터 세트를 생성하는 프로세스 ,데이터 세트의 소유자 및 사용자가 포함됨 
    - 기술 메타데이터는 여러 소스 간 연관 관계를 고려하지 않고 각각의 데이터 소스를 크롤링 해서 추출함 
    - 메타데이터를 수집하는 데 세 가지 주요 과제 
      - 형식 차이 
      - 스키마 유추
      - 변경 추적 
- 운영 메타데이터 추출하기 
  - 두 가지 주요 버킷 
    - 계보(lineage)
      - 데이터 세트가 어떻게 생성됐는지와 다른 데이터 세트에 대한 종속성을 추적함 
      - 특정 데이터 세트의 계보는 모든 종속 입력 테이블, 파생 테이블, 출력 모델 및 대시보드를 포함함 
      - 최종 출력 도출을 위해 변환 로직을 구현하는 작업이 포함됨 
    - 데이터 프로파일링 통계
      - 가용성 및 품질 통계
      - 데이터 세트의 열 수준 및 설정 수준 특성을 포착함 
      - 완료 시간, 처리된 데이터 ,파이프라인과 관련된 오류를 포착하는 실행 통계도 포함됨 
  - 서로 다른 다양한 유형의 데이터베이스, 스케줄러, 쿼리 엔진, BI(비즈니스 인텔리전스) 툴로 인해 서로 다른 처리 프레임워크, 데이터 플랫폼, 스케줄링 시스템에 걸친 전반적인 데이터 흐름과 계보를 이해하는 것은 어려운 과제. 처리 프레임워크의 다양성을 고려하면서 세부 사항을 짜맞춰 연결하는 것이 이 과제에 해당함. UDF, 외부 매개변수 등의 경우에는 코드로부터 계보를 유추하는 것이 쉽지 않기 때문 
  - 팀 지식 수집하기 
    - 팀 지식의 네 가지 범주 
      - 주석, 문서, 속성 설명 형식의 사용자 정의 메타데이터
      - 비즈니스 직관적 계층 구조(business-intuitive hierarchy)에서 데이터 개체 및 메트릭을 연결하고 구성하기 위한 비즈니스 분류법 또는 어휘
      - 규정 준수, 개인 식별 가능 정보(PII, Personally identifiable information) 데이터 필드, 데이터 암호화 요구 사항 등과 같은 측면의 데이터 세트 상태
      - 가장 인기 있는 테이블, 쿼리, 기타 형태의 ML 증강 메타데이터(ML-augmented metadata) 
- 구현 패턴
  - 메타데이터 카탈로그 서비스에 대한 자동화 수준 
    - 소스 특화 커넥터 패턴 : 서로 다른 데이터 소스에 연결하고 데이터와 연결된 메타데이터 정보를 추출하는 작업을 간소화함
    - 계보 상관 패턴 : 소스 테이블과 대상 테이블을 상관시키는 변환 계보를 추출하는 작업을 자동화함
    - 팀 지식 패턴 : 비즈니스 문맥 수집과 데이터 사용자 간의 지식 공유를 단순화함 
  - 메타데이터 카탈로그 서비스는 금융산업규제당국(finra)의 Herd, 우버의 Databook, 링크드인의 WhereHows와 Data Hub, 넷플릭스의 Metacat, 아파치의 Atlas 프로젝트, AWS Glue 같은 클라우드 서비스가 있음 
  - 소스 특화 커넥터 패턴
    - 소스 특화 커넥터 패턴은 기술 메타데이터 집계를 위해 소스에서 메타데이터를 추출함
    - 데이터 세트는 URN(Uniform Resource Name) 기반 이름을 사용해 식별됨 
    - 두 가지 구성 요소(building block)
      - 커스텀 추출기
        - 소스 특화 커넥터는 메타데이터를 연결하고 지속적으로 가져오는 데 사용됨. 커스텀 추출기를 RDBMS, Hive, 깃허브 등의 데이터스토어에 연결하기 위해 자격 증명을 인증하려면 적절한 액세스 권한이 필요함 
        - 추출기가 소스에 연결되면 데이터 세트의 형식, 스키마, 관련 속성을 결정하는 분류자(classifier)를 구현해 세부 정보를 수집함 
      - 연합 지속성(federated persistence)
        - 메타데이터 세부 정보는 정규화된 방식으로 유지됨 
  - 계보 상관 패턴(lineage correlation pattern) 
    - 데이터 및 작업에 걸친 운영 메타데이터를 연결해 실행 통계와 결합함 
    - 작업 실행 레코드를 계보와 결합함으로써 데이터 신선도, 서비스 수준 협약(SLA, Service Level Agreement), 영향을 받는 특정 테이블의 다운스트림 작업, 사용량에 따른 파이프라인 내의 테이블 순위 등에 관한 질문에 답변할 수 있음 
      - 쿼리 구문 분석
      - 파이프라인 상관관계
      - 실행 통계를 통한 계보 보강 
    - 아파치 Atlas는 Sqoop, Hive, Kafka, Storm 등 여러 Hadoop 에코시스템 구성 요소에 걸쳐 계보를 추출함. Atlas는 Hadoop job ID가 주어지면 job history 노드에서 job conf 쿼리를 수집함. Sqoop 작업에도 비슷한 접근법이 적용돼 있음. 
    - Atlas는 테이블 수준 계보 외에도 다음과 같은 유형의 종속성을 추적해 열 수준 계보를 지원함
      - 단일 종속성 : 출력 열의 값이 입력 열과 동일함 
      - 표현 종속성 : 출력 열은 런타임 시 입력 열의 일부 표현식(Hive SQL 표현식)에 의해 변환됨
      - 스크립트 종속성 : 출력 열은 사용자가 제공한 스크립트에 의해 변환됨 
      - 강점은 종속성을 재구성하는 간섭 없는 방법을 제공함. 단점은 계보가 쿼리 유형을 100% 커버하지 못하고 대략적이라는 것 
  - 팀 지식 패턴
    - 팀 지식의 세 가지 주요 유형
      - 데이터 문서 : 속성 의미, 열거형, 데이터 설명의 세부 정보가 포함됨
      - 비즈니스 분류법 및 태그 : 비즈니스 영역과 주제 영역에 따라 데이터를 분류하는 분려법으로, 비즈니스 내에서 사용되는 개념이 포함됨 
      - 플리거블 검증(pluggable validation) : 테이블 소유자는 테이블에 대한 감사 정보를 메타데이터로 제공할 수 있음. 테이블 작성에 사용할 열 기본값과 검증 규칙을 제공할 수 있음 

## 검색서비스
- 인사이트를 개발하는 반복적인 프로세스 중 연관 데이터 세트(테이블, 뷰, 스키마, 파일, 스트림, 이벤트)와 아티팩트(지표, 대시보드, 모델, ETL, 임시 쿼리)를 찾는 것에 초점을 맞춤 
- 검색 서비스를 통해 데이터 사용자는 키워드, 와일드카드 검색, 비즈니스 용어 등을 사용해 원하는 것을 표현함. 
- 소스 발견, 데이터 세트 및 아티팩트 인덱싱, 결과 순위 지정, 액세스 거버넌스(access governance) 보장, 지속적인 변경 관리 등의 어려운 업무를 보이지 않는 곳에서 수행함 
- 데이터 세트 및 아티팩트 인덱싱
  - 인덱싱의 두 가지 작업
    - 데이터 세트와 아티팩트의 소스 찾기
    - 해당 소스를 조사해 스키마와 메타데이터 속성 같은 세부 정보 수집 
  - 접근 제어하기 
    - 데이터 세트 및 아티팩트 소스에 안전하게 연결
    - 검색 결과에 대한 접근 제한 
- 검색 서비스를 구축하는 데는 세 가지 주요 모듈 
  - 인덱서 모듈 
    - 사용 가능한 데이터 세트와 아티팩트를 발견하고, 스키마 및 메타데이터 속성을 추출하고, 카탈로그에 추가함. 이 모듈은 변경 내용을 추적하고 세부 정보를 지속적으로 업데이트함 
  - 순위 모듈 : 관련성과 인기도의 조합에 따라 검색 결과의 순위를 매기는 역할을 함
  - 액세스 모듈 : 데이터 사용자에게 표시되는 검색 결과가 접근 제어 정책을 준수하도록 함 
- 요구 사항 순위 매기기 
  - 데이터 세트와 아티팩트에 관련된 메타데이터의 범주
  - |메타데이터 범주|속성 예|
    |:---:|:---:|
    |기본|크기,형식,최종 수정, 가명, 접근 제어 목록
    |콘텐츠 기반|스키마,기록 수,데이터 핑거프린트,키 필드
    |계보|읽기 작업,쓰기 작업, 다운스트림 데이터 세트, 업스트림 데이터 세트
    |사용자 정의|태그, 카테고리
    |사람|소유자,팀 접근, 팀 업데이트
    |시간|변경 히스토리 
  - 접근 제어 요구 사항
    - 사용자별 정책은 역할 기반 접근 제어(RBAC, Role-Based Access Control), 속성별 정책은 속성 기반 접근 제어(ABAC, Attribute-Based Access Control), 사용자 그룹에 대한 가시성 제한은 RBAC 정책이며 데이터 태그 또는 개인 식별 정보(PII)에 대해 정의된 정책은 ABAC 정책 
    - 다른 특수 처리 요구 사항이 필요할 수 있음 
      - 행 또는 열 값의 마스킹 
      - 데이터 세트와 아티팩트를 특정 타임스탬프까지 볼 수 없도록 하는 시간 변동 정책(분기별 결과가 공식적으로 발표된 날짜까지 표를 볼 수 없음) 
  - 비기능 요구 사항
    - 비기능 요구 사항(NFR,Nonfunctional Requirement)
      - 검색 응답 시간 : 검색 서비스가 초 단위로 검색 쿼리에 응답하도록 하는 것이 중요함 
      - 대규모 인덱 지원을 위한 확장 : 기업이 성장함에 따라 수천 개의 데이터 세트와 아티팩트를 지원하도록 검색 서비스를 확장하는 것이 중요함 
      - 새로운 소스에 대한 손쉬운 온보딩 : 데이터 소스 소유자가 검색 서비스에 소스를 추가할 때의 UX를 단순화해야 함 
      - 자동 모니터링과 알림 : 서비스 상태는 모니터링하기 쉬워야 함. 프로더션 중 문제가 발생하면 자동 경고가 생성돼야 함 
- 구현 패턴
  - 기존 작업 지도에 따라 검색 서비스에 대한 자동화 수준은 세 가지 
    - 푸시 풀 인덱서 패턴 : 사용 가능한 데이터 세트와 아티팩트를 발견하고 지속적으로 업데이트함 
    - 하이브리드 검색 순위 패턴 : 데이터 사용자가 데이터 프로젝트의 요구 사항에 맞는 가장 관련성 높은 데이터 세트와 아티팩트를 찾을 수 있도록 결과의 순위를 매김 
    - 카탈로그 접근 제어 패턴 : 데이터 사용자 및 기타 특성에 따라 검색 서비스에 표시되는 데이터 세트와 아티팩트에 대한 접근을 제어함 
  - 푸시 풀 인덱서 패턴
    - 기업의 사일로 전체에서 사용 가능한 데이터 세트와 아티팩트를 발견하고 업데이트함 
    - 데이터 세트를 인덱싱할 수 있는 넷플릭스의 오픈소스 Metacat 카탈로그
      - Metacat은 데이터 세트 세부 정보를 추출하기 위해서뿐 아니라 데이터 소스가 Kafka와 같은 이벤트 버스에 업데이트를 게시하는 푸시 알림 모델에서도 풀 모델을 사용함. 데이터 소스는 명시적 REST API를 호출해 변경 이벤트를 게시할 수도 있음. Metacat에서는 변경 사항이 아마존 SNS에도 게시됨. SNS에 이벤트를 게시하면 데이터 플랫폼의 다른 시스템이 이러한 메타데이터 또는 데이터 변경에 따라 반응을 할 수 있음 
      - 강점 
        - 인덱스 업데이트가 시기적절함. 새 소스는 주기적으로 크롤링되고 변경 이벤트 처리를 위해 이벤트 버스에 푸시됨 
        - 다양한 범주의 메타데이터 속성을 추출하고 업데이트하기 위한 확장 가능한 패턴
        - 푸시 및 풀 방식의 조합을 고려할 때 많은 소스를 지원하도록 확장 가능함 
      - 약점
        - 다양한 소스 유형에 대한 구성과 배포가 어려울 수 있음 
        - 풀을 통해 세부 정보에 접근하려면 소스 권한이 필요한데, 규제된 소스에는 우려 사항이 될 수 있음 
  - 하이브리드 검색 순위 패턴
    - 문자열 입력이 주어지면 순위 패턴이 데이터 세트와 아티팩트의 목록을 생성함. 이 목록은 테이블 이름, 비즈니스 어휘 개념, 분류 태그 등의 문자열로 구성될 수 있음 
    - 이 패턴의 성공 기준은 가장 관련성 높은 결과가 목록의 상위 다섯 건에 들어있는지 여부 
    - 하이브리드 검색 순위 패턴의 예로는 아문센(Amundsen) 오픈소스 프로젝트 
      - 아문센은 데이터 세트와 아티팩트를 인덱싱함. 입력 구문 분석에서는 정확한 매칭 개선을 위해 자동 완성(type-ahead) 기능을 구현함. 입력 문자열은 와일드카드와 키워드, 범주, 비즈니스 어휘 등을 지원함 
      - 아문센은 얇은 Elasticsearch 프록시 계층을 구현해 카탈로그와 상호 작용함으로써 퍼지 검색을 가능하게 함. 
      - 메타데이터는 Neo4j에서 유지됨. 인덱스 구축을 위해서는 데이터 수집 라이브러리를 사용함 
  - 카탈로그 제어 패턴
    - 메타데이터 카탈로그에 접근 제어를 시행하고 세분화된 권한 부여 및 접근 제어를 위한 중앙 집중식 접근 방식을 제공함 
    - 카탈로그 접근 제어 패턴의 세 단계 
      - 분류
      - 정의
        - 정책 정의는 크게 두 가지의 광범위한 버킷으로 나뉨. 
        - 역할 기반 접근 제어 : RBAC,Role-Based Access Control, 사용자를 기반으로 정책이 정의됨 
        - 속성 기반 접근 제어 : ABAC,Attriubte-Based Access Control, 사용자 정의 태그, IP 주소를 기반으로 하는 지리적 태그, 시간 기반 태그 등과 같은 속성을 기반으로 정책이 정의됨 
      - 시행 
        - 검색 결과에서 접근 제어 정책을 시행하는 세 가지 방법
        - 모든 사용자를 위한 기본 메타데이터 : 검색 쿼리에 대한 응답 결과로 기본 메타데이터(이름,설명,소유자,업데이트 날짜, 사용자 정의 태그 등)를 모든 사용자엑 접근 권한 여부에 관계없이 표시함 
        - 선택적 고급 메타데이터 : 선별된 사용자가 접근 제어 정책에 따라 열 통계 및 데이터 미리 보기와 같은 고급 메타데이터를 가져옴 
        - 열 및 행 마스킹 ; 접근 제어에 따라 동일한 데이터 세트의 열 개수는 물론 데이터 미리 보기의 행이 달라짐 
    - 세분화된 권한 부여와 접근 제어를 위해 널리 사용되는 오픈소스 솔루션의 예로 아파치 Ranger 
      - Atlas 카탈로그와 모든 Hadoop 에코시스템에 대한 보안 정책 구현을 위한 중앙 집중식 프레임워크를 제공함 
      - 개별 사용자, 그룹, 접근 유형, 사용자 정의 태그, IP 주소와 같은 동적 태그 등을 기반으로 한 RBAC 및 ABAC 정책을 지원함 
    - 강점
      - 카탈로그 수준의 중장 집중식 접근 제어 정책을 통해 쉽게 관리할 수 있음 
      - 다양한 사용자 및 유스 케이스에 따라 조정 가능한 접근 제어 기능을 제공함 
    - 약점
      - 카탈로그 접근 제어 정책이 데이터 원본 정책과 동기화되지 않을 수 있음

# 피처 저장소 서비스 
- 요구 사항 정의
  - 피처 연산
    - 피처 비닝(feature binning) : 연속 피처를 개별 피처로 변환
    - 피처 해싱(feature hashing) : 원-핫 인코딩된 피처의 메모리 풋프린트(memory footprint)를 줄이기 위함 
    - Spark는 대규모 데이터 세트로 작업하는 사용자 간의 데이터 랭글링에 선호됨. 작은 데이터 세트로 작업하는 사용자는 Numpy, pandas와 같은 프레임워크를 선호함. 피처 엔지니어링 작업은 노트북(notebook), 파이썬 파일 또는 .jar 파일을 사용해 빌드되고 samza, Spark, Flink, Beam과 같은 연산 프레임워크에서 실행됨 
- 구현 패턴
  - 하이브리드 피처 연산 패턴 : 피처 연산을 위한 일괄 처리 및 스트림 처리를 결합하는 패턴을 정의함 
  - 피처 레지스트리 패턴 : 학습자 추론을 위한 기능을 제공하는 패턴을 정의함 
- 하이브리드 피처 연산 패턴 
  - 세 가지 구성 요소 
    - 일괄 처리 연산 파이프라인 
      - 전통적인 일괄 처리 작업에서는 몇 시간마다 또는 매일 ETL 작업으로 실행돼 과거 피처 값을 계산함 
    - 스트리밍 연산 파이프라인
      - 실시간 메시지 버스의 데이터 이벤트에 대해 수행되는 스트리밍 분석을 통해 낮은 지연 시간으로 피처 값을 계산함 
    - 피처 사양 
      - 일관성을 보장하기 위해 데이터 사용자는 새로운 피처에 대한 파이프라인을 생성하는 대신 도메인 특화 언어(DSL, Domain-Specific Language)를 사용해 피처 사양을 정의함 
  - 우버의 Michelangelo
    - 아파치 Spark와 Samza의 조합을 구현함. Spark는 일괄 처리 피처를 연산하는 데 사용되며 결과는 Hive에서 유지됨. 일괄 처리 작업은 피처 그룹을 연산하고, 이를 컬럼당 피처로서 단일 Hive 테이블에 씀 
    - 스트리밍 파이프라인의 경우 Kafka 토픽은 Samza 스트리밍 작업과 함께 소비돼 Cassandra에서 키-값 형식으로 유지되는 준실시간 피처 값을 생성함 
    - 히스토리 피처의 대량 사전 연산 및 과거 피처의 로딩이 정기적으로 Hive에서 Cassandra로 이뤄짐 
  - 강점 
    - 일괄 처리 및 스트리밍 타임 윈도우에 걸쳐 최적의 피처 연산 성능을 제공함 
    - 피처를 정의하는 DSL은 학습과 추론을 위한 파이프라인 구현 불일치에 관련된 모순을 방지함 
  - 약점 
    - 프로덕션 환경에서 구현되고 관리하는 것은 쉽지 않음. 데이터 플랫폼이 상당히 성숙해야 함 
- 피처 레지스트리 패턴 
  - 피처를 쉽게 검색하고 관리할 수 있음 
  - Hopsworks 피처 저장소 
    - 사용자가 피처 저장소를 SQL 또는 프로그래밍 방식으로 쿼리하면 피처 저장소는 피처를 데이터프레임으로 변환함 
    - Hopworks 피처 저장소의 피처 그룹 및 학습 데이터 세트는 Spark/Numpy/pandas 작업에 연결돼 있어 필요할 때 피처를 재현하고 재연산할 수 있음 
  - 강점 
    - 학습 데이터 세트와 피처 값의 성능 기준에 맞는 성능을 제공함 
    - 데이터 사용자의 피처 분석 시간을 단축함 
  - 약점 
    - 수백 개의 모델을 제공하는 동안 잠재적인 성능 병목 현상이 나타남
    - 피처가 계속 증가해 피처 분석을 위한 확장을 지속함 

# 데이터 이동 서비스 
- 원시 데이터를 전문 쿼리 엔진으로 이동
  - 점점 더 많은 쿼리 처리 엔진이 다양한 유형의 쿼리 및 데이터 워크로드에 최적화되고 있음 
  - 시계열 데이터 세트의 데이터 분할(slice-and-dice) 분석의 경우 데이터는 Druid와 Pinot 같은 전문 분석 솔루션으로 복사됨 
- 데이터 품질 검증 
  - 실제 배포 환경에서는 소스 오류, 어댑터 실패, 집계 문제 등과 같은 다양한 이유로 품질 오류가 발생할 수 있음
  - 데이터 이동 중 데이터 패리티(data parity) 모니터링은 데이터 품질 오류를 발견하지 못하거나 비즈니스 지표 및 ML 모델의 정확성에 영향을 미치지 않도록 하기 위해 반드시 필요함 
- 요구 사항 정의
  - 데이터 이동 서비스의 네 가지 주요 모듈 
    - 수집 모듈 : 소스에서 대상 데이터스토어로 데이터를 한 번 또는 지속적으로 복사하는 것을 담당함 
    - 변환 모듈 : 소스에서 대상으로 복사되는 데이터의 변환을 담당함 
    - 규정 준수 모듈 : 분석 목적으로 데이터를 이동함으로써 규정 준수 요구 사항을 충족함 
    - 검증 모듈 : 소스와 대상 간의 데이터 패리티를 보장함 
수집 요구 사항 
  - 요구 사항 수집의 일부로 수집할 데이터스토어 범주
    - |데이터스토어 범주|인기 있는 예시|
      |:---:|:---:|
      |트랜잭션 데이터베이스|Oracle, SQL Server, MySQL|
      |NoSQL 데이터스토어|Cassandra, Neo4j, MongoDB|
      |파일 시스템|Hadoop FileSystem, NFS appliance, Samba|
      |데이터 웨어하우스|Vertica, Oracle Exalogic, AWS Redshift|
      |오브젝트 저장소|AWS S3|
      |메시징 프레임워크|Kafka, JMS|
      |이벤트 로그|Syslog,NGNIX logs|
  - 데이터 규모
    - 데이터 엔지니어가 이해해야 하는 구모의 주요 측면
      - 행의 개수로 볼 때 테이블의 크기가 얼마나 큰가(즉, 수천 개의 행이 있는지, 수십억 개의 행이 있는지)?
      - TB 단위로 표의 대략적인 크기는 얼마인가?
      - 지속적으로 복사해야 하는 테이블의 수는 얼마인가?
    - 삽입, 업데이트, 삭제 횟수와 관련해 테이블이 빠르게 변경되는지 여부를 추정하는 변화율 
- 규정 준수 요구 사항 
  - 구정 준수에 대한 여러 측면을 고려해야 함
  - 매슬로우의 욕구 계층 구조(역피라미드) 
    - 삼각형의 맨 아래에는 규정 준스를 위한 3A인 인증(authentication), 접근 제어(access control), 감사 추적(audit tracking)이 있음 
    - 그 위에 암호화 및 마스킹과 관련해 개인 식별 정보(PII)를 처리할 때 고려해야할 사항이 있음 
    - 다음은 SOX,PCI 등과 같은 규정 주수 관련 요구 사항 
    - 맨 위에는 CCPA, GDPR 등의 법률에 따른 데이터 권한 준수가 있음 
- 구현 패턴
  - 데이터 이동 서비스는 수집, 변환, 규정 준수, 검증 모듈이라는 네 가지 주요 작업을 수행함 
  - 데이터 이동 서비스의 다양한 자동화 수준
    - 일괄 수집 패턴
      - 일괄 수집(batch ingestion)은 빅데이터 진화 초기에 널리 사용됐던 전통적인 패턴이며, 일회성 및 예약된 데이터 이동 모두에 적용됨.
      - 일괄 처리(batch)라는 용어는 소스에 대한 업데이트가 함께 그룹화된 다음 주기적으로 대상으로 이동됨을 의미함 
      - 일괄 수집은 일반적으로 실시간 업데이트 요구가 없는 대규모 소스의 데이터 이동에 사용됨. 6~24시간 단위로 예약됨 
      - 일괄 수집 패턴에는(MapReduce의)지도 단계를 이용해 소스 데이터 개체를 분할함으로써 대상 데이터 개체로 병렬 복사하는 것이 포함됨 
      - 일괄 수집 패턴의 세 단계
        - 파티션 단계 : 복사할 소스 테이블은 데이터 이동을 병렬화하기 위해 더 작은 청크(chunk)로 논리적으로 분할됨 
        - 지도 단계 : 각 청크는 매퍼(mapper, MapReduce의 용어)에 할당됨. 매퍼는 쿼리를 실행해 소스 테이블에서 데이터를 읽고 대상에 복사함. 더 많은 매퍼를 사용하면 동시 데이터 전송 작업 수가 많아져 작업 완료 속도가 빨라질 수 있음 .데이터베이스의 로드(load)도 증가해 잠재적으로 소스가 포화될 수 있음. 증분 테이블 복사의 경우, 매퍼는 마지막 업데이트 이후 소스 테이블에 대한 삽입, 업데이트, 삭제를 처리함 
        - 축소 단계 : 매퍼의 출력은 스테이징 파일로 저장되고 리듀서에 의해 대상 데이터스토어의 단일 구체화 뷰로 결합됨. 리듀서는 변환 기능을 구현할 수도 있음 
      - 아파치 Sqoop
        - 일반적으로 관계형 데이터베이스와 파일 시스템 간에 HDFS와 아파치 Hive로 대량의 데이터를 이동할 때 사용됨. 클라이언트-서버모델로 구현됨.
        - 클라이언트는 소스 및 대상 데이터스토어에 설치되고 데이터 이동은 클라이언트와 대응하는 Sqoop 서버에 의해 MapReduce 작업으로 오케스트레이션됨 
        - 데이터스토어에 연결하기 위한 기술 특화 어댑터는 클라이언트에 설치됨(최신 Sqoop2 버전에서는 드라이버가 서버에 설치됨). 데이터 이동은 소스 클라이언트의 매퍼가 소스에서 데이터를 전송하는 동안 대상 클라이언트의 리듀서가 데이터를 복사 및 변환하는 MapReduce 작업 
      - 강점
        - 광범위한 소스 및 대상 데이터스토어에 적용할 수 있는 전통적인 데이터 이동 패턴. 데이터 소스 소유자가 소스 데이터스토어를 온보딩, 관리, 유지 관리 하는 데 최소한의 노력만 필요함 
        - 매일 수천 개의 예약된 데이터 이동으로 확장할 수 있음. MapReduce를 활용해 장애 복구를 구현함
        - 기본적으로 복사 후 데이터 유효성 검사를 지원함 
      - 약점
        - 준실시간 데이터 새로 고침을 지원하지 않음 
        - 소스 데이터스토어의 성능에 잠재적으로 영향을 미칠 수 있음. 제한 규정 준수 상태의 소스 데이터스토어를 연결하는 데 사용되는 JDBC 연결과 관련된 잠재적인 규정 준수 문제가 있음 
        - 영구 삭제(hard delete)가 수반되는 증분 테이블의 새로 고침 및 데이터 변환 기능에 대한 지원이 제한적 
    - 지속적 변화 수집 패턴 / 변경 데이터 캡처 수집 패턴
      - 조직이 성숙해지면 일괄 수집을 넘어 변경 데이터 캡처(CDC, Change Data Capture) 패턴으로 이동함 
      - 짧은 지연 시간(몇 초 또는 몇 분)으로 대상에서 소스 업데이트가 필요한 지속적인 데이터 이동에 적용 가능함. CDC는 소스에서 모든 변경 이벤트(업데이트,삭제,삽입)를 캡처하고 대상에 업데이트를 적용함 
      - CDC 패턴은 일반적으로 CDC 패턴을 사용해 연속 업데이트가 수행되는 동안, 소스 테이블을 처음으로 전체 복사할 때 사용되는 일괄 수집과 함께 사용됨 
      - CDC 수집 패턴
        - 1.CDC 이벤트 생성
          - CDC 어댑터는 소스 데이터베이스에 설치되고 구성됨. 이 어댑터는 사용자 지정 테이블에 대한 삽입, 업데이트, 삭제를 추적하기 위한 소스 데이터스토어 특화 소프트웨어 
        - 2. 이벤트 버스에 게시된 CDC
          - CDC는 이벤트 버스에 게시되며 하나 이상의 분석 유스 케이스에서 사용할 수 있음. 버스의 이벤트는 내구성이 뛰어나며 오류가 발생한 경우 재생 가능함 
        - 3. 이벤트 병합
          - 각 이벤트(삽입,삭제,업데이트)는 대상 테이블에 적용됨. 최종 결과는 소스 테이블보다 짧은 지연 시간이 있는 테이블의 구체화 뷰. 대상 테이블에 해당하는 메타데이터는 새로 고침 타임스탬프와 기타 속성을 반영하기 위해 데이터 카탈로그에 업데이트됨 
      - CDC 수집 패턴 중에는 병합 단계를 거치지 않고 직접 이벤트를 사용할 수 있는 변형도 있음. 이 변형 패턴은 일반적으로 원시 CDC 이벤트가 비즈니스 특정 이벤트로 변환되는 시나리오에 적용됨 
      - CDC 이벤트를 시간 기반 저널(time-based journal)로 저장하는 것. 일반적으로 리스크 및 사기(fraud) 탐지 분석에 유용함 
      - 아파치 Kafka와 결합된 Debezium
        - Debezium은 지연 시간이 짧은 CDC 어댑터
        - 데이터베이스 기술에 관계없이 표준화된 이벤트 모델에서 커밋된 데이터베이스 변경 사항을 캡처함.
        - 이벤트는 변경된 내용, 시기 및 위치를 설명함. 이벤트는 아파치 Kafka에 하나 이상의 Kafka 토픽(일반적으로 데이터베이스 테이블당 하나의 토픽)으로 게시됨 
        - Kafka는 모든 이벤트가 복제되고 완전히 정렬되도록 보장하며, 많은 소비자가 업스트림 시스템에 거의 영향을 주지 않으면서 동일한 데이터 변경 이벤트를 독립적으로 사용할 수 있게 함 . 병합 프로세스 중에 오류가 발생하는 경우 중단된 지점에서 정확히 다시 시작할 수 있음 
        - 이벤트는 정확히 한 번(exactly-once) 또는 최소한 한 번(at-least-once) 정확하게 전달됨. 각 데이터베이스/테이블에 대한 모든 데이터 변경 이벤트는 업스트림 데이터베이스에서 발생한 것과 동일한 순서로 전달됨 
        - CDC 레코드를 구체화된 대상 테이블로 병합하기 위해 널리 사용되는 접근 방식은 MapReduce를 사용하는 일괄 처리 지향적 방식 또는 Spark와 같은 기술을 사용하는 스트리밍 지향적 방식
      - 아파치 Gobblin(인기 있는 오픈소스 솔루션으로는 MapReduce를 사용함), Spark를 사용하는 우버의 Marmaray
        - Gobblin의 병합 구현에는 역직렬화/추출, 포맷 변환, 품질 검증, 대상에 대한 쓰기가 포함됨. Gobblin과 Marmaray는 모두 어떤 소스에서 어떤 대사응로든 데이터를 이동을 할 수 있도록 설계됨 
      - 강점
        - CDC 패턴은 소스 데이터스토어에 미치는 성능 영향을 최소화하면서 대상을 업데이트하는 지연 시간이 짧은 솔루션
        - CDC 어댑터는 광범위한 데이터스토어에 사용할 수 있음 
        - 데이터 이동 과정에서 필터링 또는 데이터 변환을 지원함
        - 증분 수집(incremental ingestion)을 사용해 대형 테이블을 지원함 
      - 약점
        - CDC 어댑터의 최적 구성 옵션을 선택하는 데 필요한 전문 지식이 없으면 온보딩이 쉽지 않음 
        - Hadoop MapReduce 대신 Spark를 사용하는 병합 구현에서는 약 10억 행 이상의 매우 큰 테이블에서 문제가 발생할 수 있음 
        - 증분 변경 내용을 추적하려면 CDC 열이 있는 테이블이 필요함
        - 필터링 또는 데이터 변환을 제한적으로 지원함 
      - 이 접근 방식은 빠르게 이동하는 대용량 데이터에 적합하며, 널리 사용되고 가장 인기 있는 접근법 중 하나. 오류 없는 업데이트 추적 및 대규모 업데이트 병합을 보장하려면 소스 팀과 데이터 엔지니어링 팀 간의 운영 성숙도가 필요함 
    - 이벤트 수집 패턴 (이벤트 집계 패턴)
      - 사기 탐지, 알림, IoT 등을 위해 실시간으로 지속적인 이벤트를 집계해야 하는 애플리케이션 이벤트뿐만 아니라 로그 파일을 집계하는 일반적인 패턴 
      - 웹 액세스 로그, 광고 로그, 감사 로그, Syslog, 센서 데이터 등 로그의 수가 증가함에 따라 적용 범위가 넓어짐 
      - 여러 소스에서 집계하고, 단일 스트림으로 통합하고, 이를 일괄 처리 또는 스트리밍 분석에 사용할 수 있도록 하는 작업이 포함됨 
        - 이벤트 전달
          - 에지 노드, 로그 서버, IoT 센서 등으로부터의 이벤트 및 로그가 집계 단계로 전달됨. 로그를 실시간으로 푸시하기 위해 경량 클라이언트가 설치됨 
        - 이벤트 집계 
          - 여러 소스의 이벤트가 정규화되고 변환돼 하나 이상의 대상에서 사용할 수 있음. 집계는 스트리밍 데이터 흐름을 기반으로 함. 이벤트 스트림은 버퍼링돼 주기적으로 데이터스토어 대상에 업로드됨 
      - 아파치 Flume
        - 데이터 이동 작업의 일부로, 구성 파일에서는 이벤트 소스와 데이터가 집계되는 대상을 정의함 
        - Flume의 소스 구성 요소는 소스에서 로그 파일과 이벤트를 가져와 데이터가 처리되는 집계 에이전트로 보냄. 로그 집계 처리는 메모리에 저장되고 대상으로 스트리밍됨 
        - Flume은 기본적으로 웹 서버에서 생성된 대량의 로그 파일을 Hadoop으로 빠르고 안정적으로 스트리밍할 수 있도록 설계됐으며, Kafka 브로커, 페이스북, 트위터와 같은 소스의 데이터를 포함해 이벤트 데이터를 처리하도록 진화했음 
      - Fluent Bit과 Fluentd, 오픈소스 로그 수집기(log collec색) 및 로그 집계기(log aggregator)로 널리 사용됨 
      - 강점 
        - 이벤트 집계 패턴은 로그와 이벤트에 최적화된 실시간 솔루션. 신뢰성, 가용성이 높고 횡적 확장성이 뛰어남 
        - 소스 성능에 미치는 영향을 최소화함
        - 확장성과 커스터마이징이 용이하며 운영 오버헤드를 최소화함
        - 데이터 이동 프로세스 중 필터링과 데이터 변환을 지원함
        - 대량의 로그 및 이벤트 데이터를 처리하도록 확장됨 
      - 약점 
        - 소스 이벤트에 대한 정렬을 보장하지 않음
        - 메시지를 정확히 한 번만 전달하지 않고 최소 한 번 전달하기 때문에 대상에서 중복 이벤트를 처리해야 함 
      - 로그 및 이벤트 데이터에 최적화돼 있음 

# 클릭스트림 추적 서비스
- 클릭스트림 데이터로 알려진 행동 데이터를 수집, 분석, 집계하는 것. 클릭스트림은 애플리케이션 또는 웹 사이트 내에서 방문자의 행동을 나타내는 일련의 이벤트 
- 클릭, 보기 및 페이지 로드 시간, 방문자가 사용하는 브라우저 또는 장치 등과 같은 관련 컨텍스트가 포함됨. 클릭스트림 데이터는 고객 트래픽 분석, 마케팅 캠페인 관리, 시장 세분화, 세일즈 퍼널 분석(sales funnel analysis) 등과 같은 비즈니스 프로세스 인사이트에 중요함 
- A/B 테스트는 클릭스트림 데이터 스트림을 사용해 비즈니스 상승 효과를 계산하거나 제품 또는 웹 사이트의 새로운 변경 사항에 대한 사용자 피드백을 캡처함 
- 세 가지 중요한 문제점 
  - 데이터 사용자는 분석 요구 사항에 따라 제품 및 웹 페이지에 새로운 추적 비콘(tracking beacon)을 지속적으로 추가해야함. 이러한 비콘을 추가하는 것은 셀프서비스가 아니며 계측 비콘을 추가할 위치, 사용할 계측 라이브러리, 사용할 이벤트 분류를 결정하기 위한 전문 지식이 필요함 
  - 클릭스트림 데이터는 인사이트 생성에 사용되기 전에 집계, 필터링, 보강돼야 함 
  - 클릭스트림 분석은 트랜잭션 기록과 실시간 클릭스트림 데이터에 대한 액세스를 필요로 함 
- 여정 지도
  - 마케팅 캠페인에서는 최적화를 위한 다양한 목표가 존재함. 판매 수익 증대, 고객 유지 개선, 브랜드 범위 확대 등이 그 예. 
  - 인사이트는 웹 추적 이벤트(클릭,뷰,전환), 광고 추적 이벤트(광고 노출, 비용), 인벤토리 데이터베이스(제품, 재고,마진),고객 주문 추적(고객, 주문, 크레딧)으로 구성된 원시 데이터에서 추출해야 함 
  - 웹 트래픽 분석은 트래픽을 가져오는 소스, 인기 키워드, 다른 트래픽 소스 방문자로부터의 전환율, 캠페인에 연결된 코호트 분석 등에 대한 인사이트를 제공함 
  - 클릭스트림 유스 케이스의 세 가지 구성 요소 
    - 고객의 클릭과 뷰를 캡처하기 위해 제품과 웹 페이지에 추적 코드를 추가
    - 비콘에서 데이터를 수집한 뒤 집계, 상관, 정리, 보강
    - 실시간 클릭스트림 이벤트와 데이터 레이크의 기록 데이터를 결합해 인사이트 생성 
- 클릭 시간 지표 최소화
  - 클릭 시간 지표에는 계측 관리, 수집된 이벤트 보강, 데이터 소비에 대한 분석 시간이 포함됨 
  - 계측 관리 
    - 클릭스트림 이벤트를 생성하려면 제품 도는 웹 페이지 내에 계측 비콘이 필요함. 비콘은 일반적으로 모든 요청에 대해 페이지로 로드되는 자바스크립트 추적기로 구현되고 뷰, 클릭 및 기타 동작에 대한 세부 정보와 함께 수집기 서비스로 JSON POST 요청을 보냄 
  - 이벤트 보강
    - 봇 필터링 : 봇에 의해 트리거된 이벤트는 방문자당 고객 인터랙션 및 전환과 관련된 주요 지표를 왜곡하기 때문에 필터링이 필요함 
    - 세션화
      - 원시 클릭스트림 이벤트는 고객 행동을 더 잘 이해하기 위해 세션으로 쪼개짐. 세션은 두 개 이상의 장치 및 사용자 간의 짧은 대화형 정보 교환
      - 세션을 사용하면 구매 빈도가 가장 높은 경로, 사용자가 특정 페이지로 이동하는 방법, 사용자가 이탈하는 시기와 이유, 일부 획득 유입 경로가 다른 페이지보다 효율적인지 등의 질문에 답할 수 있음 
    - 풍부한 컨텍스트
      - 효과적으로 인사이트를 추출하기 위해 클릭스트림 이벤트는 기기 유형, 브라우저 유형, OS 버전과 같은 사용자 에이전트 세부 정보를 추가 컨텍스트로 사용해 보강됨 
  - 인사이트 쌓기
    - 실시간 대시보드는 E2E 고객 여정, 고객 360 프로필, 개인화 등을 파악하는 데 사용됨. 실시간으로 사용자 행동을 추적하면 추천 내용을 업데이트하고, 고급 A/B 테스트를 수행하거나 고객에게 알림을 보낼 수 있음 
    - 고객 ID가 상호 연결돼야 함(이를 ID 스티칭-identity stitching), ID 스티칭 시에는 정확하게 일치하는 프로필을 가지기 위해 가능한 한 많은 식별자와 고객을 일치시킴
    - 단일 파이프라인의 모든 이벤트를 추적하면 IP 주소를 매칭해서 고객 이벤트를 상호 연관시킬 수 있음. 고객이 이메일을 열때 쿠키 ID를 사용한 다음 쿠키가 이메일 주소 해시 코드를 추적하도록 하는 것 
    - 고객의 온라인 여정 지도는 구매 결정에 영향을 미치는 다양한 접점과 채널로 인해 매우 복잡함. 기업의 자체 웹 사이트만을 사용해 고객 행동을 추적하는 것은 라스트 터치 어트리뷰션 모델(last-touch attribution model - 고객의 마지막 접점에만 크레딧을 부여하는 모델)을 사용하는 것과 유사하고 완전한 그림을 제공하지 않음
- 요구 사항 정의
  - 계측 요구 체크리스트
    - 이벤트에서 캡처된 속성 : 이벤트 속성, 즉 누구인지, 무엇인지, 어디인지와 도메인 세부 정보 및 이벤트 유형(페이지 뷰, 클릭 등)을 정의함 
    - 클라이언트 측 이벤트 수집 : 모바일 클라이언트, 데스크톱 응용프로그램, 웹 응용프로그램의 인벤토리를 수집함 
    - 타사 소스 수집 : 구글,페이스북 픽셀, 광고 대행사 등 타사 소스의 로그 데이터와 통계를 집계할 필요가 있는지 판단함. 각 에이전시에 해당하는 웹훅(webhook)을 식별함 
    - 서버 측 이벤트 수집 : 백엔드 애플리케이션 서버에서 이벤트를 캡처해야 하는지 여부를 결정함 
    - 속도와 피드 : 비콘 수, 이벤트 생성 비율, 이벤트 보존 기간에 대한 대략적인 추정치를 가져옴 
