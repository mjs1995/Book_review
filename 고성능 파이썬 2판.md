# 서평
- ![제목 없는 디자인 (6)](https://user-images.githubusercontent.com/47103479/194050818-a2d40311-20bc-424b-8063-31848da62658.png)
- 책을 선택하게 된 계기는 간단한 거 같습니다. 대용량 데이터를 다루면서 확장성 좋은 아키텍처가 필요하다고 느꼈고 프로젝트를 진행하면서 튜닝 포인트나 다른 프로젝트에서 나였다면 어떻게 행동했을까라는 생각을 하면서 파이썬에 대해서 디테일하게 배우고 싶어서 책을 읽게 되었습니다.
- 이 책은 고성능 코드를 작성할 때 필요한 이론과 실무에 한 걸음 다가가고 싶은 분, 성능 좋은 시스템을 만드는 방법을 이해하고 싶은 모든 개발자, 파이썬을 충분히 사용해보았고 특정 부분이 왜 느린지 생각해본 적이 있으며, 이를 위한 해법으로 거론되는 사이썬(Cython), 넘파이, PyPy 같은 기술을 들어본 독자를 대상으로 하고 있습니다. 또, 다른 언어로 프로그래밍해본 경험이 있어서 성능을 개선하는 방법이 여러 가지임을 아는 독자분들에게 추천드립니다. 
- 책의 서평에서 책에서 다루는 전반적인 내용에 대해서 미리 알려줘서 전반적인 구조를 이해하는데 많은 도움이 되었습니다. 또한 이 책은 효율적이고, 이해하기 쉽고, 성능 좋은 시스템을 모두 달성하려는 사람을 위한 안내서입니다.
- 이 책을 읽음으로써 프로파일링으로 코드의 느린 부분을 파악하는 방법, Numpy를 사용해서 코드를 더 빠르게 만드는 방법, 다수의 프로세스나 컴퓨터를 사용하기 위한 여러 접근 방법, 컨테이너 가상화를 사용해 코드 환경을 관리하고 클러스터 배포를 쉽게 하는 법, 서로 다른 자료구조와 확률적인 접근 방법을 사용해서 RAM을 덜 사용하도록 만드는 여러 가지 방식에 대해 배웠습니다.
- 고성능 파이썬의 저자인 이안 오스발트는 다음과 같은 말을 서술하였습니다. 축하할만한 일의 로그를 작성하라는 것입니다. 성취했던 일을 잊고 일상에 묻혀 지내기 쉽습니다. 사람들은 쉴 새 없이 달리기 때문에 번아웃되는 게 아니라, 자신이 얼마나 발전했는지 잊어버려서 번아웃된다. 축하할만한 일의 목록을 만들고, 각각 어떻게 축하할지 적어보아라. 이런 의미에서 회고를 하면서 한 해를 돌아보는 과정이 새로운 해에 번아웃은 없이 기술을 갈고닦는데 도움이 된다고 생각합니다. 개인적인 삶의 우선순위를 더 높여서 컴퓨터와 일에서 며칠 떨어져 기술적이지 않은 일을 하면서 축하할만한 일의 로그를 작성하려고 합니다. 

# 들어가며 
- 파이썬은 고수준 언어이면서 배터리 포함이라는 개념하에 다양한 도구를 기본 제공하므로 누구나 쉽게 데이터 전처리나 데이터 분석에 사용할 수 있음, 파이썬은 너무 고수준 언어라서 이를 실행해주는 운영체제나 컴퓨터 시스템 전반을 충분히 이해하지 못할 때가 많음 
- 대용량 자료구조를 처리하는 과정에서 병렬 처리의 어려움이나 메모리 장벽, 성능 저하 등으로 문제가 있을때 저수준의 최적화 기법이나 시스템을 이해하면 도움이 됨 
- 책에서 다루는 내용
  - 컴퓨터의 저수준 동작 방식 : 내부적으로 어떤 일이 일어나는지 이해하기 
  - 리스트와 튜플 : 기본 자료구조인 리스트와 튜플의 미묘한 의미 차이와 속도 차이
  - 사전과 셋 : 중요한 자료구조인 사전과 셋의 메모리 할당 전략과 접근 알고리즘
  - 이터레이터 : 이터레이터를 통해 데이터를 스트리밍 하는 방법과 더 파이썬다운 코드를 작성하는 방법
  - 순수 파이썬 방식의 접근 : 파이썬과 모듈을 효율적으로 사용하는 방법
  - 행렬과 넘파이 : numpy 라이브러리를 고수처럼 사용하는 방법
  - 컴파일과 JIT 컴퓨팅 : 기계어로 컴파일해 더 빠르게 처리하기, 프로파일링 결과에 따라 성능 개선 방향 정하기
  - 동시성 : 데이터를 효과적으로 옮기는 방법
  - 다중 처리 : 병렬 컴퓨팅과 numpy 행렬을 효율적으로 공유하기 위해 기본 라이브러리인 multiprocessing 모듈을 이용하는 방법, 프로세스 간 통신(IPC)의 비용과 장점
  - 클러스터 컴퓨팅 : 연구나 프로덕션 시스템에서 다중 처리를 사용한 코드를 수정하여 로컬 또는 리모트 클러스터에서 실행하는 방법
  - 메모리 아껴 쓰기 : 크고 비싼 컴퓨터를 구입하지 않고 대용량 문제를 해결하는 접근법
  - 현업에서 얻은 교훈 : 현업에서 고군분투했던 문제에서 얻은 교훈을 통해 같은 문제를 겪지 않도록 예방하기 

# 고성능 파이썬 이해하기 
- 컴퓨터 프로그래밍이란 특별한 방법으로 데이터를 가공해서 주고받으며 어떤 결과를 얻는 과정 
- 고성능 프로그래밍은 이런 과정 중에 발생하는 부가비용을 줄이고(효과적인 코드 작성 등) 각 과정을 더 의미 있는 방법(더 적합한 알고리즘 등)으로 변경하여 시간 비용을 줄이는 행위 
- 기본 컴퓨터 시스템
  - 컴퓨터를 구성하는 요소는 크게 연산 장치, 메모리 장치, 장치들을 이어주는 연결 장치로 구성되어 있음
  - 연산 장치는 초당 얼마나 많이 계산할 수 있는지, 메모리 장치는 데이터를 얼마나 많이 저장할 수 있으며 얼마나 빠르게 읽고 쓸 수 있는지, 연결 장치에는 장치 간에 데이터를 얼마나 빠르게 옮길 수 있는지 알려주는 속성이 있음 
  - 일반적인 워크스테이션은 CPU라는 연산 장치, 용량과 접근 속도가 서로 다른 RAM과 하드 드라이브라는 저장 장치, 그리고 이들을 포함한 모든 부품을 연결하는 장치인 버스(bus)로 생각해볼 수 있음 
  - 연산 장치
    - 컴퓨터를 사용하는 데 가장 핵심적인 장치, 입력된 Bit를 다른 Bit로 변환하거나 프로세스의 상태를 변경하는 기능을 제공함 
    - 가장 널리 쓰이는 연산 장치는 CPU지만 최근에는 GPU(graphics processing units)가 보조 연산 장치로 인기를 끌음, 원래 GPU는 그래픽 처리에 사용되었으나 고유의 병렬적인 특성 때문에 많은 계싼을 동시에 처리할 수 있으므로 계산 애플리케이션에서도 유용함 
    - 연산 장치는 종류에 관계없이 여러 Bit(예를 들면 수를 나타내는 Bit)를 입력받아 다른 Bit 조합(예를 들면 각 수의 합)으로 변환함 
    - CPU 제조사는 더 빠른 속도를 얻으려고 동시적인 다중 스레딩(multithreading - 여러 스레드를 병렬로 동시에 실행), 비순차적 명령어 처리(out-of-order execution), 멀티 코어 아키텍처 같은 다른 방법을 모색함 
    - 하이퍼스레딩(hyperthreading)은 운영체제에 가상의 두 번째 CPU를 인식시킨 다음, 똑똑한 하드웨어 로직이 단일 CPU의 실행 유닛에 두 스레드를 번갈아 가며 실행하도록 하는 기법, 잘만 작동하면 단일 스레드 대비 30% 까지 성능을 끌어 올릴 수 있음 
    - 비순차적 명령어 처리는 프로그램 실행 과정에서 이전 작업의 결과에 영향을 받지 않는 부분을 찾아내서 두 작업을 순서와 관계없이 실행하거나 동시에 실행하는 기법
    - 멀티 코어 아키텍처는 실행 유닛 하나에 CPU를 여러 개 두어 전체적인 처리량이 단일 CPU의 처리량을 능가하도록 함 
    - 암달의 법칙 : 단순히 CPU에 코어를 더 넣는다고 해서 프로그램의 실행 시간이 무조건 단축되지는 않음, 멀티 코어에서 작동하도록 설계된 프로그램일지라도 하나의 코어에서 실행해야 하는 루틴이 존재하고, 이 루틴이 코어를 더 투입했을 때 기대할 수 있는 최대 성능 향상치의 병목으로 적용한다는 법칙
- 메모리 장치
  - 메모리 장치에는 메인보드의 레지스터나 RAM, 하드 드라이브도 포함됨
  - 메모리 장치는 대부분 데이터를 조금씩 자주 읽을 때(임의 접근 random access)보다 한꺼번에 많이 읽을 때 훨 씬 빠르게 작동함(순차 접근 sequential access)
  - 레이턴시(latency) : 장치가 데이터를 찾기까지 걸리는 시간을 의미함
  - 하드디스크
    - 컴퓨터의 전원이 꺼진 상태에서도 데이터를 오래 보관할 수 있는 저장 장치, 물리적으로 헤드를 움직여야 하므로 읽기/쓰기 속도가 느림, 임의 접근 성능이 떨어지지만 10TB 수준의 대용량 데이터를 저장할 수 있음 
  - 솔리드 스테이트 드라이브(SSD) 
    - 하드디스크와 비슷함, 하드디스크보다 읽기/쓰기 속도가 빠르지만, 용량은 작음
  - RAM
    - 애플리케이션 코드나 사용 중인 변수 같은 데이터를 저장하는 데 쓴다, 읽기/쓰기 속도가 빠르며 임의 접근에도 성능 하락이 적으나, 일반적으로 용량이 64GB 단위로 제한적임 
  - L1/L2 캐시
    - 읽기/쓰기 속도가 매우 빠름, CPU로 전달하는 데이터는 항상 이 캐시를 거쳐 감, MB 단위로 용량이 아주 작음 
    - 읽기/쓰기 속도와 용량은 반비례하는 경향이 뚜렷함, 빠른 속도를 원한다면 줄어드는 용량을 감수해야 함
- 통신 계층
  - FSB는 RAM과 L1/L2 캐시를 연결함, FSB는 처리할 준비가 된 데이터를 옮겨서 프로세서가 계산할 수 있도록 하며, 계산이 완료되면 다시 돌려줌 
- 무거운 데이터(heavy data) : 데이터를 옮기는 데 시간과 노력이 필요하다는 뜻 

- 파이썬 개선점
  - 내부적으로 잘 최적화된 명령어 집합을 실행하지만, 명령어 집합을 올바른 순서로 실행하도록 하면 성능이 더 좋아짐 
  - 글로벌 인터프리틱 락(Global Interpreter Lock - GIL) 때문에 코어를 여러 개 활용하기가 쉽지 않음, GIL을 현재 사용중인 코어가 몇 개든, 한 번에 명령 하나만 실행하도록 강제함. 파이썬에서 동시에 여러 개의 코어에 접근하더라도 한 번에 파이썬 명령 하나만 실행됨
    - 다른 표준 라이브러리인 multiprocessing 모듈을 사용하거나, numpy나 numexpr, 사이썬 같은 기술을 이용하거나, 분산 컴퓨팅 모델을 사용하는 방법으로 해결할 수 있음 
  - 파이썬이 메모리를 자동으로 할당하고 해제하는 가비지 컬렉터(garbage collector GC)를 사용하기 때문, CPU 캐시에 데이터를 전송하는 데 영향을 미치는 메모리 단편화를 일으킴, 게다가 어디에서도 메모리에 저장되는 자료구조를 직접 변경할 수 없으므로 버스 폭이 아주 넓더라도 한 번의 계산에 필요한 정보를 한 번에 전송할 수 없음
  - 파이썬이 동적 타입을 사용하며 컴파일되지 않는다는 점
    - 정적인 코드를 컴파일 할 때, 컴파일러는 CPU가 특정 명령을 실행하는 방식을 포함한 많은 부분을 변경해서 최적화 할 수 있음, 파이썬은 컴파일되지 않는 데다가 코드의 기능이 런타임에 변경되는 동적 타입 언어라 최적화 알고리즘이 제 기능을 발휘하기 어렵다, 이 문제를 극복하는 여러 방법 중 사이썬(Cython)이 가장 대표적, 사이썬은 파이썬 코드를 컴파일하고 컴파일러에게 동적인 코드가 실제로 어떻게 동작하는지 힌트를 줄 수 있음 
- 파이썬을 쓰는 이유
  - 표현력이 좋고 배우기 쉽다는 장점
  - 많은 파이썬 라이브러리는 타 언어로 작성된 도구를 감싸서 다른 시스템을 쉽게 호출함
  - 주된 강점 하나는 빠른 프로토타이핑, 비록 처음부터 그럴싸하지는 않더라도 다양한 라이브러리를 활용해서 실현 가능한 아이디어인지 빠르게 검증해볼 수 있음 
  - 기본 라이브러리
    - unicode와 bytes : 언어 핵심에 녹아 있음
    - array : 메모리를 효율적으로 사용하는 배열
    - math : 간단한 통계를 포함한, 기본적인 수학 연산 모듈
    - sqlite3 : 널리 사용되는 파일 기반 데이터베이스인 SQLite3의 래퍼
    - collections : 데크(deque), 카운터, 여러 가지 사전을 포함하는 다양한 객체 집합
    - asyncio : async와 await 구문을 사용해 I/O 위주 작업의 동시 처리 지원, 기본적으로 지원하지는 않지만, 다양성을 더해주는 다음과 같은 외부 라이브러리가 있음 
    - Numpy : 파이썬 수학 라이브러리(행렬을 사용할 때 필수 라이브러리)
    - scipy : 높은 평가를 받는 C와 포트란 라이브러리를 감싼 계산 라이브러리 모음
    - Pandas : R의 dataframe이나 엑셀 스프레드시트와 유사한 데이터 분석 라이브러리, scipy와 numpy를 사용 
    - 사이킷런 : 빠르게 머신 러닝의 기본 모듈이 되고 있음, scipy를 사용
    - tornado : 웹 프레임워크이자 비동기 네트워크 라이브러리
    - PyTorch와 TensorFlow : 페이스북과 구글이 만든 딥러닝 프레임워크, 파이썬과 GPU를 강력히 지원
    - NLTK, SpaCy, Gensim : 파이썬을 잘 지원하는 자연어 처리 라이브러리
    - 데이터베이스 바인딩 : 레디스, 몽고DB, HDF5, SQL 등 실질적으로 대부분의 데이터베이스를 지원
    - 웹 프레임워크 : 웹 사이트 개발을 지원하는 aiohttp, flask, django, pyramid, tornado 등
    - OpenCV : 컴퓨터 비전을 위한 바인딩
    - API 바인딩 : 구글, 트위터, 링크드인 등 인기 서비스에 제공하는 웹 API를 위한 바인딩
    - 파이썬 배포판과 셸
      - 간단하고 가벼우며 이식성 좋은 파이썬 환경을 제공하는 pipenv, pyenv, virtualenv
      - 배포(deploy)와 프로덕션(production)에서 시작과 재현이 간편한 환경을 만들어주는 도커
      - 과학 계산에 초점을 맞춘 아나콘다사의 아나콘다 환경
      - IDE를 포함하며 매트랩과 유사한 환경을 제공하는 Sage
      - 개발자와 과학자들이 많이 쓰는 대화형 파이썬 셸인 IPython
      - 브라우저에서 돌아가는 IPython인 주피터 노트북, 교육과 데모용으로 많이 쓰임
- 뛰어난 성과를 거두는 파이썬 프로그래머가 되는 방법
  - 일반적인 접근 방법
    - 작동하게 만들라
      - 먼저 충분히 좋은 해법을 만들어야 함, 프로토타입 해법으로 사용되는 폐기한다는 가정하에 일단 만들어 보기를 적용하고 두 번째 버전에서 더 나은 구조를 사용할 수 있을 것이라 생각하자
      - 두 번 측정하고, 한 번만 잘라라(measure twice, cut once)
    - 재대로 만들라
      - 강력한 테스트 스위트를 만들고 코드와 테스트를 문서로 뒷받침해야 함, 다른 팀원이 사용할 수 있도록 명확한 재현 방법도 문서로 남김
    - 빠르게 만들라
      - 프로파일링, 컴파일링, 병렬화 등에 초점을 맞추고, 기존 테스트 스위트를 사용해 새로운 빠른 해법이 여전히 예상대로 작동하는지 확인해야 함 
- 모범적인 작업 절차
  - 문서화, 좋은 구조, 테스트가 핵심 요소
  - 최상위 수준에 README 파일을 작성하는 작업이 좋은 출발점임
  - 프로젝트 목적, 폴더 내용, 데이터 출처, 중요한 파일 목록, 프로그램과 파일의 실행 방법, 테스트 실행 방법 등을 적어라
  - 최상위 Dockerfile은 차후 이 프로젝트를 성공적으로 실행하는 데 운영체제에서 필요한 라이브러리를 정확히 알려줌, 그리고 다른 컴퓨터나 클라우드 환경에 프로젝트를 배포할 때도 어려움 없이 프로젝트를 실행할 수 있게 해줌 
  - tests/ 폴더를 추가하고 단위 테스트를 만들어라, 최신 테스트 도구로 pytest를 추천함, pytest는 파이썬 내장 unittest 모듈을 사용해 만들어졌음, 먼저 테스트를 한두 개 작성하고 점점 발전시켜라
  - 프로젝트 전체 흐름을 검사하면서 특정 입력에 대해 여러분이 지정한 출력이 나오는지를 체크하는 통합 테스트(integration test)가 있어야 함, 나중에 코드를 변경할 때 코드의 일관성을 유지하는 데 도움이 됨 
  - 코드의 모든 함수, 클래스, 모듈에 독스트링(docstring)을 추가하면 큰 도움이 됨, 함수가 달성하려는 내용을 제대로 설명하려 노력하라, 가능하면 예상 출력을 보여주는 간단한 예제도 추가하자 
  - 코드가 너무 길어지면(예컨대 한 화면에 다 보이지 않는 함수) 리팩터링해 코드를 짧게 만들어라, 짧은 코드는 테스트하기 쉽고 지원하기도 쉽다
  - 항상 소스 관리(source control)를 사용하라, 중요한 시기에 필수적인 코드를 덮어썼다면 소스 관리를 사용한 자기 자신에게 감사하게 됨, 커밋(commit)을 자주(매일 아니면 10분마다) 하고 매일 리포지터리(repository)에 작업을 푸시하라
  - PEP8 코딩 표준을 지켜라. black(원하는 대로 설정할 수 있는 코드 정리기formatter)을 소스 컨트롤의 커밋 전 훅(pre-commit hook)에 추가해서 코드를 표준 형식으로 자동 정리하면 더 좋음, flake8을 적용해 소스 코드를 린트(lint)해서 다른 실수를 방지하라
  - 운영체제와 분리된 환경을 만들면 더 코딩이 쉬워짐, 아나콘다, pipenv와 도커를 함께 쓰는 쪽을 선호함
  - 자동화는 여러분의 친구라는 사실을 기억하라, 수동 작업을 덜 하면 오류가 끼어들 가능성도 줄어듬, 자동 빌드 시스템, 자동 테스트 스위트 실행기(runner)를 사용한 지속적 통합(continuous integration), 자동 배포(automated deployment)는 지겹고 실수하기 쉬운 작업을 누구든 실행하고 지원할 수 있는 표준 절차로 바꿔줌
  - 가독성이 더 중요하다는 사실을 기억하라, 짧지만 복잡하고 읽기 어려운 코드는 유지보수하기 어렵다. 더 길더라도 읽기 편한 함수를 작성하고 함수에 관한 유용한 문서를 작성하는 편이 바람직하다. 함수가 실제로 원하는 대로 작동하는지 확인하는 테스트로 이 모든 내용을 보완하라 
- 주피터 노트북 잘 다루기
  - 코드를 IPython이나 QTConsole에서 프로토타이핑하라. 이런 콘솔에서 테스트한 코드들을 노트북 함수로 분리하고, 노트북 함수 중에 자주 쓰거나 복잡한 부분은 노트북에서 추출해서 모듈로 만들면서 테스트를 보완하라. 데이터 은닉(data hiding)이나 캡슐화(encapsulation)가 유용한 경우에는 코드를 클래스로 감싸라
  - assert 문을 노트북 여기저기에 자유롭게 넣어서 함수가 여러분 생각대로 작동하는지 검증하라
  - 함수가 예상하지 못한 입력값을 만났을 때 던질 수 있는 일반적인 예외로는 ValueError, Bulwark 라이브러리는 데이터가 정해진 제약 조건을 만족하는지 검사해주는 팬더스에 초점을 맞춘 테스트 프레임워크의 예다 
  - 노트북의 끝에 데이터 무결성 검사를 추가하라, 무결성 검사는 노트북에서 방금 생성한 데이터가 여러분에 피룡한 데이터인지 검사하는 논리 검사와 raise, print 문을 혼합한 코드 조각
  - nbdime은 성장 중인 새로운 도구로, 노트북 사이의 차이를 알려줘서 동료들과 협업할 때 큰 도움이 됨 
- 일하는 즐거움 되찾기
  - 새로운 활동을 하면서 계속 기쁨을 찾아라, 왜 이런 결정을 내렸지?, 내가 하면 어떻게 다르게 할 수있을까? 같은 질문을 할 수 있고, 갑자기 상황이 어떻게 더 나아지거나 바뀌었는지에 관한 이야기를 시작하게 될 것이다.
- 프로그래밍은 (특히 성능이나 성취에 초점을 맞추면) 기술적인 세부 사항을 깊이 파고들려는 자발성과 호기심이 있어야 번창함, 천천히 시간을 두고 여러분의 여정을 즐기며 호기심과 즐거움을 계속 유지하라 

## 프로파일링으로 병목 지점 찾기
- 프로파일링으로 병목 지점을 찾아 최소한의 노력으로 성능을 최대한 끌어올릴 수 있음 
- 효과적으로 프로파일하기
  - 프로파일링의 첫 번째 목표는 시스템의 어느 부분이 느린지, 어디서 RAM을 많이 쓰는지, 디스크 I/O나 네트워크 I/O를 과도하게 발생시키는 부분이 어디인지를 확인하는 것 
  - 기본적인 프로파일링 기법은 IPython의 %timeit 매직 명령어와 time.time(), 데커레이터(decorator)를 활용한 시간 측정 
  - line_profiler는 각 줄을 몇번 실행했는지, 총 소요 시간은 얼마인지를 검사함, 이는 어느 부분이 왜 느린지를 이해할 수 있는 정보
  - CPU에서 실행된 명령의 수와 CPU 캐시가 얼마나 효율적으로 활용되었는지 알아볼 수 있는 perf stat 사용법을 배움, 이 정보는 매트릭스 연산을 튜닝하는 고급 기번에 활용됨 
  - C파이썬 내부에 쓰이는 파이썬 바이트코드, 바이트코드를 알면 파이썬 내부를 더 잘 이해할 수 있음, 파이썬의 스택 기반 가상 머신을 이해하면 왜 특정 코딩 습관이 코드를 느리게 하는지를 알 수 있음 
- 코드는 결정적(deterministic)이므로, 계산된 값을 모두 더해서 함수가 기대하는 대로 잘 작동하는지 확인할 수 있음, 검증 코드를 추가하면 유용함 
  - 수치 계산을 하는 코드를 수정할 때는 우리가 변경한 내용이 알고리즘을 깨지 않았는지 검사하는 작업이 매우 중요함 
  - 이상적으로는 단위 테스트를 사용해서 문제의 여러 가능성도 테스트해야함 
- 시간을 측정하는 간단한 방법 : print와 데커레이터
  - 데커레이터는 print 문보다 조금 더 깔끔한 방법, 여기서는 시간을 측정하려는 함수 위에 코드를 한 줄 추가함 
  - 가변 길이 인자인 *args와 키워드 인자인 **kwargs를 받아, 실행하는 fn 함수로 넘겨준다.
  - @wraps(fn)을 사용해서 데커레이터로 넘겨온 함수 이름과 독스트링을 호출하는 함수에서 확인할 수 있도록 함(그렇지 않으면 데커레이터로 넘어온 함수가 아니라 데커레이터 함수 그 자체의 이름과 독스트링을 보게 됨)
- cProfile 모듈 사용하기
  - 표준 라이브러리에 내장된 프로파일링 도구로, C파이썬의 가상 머신 안에서 확인되는 모든 함수에 시간을 측정하는 장치를 연결함, 이는 큰 오버헤드를 유발하지만 그만큼 더 많은 정보를 제공함 
  - profile은 수수 파이썬 기반의 프로파일러로 cProfile보다 느림 
  - cProfile은 profile과 같은 인터페이스를 제공하며 오버헤드를 줄이려고 C로 작성함 
  - 프로파일하기 전에 프로파일하려는 코드의 기대 속도에 대한 가설을 세우는 습관을 들여라 
- SnakeViz로 cProfile 결과 시각화하기
  - snakeviz는 cProfile로 생성한 통계 정보를 시각화하는 도구, 더 오랜 시간을 소비한 영역을 더 큰 상자로 표시하여, 기존의 runsnake 도구를 대신함 
  - 통계를 cumtime(누적 시간), percall(호출 당 비용), ncalls(호출 회수) 등의 지표 기준으로 정렬할 수 있음, cumtime을 기준으로 정렬하면 어떤 함수가 전체적으로 가장 많은 시간을 소모했는지 알 수 있음 
- line_profiler로 한 줄씩 측정하기
  - line_profiler가 파이썬 코드에서 CPU 병목 원인을 찾아주는 가장 강력한 도구라 생각함
  - line_profiler는 개별 함수를 한 줄씩 프로파일하므로, 먼저 cProfile을 사용해서 어떤 함수를 line_profiler로 자세히 살펴볼지 정하면 됨 
  - 코드를 수정하면서 line_profiler 결과에 버전을 기록해두면 변경 사항의 성공/실패 기록을 빠르게 참고할 수 있음 
- memory_profiler로 메모리 사용량 진단하기
  - CPU 사용량을 측정하는 로버트 컨의 line_profiler 패키지처럼 메모리 사용량을 줄 단위로 측정해주는 memory_profiler가 있음 
- PySpy로 기존 프로세스 살펴보기
  - py-spy는 새로운 샘플링 프로파일러(sampling profiler) 
  - 코드를 변경하는 대신, py-spy는 이미 실행 중인 파이썬 프로세스를 들여다보고 콘솔에 top과 비슷한 방식으로 상황을 표시해줌 
  - py-spy는 러스터(Rust)로 작성됐고, 다른 프로세스를 들여다보려면 관리자 권한이 필요함 

## 리스트와 튜플
- 성능을 고려한 프로그래밍에서는 어떤 데이터를 어떻게 다룰지를 고민하고 그 상황에서 빠르게 작동하는 자료구조를 선택하는 일이 큰 비중을 차지함 
- 리스트와 튜플은 배열이라는 자료구조에 속함, 배열은 정해진 고유의 순서에 따라 데이터를 나열해둔 것 
- 리스트는 저장하는 데이터나 배열 크기를 변경할 수 있는 동적 배열
- 튜플은 내용이 고정된 변경 불가능한(immutable) 정적 배열 
- numpy 배열은 정적으로 타입이 정해져 있어서 다른 타입의 값을 저장할 수 없음
- 더 효율적인 탐색
  - 파이썬 리스트는 정렬 알고리즘을 내장하며 팀(Tim) 정렬을 사용함, 팀 정렬의 시간복잡도는 최적일 때 O(n), 최악일 때 O(n log n)
  - 팀 정렬은 자양한 정렬 알고리즘을 활용하여 주어진 데이터에 어떤 알고리즘을 적용하는 것이 최선인지를 추측하는 휴리스틱을 사용함(삽입 정렬과 병합 정렬 알고리즘을 조합해서 사용함)
  - 파이썬 표준 라이브러리의 bisect 모듈을 이용하면 잘 최적화된 이진 탐색 기법으로 항목을 찾을 수 있을 뿐 아니라 새로운 항목을 추가해도 정렬된 상태가 유지됨 
- 리스트와 튜플
  - 차이점
    - 리스트는 동적인 배열, 수정이 가능하며, 저장 용량을 늘리거나 줄일 수도 있음
    - 튜플은 정적인 배열, 일단 생성되면 배열의 크기뿐 아니라 그 안의 데이터도 변경할 수 없음
    - 튜플은 파이썬 런타임에서 캐시하므로 사용할 때마다 커널에 메모리를 요청하지 않아도 됨 
  - 튜플은 변치 않는 특정 대상의 여러 속성이며 리스트는 서로 이질적인 객체들의 모음 
  - 튜플 : 정적 배열
    - 여유 공간이 부족할 때만 할당과 복사가 일어나는 리스트와 달리 튜플에서는 새로운 항목을 추가할 때마다 복사가 일어남, 두 튜플을 합치면 항상 새로운 튜플 하나의 메모리를 새로 할당함
    - 여유 공간을 할당하지 않으면 자원을 더 적게 사용하는 장점이 있음, 크기가 1억인 리스트를 append로 생성하면 실제로는 112,500,007 크기의 메모리를 사용하는데, 튜플은 정확히 1억만큼만 사용함, 이 때문에 데이터가 정적일 때는 튜플이 더 가볍고 좋음 
    - append를 사용하지 않아 여유 공간을 할당하지 않더라도, 리스트는 여전히 같은 데이터를 저장하는 튜플보다 메모리를 더 잡아먹음, 리스트는 크기 변경을 효율적으로 하려고 상태 정보를 관리하기 때문 
    - 파이썬 내부적으로 수행하는 리소스 캐싱, 파이썬은 GC를 통해 더는 사용되지 않는 변수에 할당된 메모리를 반환함, 하지만 크기가 20 이하인 튜플은 크기별로 최대 2만 개까지(즉, 2-튜플 2만 개, 3-튜플 2만 개, ..., 20- 튜플 2만 개까지) 즉시 회수하지 않고 나중을 위해 저장해둠, 이는 같은 크기의 튜플이 나중에 다시 필요해지면 운영 체제에서 메모리를 새로 할당받지 않고 기존에 할당해둔 메모리를 재사용한다는 뜻, 파이썬 프로세스가 필요한 양보다 메모리를 약간 더 사용한다는 뜻
- 리스트와 튜플은 정렬된 데이터에 적합한 빠르고 오버헤드가 적은 자료구조
  - 리스트를 사용할 때는 크기 변경으로 발생한 초과 할당까지 고려해서 메모리에 데이터를 저장할 수 있을지 신경 써야 함 
  - 튜플은 빠르게 생성할 수 있고 리스트보다 메모리 부담이 적은 대신에 내용을 변경할 수 없음

## 사전과 셋
- 셋과 사전은 (삽입 순서를 제외하면) 미리 정해진 순서로 정렬되지 않으나, 특정 데이터를 고유하게 참조할 수 있는 별도 객체가 있는 상황에 이상적인 자료구조 
- 참조하는 객체는 일반적으로 문자열이지만, 해시가 가능하다면(hashable) 어떤 타입이라도 상관없다, 참조 객체를 키, 데이터를 값이라고 함 
- 사전과 셋은 거의 같지만 셋에는 값이 없다는 점이 다름, 쉽게 말해 셋은 유일한 키를 저장하는 자료구조, 셋은 집합 연산을 수행할 때 아주 유용함 
- 개방 주소(open address) 해시 테이블
  - 해시 테이블은 처음에는 데이터가 각 버킷에 골고루 분포하더라도, 확률적으로 어느 시점에는 해시값이 충돌할 수 밖에 없음, 이에 따라 충돌 해결 알고리즘이 필요함
  - 체이닝(chaining) 방식 : 충돌이 발생한 버킷의 값을 버킷마다 별도의 연결 리스트로 저장하는
  - 개방 주소 방식 : 충돌 발생 시 미리 정해진 알고리즘을 사용해 다른 버킷을 찾아서 키/값을 저장하는 
  - 폐쇄 해싱(closed hasing) : 버킷상의 항목 주소가 해시 키로 정해지지 않고 열려 있어서 개방 주소 방식이라 부르지만, 모든 항복이 버킷이 할당된 영역 안에 다 저장하기 때문 
  - 폐쇄 주소(closed address)방식의 해싱 : 체이닝의 경우 항목이 저장되는 버킷의 주소는 해시 함수로 정해지기 때문 
  - 개방 해싱(open hashing) : 항목이 버킷이 아닌 다른 영역(연결 리스트)에 들어갈 수도 있기 때문
- 사전과 셋의 동작 원리
  - 사전과 셋은 모두 해시 테이블을 사용해서 시간복잡도가 O(1)
  - 임의의 키(문자열이나 객체)를 리스트의 색인으로 변환하는 해시 함수를 효율적으로 사용한 결과, 해시 함수와 리스트는 나중에 검색을 하지 않고도 특정 데이터가 제대로 들어있는지 확인하는 용도로 사용 
  - 데이터의 키를 리스트의 색인천럼 사용하도록 변환하는 작업을 하면 리스트와 같은 성능을 냄
  - 데이터를 가리키는 수의 색인(수로 데이터를 가리키려면 데이터에 어떤 식으로든 순서를 부여해야 함) 대신 임의의 키를 사용해서 데이터를 참조할 수 있음 
- 프로빙(probing) : 새로운 색인은 단순한 선형 함수를 이용해서 계산, 파이썬의 프로빙 메커니즘은 원래 해시값에서 더 상위 Bit를 활용함 
- 로드 팩터(load factor) : 해시 테이블에 데이터가 얼마나 균등하게 분포하는지를 의미함, 해시 함수의 엔트로피와 관련 있음 
- 해시함수의 엔트로피 : 해시 함수가 얼마나 균일한 분포로 해시값을 만들어 내는지
- 완전 해시 함수 : 엔트로피가 최대가 되는 해시 함수는 최소 충돌을 보장
- 사전과 네임스페이스
  - 파이썬에서 변수, 함수, 모듈이 사용될 때 그 객체를 어디서 찾을지 결정하는 계층이 있음, 가장 먼저 모든 지역 변수를 담은 locals() 배열을 찾음, 파이썬은 지역 변수 탐색을 빨리 끝내도록 최선을 다하며, 이 과정은 사전 탐색을 하지 않는 유일한 부분
  - 만약 여기서 해당 객체를 찾을 수 없으면 globals() 사전에서 찾음, globals()에서도 찾을 수 없다면 마지막으로 __builtin__ 객체에서 찾음
  - locals()와 globals()는 명백한 사전이지만 __builtin__은 기술적으로는 모듈 객체라는 점이 중요함, __builtin__은 그 모듈 내부에서 locals() 사전(여기에 모듈 객체와 클래스 객체가 저장됨)을 탐색하여 특정 속성을 찾음 
    - locals() 배열은 함수 호출 시 만들어지는 스택 프레임 안의 지역 변수 영역을 의미함, 어떤 함숭 안에서 자신의 지역 변수에 접근할 때는 그 변수가 스택 프레임 내의 지역 변수 영역에서 몇 번째에 있는지를 이미 알기에 색인을 사용해 빠르게 접근할 수 있음, 반면 __builtin__에서 locals() 사전에 접근할 때는 색인으로 접근할 수가 없고, 변수 이름으로 검색해야 함 

## 행렬과 벡터 계산
- 메모리 단편화
  - 파이썬은 벡터 연산을 기본으로 제공하지 않음
    - 파이썬의 리스트는 실제 데이터를 가리키는 포인터를 저장한다는 점
    - 파이썬 바이트 코드는 벡터 연산에 최적화되지 않았다는 점 
    - for 루프는 벡터 연산을 언제 수행해야 도움이 되는지 예측할 수 없음, 파이썬 리스트가 포인터를 저장한다는 얘기는 리스트가 실제 데이터가 아닌 데이터의 위치를 저장한다는 의미 
  - CPU에 데이터가 필요할 때 즉시 공급하는 과정에서 발생하는 문제는 폰 노이만 병목(von Neumann bottleneck)과 관련 있음, 현대 컴퓨터의 구조적인 한계 때문에 메모리와 CPU 사이의 대역폭이 제한적이어서 발생하는 현상, 만일 우리가 데이터를 무한히 빠른 속도로 옮길 수 있다면 CPU는 필요한 데이터를 즉시 얻을 수 있으니 캐시가 필요 없음 
  - CPU는 현재 명령을 실행하는 동안 다음에 실행할 명령을 예측해 관련 데이터를 캐시에 미리 적재해두는 분기 예측(branch prediction)과 파이프라이닝(pipelining)이라는 훌륭한 기법을 제공함 
- 행렬 최적화에서 얻은 교훈
  - 초기화 과정에 필요한 관리 요소를 모두 고려해야 한다는 점
  - 메모리 할당, 설정 파일을 읽는 과정, 프로그램이 실행되는 동안 필요한 값을 미리 계산하는 과정도 모두 여기에 포함
  - 초기화 작업을 한번에 완료해서 전체 실행 횟수를 줄이고 나중에 불필요한 자원이 낭비되지 않도록 함 
  - 프로그램의 흐름을 방해하지 않아야 한다. 캐시에 관련 데이터만 채워지게 하고 파이프라인을 효율적으로 유지할 수 있음 
  - 데이터 지역성(data locality)과 데이터 CPU에 빠르게 전달하는 일의 중요성도 알게 되었음 
  - 외부 라이브러리 사용에 관한 것, 파이썬은 사용이 쉽고 가독성이 높아서 코드를 빠르게 작성하고 디버깅 할 수 있음, 하지만 성능을 개선할 때는 반드시 외부 라이브러리까지 고려해야 함 
  - 실험하기 전에 성능에 관한 가설을 세우고 성능을 측정해야 한다는 점도 배움 
- 팬더스
  - 과학기술 파이썬 생태계에서 사실상 표준인 데이터 조작 도구로 표 형태의 데이터 처리에 사용함, 팬더스는 (엑셀과 비슷하게) 균일하지 않은 데이터 유형으로 이뤄진 표(DataFrame)를 쉽게 조작하게 해주고, 시계열 연산을 강력히 지원함 
  - 연산은 단일 스레드로 실행되며 파이썬의 GIL 때문에 제한될 수 있음, 파이썬 내부 구현이 점차 개선되면서 GIL이 자동으로 비활성화될 수 있게 만들어, 병렬 연산이 가능해졌음, Dask로 팬더스 병렬화하기에서 Dask를 활용한 병렬화 접근법
  - 내부에서는 BlockManager가 같은 dtype으로 이뤄진 열을 하나로 묶음, 이런 숨겨진 장치는 같은 타입으로 이뤄진 열에 대한 행 단위 연산을 더 빠르게 수행하게 해줌 
  - 넘파이에서 온 타입은 int8(1바이트), int64(8바이트, 첫 글자가 소문자'i'), float16(2바이트), float64(8바이트), bool(1바이트) 등이 있음 
- 효율적인 팬더스 개발을 위한 조언
  - 코드를 너무 간략하게 작성하자 말라. 코드를 읽고 디버깅하기 쉽게 만들어서 미래의 자기 자신에게 도움이 되게 하라
  - 팬더스는 메서드 체이닝 스타일을 지원하지만, 팬더스 연산에서 너무 많은 행을 체이닝하는 일은 바람직하지 않다. 체이닝이 길어지면 디벙깅할 때 문제가 생긴 코드 줄이 어디인지 알아내기 어려워지고, 결국에는 각 줄을 나눠서 분석해야 함. 처음부터 유지보수를 고려해서 한두 가지 연산만 체이닝하고 코드를 여러 부분으로 나눠 구성하는 편이 낫다.
  - 처리를 필요 이상으로 하지 말라. 계산하기 전에 데이터에 필터를 적용하는 편이 계산을 수행한 후 필터를 적용하는 것보다 낫다. 일반적으로 고성능을 달성하려면, 컴퓨터가 가능한 한 적은 계산을 수행하게 해야 한다. 데이터 중 상당 부분을 필터로 거르거나 마스크해 없앨 수 있다면, 아마도 성능상 큰 이익이 따라올 것이다. 
  - DataFrame 스키마를 변경할 때마다 bulwark 같은 도구를 사용해 스키마를 검사하라.검사를 수행하면 실행 시점에 데이터가 스키마를 만족하는지 보장할 수 있고, 코드를 리뷰하는 과정에서 여러분의 예상에 맞게 코드와 스키마가 작성됐는지를 시각적으로 확인할 수 있음 
  - 모든 처리 코드에 단위 테스트를 꼭 추가하라. 처리 코드는 쉽게 복잡해지고 디버깅하기 점점 어려워지므로 단위 테스트가 필요함

## C언어로 컴파일하기
- 코드를 빠르게 하는 가장 쉬운 방법은 처리할 작업의 양을 줄이는 것, 이미 최적의 알고리즘을 사용하며 처리해야 할 데이터를 간소화했다고 가정하면, 수행할 명령의 수를 줄이는 가장 쉬운 방법은 코드를 기계어로 컴파일 하는 것 
- 순수 C기반의 컴파일을 수행하는 사이썬, LLVM 기반의 컴파일을 제공하는 Numba, 파이썬 가상 머신을 대체하는 내장 JIT 컴파일러를 포함하는 PyPy 등 여러가지
  - 사이썬 : C 언어로 컴파일하는 데 사용하는 가장 일반적인 도구, numpy와 일반 파이썬 코드를 모두 커버함(C 언어를 어느 정도 이해해야 함)
  - Numba : numpy 코드에 특화된 새로운 컴파일러
  - PyPy : 일반 파이썬 실행환경을 대체하는 비 numpy 코드를 위한 JIT 컴파일러  
- JIT 대 AOT 컴파일러
  - 미리 컴파일하는 방식이 AOT(ahead of time - 사이썬)와 적절한 때에 컴파일하는 방식인 JIT(Just in time(Numba, PyPy) 
  - AOT 방식 : 사용할 컴퓨터에 특화된 정적 라이브러리를 생성함
  - JIT 방식은 어떤 작업도 미리 하지 않고 컴파일러가 적절한 때에 컴파일을 시작함, 즉 콜드 스타트에 문제가 있다는 뜻, 프로그램 대부분이 컴파일되어야 하는데 아무것도 컴파일되지 않은 상태라면, 프로그램 실행 후에야 컴파일하느라 프로그램이 초반에 느리게 실행됨 
- 사이썬
  - 타입을 명시한 파이썬 코드를 컴파일된 확장 모듈로 변경해주는 컴파일러, 타입 어노테이션은 C와 유사한 형태
  - 주로 계산 코드의 속도를 빠르게 할 때 이 도구를 사용함, 다양한 사용성과 성숙도 그리고 OpenMP을 지원하는 점 때문
  - OpenMP 표준과 사이썬을 사용하면 한 컴퓨터의 여러 CPU에서 실행할 수 있도록 병렬 처리 문제를 다중 처리를 고려한 모듈로 변경할 수 있음, 이 스레드는 파이썬 코드 수준이 아니라 사이썬이 생성한 C 코드 수준에서 동작함
  - 사이썬을 사용하여 순수 파이썬 코드 컴파일하기
    - 호출하려는 파이썬 코드(앞서 작성한 줄리아 집합 코드들)
    - 새로 컴파일된 .pyx 파일
    - 확장 모듈을 작성하기 위해 사이썬을 호출하는 과정이 있는 setup.py 파일
      - setup.py 스크립트에서 사이썬을 사용해서 .pyx 파일을 컴파일함. 컴파일된 모듈은 유닉스 계열 시스템에서는 .so 파일일 가능성이 높고, 윈도우에서는 항상 (DLL과 비슷한 라이브러리인) .pyd 파일
- 강도 저감(strength reduction) : 같은 일을 하지만 좀 더 특화된 코드로 같은 문제를 해결하는 방법, 실행을 빠르게 하려고 유연성과 가독성을 희생하는 방법 
- 한 컴퓨터에서 OpenMP를 사용해 병렬화하기
  - OpenMP(Open Multi-Processing)는 C, C++, 포트란에서 병렬 실행과 메모리 공유를 지원하는 잘 정의된 다중 플랫폼 API 
  - 사이썬에서는 prange(병렬 범위) 연산자를 사용하고 setup.py에 -fopenmp 컴파일러 지시자를 넣어서 OpenMP를 추가할 수 있음
  - prange 연산자는 GIL을 비활성화하므로 prange 상에서는 루프를 병렬로 수행할 수 있음
  - GIL은 파이썬 객체로의 접근을 보호하며, 여러 스레드나 프로세스 같은 메모리에 동시에 접근해서 메모리를 오염시키는 일을 막음, 수동으로 GIL을 비활성화하면, 우리가 자체 메모리를 오염시키지 않겠다고 선언하는 것 
- Numba
  - 컨티넘 애널리틱스의 Numba는 numpy 코드에 특화된 JIT 컴파일러, 코드를 실행 시점에(앞의 예에서 사용했던 g++이나 gcc가 아니라) LLVM 컴파일러로 컴파일함 
  - 미리 컴파일하는 단계가 필요 없으므로, 새로운 코드를 실행할 때마다 Numba가 여러분의 컴퓨터에 맞춰 어노테이션이 달린 각 함수를 컴파일함
  - 집중해야 하는 함수를 알려주는 데커레이터를 제공하고, Numba가 그것을 이어받는다는 장점이 있음 
  - Numba는 외부 C 라이브러리와 연동하지 못하지만(사이썬은 연동 가능), 자동으로 GPU에 대한 코드를 생성할 수는 있음(사이썬은 생성 불가)
  - Numbda의 단점 하나는 툴체인, LLVM을 사용하므로 의존관계가 복잡함, 새 환경에 Numba를 설치하려면 시간이 오래 걸리므로, 모든 것이 포함된 컨티넘의 아나콘다 배포판을 추천함 
- PyPy
  - 추적형(tracing) JIT 컴파일러가 있는 또 다른 파이썬 언어 구현체, PyPy는 파이썬 3.5 이상과 호환됨, 보통 PyPY는 파이썬 최신 버전을 약간 늦게 지원함 
  - C파이썬을 완전히 대체할 수 있으며 모든 내장 모듈을 제공함, RPython 번역 도구와 그 도구로 만들어진 PyPy로 구성됨(RPython으로 다른 인터프리터를 만들 수 있음)
  - PyPy의 JIT 컴파일러는 매우 효율적이며, 그대로 사용하거나 약간의 작업만으로도 성능을 상당히 높일 수 있음 
  - PyPy가 모든 내장 모듈을 지원함, PyPy에서도 multiprocessing이 작동한다는 뜻 
- 가비지 컬렉션 방식의 차이
  - C파이썬은 참조 카운팅(reference counting)을 사용하는 반면, PyPy는 사용하지 않는 객체를(참조 카운팅보다) 훨씬 나중에 없애는 마크 앤 스윕(mark and sweep)을 사용함 
  - C파이썬에는 참조 카운터의 동작을 바탕으로 구현한 부분이 있음, 특히 파일을 열어서 쓴 다음 명시적으로 닫지 않아도 파일을 플러시(flush)하는 점이 그렇다. PyPy에서도 같은 코드가 실행되지만, 파일에 쓴 데이터는 나중에 GC가 실행되는 시점에 디스크로 플러시됨. PyPy와 C파이썬에서 모두 잘 작동하는 다른 코딩 방식은 with를 사용해서 파일을 열고 자동으로 닫도록 컨텍스트 관리자를 사용하는 것 
- 각 기술의 사용 시점
  - 컴파일러 선택 사항 요약

|특성|사이썬|Numba|PyPY
|:---:|:---:|:---:|:---:|
|성숙함|Y|Y|Y
|널리 사용 중|Y|-|-
|numpy 지원|Y|Y|Y
|기존 코드를 깨지 않음|-|Y|Y
|C 언어 지식 필요|Y|-|-
|OpenMP 지원|Y|Y|-

    - Numba는 시간과 노력을 적게 들이고도 성능을 높이지만, 몇 가지 제약이 있어 여러분의 코드에서 잘 작동하지 않을 수 있음
    - 사이썬은 보통 광범위한 문제에서 좋은 결과를 냄, 하지만 더 큰 노력을 들여야 하며 파이썬과 C 어노테이션을 혼용하기에 유지보수 비용도 커짐
    - numpy 등 포팅하기 어려운 C확장을 사용하지 않는다면 PyPy를 선택하는 편이 좋음
    - 프로덕션 도구를 배포한다면 잘 알려진 도구를 사용하고 싶을 것, 사이썬이 가장 좋은 선택 
- 떠오르는 다른 프로젝트들
  - PyData
    - 컴파일러 페이지에 고성능 및 컴파이럴 도구 목록이 있음
  - Pythran 
    - numpy를 사용 중인 과학자를 위한 AOT 컴파일러 
    - 소수의 어노테이션만 사용해서 파이선 수치 계산 코드를 더 빠른 바이너리 코드로 컴파일할 수 있음
    - Pythran은 사이썬과 거의 비슷한 수준으로 속도를 높이지만, 해야 할 일은 훨씬 더 적음 
    - Pythran은 GIL을 항상 해제하며 SIMD 명령어와 OpenMP를 모두 활용함 
    - Numba와 마찬가지로 Pythran은 클래스를 지원하지 않음
  - Transonic
    - 사이썬,Pythran,Numba 등의 컴파일러를 통일한 단일 인터페이스를 제공함 
    - 코드를 재작성하지 않고도 여러 컴파일러를 빠르게 평가할 수 있음 
  - ShedSkin
    - 과학 계산이 아닌 순수 파이썬 코드를 목표로 만들어지 AOT 컴파일러
    - numpy를 지원하지 않음
  - PyCUDA 
    - PyOpenCL
      - CUDA와 OpenCL 바인딩을 파이썬에 제공하여 직접 GPU에 접근할 수 있게 해줌 
  - Nuitka
    - 일반적인 C파이썬 인터프리터의 대안으로 개발된 파이썬 컴파일러로, 컴파일한 실행 파일을 만드는 옵션을 제공함 
- GPU
  - 동적 그래프 : 파이토치
    - 파이토치는 정적 계산 그래프 텐서 라이브러리로, 특히 numpy에 익숙한 사용자가 이용하기 쉬우며 API도 아주 직관적
    - 파이토치는 텐서 라이브러리이므로 numpy와 같은 기능을 제공하며, 자체 저적 계산 그래프를 통해 함수를 만들고 이런 함수의 도함수를 autograd라는 메커니즘을 통해 계산해주는 기능을 추가로 제공함 
      - autograd는 어떤 값에 대해서도 즉석에서 도함수를 계산할 수 있음
  - 정적 계산 그래프
    - 파이토치 객체에 대한 연산을 수행하면 백그라운드에서 GPU 코드로 컴파일될 수 있는 프로그램의 동적인 정의를 만들어낸다는 뜻 
    - 동적이므로 파이썬 코드를 변경하면 자동으로 GPU 코드에 반영되며, 별도의 컴파일 단계가 필요치 않음, 이 덕분에 텐서플로 같은 정적 그래프 라이브러리보다 디버깅이 쉽고 상호작용성이 늘음 
   - 텐서플로와 같은 정적 그래프에서는 먼저 계산을 설정한 다음 컴파일 해야함, 그 후에는 계산이 돌에 새겨진 것처럼 고정되며, 전체를 다시 컴파일해야만 계산을 변경할 수 있음
   - 파이토치 같이 동적인 그래프에서는 계산 그래프를 조건에 따라 바꾸고 점진적으로 구축해나갈 수 있다. 따라서 코드를 조건에 따라 디버깅할 수도 있고, IPython 대화식 세션에서 GPU에서 코드를 실행해볼 수도 있다. 유연하게 GPU를 제어하는 능력은 복잡한 GPU 기반의 부하를 처리할 때 완벽한 게임 체인저(game changer)
- 기본 GPU 프로파일링
  - GPU를 얼마나 활용하는지 정확히 검증하는 한 가지 방법은 nvidia-smi 명령을 사용해 GPU의 자원 활용도를 살펴보는 것 
  - 가장 관심을 가져야 할 두 값은 소비 전력(power usage)과 CPU 사용률(utilization)
  - GPU 사용 시 성능상 고려할 점
    - GPU는 컴퓨터에서 완전히 보조적인 하드웨어이고, CPU와 비교될 만큼 자체적인 구조를 가지므로 GPU에만 해당하는 성능상 고려 사항이 많음 
    - GPU 속도에서 가장 고려해야 할 점은 시스템 메모리에서 GPU 메모리로 데이터를 전송하는 데 걸리는 시간 
- 캐스팅(casting) : 함수 객체의 인자와 변환 타입을 명시하는 일과 더불어, 함수에서 사용할 데이터 타입도 변환해야 함 
- cffi
  - 임포트하고 결과를 만드는 함수의 타입을 제대로 지정했는지 검사함 

## 비동기 I/O
- 실제 코드 자체보다는 코드에 필요한 데이터를 얻어오는 작업이 병목이 될 수도 있음, 프로그램이 I/O위주(I/O bound)
- I/O 대기(I/O wait) : 일시 정지된 상태를 일컬음
- 비동기 프로그래밍 소개
  - 일반적으로 프로그램이 I/O 대기에 들어가면, 실행이 멈추고 커널이 I/O 요청과 관련된 저수준 연산을 처리하며(이를 컨테스트 스위칭), I/O 연산이 끝날 때까지 ㅡ로그램은 재개되지 앟음, 컨텍스트 스위칭은 상당히 비싼 연산 
  - 동시성 프로그램은 보통 실행할 대상과 시점을 관리하는 이벤트 루프를 사용함, 이벤트 루프는 실행할 함수의 목록에 지나지 않음 
  - 콜백 패러다임에서는 각 함수를 호출할 때 콜백이라는 인자를 넘김, 함수가 값을 반환하는 대신, 극 값을 인자로 실어 콜백 함수를 호출함. 이 구조에서는 호출한 함수의 결과를 받는 함수가 더해지고, 다시 그 함수의 결과를 받는 또 다른 함수가 더해지면서 함수의 사슬이 만들어짐
    - 콜백 지옥 : 위의 방식으로 콜백 깊이가 깊어지는 상황
- async/await의 동작 방식
  - async 함수(async def)는 코루틴(coroutine)이라 불림
  - 파이썬에서 코루틴은 제너레이터와 같은 철학으로 구현됨, 제너레이터에 이미 실행을 일시 중단하고 나중에 계속 실행할 수 있는 장치가 있으므로 구현이 편리함, 이 패러다임을 사용하면 await 문은 함수의 yield문과 기능 면에서 비슷해짐 
- gevent
  - 굉장히 단순한 비동기 라이브러리, 비동기 함수가 퓨처를 반환한다는 패러다임을 따름, 코드의 로직 대부분을 동시에 실행할 수 있다는 뜻 
  - gevent는 표준 I/O 함수를 몽키패치(monkey patch)해서 비동기적으로 만듬, 보통 표준 I/O 패키지를 사용하기만 해도 비동기적 동작의 이점을 살릴 수 있음 
  - 그린렛(greenlet)은 코루틴의 일종으로 스레드와 같다고 생각할 수 있음 
- tornado
  - 파이썬 비동기 I/O에 자주 사용함, HTTP 클라이언트와 서버를 위해 페이스북에서 개발한 패키지
- 파이프라이닝 : 결과를 일괄 처리하는 방식
  - I/O 작업의 부하를 낮추고 싶을 때 큰 도움이됨, 파이프라이닝은 비동기 I/O의 속도와 순차 프로그램의 작성 용이성을 잘 절충한 방식, 파이프라이닝 시 사용할 적절한 묶음의 크기는 상황에 따라 달라지므로 최선의 결과를 얻으려면 프로파일링과 튜닝이 필요함 
- gevent는 비동기 I/O를 위한 가장 높은 수준의 인터페이스를 제공함, tornado와 aiohttp를 사용하면 비동기 I/O 스택을 직접 제어할 수 있음, 서로 다른 수준의 추상화와 더불어, 각 라이브러리는 서로 다른 문법 패러다임을 사용함, asyncio는 비동기 해법을 하나로 묶는 접착제이며, 이 모두를 제어할 수 있는 토대를 제공함 

## multiprocessing 모듈 
- 프로세스와 스레드 기반의 병렬 처리를 사용해서 작업을 대기열에 분산시키고 프로세스 간에 데이터를 공유할 수 있또록 함, 단일 컴퓨터의 멀티 코어 병렬 처리에 초점이 맞춰져 있음
- 가장 일반적인 사용법은 CPU 위주의 작업을 여러 프로세스로 병렬화하는 것, I/O 위주의 문제를 병렬화하는 데 OpenMP 모듈을 사용할 수도 있음 
- multiprocessing 모듈로 처리할 수 있는 전형적인 작업의 예
  - CPU 위주의 작업을 Process나 Pool 객체를 사용해 병렬화함
  - dummy 모듈을 사용해서 I/O 위주의 작업을 스레드를 사용하는 Pool로 병렬화함
  - Queue를 통해 피클링(pickling)한 결과를 공유함
  - 병렬화한 작업자 사이에서 바이트,원시 데이터 타입, 사전, 리스트 등의 상태를 공유함 
- 파이썬스레드가 OS의 네이트브 스레드이며(즉 파이썬 스레드는 실제 운영체제가 실행하는 스레드로, 에뮬레이션된 것이 아님), GIL에 의해 제한되며, 한 번에 오직 한 스레드만 파이썬 객체들과 상호작용할 수 있음을 알아야만 함 
- 프로세스를 사용하여 여러 파이썬 인터프리터를 병렬로 실행할 수 있고, 각각의 인터프리터는 독립된 메모리 공간과 GIL을 가지며, 각각 순차적으로 실행됨(따라서 각각의 GIL을 두고 경쟁하지 않음), 파이썬에서 CPU 위주의 작업의 속도를 높이는 가장 쉬운 방법
- multiprocessing 모듈 소개
  - 프로세스와 스레드 기반의 병렬화를 위한 저수준 인터페이스를 제공함
  - 프로세스(process)
    - 현재 프로세스를 포크(fork)한 복사본, 새로운 프로세스 식별자가 부여되며 운영체제상에서 별도의 자식 프로세스로 작업을 실행함, Process를 시작하고 상태를 쿼리할 수 있으며, 실행할 target 메서드를 지정할 수 있음 
  - 풀(Pool)
    - Process나 threading. Thread API를 감싸서 사용하기 편한 작업자 풀(worker pool)로 만듬, 작업을 공유하고 합쳐진 결과를 반환함 
  - 큐(Queue)
    - 여러 생산자(producer)와 소지바(consumer)가 사용할 수 있느 FIFO(선입선출) 대기열
  - 파이프(Pipe)
    - 두 프로세스 사이의 단방향 또는 양방향 통신 채널 
  - 관리자(Manager)
    - 프로세스 간에 파이썬 객체를 공유하는 고수준의 관리된 인터페이스
  - ctypes
    - 프로세스를 포크한 다음 여러 프로세스가 원시 데이터 타입(예: 정수, 실수, 바이트)을 공유하게 해줌 
- 프로세스를 사용하는 버전은 이런 제약이 없음, 각 프로세스가 단일 스레드를 실행하는 별도의 파이썬 인터프리터이니 공유 객체로 인한 GIL 경쟁이 없음 
- Joblib 라이브러리
  - multiprocessing 라이브러리 위에 만들어졌으며, 여러 플랫폼 간 호환성을 높여주고, 병렬화를 위한 간단한 API를 제공하며, 캐시된 결과를 편리하게 영속화하게 해줌 
  - multiprocessing을 개선한 모듈로 경량 파이프라이닝을 활성화하면서 병렬 계산을 쉽게 하고, 결과를 쉽게 디스크 기반의 캐시로 사용할 수 있게 해줌 
  - 다음과 같은 경우 Joblib을 사용하면 쉽게 성능을 높일 수 있음
    - 당황스러울 정도로 병렬적인 루프를 처리하는 데 순수 파이썬을 사용 중(넘파이 사용 여부는 상관 없음)
    - 출력을 디스크에 저장해 세션과 세션 사이에 결과를 캐시할 수 있는데도, 부작용 없이 비용이 많이 드는 함수를 호출함
    - 프로세스 사이에 넘파이를 공유할 수 있지만 어떻게 하는지를 모름
  - Joblib은 Loky 라이브러리 위에 만들어졌고(Locky는 파이썬 concurrent.futures를 개선한 라이브러리) cloudpickle을 사용해 상호작용 영역에서 정의된 함수를 피클링할 수 있음. 내장 multiprocessing 라이브러리를 사용할 때 흔히 경험하는 몇몇 문제를 해결할 수 있음
  - 병렬 계싼에는 Parallel 클래스와 delayed 데커레이터가 필요함. Parallel 클래스는 앞절에서 사용한 multiprocessing의 pool과 비슷한 프로세스 풀을 만듬, delayed 데커레이터는 대상 함수를 감싸서 함수가 이터레이터를 통해 인스턴스화된 Parallel 객체에 접근할 수 있게 함 
  - 함수 호출 결과를 똑똑하게 캐시하기
    - Joblib의 Memory 캐시는 유용한 기능 
    - Memory는 함수 결과를 입력 인자에 따라 디스크 캐시로 저장하는 데커레이터, 이 캐시는 파이썬 세션 간에 영속적으로 유지되므로, 컴퓨터를 껐다가 다음날 켜서 같은 코드를 다시 실행해도 캐시에 저장한 결과를 사용할 수 있음 
- 작업 큐
  - multiprocessing.Queue 객체는 피클 가능한 파이썬 객체를 프로세스 간에 전송할 수 있는 영속적이지 않은 큐를 제공함. 각 객체를 전송하려면 피클화해야 하고, 소비자에서는 이를 다시 언피클해야 하므로 이 과정에는 부가비용이 듬(락 관련 연산 비용도 듬) 
- 회복탄련성(resilience)을 위해 작업 그래프 사용을 고려하기. 오래 실행되는 큐를 사용하는 데이터 과학 작업은 비순환 그래프로 이뤄진 작업 파이프라인으로 지정하면 잘 작동하는 경우가 많음, 강력한 라이브러리로 Airflow와 Luigi가 있음, 업계에서도 이들을 자주 사용하며 임의의 작업 체이닝, 온라인 감시, 유연한 규모 확장을 지원함 
- Manager.Value를 플래그로 사용하기
  - multiprocessing.Manager()를 사용하면 고수준 파이썬 객체를 프로세스 간에 매니지드(managed) 공유 객체로 활용할 수 있음
  - 저수준 객체들은 프록시(Proxy) 객체로 감쌈, 감싸고 안전성을 보장하면서 속도가 느려지는 대신 엄청난 유연성을 얻을 수 있음. 정수나 부동소수점 수같은 저수준 객체와 리스트, 사전 등을 모두 공유할 수 있음 
- 레디스를 플래그로 사용하기
  - 레디시는 인메모리 키/값 저장소 엔진 
  - 자체 락을 제공하며 각 연산은 원자적, 파이썬(또는 어떤 언어든) 안에서는 락 사용을 걱정할 필요가 없음 
  - 레디스를 사용하면 언어와 무관한 데이터 저장소를 만들 수 있음, 레디스와 인터페이스하는 언어나 도구라면 데이터를 서로 호환되는 방식으로 공유할 수 있다는 의미, 파이썬, 루비, C++, PHP 등의 언어 사이에서 데이터를 똑같이 쉽게 공유할 수 있음
  - 데이터를 한 컴퓨터에서 지역적으로 공유하거나 네트워크를 통해 공유할 수도 있음. 다른 컴퓨터와 공유하고 싶다면 레디스에서 지역적으로 공유하거나 네트워크를 통해 공유할 수도 있음, 다른 컴퓨터와 공유하고 싶다면 레디스에서 기본 제공하는 localhost의 공유 설정을 바꾸기만 하면 됨
  - 레디스 저장 내역
    - 문자열의 리스트
    - 문자열의 집합
    - 문자열을 정렬한 집합
    - 문자열의 해시 
  - 레디스는 모든 것을 RAM에 저장하고 디스크에 스냅샷을 저장하며(저널링 옵션 사용), 레디스 클러스터 사이에 마스터/슬레이브 복제를 지원함, 레디스를 사용하면 클러스터에서 부하를 공유할 수 있음 
  - 여러 컴퓨터가 상태를 읽거나 쓸 수 있고, 레디스는 고속 중앙 집중 데이터 리포지터리 역할을 함 
- RawValue를 플래그로 사용하기
  - multiprocessing.RawValue는 바이트의 ctypes 블록을 감싸는 얇은 래퍼, RawValue는 동기화 요소를 제공하지 않으므로 처리에 추가되는 부분이 거의 없어서, 검색 시 프로세스 사이에 플래그를 설정하는 가장 빠른 방법이 될 수 있음 
- mmap을 플래그로 사용하기
  - 바이트를 공유하는 가장 빠른 방식에 도달함 
  - mmap 모듈을 사용한 메모리 매핑(공유 메모리) 해법을 보여줌, 공유 메모리 블록의 바이트들은 동기화되지 않으며 부가비용도 매우 적음, 파일처럼 작동함(여기서는 파일과 유사한 인터페이스를 제공하는 메모리 블록) 
- $ps -A -o pid,size,vsize,cmd | grep np_shared(생략.py)
  - ps : 프로세스 정보를 표시함
  - -A : 모든 프로세스를 나열함
  - -o pid, size, vsize, cmd : PID, 크기 정보, 명령어 이름을 표시함
  - grep : 결과 중에서 우리 데모와 관련된 부분만 걸러내 표시함
- assert 검사 : 각 PID의 빈도가 예상과 일치하는지 확인하는 검사 

## 클러스터와 작업 큐 
- 클러스터 : 함께 협력해서 공통의 과업을 해결하는 컴퓨터의 모음 
- 서로 다른 계산 작업에는 서로 다른 클러슽터 설정, 크기, 용량이 필요함
- 클러스터화한 해법을 살펴보기 전에 확인해야할 것
  - 시스템을 프로파일해서 병목이 어딘지 판별했는가?
  - Numba나 사이썬 같은 컴파일러를 활용해봤는가?
  - Joblib이나 multiprocessing으로 단일 컴퓨터에서 멀티 코어를 활용해봤는가(코어가 더 많은 더 큰 기계에서 시도해봤는가)?
  - RAM을 덜 사용하기 위한 기법을 활용해봣는가?
- 제품이 정말 많은 CPU를 요구하거나, 데이터를 디스크에서 가져와 병렬 처리하는 능력이 필요하거나, 복원력이 높고 응답이 빨라야 한다면 클러스터로 옮겨가라
- 큰 컴퓨터 하나만 사용하면 네트워크를 사용하는 복잡성이 없어 Dask 등의 도구로 팬더스나 평범한 파이썬 코드를 쉽게 병렬화할 수 있다는 이점이 있음, Dask는 여러 컴퓨터로 이뤄진 클러스터를 제어해서 팬더스, 넘파이, 순수 파이썬 문제를 병렬화할 수도 있음
- Swifter는 Dask를 활용해 일부 멀티 코어 단일 컴퓨터 문제를 자동으로 병렬화할 수 있음.
- 클러스터링의 이점
  - 계산 요구사항에 맞춰 시스템을 쉽게 키울 수 있다는 점, 데이터를 더 많이 처리해야 하거나 답을 더 빨리 얻어야 한다면, 단지 더 많은 컴퓨터(또는 노드)를 추가하면 됨 
  - 컴퓨터를 추가하면 신뢰성도 높일 수 있음. 각 컴퓨터의 구성 요소는 어느 정도 실패할 확률이 있음 
  - 지리적으로 클러스터를 분리하더라도 여전히 중앙에서 제어할 수 있다는 점, 홍수나 정전 등으로 특정 지역에 문제가 생기더라도 다른 클러스터는 계속 동작함 
  - 서로 다른 소프트웨어 환경(예를 들어 서로 달느 운영체제 버전이나 처리 소프트웨어)을 실행하게 해줌 
- 클러스터링의 단점
  - 두 대 이상의 컴퓨터를 사용하면 어떤 일이 벌어질지를 염두에 둬야 함 
  - 장애를 용인할 수 있다는 젇모 고려해야 함 
  - 고정된 인프라를 유지하는 비용도 만만치 않음 
  - 소프트웨어 자동 업데이트에 문제가 생기고, 네트워크 카드가 고장 나며, 디스크에 쓰기 오류가 발생하고, 전원 공급 장치에서(데이터에 문제를 일으키는) 순간적인 고전압이 발생하고, 우주선(cosmic ray)이 RAM 모듈의 Bit를 뒤집을 수도 있음 
- 일반적인 클러스터 설계
  - 일반적으로 어느 정도 비슷한 수준의 컴퓨터로 애드혹 지역 클러스터를 구축하는 것부터 시작함 
  - 기가비트 이더넷 대신 인피니밴드(InfiniBand)를 사용하거나, 여러분의 읽기, 쓰기, 복원성 관련 요구사항을 충족하기 위해 특별히 설정된 RAID 드라이브를 사용할 수도 있음, 일부 컴퓨터에서는 CPU와 GPU를 조합하거나 그냥 CPU만 사용할 수도 있음 
- 클러스터화한 해법을 시작하는 방법
  - 컴퓨터를 부팅할 때 클러스터 구성 요소를 시작하는 작업의 신뢰성을 높이기 위해서, 크론(cron) 작업, 서커스(Circus), 슈퍼바이저드(supervisord)를 사용하고는 함 
  - 서커스와 슈퍼바이저드 모두 파이썬 기반이며 수년 전부터 사용했음, 크론은 오래된 방식이지만, 필요에 따라 하위 프로세스를 포크하는 모니터링 프로세스 등을 시작하는 스크립트를 실행하는 목적으로만 사용한다면 신뢰성이 매우 높음 
  - 넷플릭스의 카오스 몽키(Chaos Monkey)와 같은 임의 프로세스 킬러(killer) 도구를 사용할 수도 잇음, 시스템의 일부를 죽여서 회복성(resiliency)을 테스트하게 해줌 
- 두 가지 클러스터링 솔루션
  - IPython Parallel
    - IPython Parallel을 사용해 연구 지원하기
      - IPython 클러스터는 한 대의 멀티 코어 컴퓨터에서 사용하기가 매우 쉬움 
      - IPython Parallel을 사용하면 원격 클러스터(예컨대 아마존 AWS와 EC2)를 지역 클러스터처럼 쉽게 사용할 수 있다는 큰 이점 
      - IPython이 지역과 원격 처리 엔진의 인터페이스가 되어 데이터를 여러 엔진에 보내고 작업을 원격 컴퓨터에 밀어 넣을 수 있음, 원격 디버깅도 가능하며 선택적으로 메시지 전달 인터페이스(message passing interface - MPI)도 지원함
      - 작업을 지역 클러스터의 컴퓨터에 보낼 수 있고, 문제가 발생하면 서로 상호작용하며 디버깅할 수 있으며, 데이터를 여러 컴퓨터에 보내고, 결과를 수집할 수 있음, 이 모든 과정을 대화식으로 진행할 수 있음, PyPy도 IPython과 IPython Parallel을 실행한다는 점을 기억하라
      - 내부적으로 ZeroMQ를 메시지 전달 미들웨어로 사용함, ZeroMQ는 설계상 어떤 보안도 제공하지 않음을 유의
      - 프로젝트의 네 가지 요소
        - 엔진 
          - IPython 커널을 확장한 것
          - 엔진은 동기화된 파이썬 인터프리터로 코드를 실행함, 이런 엔진을 여럿 실행해서 병렬 계산을 하도록 만들 것 
        - 컨트롤러
          - 엔진에 대한 인터페이스를 제공함 
          - 작업 배분을 담당하고 작업 스케줄러를 제공하는 직접 인터페이스와 부하 분산 인터페이스를 제공함 
        - 허브(hub)
          - 엔진, 스케줄러, 클라이언트를 계속 추적함 
        - 스케줄러 : 엔진의 동기적인 특성을 감춰주며 비동기로 인터페이스를 제공함 
      - 아마존의 EC2와 같은 클라우드 서비스나 슈퍼컴퓨터를 포함하는 더 큰 클러스터 환경에서 사용할 수 있다는 점
      - ElastiCluster 프로젝트는 IPython 같은 공통 병렬 처리 환경을 제공하며 AWS, 애저, 오픈스택(OpenStack)등에 이를 배포할 수 있음 
    - Dask로 팬더스 병렬화하기
      - 노트북의 단일 코어부터 멀티 코어 컴퓨터, 더 나아가 클러스터의 수천 개의 코어까지 규모가 변할 수 있는 병렬화 해법 스위트를 제공하는 목표가 있음, 아파치 스파크 라이트(Apache Spark lite)
      - 아파치 스파크의 모든 기능(복제 쓰기와 다중 기기 페일오버(failover) 기능 포함)이 필요하지 않고 두 번째 계산 및 저장소 환경도 필요 없다면, Dask가 RAM 보다 더 큰 데이터를 처리할 수 있는 병렬화 해법을 제공해 줄 수 있음 
      - 작업 그래프는 일련의 계산 시나리오를 지연 계산하는 방식으로 구성됨 
        - 백(bag) : 구조화되지 않았거나 반쯤 구조화된 데이터를 병렬 계산할 수 있게 해줌, 데이터로는 텍스트 파일, JSON, 사용자 정의 객체 등이 있음 , map,filter,groupby를 리스트나 집합 같은 일반 파이썬 객체에 대해 지원함 
        - 배열 : array는 RAM보다 더 크고 분산된 numpy 연산을 수행하게 해줌 
        - 분산 DataFrame : dataframe은 RAM 보다 더 크고 분산된 팬더스 연산을 수행하게 해줌 
        - Delayed : 임의의 파이썬 함수 체인을 지연 계산하자는 아이디어를 확장함, visualize() 함수가 작업 그래프를 그려서 문제 분석을 도와줌 
        - 퓨처 : 지연 계산을 하고 작업 추가나 삭제를 지원하지 않는 delayed와 달리 Client 인퍼테이스는 작업을 즉시 실행하고 계산하게 해줌, Future 인터페이스는 작업 간의 협력을 지원하는 Queue와 Lock을 제공함 
      - 팬더스 사용자에게는 Dask가 RAM보다 더 큰 데이터셋과 멀티 코어 병렬화라는 두 가지 용례에 도움이 됨, 노트북의 멀티 코어를 (클러스터에서 활용하는 것만큼 쉽게) 활용하는 것 
    - Dask에서 Swifter를 사용해 apply 병렬화하기 
      - Dask 위에 만들어진 Swifter는 아주 간단한 세 가지 호출(appy, resample, rolling)을 사용한 병렬화를 제공함
      - 내부에서 Swifter는 DataFrame의 하위 샘플을 추출해서 함수 호출을 벡터화하는 시도를 함, 이 방식이 잘 작동하면 그대로 적용하고, 작동은 하지만 느리다면 Dask를 사용해 멀티 코어상에서 실행함 
      - 휴리스틱을 사용해서 코드 실행 방식을 결정하므로, Swifter를 사용하지 않을 때보다 코드가 느려질 수 있음, 하지만 한 번 사용해보는 데 드는 비용은 코드 한 줄뿐
      - Dask로 얼마나 많은 코어를 사용할지와 이를 평가하는 데 얼마나 맣ㄴ은 행을 샘플링할지 스스로 결정함 
    - RAM보다 큰 DataFrame을 위한 Vaex
      - RAM보다 더 큰 데이터의 계산을 지원하는 팬더스 DataFrame과 비슷한 구조를 제공하는 새로운 라이브러리 
      - 지연 계산을 사용해 열 결과를 그때끄때 계산함 , 사용자가 요청하는 행에 속한 열만 계산함 
      - 팬더스의 문자열 지원은 C파이썬에서 왔고, GIL에 의해 제한됨, 문자열 객체들은 메모리상에 여기저기 흩어져 있는 큰 객체이며, 벡터화한 연산을 지원하지 않음, Vaex는 자체 문자열 라이브러리를 사용해 팬더스와 비슷한 인터페이스를 제공하면서 충분히 빠른 문자열 기반 연산을 제공함 
      - 문자열을 많이 처리하거나 RAM보다 더 큰 데이터셋을 사용한다면 Vaex를 꼭 평가해보기 
  - NSQ
    - 프로덕션에 바로 사용할 수 있는 큐 시스템 
    - 영속성을 제공하며(따라서 컴퓨터가 죽으면 작업을 다른 컴퓨터가 가져갈 수 있음), 규모 가변성을 지원하는 강력한 메커니즘을 제공함 
    - 강건한 프로덕션 클러스터링을 위한 NSQ
      - 프로덕션 환경에서는 지금까지 언급한 것보다 훨씬 더 강건한 솔루션이 필요함, 클러스터를 매일 운용하는 상황에서는 일부 노드를 사용할 수 없게 되거나, 코드가 오류로 중단되거나, 네트워크가 망가지거나, 그 외의 일어날 가능성이 있는 수천 가지 문제 중 어떤 일이 벌어질 것이기 때문 
      - NSQ는 고성능 분산 메시징 플랫폼으로, 고(GO) 언어로 작성되었지만 데이터 형식이나 언어와 무관함, 다양한 언어용 라이브러리가 존재하며, NSQ의 기본 API가 REST라서 HTTP 호출만 가능하다면 사용할 수 있음, 더 나아가 JSON, 피클, msgpack 등 어떤 형태로든 원하는 형식으로 메시지를 보낼 수 있음
      - 메시지 배달을 근본적으로 보장해주며, 큐와 출판자/구독자(publisher/subscriber, pub/sub)라는 단순한 두 디자인 패턴을 사용해 이 모든 기능을 제공한다는 점 
      - NSQ를 선택한 이유는 사용이 쉽고 전반적인 성능도 좋기 때문, NSQ가 클러스터상의 큐와 메시징에서 고려해야 할 내용을 명확히 보여준다는 점 
    - 큐
      - 메시지를 위한 버퍼의 일종, 메시지를 처리 파이프라인의 다른 부분에 전달하고 싶을 때 큐에 메시지를 보냄. 큐는 메시지를 저장했다가 다른 작업자가 요청하면 해당 메시지를 그 작업자에게 내어줌. 
      - 분산 처리에서 생산자와 소비자 사이의 불균형이 존재할 때 큐가 가장 유용함. 불균형이 생기면, 단지 생산과 소비 비율이 같아질 때까지 소비자를 추가하면 됨. 메시지를 소비해야 하는 컴퓨터가 작동을 멈춰도 메시지가 손실되지 않고 다른 소비자가 나타날 때까지 큐에 남음. 메시지 배달을 보장할 수 있음 
      - 추천서버 큐 예시
        - 사용자가 웹 사이트의 새 상품을 평가할 때마다 새로운 상품을 추천하고 싶다고하자. 큐가 없다면 추천을 담당하는 서버가 얼마나 바쁜가와는 관계없이 평가라는 동작이 직접 추천 상품 재계산 동작을 시작할 것, 갑자기 수천 명이 상품을 평가한다면, 추천 서버는 너무 많은 요청을 받아서 타임아웃을 발생시키기 시작하고, 자신에게 들어온 요청 메시지를 잃어버리며, 결국 요청에 더 응답할 수 없게 됨.
        - 반면, 큐가 있다면 추천 서버가 준비되었어을 때만 추가 작업을 요청할 것, 새로운 평가동작은 새 작업을 큐에 넣고, 추천 서버는 작업을 수행할 준비가 된 경우에만 새 작업을 큐에서 가져와서 처리할 것, 이런 설정 하에서 평소보다 많은 사용자가 상품을 평가한다면, 큐가 차오르기 시작하며 추천 서버를 위한 버퍼 역할을 담당하게 됨, 큐가 빌 때까지, 즉 모든 메시지를 처리할 때까지 추천 서버의 부하는 변화가 없을것 
        - 큐가 잇는 시스템을 사용할 때는 평소의 작업량을 처리하는 데 최대 처리 능력의 60% 정도를 사용하도록 구성하는 편이 좋음, 일반적인 수준을 넘어서는 부하가 가해지는 상황을 충분히 처리할 수 있으면서도 예비 자원을 너무 많이 할당하지 않도록 하는 합리적틴 타협점 
      - NSQ는 다수의 저장소 백엔드를 제공하는 방식, 메시지 양이 메모리 용량을 초과하면 메시지를 디스크에 저장함 
    - 출판자/구독자
      - 누가 어떤 메시지를 받을지를 표현함 
      - 데이터 출판자는 특정 주제의 데이터를 밀어 넣을 수 있고 데이터 구독자는 서로 다른 데이터 피드(feed)를 구동할 수 있음. 출판자가 정보를 밀어 넣으면 모든 구독자에게 그 정보가 전달됨(각 구독자는 원본 메시지와 동일한 복사본을 받음)
      - NSQ는 데이터 소비자라는 개념을 추가함, 동일한 데이터를 구독하는 데 여러 프로세스가 관심을 보일 수 있음 
      - 출판자/구독자/소비자 패러다임
        - 클릭됨이라는 주제에서 새로운 메시지가 출판된다면, 관련한 모든 구독자(측정,스팸,분석,아카피으, NSQ의 용어로는 채널)는 복사본을 받음. 각 구독자는 소비자 하나 이상으로 이뤄지고, 소비자는 해당 메시지에 반응하는 실제 프로세스를 표현함 
    - 분산 소수 계산
      - NSQ를 사용하는 코드는 보통 비동기적
        - 비동기성은 NSQ가 소비자에게 밀기 기반(pull-based)방식으로 메시지를 전달하는 프로토콜을 사용하기에 가능함, 밀기 방식을 사용하면 사용자가 작성한 코드는 NSQ에 대한 연결에서 데이터 읽기를 비동기적으로 시도하면서 백그라운드로 내려가 있다가, 메시지가 들어오면 신호를 받고 다시 깨어남 
        - 파이프라이닝 : 동일한 데이터에 대한 여러 유형의 분석을 효율적으로 수행할 수 있는 방법 
        - 핸들러(handler) : 단순히 해당 주제의 메시지가 도착하면 호출하는 함수 
- 클러스터 환경에서 많이 사용하는 도구
  - ZeroMQ
    - 저수준, 고성능 메시징 라이브러로 노드 사이에 메시지를 주고 받게 해줌
    - 처음부터 출판자/구독자 패러다임을 지원했고, 여러 유형의 전송방식(TCP,UDP,웹소켓 등) 위에서 메시지를 보낼 수 있음 
    - 아주 저수준이며 유용한 추상화를 그리 많이 제공하지는 않아서 조금 사용하기는 어려움 
  - BSD 라이선스의 셀러리
    - 널리 사용 중인 비동기 작업 큐, 분산 메시지 구조를 사용하며 파이썬으로 작성됨 
    - 셀러리는 파이썬,PyPy,Jython으로 포팅됨, 보통은 메시지 브로커로 RabbitMQ를 사용하지만 레디스나 몽고 DB도 지원함
    - 웹 개발 프로젝트에서 자주 사용함 
  - Airflow
    - 방향성 비순환 그래프를 사용해 의존관계가 있는 작업을 시퀀스로 만들고 신뢰성 있게 실행하며, 모니터링과 보고 서비스를 제공함 
  - SQS
    - 아마존의 단순 큐 서비스(Simple Queue Service) 는 아마존 웹 서비스에 통합된 작업 처리 시스템
    - 작업 소비자와 생산자들은 AWS 안에서 실행되거나 외부에 있을 수 있음
    - SQS는 시작하기 쉽고 클라우드에 통합하기도 편리함. 다양한 언어에서 사용할 수 있는 라이브러리도 제공함 
- 도커
  - 여러분의 코드를 실행하고, 런타임 환경을 공유하고 제어하며, 팀원 사이에서 실행 코드를 쉽게 공유하고, 자원의 필요에 따라 클러스터 노드에 코드를 배포할 수 있는 재생산 가능한 환경을 제공함 
  - 성능
    - CPU와 메모리 접근 측면에서 도커(그리고 다른 모든 컨테이너 기반 해법)는 어떤 성능 저하도 가져오지 않음. 도커는 코드가 평범하게 실행될 수 있는 호스트 운영체제 안에, 다른 실행 중인 프로그램과 별도의 제약사항을 가지는 특별한 이름공간을 만들기 때문 
    - VMware나 VirtualBox와 같은 하드웨어 수준의 가상화가 아니라 운영체제 수준의 가상화 인스턴스이기 때문. 하드웨어 가상화를 하면 소프트웨어는 모든 자원 접근 시 부가비용이 붙는 가짜 하드웨어상에서 실행됨. 운영체제 가상화는 가짜 운영체제상의 진짜 하드웨어를 사용함 
  - 고성능 코드가 포함된 도커 컨테이너를 만들 때 고려해야 할 목록
    - 도커 컨테이너에 데이터를 너무 많이 복사하거나, 도커 빌드와 똑같은 디렉터리에 너무 많은 데이터를 함께 두는 일을 피하라, build context가 너무 크면 성능이 나빠짐(.dockerignore 파일로 이를 해결할 수 있음) 
    - 도커는 여러 파일 시스템 트릭을 사용해서 한 파일 시스템 위에 다른 파일 시스템을 추가하는 식으로 도커 내에서 사용할 파일 시스템 구조를 만들어 줌. 이렇게 하면 빌드를 캐시할 때는 좋지만 직접 호스트 파일 시스템을 다룰 때보다 속도가 느려짐 
    - 데이터에 빠르게 접근해야 한다면 호스트 수준의 마운트(mount)를 사용하거나, volumes를 읽기 전용으로 설정해서 사용할 인프라에 적합한 볼륨 드라이버를 선택하라 
    - 도커는 모든 컨테이너가 사용할 가상 네트워크를 만듬. 이 네트워크는 도커에서 실행되는 서비스 대부분을 게이트웨이 뒤에 감추는 데 유용하지만 약간의 네트워크 부가비용이 발생함, 대부분의 용례에서 부가비용은 무시할만하지만, 네트워크 드라이버를 변경해서 부가비용을 줄일 수도 있음
    - 도커 전용으로 만들어진 런타임 드라이버를 사용하면 GPU나 다른 호스트 수준의 장치에 접근할 수 있음
    - 문제가 무엇인지 알아내고 쉽게 효율성을 높일 수 있는지 알아내려면 도커 컨테이너를 프로파일링 해야함, docker stats 명령어는 컨테이너의 현재 실행 시점 성능을 이해하는 데 도움이 되는 고수준의 뷰를 제공함 
  - 장점
    - 도커를 사용하지 않으면 성능 퇴행이 발생했을 때 실행 환경을 다시 재현하기 어려워서 테스트가 힘들지만, 도커가 있으면 굉장히 쉽게 과거 버전의 성능을 계속 테스트할 수 있음 
    - 도커 이미지를 저장하고 공유하는 작업을 docker pull과 docker push라는 간단한 명령어를 사용해 수행할 수 있음 
    - 코드를 도커화하면서 쿠버네티스(kubernetes)나 다른 유사 기술을 사용하면 실제 코드를 필요한 자원과 함께 실행할 때 도움이됨, 쿠버네티스를 사용하면 노드로 이뤄진 클러스터를 만들고, 각 노드에 자원 이름으로 레이블을 붙이고, 노드에서 실행되는 컨테이너를 조율하며 관리할 수 있음. 쿠버네티스는 실행되는 인스턴스 개수가 맞는지 확인해줌 
    - 도커 가상화 덕분에 각 인스턴스에서 실행되는 코드는 모두 여러분이 도커에 저장한 환경과 똑같은 환경에서 실행됨 

## RAM 덜 사용하기 
- 데이터에는 질량이 있다. 데이터가 크면 클수록 옮기는 데 더 큰 비용이 든다 
- 실행 중인 프로세스에서는 메모리를 캐시할 수 있음, memit을 사용해 메모리를 프로파일할 때는 항상 파이썬 셸을 종료하고 다시 시작하는 편이 더 안전함
  - %memit : 프로세스가 현재 소비 중인 RAM의 양을 보여줌 
- NumExpr을 사용해 넘파이에서 RAM 덜 사용하기
  - NumExpr은 중간 연산의 크기를 줄이고 속도를 높여주는 도구 
- 컬렉션이 사용하는 RAM 이해하기
  - sys.getsizeof(obj)를 호출하면 객체가 사용하는 메모리에 대해 무언가 알려줄 것(전부는 아니지만, 대부분의 객체가 이를 지원함) 
  - getsizeof는 비용 중 일부만을 보고하며 종종 부모 객체의 비용만을 알려줌, 유용성의 한계가 있음 
  - pympler의 asizeof : 더 나은 도구 
    - 컨테이너의 계층 구조를 뒤져서 찾아낸 모든 객체의 크기를 최선을 다해 추정한 다음, 전체 합계를 돌려줌. 하지만 상당히 느리다는 단점 
    - 추정이나 가정에 의존할 뿐 아니라 내부적으로 할당한 메모리도 측정할 수 없음 
    - 큰 리스트에 대해 추정한 크기를 검토해보기 
- 방향성 비순환 단어 그래프(DAWG)
  - 방향성 비순환 단어 그래프는 공통의 접두사와 접미사가 있는 문자열을 효율적으로 표현하려고 시도함 
  - 접두사 검색 등 다양한 질의를 지원함, 영속성을 허용하며 정수 인덱스뿐만 아니라 바이트(바이너리 데이터)나 레코드(파이썬 객체)도 값으로 저장하도록 지원함 
- 마리사 트라이
  - 외부 라이브러리에 대한 사이썬 바인딩을 사용하는 정적 트라이 
  - 정적이므로 한 번 만들고 나면 변경할 수 없음, DAWG와 마찬가지로 정수 인덱스를 값으로 저장할 수 있으며 바이트값과 레코드값도 저장할 수 있음 
  - 값을 차증ㄹ 때 키를 사용할 수 있고 역으로 가능함. 같은 접두사를 공유하는 모든 키를 효율적으로 찾을 수 있음
  - 트라이의 내용은 영속화할 수 있음 
  - 프로덕션 시스템에서 트라이(그리고 DAWG) 사용하기
    - 트라이는 메모리상에서 많은 문자열을 표현할 때 매우 효율적이며 이미 이를 구현해 둔 오픈 소스 라이브러리도 있어서(마리사 트라이를 선택) 사용하기도 아주 간단함 
    - 애프리케이션(플라스크 프레임워크로 만든 작은 웹 API까지 포함해도), 코드는 단순함. 서비스는 매우 가볍고 데이터베이스 의존성이나 외부 요구사항이 없으므로 헤로쿠(Heroku)와 같은 무료 호스팅 플랫폼에 어려움 없이 배포하고 실행할 수 있음
    - DAWG와 트라이는 강력한 자료구조로, 준비하는 데 약간의 노력을 추가함으로써 RAM과 시간을 절약해줌 
- 사이킷런의 FeatureHasher를 사용해 더 많은 테스트 모델링하기
  - 텍스트를 분리하는 강력하고 단순한 기법은 원본 텍스트를 n-그램(n-gram)으로 나누는 것, 보통 유니그램(unigram), 바이그램(bigram), 트라이그램(trigram)을 자주 씀(각각을 1-gram, 2-gram, 3-gram이라 부름)
- DictVectorizer와 FeatureHasher
  - DictVectorizer로 단어와 빈도로 이뤄진 사전을 입력받아 가변 너비 희소 행렬로 만들어줌 
  - FeatureHasher로 DictVectorizer의 입력과 같은 단어와 빈도수의 사전을 입력받아 고정 너비 희소 행렬을 반환함 
  - FeatureHasher는 단어 리스트를 저장하지 않고 해시 알고리즘을 사용해 각 열에 토큰 빈도를 할당함 
  - 해시는 유일한 원소(여기서는 텍스트 토큰)를 숫자로 변환해줌. 이때 여러 유일한 원소가 같은 해시값으로 매핑될 수도 있음. 이를 충돌이라 함, 많은 유일한 원소를 더 적은 표현으로 매핑하려면 충돌이 불가피함, 해시 함수는 역방향 변환이 어렵다는 특징이 있음. 따라서 해싱한 값을 원래의 토큰으로 되돌리 수는 업승ㅁ 
- RAM을 덜 사용하기 위한 팁
  - RAM에 넣지 않아도 되는 것은 넣지 말라. 어떤 것을 적재하든 RAM을 소비하게 됨, 데이터 중 일부만 적재하는 방법도 있음. 메모리 매핑한 파일을 사용할 수 있음 
  - 모든 데이터를 한 번에 다 적재하는 대신, 부분적으로 계산에 필요한 데이터만 적재하도록 제너레이터를 사용할 수도 있음 
  - 수치 데이터로 작업한다면 대부분 Numpy 배열을 사용 
  - 문자열을 다룰 때 바이트 수준에서 작업해야 하는 특별한 이유가 없다면 bytes 대신 str을 사용, 무수히 많은 텍스트 인코딩을 직접 처리하는 힘든 작업을 UTF-8(또는 다른 유니코드 형식)이 해결해줌 
  - 정적인 구조에 유니코드 객체를 많이 저장해야 한다면 이 장의 앞에서 설명한 DAWG나 트라이 구조를 사용할 수도 있음 
  - 수많은 Bit 문자열을 다뤄야 한다면 numpy와 bitarray 패키지를 살펴보기, 둘 다 Bit를 바이트에 집어넣어서 효율적으로 표현함. Bit 패턴을 효율적으로 저장해주는 레디스를 살펴보면 도움이 될 수도 있음 
  - PyPy 프로젝트는 균일한 자료구조를 더 효율적으로 표현하는 방식을 시험하고 있음, 동일한 원시 타입(예컨대 저웃)의 리스트는 C파이썬의 동일한 자료구조보다 PyPy에서 훨씬 비용이 덜 들것 
  - RAM 사용량을 최적화하려면 벤치마크해야 한다는 점과 알고리즘을 변경하기 전에 단위테스트 스위트를 만들어 두면 크게 도움이 된다는 점 
- 확률적 자료구조를 사용하면 정확도를 낮추는 대신 메모리 사용을 상당히 줄일 수 있음 
- 멱등성(idempotence) : 자료구조에서 같은 입력을 사용해 같은 연산을 반복하더라도 상태가 바뀌지 않는다는 뜻 
- 카디널리티는 집합 이론에서 비롯된 용어로 확률적인 자료구조를 분석할 때 더 많이 사용함 
- 블룸 필터(Bloom filter)
  - 이 원소를 전에 본 적이 있나?라는 질문에 답하기 위해 만들어짐  
  - 서로 다른 여러 해시 함수를 사용함, 어떤 값은 그 값을 여러 해시 함수로 해시한 결과로 이뤄진 정수 집합으로 표현할 수 있음 
  - 이중 해싱(double hashing) : 서로 독립적인 두 해시 함수만 있다면 다양한 해시 함수를 시뮬레이션할 수 있음 
  - 규모 확장성 볼륨 필터라는 변종들을 사용하는 것, 여러 개의 블룸 필터를 연결하는 방식으로 동작함. 각 블룸 필터의 오류율을 미리 특정한 방식으로 서로 다르게 설정함, 전체 오류율을 보장하면서 용량이 더 필요할때 단순히 새로운 블룸 필터를 추가해 늘릴 수 있음 
  - 타이밍(timing) 블룸 필터 : 자료구조에서 원소를 제외할 수 잇어서 원소를 추가하기 위한 공간을 확보할 수 있음. 스트림에 다룰때 특히 유용함, 최근 한 시간 동안 어떤 일이 벌어졌는지를 살펴볼 수 있는 좋은 뷰를 얻을 수 있음 
  - 쿠쿠 필터(Cuckoo filter)
    - 블룸 필터와 비슷한 기능을 제공하면서 객체를 더 쉽게 삭제할 수 있게 해줌 
    - 보통 부가비용이 더 적기 때문에 블룸 필터보다 공간을 더 적게 사용함, 추적할 객체 수가 고정됐다면 쿠쿠 필터가 더 나은 선택 
    - 부하 한계에 도달하면 성능이 급격히 나빠지고, 자료구조의 규모를 자동으로 확장할 방법이 없음(규모 가변성 블룸 필터와 쿠쿠 필터가 다른 점)
- 로그로그 카운터
  - 로그로그(LogLog) 유형의 카운터는 해시 함수의 개별 Bit를 난수처럼 생각할 수 있다는 깨달음에서 비롯됨, 해시의 첫 번째 Bit가 1일 확률은 50%이고, 처음 두 Bit가 01일 확률은 25%이며, 처음 세 Bit가 001을 확률을 12.5%이다. 확률을 알고 0이 가장 많은 해시(즉, 발생할 확률이 가장 낮은 해시값)를 시작 부분에 위치시킨다면 지금까지 얼마나 많은 원소를 살펴봤는지 추정할 수 있음 
  - 가장 큰 단점은 시작하자마자 카운터를 증가시키는 해시값을 입력으로 받으면 추정이 치우쳐버린다는 데 있음 
  - 슈퍼로그로그 : 레지스터 중 가장 낮은 70%만을 크기 추정에 사용하며, 각각의 값은 주어진 제약 규칙에 따른 최대값으로 제한됨 
  - 하이퍼로그로그 : 개별 레지스터의 평균을 계산하는 방법을 변경하여 정확도를 높였음, 단순 평균을 구하는 대신, 통계적으로 로그로그 방식이 고려해야 하는 여러 가지 극단적인 경우를 고려한 구형 평균 방식(spherical averaging scheme)을 사용했음 , 슈퍼로그에서 필요했던 정렬 연사을 없앨 수 있음, 이렇게 하면 많은 원소를 추가해야 할 때 자료구조의 성능을 엄청나게 높일 수 있음 
  - 정확도를 더 높인 알고리즘은 하이퍼로그 ++ 뿐, 상대적으로 많이 빈 자료구조의 정확도를 높임, 원소를 일정 수준 이상으로 추가하면 표준 하이퍼로그로그로 바뀜 

## 현장에서 얻은 교훈
- 특성 엔진으로 피처 엔지니어링 파이프라인 흐름 만들기
  - 피처 엔지니어링 : 변수 변환의 모음 
    - 빠진 데이터를 산입(impute)하고, 범주형 변수를 인코딩하고, 수치형 변수를 변화 또는 이산화하고, 특성들을 똑같은 스케일(scale)로 만들고, 여러 특성을 조합한 새로운 변수를 만들고, 날짜에서 정보를 추출하고, 트랜잭션 데이터를 하나로 합치고, 시계열(time series)이나 텍스트, 이미지에서 특성을 파생시키는 등의 작업이 포함됨 
  - 오픈 소스 프로젝트나 철저히 개발한 인하우스 라이브러리를 사용해야 하는 이유 
    - 잘 개발한 프로젝트는 보통 문서화도 철저하게 함. 따라서 코드의 각 부분이 달성하려는 목표가 무엇인지 명확함 
    - 안정된 오픈 소스 패키지에서는 버그가 생기지 않도록 막고, 변환이 원하는 결과를 달성하는지 확인하며, 재현가능성을 최대화하는 테스트가 이뤄짐 
    - 안정된 프로젝트는 커뮤니티에서 널리 사용하며 입증되었으니 코드 품질 측면에서 심리적인 안정을 얻을 수 있음
    - 연구와 프로덕션 환경에서 같은 패키지를 사용할 수 있어서 배포 중에 코드를 리팩토링하는 일을 최소화할 수 있음 
    - 패키지는 버전이 명확하므로 머신러닝 파이프라인을 개발할 때 사용한 버전을 프로덕션에 배포하여 재현가능성을 보장하면서 새 버전에 기능을 추가할 수 있음 
    - 오픈 소스 패키지는 공유할 수 있으니 여러 조직이 서로 협력해 도구를 개발하기 편함 
    - 오픈 소스 패키지는 숙련된 개발자들이 관리하지만, 커뮤니티를 통해서 패키지와 코드의 품질을 높여주는 새로운 아이디어나 기능을 추가할 수 있음 
    - 안정된 오픈 소스 라이브러리를 사용하면 직접 코딩하지 않아도 됨, 따라서 팀 성능, 재현가능성, 현업의 정도가 높아지는 동시에 모델 연구와 배포에 걸리는 시간을 줄일 수 있음 
  - 새 오픈 소스 패키지 적용 돕기
    - 성공적인 오픈 소스 패키지를 만들려면 성능이 좋으면서 테스트가 잘 되어있고, 제대로 문서를 제공하며, 유용한 코드를 작성하고, 커뮤니티가 이 패키지의 존재를 알게 하며, 사용자들이 패키지를 도입하도록 장려하고, 개발자 커뮤니티를 끌어들이는 등의 과정이 필요함 
    - 사용자는 새로운 기능을 제안할 수 있고, 개발자 커뮤니티는 더 많은 기능을 추가하며, 문서를 개선하고, 코드 품질을 높이면서 성능을 끌어올릴 수 있음, 즉 패키지 개발자가 코드를 개발하는 시간과 공유 전략을 설계하고 실행하는 시간을 배분해야 한다는 뜻 
  - 오픈 소스 라이브러리의 개발과 유지 그리고 기여 장려하기
    - 패키지를 개발할 때는 코드 유지보수성을 고려해야함, 코드가 단순하고 짧을수록 유지보수하기도 수비고 기여자나 메인테이너를 유치하기도 쉬움
    - 기여 지침은 새로운 기여자가 도움을 줄 수 있는 방법을 알려줌. 버그를 수정하거나, 새로운 기능을 추가하거나, 문서를 개선해서 프로젝트에 이바지할 수 있음. 새로운 기발자에게 기여 사이클(contributing cycle), 리포지터리를 포크하는 방법, 기여 브랜치에서 작업하는 방법, 코드 리뷰 사이클의 운영 방법, 풀 요청(pull request)을 보내는 방법도 알려줌 
    - 협업을 하면 코드 품질과 기능을 개선하고, 새 기능을 추가하며, 문서를 개선함으로써 라이브러리의 품질과 성능을 높일 수 있음 
- 고성과 데이터 사이언스 팀 
  - 예상과 산출물 관리하기
    - 산출물이 나오는 데 걸리는 시간에 영향을 끼치는 문제가 많음. 다음과 같은 요소에 주의를 기울여 팀 프로젝트에 예상되는 다양한 문제를 관리하라 
      - 조금씩 늘어나는 범위 : 작업 범위가 미묘하게 달라지면서 초기 계획보다 더 많은 작업이 필요해지는 현상, 짝코딩이나 검토가 이런 형상을 감소시킬 수 있음 
      - 비기술적 작업 과소평가 : 토론, 사용자 리서치, 문서화 등의 작업을 잘 모르면 쉽게 과소평가할 수 있음 
      - 가용성 : 팀 멤버의 일정 변경이나 참여가 불가능해지는 등의 일로 지연이 생길 수 있음 
      - 데이터 품질 문제 : 작업 데이터셋이 좋은지 확인하는 것부터 편향을 찾아내는 일에 이르기까지, 데이터 품질은 복잡한 문제를 일으키거나 종종 작업 결과를 버리게 할 수도 있음 
      - 대안 : 예상치 못한 문제가 발생하면 대안을 찾아보는 편이 합리적일 수 있음, 매몰 비용(SUNK COST) 때문에 팀이 이런 결정을 내리기 주저할 수도 있고, 이로 인해 작업이 지연되어 팀이 자신이 하는 일에 관해 잘 모른다는 인상을 줄 수 있는 위험이 있음 
      - 테스트 부족 : 데이터 입력이 갑자기 바뀌거나 데이터 파이프라인에 버그가 있으면 기존 가정을 무효화할 수 있음, 처음부터 프로젝트 전반에 걸쳐 테스트하면 팀의 속도가 높아지고 결국에는 테스트로 인한 이익을 돌려받을 수 있음 
      - 테스트나 검증의 어려움 : 가설을 테스트하고 검증하는 데 시간이 부족하다면 일정이 지연될 수 있음, 가정이 바뀌면 테스트 계획도 바꿔야 할 수 있음 
- Numba
  - 수치 계산에 초점을 맞춘 파이썬을 위한 오픈 소스 JIT 함수 컴파일러
  - Numba의 주된 용례는 수치 및 과학 계산 파이썬 코드의 가속화, 주 진입 점은 @jit 데커레이터로 이를 컴파일이 필요한 구체적인 함수(이상적으로는 애플리케이션의 병목 지점인 함수)에 적용하면 됨, Numba는 이런 함수를 JIT 컴파일함. 이는 함수를 최초 실행 시 컴파일한다는 뜻, 그 이후로 타입이 같은 인자를 전달해 함수를 실행하면 컴파일된 버전을 사용해 원래 버전보다 빠르게 작동함 
  - Numba는 파이썬만 컴파일하지 않고 넘파이를 인식해서 넘파이를 사용하는 코드도 컴파일함. 내부에서 Numba는 LLVM 프로젝트에 의존함. 재사용할 수 있고 모듈화된 컴파일러와 툴체인 기술의 모음 
  - 모범 사례와 권장 사항
    - Numba에 가장 중요한 권장 사항은 가능하면 노파이썬(nopython) 모드를 사용하라는 점, 이 모드를 활성화하려면 앞에서 본 소수 구하기 알고리즘처럼 nopython=True 옵션을 @jit 데커레이터에 지정해야 함. @njit 데커레이터 별명을 사용해도 됨 
- 어댑티브 랩의 소셜 미디어 분석, 소마 
  - 파이썬은 작고 독립적이며 오래 실행해야 하는 데몬에 이상적, 장고(django)와 피라미드(pyramid)처럼 유연하고 풍부한 기능을 제공하는 웹 프레임워크와 함께 사용하면 더 좋음. 파이썬 커뮤니티는 반성하고 있으며 오픈 소스 도구도 아주 다양함 
  - 프로비저닝(provisioning - 요청에 따라 서버를 설정하고 제공함)에는 솔트스택(SaltStack)을 사용하고, 장시간 실행되는 프로세스를 관리하기 위해 모질라(Mozilla)의 서커스를 사용함 
- RadimRehurek.com의 딥러닝 플라이 만들기
  - 스위트 스팟(sweet spot - 원래는 테니스, 골프, 탁구 등의 운동 용어로, 라켓으로 공을 맞힐 때 최고의 효과를 얻기 위해 여러 가지 요소를 고려한 최적 지점을 의미함)을 잘 선택한다면 가치/비용 비율을 최대화할 수 있음 
  - 단순하게 만들어, 멍청아!(Keep It Simple, Stupid!, KISS)
    - 가장 좋은 코드는 유지보수할 필요가 없는 코드, 간단한 코드로 시작해서 필요할 때마다 개선하라. 한 가지 일만 하되, 그 일을 잘하라라는 유닉스 철학을 따르는 도구를 선호함 
  - 파이썬의 풍부한 생태계의 이점을 살려라
    - numpy의 강력한 배열 인터페이스와 메모리 접근 패턴, 그리고 일반 벡터 연산을 엄청나게 빨리 수행해주는 BLAS 루틴을 감싼 기능을 활용하면 간결하고 깔끔하면서 빠른 코드를 만들 수 있었다(대강 만든 파이썬 코드보다 수백 배는 더 빠르다) 
  - BLAS를 알라
    - numpy의 산뜻한 특징 하나는 가능하면 BLAS(기본 선형대수 서브프로그램(Basic Linear Algebra Subprograms)이라는 뜻으로, 원래는 포트란에서 선형대수 등을 처리하기 위해 정의한 표준 라이브러리였으나, 현재는 다양한 언어로 된 구현체가 존재함)를 감싸서 사용한다는 점 
- Lyst.com의 대규모 머신러닝
  - 보고와 모니터링
    - 보고에는 그래파이트(Graphite)를 사용함, 배포하자마자 성능 회귀 정보를 눈으로 관찰할 수 있음 
    - 그래파이트를 활용하면 필요에 따라 쉽게 이벤트를 추가하거나 삭제하면서 상세 이벤트 보고서를 보고, 줌아웃해서 사이트 전체 현황을 조망하는 거시적 보고서를 살펴볼 수 있음 
    - 스테이징 사이트는 실제 방문자 중 일부에게 가장 나중 배포된 버전을 볼 수 있도록 하는 용도로도 활용함, 버그나 성능 퇴행이 발생하더라도 일부 방문자에게만 영향을 주고, 해당 버전을 빠르게 폐기할 수 있음. 이렇게 하면 버그를 배포하더라도 처리하는 비용이 적게 들고 문제도 적게 일으킴 
- 스메시에서의 대규모 소셜 미디어 분석
  - AWS와의 상호작용에 보토(Boto)를 사용
- 가독성과 유지보수성이 필요한 대규모 소스 코드로 이뤄진 순수 파이썬 프로젝트에서 실행 속도가 중요하다면 PyPy가 탁월한 선택.
- 모든 프로그램은 정적이거나 균일한 타입을 사용해 장시간 실행했기에 JIT가 큰 역할을 할 수 있었음. 전체 시스템을 C파이썬에서 테스트해본 결과 PyPy를 사용하면 C파이썬보다 약 2배 빨라졌음
- 앞으로 제공할 소프트웨어 트랜잭션 메모리(STM) 구현을 통해 파이썬 코드를 규모 가변성 있게 병렬 실행할 수 있으리라 기대함 
- 파이썬은 일반적으로 구성 요소 간의 느슨한 결합을 장려함, 이는 충분히 좋은 구현인 상태로 배포한 다음 나중에 더 나은 버전으로 대치하기 쉽다는 뜻 
