# 서평
- 이 책은 고성능 코드를 작성할 때 필요한 이론과 실무에 한 걸음 다가가고 싶은 분, 성능 좋은 시스템을 만드는 방법을 이해하고 싶은 모든 개발자, 파이썬을 충분히 사용해보았고 특정 부분이 왜 느린지 생각해본 적이 있으며, 이를 위한 해법으로 거론되는 사이썬(Cython), 넘파이, PyPy 같은 기술을 들어본 독자를 대상으로 하고있습니다. 또, 다른 언어로 프로그래밍해본 경험이 있어서 성능을 개선하는 방법이 여러가지임을 아는 독자분들에게 추천드립니다. 
- 책의 서평에서 책에서 다루는 전반적인 내용에 대해서 미리 알려줘서 전반적인 구조를 이해하는데 많은 도움이 되었습니다. 또한 이 책은 효율적이고, 이해하기 쉽고, 성능 좋은 시스템을 모두 달성하려는 사람을 위한 안내서입니다.
- 고성능 파이썬의 저자인 이안 오스발트는 다음과 같은 말을 서술하였습니다. 축하할만한 일의 로그를 작성하라는 것입니다. 성취했던 일을 잊고 일상에 묻혀 지내기 쉽습니다. 사람들은 쉴 새 없이 달리기 때문에 번아웃되는 게 아니라, 자신이 얼마나 발전했는지 잊어버려서 번아웃된다. 축하할만한 일의 목록을 만들고, 각각 어떻게 축하할지 적어보아라. 이런 의미에서 회고를 하면서 한 해를 돌아보는 과정이 새로운 해에 번아웃은 없이 기술을 갈고닦는데 도움이 된다고 생각합니다. 개인적인 삶의 우선순위를 더 높여서 컴퓨터와 일에서 며칠 떨어져 기술적이지 않은 일을 하면서 축하할만한 일의 로그를 작성하려고 합니다. 

# 들어가며 
- 파이썬은 고수준 언어이면서 배터리 포함이라는 개념하에 다양한 도구를 기본 제공하므로 누구나 쉽게 데이터 전처리나 데이터 분석에 사용할 수 있음, 파이썬은 너무 고수준 언어라서 이를 실행해주는 운영체제나 컴퓨터 시스템 전반을 충분히 이해하지 못할 때가 많음 
- 대용량 자료구조를 처리하는 과정에서 병렬 처리의 어려움이나 메모리 장벽, 성능 저하 등으로 문제가 있을때 저수준의 최적화 기법이나 시스템을 이해하면 도움이 됨 
- 책에서 다루는 내용
  - 컴퓨터의 저수준 동작 방식 : 내부적으로 어떤 일이 일어나는지 이해하기 
  - 리스트와 튜플 : 기본 자료구조인 리스트와 튜플의 미묘한 의미 차이와 속도 차이
  - 사전과 셋 : 중요한 자료구조인 사전과 셋의 메모리 할당 전략과 접근 알고리즘
  - 이터레이터 : 이터레이터를 통해 데이터를 스트리밍 하는 방법과 더 파이썬다운 코드를 작성하는 방법
  - 순수 파이썬 방식의 접근 : 파이썬과 모듈을 효율적으로 사용하는 방법
  - 행렬과 넘파이 : numpy 라이브러리를 고수처럼 사용하는 방법
  - 컴파일과 JIT 컴퓨팅 : 기계어로 컴파일해 더 빠르게 처리하기, 프로파일링 결과에 따라 성능 개선 방향 정하기
  - 동시성 : 데이터를 효과적으로 옮기는 방법
  - 다중 처리 : 병렬 컴퓨팅과 numpy 행렬을 효율적으로 공유하기 위해 기본 라이브러리인 multiprocessing 모듈을 이용하는 방법, 프로세스 간 통신(IPC)의 비용과 장점
  - 클러스터 컴퓨팅 : 연구나 프로덕션 시스템에서 다중 처리를 사용한 코드를 수정하여 로컬 또는 리모트 클러스터에서 실행하는 방법
  - 메모리 아껴 쓰기 : 크고 비싼 컴퓨터를 구입하지 않고 대용량 문제를 해결하는 접근법
  - 현업에서 얻은 교훈 : 현업에서 고군분투했던 문제에서 얻은 교훈을 통해 같은 문제를 겪지 않도록 예방하기 

# 고성능 파이썬 이해하기 
- 컴퓨터 프로그래밍이란 특별한 방법으로 데이터를 가공해서 주고받으며 어떤 결과를 얻는 과정 
- 고성능 프로그래밍은 이런 과정 중에 발생하는 부가비용을 줄이고(효과적인 코드 작성 등) 각 과정을 더 의미 있는 방법(더 적합한 알고리즘 등)으로 변경하여 시간 비용을 줄이는 행위 
- 기본 컴퓨터 시스템
  - 컴퓨터를 구성하는 요소는 크게 연산 장치, 메모리 장치, 장치들을 이어주는 연결 장치로 구성되어 있음
  - 연산 장치는 초당 얼마나 많이 계산할 수 있는지, 메모리 장치는 데이터를 얼마나 많이 저장할 수 있으며 얼마나 빠르게 읽고 쓸 수 있는지, 연결 장치에는 장치 간에 데이터를 얼마나 빠르게 옮길 수 있는지 알려주는 속성이 있음 
  - 일반적인 워크스테이션은 CPU라는 연산 장치, 용량과 접근 속도가 서로 다른 RAM과 하드 드라이브라는 저장 장치, 그리고 이들을 포함한 모든 부품을 연결하는 장치인 버스(bus)로 생각해볼 수 있음 
  - 연산 장치
    - 컴퓨터를 사용하는 데 가장 핵심적인 장치, 입력된 Bit를 다른 Bit로 변환하거나 프로세스의 상태를 변경하는 기능을 제공함 
    - 가장 널리 쓰이는 연산 장치는 CPU지만 최근에는 GPU(graphics processing units)가 보조 연산 장치로 인기를 끌음, 원래 GPU는 그래픽 처리에 사용되었으나 고유의 병렬적인 특성 때문에 많은 계싼을 동시에 처리할 수 있으므로 계산 애플리케이션에서도 유용함 
    - 연산 장치는 종류에 관계없이 여러 Bit(예를 들면 수를 나타내는 Bit)를 입력받아 다른 Bit 조합(예를 들면 각 수의 합)으로 변환함 
    - CPU 제조사는 더 빠른 속도를 얻으려고 동시적인 다중 스레딩(multithreading - 여러 스레드를 병렬로 동시에 실행), 비순차적 명령어 처리(out-of-order execution), 멀티 코어 아키텍처 같은 다른 방법을 모색함 
    - 하이퍼스레딩(hyperthreading)은 운영체제에 가상의 두 번째 CPU를 인식시킨 다음, 똑똑한 하드웨어 로직이 단일 CPU의 실행 유닛에 두 스레드를 번갈아 가며 실행하도록 하는 기법, 잘만 작동하면 단일 스레드 대비 30% 까지 성능을 끌어 올릴 수 있음 
    - 비순차적 명령어 처리는 프로그램 실행 과정에서 이전 작업의 결과에 영향을 받지 않는 부분을 찾아내서 두 작업을 순서와 관계없이 실행하거나 동시에 실행하는 기법
    - 멀티 코어 아키텍처는 실행 유닛 하나에 CPU를 여러 개 두어 전체적인 처리량이 단일 CPU의 처리량을 능가하도록 함 
    - 암달의 법칙 : 단순히 CPU에 코어를 더 넣는다고 해서 프로그램의 실행 시간이 무조건 단축되지는 않음, 멀티 코어에서 작동하도록 설계된 프로그램일지라도 하나의 코어에서 실행해야 하는 루틴이 존재하고, 이 루틴이 코어를 더 투입했을 때 기대할 수 있는 최대 성능 향상치의 병목으로 적용한다는 법칙
- 메모리 장치
  - 메모리 장치에는 메인보드의 레지스터나 RAM, 하드 드라이브도 포함됨
  - 메모리 장치는 대부분 데이터를 조금씩 자주 읽을 때(임의 접근 random access)보다 한꺼번에 많이 읽을 때 훨 씬 빠르게 작동함(순차 접근 sequential access)
  - 레이턴시(latency) : 장치가 데이터를 찾기까지 걸리는 시간을 의미함
  - 하드디스크
    - 컴퓨터의 전원이 꺼진 상태에서도 데이터를 오래 보관할 수 있는 저장 장치, 물리적으로 헤드를 움직여야 하므로 읽기/쓰기 속도가 느림, 임의 접근 성능이 떨어지지만 10TB 수준의 대용량 데이터를 저장할 수 있음 
  - 솔리드 스테이트 드라이브(SSD) 
    - 하드디스크와 비슷함, 하드디스크보다 읽기/쓰기 속도가 빠르지만, 용량은 작음
  - RAM
    - 애플리케이션 코드나 사용 중인 변수 같은 데이터를 저장하는 데 쓴다, 읽기/쓰기 속도가 빠르며 임의 접근에도 성능 하락이 적으나, 일반적으로 용량이 64GB 단위로 제한적임 
  - L1/L2 캐시
    - 읽기/쓰기 속도가 매우 빠름, CPU로 전달하는 데이터는 항상 이 캐시를 거쳐 감, MB 단위로 용량이 아주 작음 
    - 읽기/쓰기 속도와 용량은 반비례하는 경향이 뚜렷함, 빠른 속도를 원한다면 줄어드는 용량을 감수해야 함
- 통신 계층
  - FSB는 RAM과 L1/L2 캐시를 연결함, FSB는 처리할 준비가 된 데이터를 옮겨서 프로세서가 계산할 수 있도록 하며, 계산이 완료되면 다시 돌려줌 
- 무거운 데이터(heavy data) : 데이터를 옮기는 데 시간과 노력이 필요하다는 뜻 

- 파이썬 개선점
  - 내부적으로 잘 최적화된 명령어 집합을 실행하지만, 명령어 집합을 올바른 순서로 실행하도록 하면 성능이 더 좋아짐 
  - 글로벌 인터프리틱 락(Global Interpreter Lock - GIL) 때문에 코어를 여러 개 활용하기가 쉽지 않음, GIL을 현재 사용중인 코어가 몇 개든, 한 번에 명령 하나만 실행하도록 강제함. 파이썬에서 동시에 여러 개의 코어에 접근하더라도 한 번에 파이썬 명령 하나만 실행됨
    - 다른 표준 라이브러리인 multiprocessing 모듈을 사용하거나, numpy나 numexpr, 사이썬 같은 기술을 이용하거나, 분산 컴퓨팅 모델을 사용하는 방법으로 해결할 수 있음 
  - 파이썬이 메모리를 자동으로 할당하고 해제하는 가비지 컬렉터(garbage collector GC)를 사용하기 때문, CPU 캐시에 데이터를 전송하는 데 영향을 미치는 메모리 단편화를 일으킴, 게다가 어디에서도 메모리에 저장되는 자료구조를 직접 변경할 수 없으므로 버스 폭이 아주 넓더라도 한 번의 계산에 필요한 정보를 한 번에 전송할 수 없음
  - 파이썬이 동적 타입을 사용하며 컴파일되지 않는다는 점
    - 정적인 코드를 컴파일 할 때, 컴파일러는 CPU가 특정 명령을 실행하는 방식을 포함한 많은 부분을 변경해서 최적화 할 수 있음, 파이썬은 컴파일되지 않는 데다가 코드의 기능이 런타임에 변경되는 동적 타입 언어라 최적화 알고리즘이 제 기능을 발휘하기 어렵다, 이 문제를 극복하는 여러 방법 중 사이썬(Cython)이 가장 대표적, 사이썬은 파이썬 코드를 컴파일하고 컴파일러에게 동적인 코드가 실제로 어떻게 동작하는지 힌트를 줄 수 있음 
- 파이썬을 쓰는 이유
  - 표현력이 좋고 배우기 쉽다는 장점
  - 많은 파이썬 라이브러리는 타 언어로 작성된 도구를 감싸서 다른 시스템을 쉽게 호출함
  - 주된 강점 하나는 빠른 프로토타이핑, 비록 처음부터 그럴싸하지는 않더라도 다양한 라이브러리를 활용해서 실현 가능한 아이디어인지 빠르게 검증해볼 수 있음 
  - 기본 라이브러리
    - unicode와 bytes : 언어 핵심에 녹아 있음
    - array : 메모리를 효율적으로 사용하는 배열
    - math : 간단한 통계를 포함한, 기본적인 수학 연산 모듈
    - sqlite3 : 널리 사용되는 파일 기반 데이터베이스인 SQLite3의 래퍼
    - collections : 데크(deque), 카운터, 여러 가지 사전을 포함하는 다양한 객체 집합
    - asyncio : async와 await 구문을 사용해 I/O 위주 작업의 동시 처리 지원, 기본적으로 지원하지는 않지만, 다양성을 더해주는 다음과 같은 외부 라이브러리가 있음 
    - Numpy : 파이썬 수학 라이브러리(행렬을 사용할 때 필수 라이브러리)
    - scipy : 높은 평가를 받는 C와 포트란 라이브러리를 감싼 계산 라이브러리 모음
    - Pandas : R의 dataframe이나 엑셀 스프레드시트와 유사한 데이터 분석 라이브러리, scipy와 numpy를 사용 
    - 사이킷런 : 빠르게 머신 러닝의 기본 모듈이 되고 있음, scipy를 사용
    - tornado : 웹 프레임워크이자 비동기 네트워크 라이브러리
    - PyTorch와 TensorFlow : 페이스북과 구글이 만든 딥러닝 프레임워크, 파이썬과 GPU를 강력히 지원
    - NLTK, SpaCy, Gensim : 파이썬을 잘 지원하는 자연어 처리 라이브러리
    - 데이터베이스 바인딩 : 레디스, 몽고DB, HDF5, SQL 등 실질적으로 대부분의 데이터베이스를 지원
    - 웹 프레임워크 : 웹 사이트 개발을 지원하는 aiohttp, flask, django, pyramid, tornado 등
    - OpenCV : 컴퓨터 비전을 위한 바인딩
    - API 바인딩 : 구글, 트위터, 링크드인 등 인기 서비스에 제공하는 웹 API를 위한 바인딩
    - 파이썬 배포판과 셸
      - 간단하고 가벼우며 이식성 좋은 파이썬 환경을 제공하는 pipenv, pyenv, virtualenv
      - 배포(deploy)와 프로덕션(production)에서 시작과 재현이 간편한 환경을 만들어주는 도커
      - 과학 계산에 초점을 맞춘 아나콘다사의 아나콘다 환경
      - IDE를 포함하며 매트랩과 유사한 환경을 제공하는 Sage
      - 개발자와 과학자들이 많이 쓰는 대화형 파이썬 셸인 IPython
      - 브라우저에서 돌아가는 IPython인 주피터 노트북, 교육과 데모용으로 많이 쓰임
- 뛰어난 성과를 거두는 파이썬 프로그래머가 되는 방법
  - 일반적인 접근 방법
    - 작동하게 만들라
      - 먼저 충분히 좋은 해법을 만들어야 함, 프로토타입 해법으로 사용되는 폐기한다는 가정하에 일단 만들어 보기를 적용하고 두 번째 버전에서 더 나은 구조를 사용할 수 있을 것이라 생각하자
      - 두 번 측정하고, 한 번만 잘라라(measure twice, cut once)
    - 재대로 만들라
      - 강력한 테스트 스위트를 만들고 코드와 테스트를 문서로 뒷받침해야 함, 다른 팀원이 사용할 수 있도록 명확한 재현 방법도 문서로 남김
    - 빠르게 만들라
      - 프로파일링, 컴파일링, 병렬화 등에 초점을 맞추고, 기존 테스트 스위트를 사용해 새로운 빠른 해법이 여전히 예상대로 작동하는지 확인해야 함 
- 모범적인 작업 절차
  - 문서화, 좋은 구조, 테스트가 핵심 요소
  - 최상위 수준에 README 파일을 작성하는 작업이 좋은 출발점임
  - 프로젝트 목적, 폴더 내용, 데이터 출처, 중요한 파일 목록, 프로그램과 파일의 실행 방법, 테스트 실행 방법 등을 적어라
  - 최상위 Dockerfile은 차후 이 프로젝트를 성공적으로 실행하는 데 운영체제에서 필요한 라이브러리를 정확히 알려줌, 그리고 다른 컴퓨터나 클라우드 환경에 프로젝트를 배포할 때도 어려움 없이 프로젝트를 실행할 수 있게 해줌 
  - tests/ 폴더를 추가하고 단위 테스트를 만들어라, 최신 테스트 도구로 pytest를 추천함, pytest는 파이썬 내장 unittest 모듈을 사용해 만들어졌음, 먼저 테스트를 한두 개 작성하고 점점 발전시켜라
  - 프로젝트 전체 흐름을 검사하면서 특정 입력에 대해 여러분이 지정한 출력이 나오는지를 체크하는 통합 테스트(integration test)가 있어야 함, 나중에 코드를 변경할 때 코드의 일관성을 유지하는 데 도움이 됨 
  - 코드의 모든 함수, 클래스, 모듈에 독스트링(docstring)을 추가하면 큰 도움이 됨, 함수가 달성하려는 내용을 제대로 설명하려 노력하라, 가능하면 예상 출력을 보여주는 간단한 예제도 추가하자 
  - 코드가 너무 길어지면(예컨대 한 화면에 다 보이지 않는 함수) 리팩터링해 코드를 짧게 만들어라, 짧은 코드는 테스트하기 쉽고 지원하기도 쉽다
  - 항상 소스 관리(source control)를 사용하라, 중요한 시기에 필수적인 코드를 덮어썼다면 소스 관리를 사용한 자기 자신에게 감사하게 됨, 커밋(commit)을 자주(매일 아니면 10분마다) 하고 매일 리포지터리(repository)에 작업을 푸시하라
  - PEP8 코딩 표준을 지켜라. black(원하는 대로 설정할 수 있는 코드 정리기formatter)을 소스 컨트롤의 커밋 전 훅(pre-commit hook)에 추가해서 코드를 표준 형식으로 자동 정리하면 더 좋음, flake8을 적용해 소스 코드를 린트(lint)해서 다른 실수를 방지하라
  - 운영체제와 분리된 환경을 만들면 더 코딩이 쉬워짐, 아나콘다, pipenv와 도커를 함께 쓰는 쪽을 선호함
  - 자동화는 여러분의 친구라는 사실을 기억하라, 수동 작업을 덜 하면 오류가 끼어들 가능성도 줄어듬, 자동 빌드 시스템, 자동 테스트 스위트 실행기(runner)를 사용한 지속적 통합(continuous integration), 자동 배포(automated deployment)는 지겹고 실수하기 쉬운 작업을 누구든 실행하고 지원할 수 있는 표준 절차로 바꿔줌
  - 가독성이 더 중요하다는 사실을 기억하라, 짧지만 복잡하고 읽기 어려운 코드는 유지보수하기 어렵다. 더 길더라도 읽기 편한 함수를 작성하고 함수에 관한 유용한 문서를 작성하는 편이 바람직하다. 함수가 실제로 원하는 대로 작동하는지 확인하는 테스트로 이 모든 내용을 보완하라 
- 주피터 노트북 잘 다루기
  - 코드를 IPython이나 QTConsole에서 프로토타이핑하라. 이런 콘솔에서 테스트한 코드들을 노트북 함수로 분리하고, 노트북 함수 중에 자주 쓰거나 복잡한 부분은 노트북에서 추출해서 모듈로 만들면서 테스트를 보완하라. 데이터 은닉(data hiding)이나 캡슐화(encapsulation)가 유용한 경우에는 코드를 클래스로 감싸라
  - assert 문을 노트북 여기저기에 자유롭게 넣어서 함수가 여러분 생각대로 작동하는지 검증하라
  - 함수가 예상하지 못한 입력값을 만났을 때 던질 수 있는 일반적인 예외로는 ValueError, Bulwark 라이브러리는 데이터가 정해진 제약 조건을 만족하는지 검사해주는 팬더스에 초점을 맞춘 테스트 프레임워크의 예다 
  - 노트북의 끝에 데이터 무결성 검사를 추가하라, 무결성 검사는 노트북에서 방금 생성한 데이터가 여러분에 피룡한 데이터인지 검사하는 논리 검사와 raise, print 문을 혼합한 코드 조각
  - nbdime은 성장 중인 새로운 도구로, 노트북 사이의 차이를 알려줘서 동료들과 협업할 때 큰 도움이 됨 
- 일하는 즐거움 되찾기
  - 새로운 활동을 하면서 계속 기쁨을 찾아라, 왜 이런 결정을 내렸지?, 내가 하면 어떻게 다르게 할 수있을까? 같은 질문을 할 수 있고, 갑자기 상황이 어떻게 더 나아지거나 바뀌었는지에 관한 이야기를 시작하게 될 것이다.
- 프로그래밍은 (특히 성능이나 성취에 초점을 맞추면) 기술적인 세부 사항을 깊이 파고들려는 자발성과 호기심이 있어야 번창함, 천천히 시간을 두고 여러분의 여정을 즐기며 호기심과 즐거움을 계속 유지하라 

## 프로파일링으로 병목 지점 찾기
- 프로파일링으로 병목 지점을 찾아 최소한의 노력으로 성능을 최대한 끌어올릴 수 있음 
- 효과적으로 프로파일하기
  - 프로파일링의 첫 번째 목표는 시스템의 어느 부분이 느린지, 어디서 RAM을 많이 쓰는지, 디스크 I/O나 네트워크 I/O를 과도하게 발생시키는 부분이 어디인지를 확인하는 것 
  - 기본적인 프로파일링 기법은 IPython의 %timeit 매직 명령어와 time.time(), 데커레이터(decorator)를 활용한 시간 측정 
  - line_profiler는 각 줄을 몇번 실행했는지, 총 소요 시간은 얼마인지를 검사함, 이는 어느 부분이 왜 느린지를 이해할 수 있는 정보
  - CPU에서 실행된 명령의 수와 CPU 캐시가 얼마나 효율적으로 활용되었는지 알아볼 수 있는 perf stat 사용법을 배움, 이 정보는 매트릭스 연산을 튜닝하는 고급 기번에 활용됨 
  - C파이썬 내부에 쓰이는 파이썬 바이트코드, 바이트코드를 알면 파이썬 내부를 더 잘 이해할 수 있음, 파이썬의 스택 기반 가상 머신을 이해하면 왜 특정 코딩 습관이 코드를 느리게 하는지를 알 수 있음 
- 코드는 결정적(deterministic)이므로, 계산된 값을 모두 더해서 함수가 기대하는 대로 잘 작동하는지 확인할 수 있음, 검증 코드를 추가하면 유용함 
  - 수치 계산을 하는 코드를 수정할 때는 우리가 변경한 내용이 알고리즘을 깨지 않았는지 검사하는 작업이 매우 중요함 
  - 이상적으로는 단위 테스트를 사용해서 문제의 여러 가능성도 테스트해야함 
- 시간을 측정하는 간단한 방법 : print와 데커레이터
  - 데커레이터는 print 문보다 조금 더 깔끔한 방법, 여기서는 시간을 측정하려는 함수 위에 코드를 한 줄 추가함 
  - 가변 길이 인자인 *args와 키워드 인자인 **kwargs를 받아, 실행하는 fn 함수로 넘겨준다.
  - @wraps(fn)을 사용해서 데커레이터로 넘겨온 함수 이름과 독스트링을 호출하는 함수에서 확인할 수 있도록 함(그렇지 않으면 데커레이터로 넘어온 함수가 아니라 데커레이터 함수 그 자체의 이름과 독스트링을 보게 됨)
- cProfile 모듈 사용하기
  - 표준 라이브러리에 내장된 프로파일링 도구로, C파이썬의 가상 머신 안에서 확인되는 모든 함수에 시간을 측정하는 장치를 연결함, 이는 큰 오버헤드를 유발하지만 그만큼 더 많은 정보를 제공함 
  - profile은 수수 파이썬 기반의 프로파일러로 cProfile보다 느림 
  - cProfile은 profile과 같은 인터페이스를 제공하며 오버헤드를 줄이려고 C로 작성함 
  - 프로파일하기 전에 프로파일하려는 코드의 기대 속도에 대한 가설을 세우는 습관을 들여라 
- SnakeViz로 cProfile 결과 시각화하기
  - snakeviz는 cProfile로 생성한 통계 정보를 시각화하는 도구, 더 오랜 시간을 소비한 영역을 더 큰 상자로 표시하여, 기존의 runsnake 도구를 대신함 
  - 통계를 cumtime(누적 시간), percall(호출 당 비용), ncalls(호출 회수) 등의 지표 기준으로 정렬할 수 있음, cumtime을 기준으로 정렬하면 어떤 함수가 전체적으로 가장 많은 시간을 소모했는지 알 수 있음 
- line_profiler로 한 줄씩 측정하기
  - line_profiler가 파이썬 코드에서 CPU 병목 원인을 찾아주는 가장 강력한 도구라 생각함
  - line_profiler는 개별 함수를 한 줄씩 프로파일하므로, 먼저 cProfile을 사용해서 어떤 함수를 line_profiler로 자세히 살펴볼지 정하면 됨 
  - 코드를 수정하면서 line_profiler 결과에 버전을 기록해두면 변경 사항의 성공/실패 기록을 빠르게 참고할 수 있음 
- memory_profiler로 메모리 사용량 진단하기
  - CPU 사용량을 측정하는 로버트 컨의 line_profiler 패키지처럼 메모리 사용량을 줄 단위로 측정해주는 memory_profiler가 있음 
- PySpy로 기존 프로세스 살펴보기
  - py-spy는 새로운 샘플링 프로파일러(sampling profiler) 
  - 코드를 변경하는 대신, py-spy는 이미 실행 중인 파이썬 프로세스를 들여다보고 콘솔에 top과 비슷한 방식으로 상황을 표시해줌 
  - py-spy는 러스터(Rust)로 작성됐고, 다른 프로세스를 들여다보려면 관리자 권한이 필요함 

## 리스트와 튜플
- 성능을 고려한 프로그래밍에서는 어떤 데이터를 어떻게 다룰지를 고민하고 그 상황에서 빠르게 작동하는 자료구조를 선택하는 일이 큰 비중을 차지함 
- 리스트와 튜플은 배열이라는 자료구조에 속함, 배열은 정해진 고유의 순서에 따라 데이터를 나열해둔 것 
- 리스트는 저장하는 데이터나 배열 크기를 변경할 수 있는 동적 배열
- 튜플은 내용이 고정된 변경 불가능한(immutable) 정적 배열 
- numpy 배열은 정적으로 타입이 정해져 있어서 다른 타입의 값을 저장할 수 없음
- 더 효율적인 탐색
  - 파이썬 리스트는 정렬 알고리즘을 내장하며 팀(Tim) 정렬을 사용함, 팀 정렬의 시간복잡도는 최적일 때 O(n), 최악일 때 O(n log n)
  - 팀 정렬은 자양한 정렬 알고리즘을 활용하여 주어진 데이터에 어떤 알고리즘을 적용하는 것이 최선인지를 추측하는 휴리스틱을 사용함(삽입 정렬과 병합 정렬 알고리즘을 조합해서 사용함)
  - 파이썬 표준 라이브러리의 bisect 모듈을 이용하면 잘 최적화된 이진 탐색 기법으로 항목을 찾을 수 있을 뿐 아니라 새로운 항목을 추가해도 정렬된 상태가 유지됨 
- 리스트와 튜플
  - 차이점
    - 리스트는 동적인 배열, 수정이 가능하며, 저장 용량을 늘리거나 줄일 수도 있음
    - 튜플은 정적인 배열, 일단 생성되면 배열의 크기뿐 아니라 그 안의 데이터도 변경할 수 없음
    - 튜플은 파이썬 런타임에서 캐시하므로 사용할 때마다 커널에 메모리를 요청하지 않아도 됨 
  - 튜플은 변치 않는 특정 대상의 여러 속성이며 리스트는 서로 이질적인 객체들의 모음 
  - 튜플 : 정적 배열
    - 여유 공간이 부족할 때만 할당과 복사가 일어나는 리스트와 달리 튜플에서는 새로운 항목을 추가할 때마다 복사가 일어남, 두 튜플을 합치면 항상 새로운 튜플 하나의 메모리를 새로 할당함
    - 여유 공간을 할당하지 않으면 자원을 더 적게 사용하는 장점이 있음, 크기가 1억인 리스트를 append로 생성하면 실제로는 112,500,007 크기의 메모리를 사용하는데, 튜플은 정확히 1억만큼만 사용함, 이 때문에 데이터가 정적일 때는 튜플이 더 가볍고 좋음 
    - append를 사용하지 않아 여유 공간을 할당하지 않더라도, 리스트는 여전히 같은 데이터를 저장하는 튜플보다 메모리를 더 잡아먹음, 리스트는 크기 변경을 효율적으로 하려고 상태 정보를 관리하기 때문 
    - 파이썬 내부적으로 수행하는 리소스 캐싱, 파이썬은 GC를 통해 더는 사용되지 않는 변수에 할당된 메모리를 반환함, 하지만 크기가 20 이하인 튜플은 크기별로 최대 2만 개까지(즉, 2-튜플 2만 개, 3-튜플 2만 개, ..., 20- 튜플 2만 개까지) 즉시 회수하지 않고 나중을 위해 저장해둠, 이는 같은 크기의 튜플이 나중에 다시 필요해지면 운영 체제에서 메모리를 새로 할당받지 않고 기존에 할당해둔 메모리를 재사용한다는 뜻, 파이썬 프로세스가 필요한 양보다 메모리를 약간 더 사용한다는 뜻
- 리스트와 튜플은 정렬된 데이터에 적합한 빠르고 오버헤드가 적은 자료구조
  - 리스트를 사용할 때는 크기 변경으로 발생한 초과 할당까지 고려해서 메모리에 데이터를 저장할 수 있을지 신경 써야 함 
  - 튜플은 빠르게 생성할 수 있고 리스트보다 메모리 부담이 적은 대신에 내용을 변경할 수 없음

## 사전과 셋
- 셋과 사전은 (삽입 순서를 제외하면) 미리 정해진 순서로 정렬되지 않으나, 특정 데이터를 고유하게 참조할 수 있는 별도 객체가 있는 상황에 이상적인 자료구조 
- 참조하는 객체는 일반적으로 문자열이지만, 해시가 가능하다면(hashable) 어떤 타입이라도 상관없다, 참조 객체를 키, 데이터를 값이라고 함 
- 사전과 셋은 거의 같지만 셋에는 값이 없다는 점이 다름, 쉽게 말해 셋은 유일한 키를 저장하는 자료구조, 셋은 집합 연산을 수행할 때 아주 유용함 
- 개방 주소(open address) 해시 테이블
  - 해시 테이블은 처음에는 데이터가 각 버킷에 골고루 분포하더라도, 확률적으로 어느 시점에는 해시값이 충돌할 수 밖에 없음, 이에 따라 충돌 해결 알고리즘이 필요함
  - 체이닝(chaining) 방식 : 충돌이 발생한 버킷의 값을 버킷마다 별도의 연결 리스트로 저장하는
  - 개방 주소 방식 : 충돌 발생 시 미리 정해진 알고리즘을 사용해 다른 버킷을 찾아서 키/값을 저장하는 
  - 폐쇄 해싱(closed hasing) : 버킷상의 항목 주소가 해시 키로 정해지지 않고 열려 있어서 개방 주소 방식이라 부르지만, 모든 항복이 버킷이 할당된 영역 안에 다 저장하기 때문 
  - 폐쇄 주소(closed address)방식의 해싱 : 체이닝의 경우 항목이 저장되는 버킷의 주소는 해시 함수로 정해지기 때문 
  - 개방 해싱(open hashing) : 항목이 버킷이 아닌 다른 영역(연결 리스트)에 들어갈 수도 있기 때문
- 사전과 셋의 동작 원리
  - 사전과 셋은 모두 해시 테이블을 사용해서 시간복잡도가 O(1)
  - 임의의 키(문자열이나 객체)를 리스트의 색인으로 변환하는 해시 함수를 효율적으로 사용한 결과, 해시 함수와 리스트는 나중에 검색을 하지 않고도 특정 데이터가 제대로 들어있는지 확인하는 용도로 사용 
  - 데이터의 키를 리스트의 색인천럼 사용하도록 변환하는 작업을 하면 리스트와 같은 성능을 냄
  - 데이터를 가리키는 수의 색인(수로 데이터를 가리키려면 데이터에 어떤 식으로든 순서를 부여해야 함) 대신 임의의 키를 사용해서 데이터를 참조할 수 있음 
- 프로빙(probing) : 새로운 색인은 단순한 선형 함수를 이용해서 계산, 파이썬의 프로빙 메커니즘은 원래 해시값에서 더 상위 Bit를 활용함 
- 로드 팩터(load factor) : 해시 테이블에 데이터가 얼마나 균등하게 분포하는지를 의미함, 해시 함수의 엔트로피와 관련 있음 
- 해시함수의 엔트로피 : 해시 함수가 얼마나 균일한 분포로 해시값을 만들어 내는지
- 완전 해시 함수 : 엔트로피가 최대가 되는 해시 함수는 최소 충돌을 보장
- 사전과 네임스페이스
  - 파이썬에서 변수, 함수, 모듈이 사용될 때 그 객체를 어디서 찾을지 결정하는 계층이 있음, 가장 먼저 모든 지역 변수를 담은 locals() 배열을 찾음, 파이썬은 지역 변수 탐색을 빨리 끝내도록 최선을 다하며, 이 과정은 사전 탐색을 하지 않는 유일한 부분
  - 만약 여기서 해당 객체를 찾을 수 없으면 globals() 사전에서 찾음, globals()에서도 찾을 수 없다면 마지막으로 __builtin__ 객체에서 찾음
  - locals()와 globals()는 명백한 사전이지만 __builtin__은 기술적으로는 모듈 객체라는 점이 중요함, __builtin__은 그 모듈 내부에서 locals() 사전(여기에 모듈 객체와 클래스 객체가 저장됨)을 탐색하여 특정 속성을 찾음 
    - locals() 배열은 함수 호출 시 만들어지는 스택 프레임 안의 지역 변수 영역을 의미함, 어떤 함숭 안에서 자신의 지역 변수에 접근할 때는 그 변수가 스택 프레임 내의 지역 변수 영역에서 몇 번째에 있는지를 이미 알기에 색인을 사용해 빠르게 접근할 수 있음, 반면 __builtin__에서 locals() 사전에 접근할 때는 색인으로 접근할 수가 없고, 변수 이름으로 검색해야 함 

## 행렬과 벡터 계산
- 메모리 단편화
  - 파이썬은 벡터 연산을 기본으로 제공하지 않음
    - 파이썬의 리스트는 실제 데이터를 가리키는 포인터를 저장한다는 점
    - 파이썬 바이트 코드는 벡터 연산에 최적화되지 않았다는 점 
    - for 루프는 벡터 연산을 언제 수행해야 도움이 되는지 예측할 수 없음, 파이썬 리스트가 포인터를 저장한다는 얘기는 리스트가 실제 데이터가 아닌 데이터의 위치를 저장한다는 의미 
  - CPU에 데이터가 필요할 때 즉시 공급하는 과정에서 발생하는 문제는 폰 노이만 병목(von Neumann bottleneck)과 관련 있음, 현대 컴퓨터의 구조적인 한계 때문에 메모리와 CPU 사이의 대역폭이 제한적이어서 발생하는 현상, 만일 우리가 데이터를 무한히 빠른 속도로 옮길 수 있다면 CPU는 필요한 데이터를 즉시 얻을 수 있으니 캐시가 필요 없음 
  - CPU는 현재 명령을 실행하는 동안 다음에 실행할 명령을 예측해 관련 데이터를 캐시에 미리 적재해두는 분기 예측(branch prediction)과 파이프라이닝(pipelining)이라는 훌륭한 기법을 제공함 
- 행렬 최적화에서 얻은 교훈
  - 초기화 과정에 필요한 관리 요소를 모두 고려해야 한다는 점
  - 메모리 할당, 설정 파일을 읽는 과정, 프로그램이 실행되는 동안 필요한 값을 미리 계산하는 과정도 모두 여기에 포함
  - 초기화 작업을 한번에 완료해서 전체 실행 횟수를 줄이고 나중에 불필요한 자원이 낭비되지 않도록 함 
  - 프로그램의 흐름을 방해하지 않아야 한다. 캐시에 관련 데이터만 채워지게 하고 파이프라인을 효율적으로 유지할 수 있음 
  - 데이터 지역성(data locality)과 데이터 CPU에 빠르게 전달하는 일의 중요성도 알게 되었음 
  - 외부 라이브러리 사용에 관한 것, 파이썬은 사용이 쉽고 가독성이 높아서 코드를 빠르게 작성하고 디버깅 할 수 있음, 하지만 성능을 개선할 때는 반드시 외부 라이브러리까지 고려해야 함 
  - 실험하기 전에 성능에 관한 가설을 세우고 성능을 측정해야 한다는 점도 배움 
- 팬더스
  - 과학기술 파이썬 생태계에서 사실상 표준인 데이터 조작 도구로 표 형태의 데이터 처리에 사용함, 팬더스는 (엑셀과 비슷하게) 균일하지 않은 데이터 유형으로 이뤄진 표(DataFrame)를 쉽게 조작하게 해주고, 시계열 연산을 강력히 지원함 
  - 연산은 단일 스레드로 실행되며 파이썬의 GIL 때문에 제한될 수 있음, 파이썬 내부 구현이 점차 개선되면서 GIL이 자동으로 비활성화될 수 있게 만들어, 병렬 연산이 가능해졌음, Dask로 팬더스 병렬화하기에서 Dask를 활용한 병렬화 접근법
  - 내부에서는 BlockManager가 같은 dtype으로 이뤄진 열을 하나로 묶음, 이런 숨겨진 장치는 같은 타입으로 이뤄진 열에 대한 행 단위 연산을 더 빠르게 수행하게 해줌 
  - 넘파이에서 온 타입은 int8(1바이트), int64(8바이트, 첫 글자가 소문자'i'), float16(2바이트), float64(8바이트), bool(1바이트) 등이 있음 
- 효율적인 팬더스 개발을 위한 조언
  - 코드를 너무 간략하게 작성하자 말라. 코드를 읽고 디버깅하기 쉽게 만들어서 미래의 자기 자신에게 도움이 되게 하라
  - 팬더스는 메서드 체이닝 스타일을 지원하지만, 팬더스 연산에서 너무 많은 행을 체이닝하는 일은 바람직하지 않다. 체이닝이 길어지면 디벙깅할 때 문제가 생긴 코드 줄이 어디인지 알아내기 어려워지고, 결국에는 각 줄을 나눠서 분석해야 함. 처음부터 유지보수를 고려해서 한두 가지 연산만 체이닝하고 코드를 여러 부분으로 나눠 구성하는 편이 낫다.
  - 처리를 필요 이상으로 하지 말라. 계산하기 전에 데이터에 필터를 적용하는 편이 계산을 수행한 후 필터를 적용하는 것보다 낫다. 일반적으로 고성능을 달성하려면, 컴퓨터가 가능한 한 적은 계산을 수행하게 해야 한다. 데이터 중 상당 부분을 필터로 거르거나 마스크해 없앨 수 있다면, 아마도 성능상 큰 이익이 따라올 것이다. 
  - DataFrame 스키마를 변경할 때마다 bulwark 같은 도구를 사용해 스키마를 검사하라.검사를 수행하면 실행 시점에 데이터가 스키마를 만족하는지 보장할 수 있고, 코드를 리뷰하는 과정에서 여러분의 예상에 맞게 코드와 스키마가 작성됐는지를 시각적으로 확인할 수 있음 
  - 모든 처리 코드에 단위 테스트를 꼭 추가하라. 처리 코드는 쉽게 복잡해지고 디버깅하기 점점 어려워지므로 단위 테스트가 필요함

## C언어로 컴파일하기
- 코드를 빠르게 하는 가장 쉬운 방법은 처리할 작업의 양을 줄이는 것, 이미 최적의 알고리즘을 사용하며 처리해야 할 데이터를 간소화했다고 가정하면, 수행할 명령의 수를 줄이는 가장 쉬운 방법은 코드를 기계어로 컴파일 하는 것 
- 순수 C기반의 컴파일을 수행하는 사이썬, LLVM 기반의 컴파일을 제공하는 Numba, 파이썬 가상 머신을 대체하는 내장 JIT 컴파일러를 포함하는 PyPy 등 여러가지
  - 사이썬 : C 언어로 컴파일하는 데 사용하는 가장 일반적인 도구, numpy와 일반 파이썬 코드를 모두 커버함(C 언어를 어느 정도 이해해야 함)
  - Numba : numpy 코드에 특화된 새로운 컴파일러
  - PyPy : 일반 파이썬 실행환경을 대체하는 비 numpy 코드를 위한 JIT 컴파일러  
- JIT 대 AOT 컴파일러
  - 미리 컴파일하는 방식이 AOT(ahead of time - 사이썬)와 적절한 때에 컴파일하는 방식인 JIT(Just in time(Numba, PyPy) 
  - AOT 방식 : 사용할 컴퓨터에 특화된 정적 라이브러리를 생성함
  - JIT 방식은 어떤 작업도 미리 하지 않고 컴파일러가 적절한 때에 컴파일을 시작함, 즉 콜드 스타트에 문제가 있다는 뜻, 프로그램 대부분이 컴파일되어야 하는데 아무것도 컴파일되지 않은 상태라면, 프로그램 실행 후에야 컴파일하느라 프로그램이 초반에 느리게 실행됨 
- 사이썬
  - 타입을 명시한 파이썬 코드를 컴파일된 확장 모듈로 변경해주는 컴파일러, 타입 어노테이션은 C와 유사한 형태
  - 주로 계산 코드의 속도를 빠르게 할 때 이 도구를 사용함, 다양한 사용성과 성숙도 그리고 OpenMP을 지원하는 점 때문
  - OpenMP 표준과 사이썬을 사용하면 한 컴퓨터의 여러 CPU에서 실행할 수 있도록 병렬 처리 문제를 다중 처리를 고려한 모듈로 변경할 수 있음, 이 스레드는 파이썬 코드 수준이 아니라 사이썬이 생성한 C 코드 수준에서 동작함
  - 사이썬을 사용하여 순수 파이썬 코드 컴파일하기
    - 호출하려는 파이썬 코드(앞서 작성한 줄리아 집합 코드들)
    - 새로 컴파일된 .pyx 파일
    - 확장 모듈을 작성하기 위해 사이썬을 호출하는 과정이 있는 setup.py 파일
      - setup.py 스크립트에서 사이썬을 사용해서 .pyx 파일을 컴파일함. 컴파일된 모듈은 유닉스 계열 시스템에서는 .so 파일일 가능성이 높고, 윈도우에서는 항상 (DLL과 비슷한 라이브러리인) .pyd 파일
- 강도 저감(strength reduction) : 같은 일을 하지만 좀 더 특화된 코드로 같은 문제를 해결하는 방법, 실행을 빠르게 하려고 유연성과 가독성을 희생하는 방법 
- 한 컴퓨터에서 OpenMP를 사용해 병렬화하기
  - OpenMP(Open Multi-Processing)는 C, C++, 포트란에서 병렬 실행과 메모리 공유를 지원하는 잘 정의된 다중 플랫폼 API 
  - 사이썬에서는 prange(병렬 범위) 연산자를 사용하고 setup.py에 -fopenmp 컴파일러 지시자를 넣어서 OpenMP를 추가할 수 있음
  - prange 연산자는 GIL을 비활성화하므로 prange 상에서는 루프를 병렬로 수행할 수 있음
  - GIL은 파이썬 객체로의 접근을 보호하며, 여러 스레드나 프로세스 같은 메모리에 동시에 접근해서 메모리를 오염시키는 일을 막음, 수동으로 GIL을 비활성화하면, 우리가 자체 메모리를 오염시키지 않겠다고 선언하는 것 
- Numba
  - 컨티넘 애널리틱스의 Numba는 numpy 코드에 특화된 JIT 컴파일러, 코드를 실행 시점에(앞의 예에서 사용했던 g++이나 gcc가 아니라) LLVM 컴파일러로 컴파일함 
  - 미리 컴파일하는 단계가 필요 없으므로, 새로운 코드를 실행할 때마다 Numba가 여러분의 컴퓨터에 맞춰 어노테이션이 달린 각 함수를 컴파일함
  - 집중해야 하는 함수를 알려주는 데커레이터를 제공하고, Numba가 그것을 이어받는다는 장점이 있음 
  - Numba는 외부 C 라이브러리와 연동하지 못하지만(사이썬은 연동 가능), 자동으로 GPU에 대한 코드를 생성할 수는 있음(사이썬은 생성 불가)
  - Numbda의 단점 하나는 툴체인, LLVM을 사용하므로 의존관계가 복잡함, 새 환경에 Numba를 설치하려면 시간이 오래 걸리므로, 모든 것이 포함된 컨티넘의 아나콘다 배포판을 추천함 
- PyPy
  - 추적형(tracing) JIT 컴파일러가 있는 또 다른 파이썬 언어 구현체, PyPy는 파이썬 3.5 이상과 호환됨, 보통 PyPY는 파이썬 최신 버전을 약간 늦게 지원함 
  - C파이썬을 완전히 대체할 수 있으며 모든 내장 모듈을 제공함, RPython 번역 도구와 그 도구로 만들어진 PyPy로 구성됨(RPython으로 다른 인터프리터를 만들 수 있음)
  - PyPy의 JIT 컴파일러는 매우 효율적이며, 그대로 사용하거나 약간의 작업만으로도 성능을 상당히 높일 수 있음 
  - PyPy가 모든 내장 모듈을 지원함, PyPy에서도 multiprocessing이 작동한다는 뜻 
- 가비지 컬렉션 방식의 차이
  - C파이썬은 참조 카운팅(reference counting)을 사용하는 반면, PyPy는 사용하지 않는 객체를(참조 카운팅보다) 훨씬 나중에 없애는 마크 앤 스윕(mark and sweep)을 사용함 
  - C파이썬에는 참조 카운터의 동작을 바탕으로 구현한 부분이 있음, 특히 파일을 열어서 쓴 다음 명시적으로 닫지 않아도 파일을 플러시(flush)하는 점이 그렇다. PyPy에서도 같은 코드가 실행되지만, 파일에 쓴 데이터는 나중에 GC가 실행되는 시점에 디스크로 플러시됨. PyPy와 C파이썬에서 모두 잘 작동하는 다른 코딩 방식은 with를 사용해서 파일을 열고 자동으로 닫도록 컨텍스트 관리자를 사용하는 것 
- 각 기술의 사용 시점
  - 컴파일러 선택 사항 요약

|특성|사이썬|Numba|PyPY
|:---:|:---:|:---:|:---:|
|성숙함|Y|Y|Y
|널리 사용 중|Y|-|-
|numpy 지원|Y|Y|Y
|기존 코드를 깨지 않음|-|Y|Y
|C 언어 지식 필요|Y|-|-
|OpenMP 지원|Y|Y|-

    - Numba는 시간과 노력을 적게 들이고도 성능을 높이지만, 몇 가지 제약이 있어 여러분의 코드에서 잘 작동하지 않을 수 있음
    - 사이썬은 보통 광범위한 문제에서 좋은 결과를 냄, 하지만 더 큰 노력을 들여야 하며 파이썬과 C 어노테이션을 혼용하기에 유지보수 비용도 커짐
    - numpy 등 포팅하기 어려운 C확장을 사용하지 않는다면 PyPy를 선택하는 편이 좋음
    - 프로덕션 도구를 배포한다면 잘 알려진 도구를 사용하고 싶을 것, 사이썬이 가장 좋은 선택 
- 떠오르는 다른 프로젝트들
  - PyData
    - 컴파일러 페이지에 고성능 및 컴파이럴 도구 목록이 있음
  - Pythran 
    - numpy를 사용 중인 과학자를 위한 AOT 컴파일러 
    - 소수의 어노테이션만 사용해서 파이선 수치 계산 코드를 더 빠른 바이너리 코드로 컴파일할 수 있음
    - Pythran은 사이썬과 거의 비슷한 수준으로 속도를 높이지만, 해야 할 일은 훨씬 더 적음 
    - Pythran은 GIL을 항상 해제하며 SIMD 명령어와 OpenMP를 모두 활용함 
    - Numba와 마찬가지로 Pythran은 클래스를 지원하지 않음
  - Transonic
    - 사이썬,Pythran,Numba 등의 컴파일러를 통일한 단일 인터페이스를 제공함 
    - 코드를 재작성하지 않고도 여러 컴파일러를 빠르게 평가할 수 있음 
  - ShedSkin
    - 과학 계산이 아닌 순수 파이썬 코드를 목표로 만들어지 AOT 컴파일러
    - numpy를 지원하지 않음
  - PyCUDA 
    - PyOpenCL
      - CUDA와 OpenCL 바인딩을 파이썬에 제공하여 직접 GPU에 접근할 수 있게 해줌 
  - Nuitka
    - 일반적인 C파이썬 인터프리터의 대안으로 개발된 파이썬 컴파일러로, 컴파일한 실행 파일을 만드는 옵션을 제공함 
- GPU
  - 동적 그래프 : 파이토치
    - 파이토치는 정적 계산 그래프 텐서 라이브러리로, 특히 numpy에 익숙한 사용자가 이용하기 쉬우며 API도 아주 직관적
    - 파이토치는 텐서 라이브러리이므로 numpy와 같은 기능을 제공하며, 자체 저적 계산 그래프를 통해 함수를 만들고 이런 함수의 도함수를 autograd라는 메커니즘을 통해 계산해주는 기능을 추가로 제공함 
      - autograd는 어떤 값에 대해서도 즉석에서 도함수를 계산할 수 있음
  - 정적 계산 그래프
    - 파이토치 객체에 대한 연산을 수행하면 백그라운드에서 GPU 코드로 컴파일될 수 있는 프로그램의 동적인 정의를 만들어낸다는 뜻 
    - 동적이므로 파이썬 코드를 변경하면 자동으로 GPU 코드에 반영되며, 별도의 컴파일 단계가 필요치 않음, 이 덕분에 텐서플로 같은 정적 그래프 라이브러리보다 디버깅이 쉽고 상호작용성이 늘음 
   - 텐서플로와 같은 정적 그래프에서는 먼저 계산을 설정한 다음 컴파일 해야함, 그 후에는 계산이 돌에 새겨진 것처럼 고정되며, 전체를 다시 컴파일해야만 계산을 변경할 수 있음
   - 파이토치 같이 동적인 그래프에서는 계산 그래프를 조건에 따라 바꾸고 점진적으로 구축해나갈 수 있다. 따라서 코드를 조건에 따라 디버깅할 수도 있고, IPython 대화식 세션에서 GPU에서 코드를 실행해볼 수도 있다. 유연하게 GPU를 제어하는 능력은 복잡한 GPU 기반의 부하를 처리할 때 완벽한 게임 체인저(game changer)
- 기본 GPU 프로파일링
  - GPU를 얼마나 활용하는지 정확히 검증하는 한 가지 방법은 nvidia-smi 명령을 사용해 GPU의 자원 활용도를 살펴보는 것 
  - 가장 관심을 가져야 할 두 값은 소비 전력(power usage)과 CPU 사용률(utilization)
  - GPU 사용 시 성능상 고려할 점
    - GPU는 컴퓨터에서 완전히 보조적인 하드웨어이고, CPU와 비교될 만큼 자체적인 구조를 가지므로 GPU에만 해당하는 성능상 고려 사항이 많음 
    - GPU 속도에서 가장 고려해야 할 점은 시스템 메모리에서 GPU 메모리로 데이터를 전송하는 데 걸리는 시간 
- 캐스팅(casting) : 함수 객체의 인자와 변환 타입을 명시하는 일과 더불어, 함수에서 사용할 데이터 타입도 변환해야 함 
- cffi
  - 임포트하고 결과를 만드는 함수의 타입을 제대로 지정했는지 검사함 

## 비동기 I/O
- 실제 코드 자체보다는 코드에 필요한 데이터를 얻어오는 작업이 병목이 될 수도 있음, 프로그램이 I/O위주(I/O bound)
- I/O 대기(I/O wait) : 일시 정지된 상태를 일컬음
- 비동기 프로그래밍 소개
  - 일반적으로 프로그램이 I/O 대기에 들어가면, 실행이 멈추고 커널이 I/O 요청과 관련된 저수준 연산을 처리하며(이를 컨테스트 스위칭), I/O 연산이 끝날 때까지 ㅡ로그램은 재개되지 앟음, 컨텍스트 스위칭은 상당히 비싼 연산 
  - 동시성 프로그램은 보통 실행할 대상과 시점을 관리하는 이벤트 루프를 사용함, 이벤트 루프는 실행할 함수의 목록에 지나지 않음 
  - 콜백 패러다임에서는 각 함수를 호출할 때 콜백이라는 인자를 넘김, 함수가 값을 반환하는 대신, 극 값을 인자로 실어 콜백 함수를 호출함. 이 구조에서는 호출한 함수의 결과를 받는 함수가 더해지고, 다시 그 함수의 결과를 받는 또 다른 함수가 더해지면서 함수의 사슬이 만들어짐
    - 콜백 지옥 : 위의 방식으로 콜백 깊이가 깊어지는 상황
- async/await의 동작 방식
  - async 함수(async def)는 코루틴(coroutine)이라 불림
  - 파이썬에서 코루틴은 제너레이터와 같은 철학으로 구현됨, 제너레이터에 이미 실행을 일시 중단하고 나중에 계속 실행할 수 있는 장치가 있으므로 구현이 편리함, 이 패러다임을 사용하면 await 문은 함수의 yield문과 기능 면에서 비슷해짐 
- gevent
  - 굉장히 단순한 비동기 라이브러리, 비동기 함수가 퓨처를 반환한다는 패러다임을 따름, 코드의 로직 대부분을 동시에 실행할 수 있다는 뜻 
  - gevent는 표준 I/O 함수를 몽키패치(monkey patch)해서 비동기적으로 만듬, 보통 표준 I/O 패키지를 사용하기만 해도 비동기적 동작의 이점을 살릴 수 있음 
  - 그린렛(greenlet)은 코루틴의 일종으로 스레드와 같다고 생각할 수 있음 
- tornado
  - 파이썬 비동기 I/O에 자주 사용함, HTTP 클라이언트와 서버를 위해 페이스북에서 개발한 패키지
- 파이프라이닝 : 결과를 일괄 처리하는 방식
  - I/O 작업의 부하를 낮추고 싶을 때 큰 도움이됨, 파이프라이닝은 비동기 I/O의 속도와 순차 프로그램의 작성 용이성을 잘 절충한 방식, 파이프라이닝 시 사용할 적절한 묶음의 크기는 상황에 따라 달라지므로 최선의 결과를 얻으려면 프로파일링과 튜닝이 필요함 
- gevent는 비동기 I/O를 위한 가장 높은 수준의 인터페이스를 제공함, tornado와 aiohttp를 사용하면 비동기 I/O 스택을 직접 제어할 수 있음, 서로 다른 수준의 추상화와 더불어, 각 라이브러리는 서로 다른 문법 패러다임을 사용함, asyncio는 비동기 해법을 하나로 묶는 접착제이며, 이 모두를 제어할 수 있는 토대를 제공함 

## multiprocessing 모듈 
- 프로세스와 스레드 기반의 병렬 처리를 사용해서 작업을 대기열에 분산시키고 프로세스 간에 데이터를 공유할 수 있또록 함, 단일 컴퓨터의 멀티 코어 병렬 처리에 초점이 맞춰져 있음
- 가장 일반적인 사용법은 CPU 위주의 작업을 여러 프로세스로 병렬화하는 것, I/O 위주의 문제를 병렬화하는 데 OpenMP 모듈을 사용할 수도 있음 
- multiprocessing 모듈로 처리할 수 있는 전형적인 작업의 예
  - CPU 위주의 작업을 Process나 Pool 객체를 사용해 병렬화함
  - dummy 모듈을 사용해서 I/O 위주의 작업을 스레드를 사용하는 Pool로 병렬화함
  - Queue를 통해 피클링(pickling)한 결과를 공유함
  - 병렬화한 작업자 사이에서 바이트,원시 데이터 타입, 사전, 리스트 등의 상태를 공유함 
- 파이썬스레드가 OS의 네이트브 스레드이며(즉 파이썬 스레드는 실제 운영체제가 실행하는 스레드로, 에뮬레이션된 것이 아님), GIL에 의해 제한되며, 한 번에 오직 한 스레드만 파이썬 객체들과 상호작용할 수 있음을 알아야만 함 
- 프로세스를 사용하여 여러 파이썬 인터프리터를 병렬로 실행할 수 있고, 각각의 인터프리터는 독립된 메모리 공간과 GIL을 가지며, 각각 순차적으로 실행됨(따라서 각각의 GIL을 두고 경쟁하지 않음), 파이썬에서 CPU 위주의 작업의 속도를 높이는 가장 쉬운 방법
- multiprocessing 모듈 소개
  - 프로세스와 스레드 기반의 병렬화를 위한 저수준 인터페이스를 제공함
  - 프로세스(process)
    - 현재 프로세스를 포크(fork)한 복사본, 새로운 프로세스 식별자가 부여되며 운영체제상에서 별도의 자식 프로세스로 작업을 실행함, Process를 시작하고 상태를 쿼리할 수 있으며, 실행할 target 메서드를 지정할 수 있음 
  - 풀(Pool)
    - Process나 threading. Thread API를 감싸서 사용하기 편한 작업자 풀(worker pool)로 만듬, 작업을 공유하고 합쳐진 결과를 반환함 
  - 큐(Queue)
    - 여러 생산자(producer)와 소지바(consumer)가 사용할 수 있느 FIFO(선입선출) 대기열
  - 파이프(Pipe)
    - 두 프로세스 사이의 단방향 또는 양방향 통신 채널 
  - 관리자(Manager)
    - 프로세스 간에 파이썬 객체를 공유하는 고수준의 관리된 인터페이스
  - ctypes
    - 프로세스를 포크한 다음 여러 프로세스가 원시 데이터 타입(예: 정수, 실수, 바이트)을 공유하게 해줌 
- 프로세스를 사용하는 버전은 이런 제약이 없음, 각 프로세스가 단일 스레드를 실행하는 별도의 파이썬 인터프리터이니 공유 객체로 인한 GIL 경쟁이 없음 
- Joblib 라이브러리
  - multiprocessing 라이브러리 위에 만들어졌으며, 여러 플랫폼 간 호환성을 높여주고, 병렬화를 위한 간단한 API를 제공하며, 캐시된 결과를 편리하게 영속화하게 해줌 
  - multiprocessing을 개선한 모듈로 경량 파이프라이닝을 활성화하면서 병렬 계산을 쉽게 하고, 결과를 쉽게 디스크 기반의 캐시로 사용할 수 있게 해줌 
  - 다음과 같은 경우 Joblib을 사용하면 쉽게 성능을 높일 수 있음
    - 당황스러울 정도로 병렬적인 루프를 처리하는 데 순수 파이썬을 사용 중(넘파이 사용 여부는 상관 없음)
    - 출력을 디스크에 저장해 세션과 세션 사이에 결과를 캐시할 수 있는데도, 부작용 없이 비용이 많이 드는 함수를 호출함
    - 프로세스 사이에 넘파이를 공유할 수 있지만 어떻게 하는지를 모름
  - Joblib은 Loky 라이브러리 위에 만들어졌고(Locky는 파이썬 concurrent.futures를 개선한 라이브러리) cloudpickle을 사용해 상호작용 영역에서 정의된 함수를 피클링할 수 있음. 내장 multiprocessing 라이브러리를 사용할 때 흔히 경험하는 몇몇 문제를 해결할 수 있음
  - 병렬 계싼에는 Parallel 클래스와 delayed 데커레이터가 필요함. Parallel 클래스는 앞절에서 사용한 multiprocessing의 pool과 비슷한 프로세스 풀을 만듬, delayed 데커레이터는 대상 함수를 감싸서 함수가 이터레이터를 통해 인스턴스화된 Parallel 객체에 접근할 수 있게 함 
  - 함수 호출 결과를 똑똑하게 캐시하기
    - Joblib의 Memory 캐시는 유용한 기능 
    - Memory는 함수 결과를 입력 인자에 따라 디스크 캐시로 저장하는 데커레이터, 이 캐시는 파이썬 세션 간에 영속적으로 유지되므로, 컴퓨터를 껐다가 다음날 켜서 같은 코드를 다시 실행해도 캐시에 저장한 결과를 사용할 수 있음 
- 작업 큐
  - multiprocessing.Queue 객체는 피클 가능한 파이썬 객체를 프로세스 간에 전송할 수 있는 영속적이지 않은 큐를 제공함. 각 객체를 전송하려면 피클화해야 하고, 소비자에서는 이를 다시 언피클해야 하므로 이 과정에는 부가비용이 듬(락 관련 연산 비용도 듬) 
- 회복탄련성(resilience)을 위해 작업 그래프 사용을 고려하기. 오래 실행되는 큐를 사용하는 데이터 과학 작업은 비순환 그래프로 이뤄진 작업 파이프라인으로 지정하면 잘 작동하는 경우가 많음, 강력한 라이브러리로 Airflow와 Luigi가 있음, 업계에서도 이들을 자주 사용하며 임의의 작업 체이닝, 온라인 감시, 유연한 규모 확장을 지원함 
- Manager.Value를 플래그로 사용하기
  - multiprocessing.Manager()를 사용하면 고수준 파이썬 객체를 프로세스 간에 매니지드(managed) 공유 객체로 활용할 수 있음
  - 저수준 객체들은 프록시(Proxy) 객체로 감쌈, 감싸고 안전성을 보장하면서 속도가 느려지는 대신 엄청난 유연성을 얻을 수 있음. 정수나 부동소수점 수같은 저수준 객체와 리스트, 사전 등을 모두 공유할 수 있음 
- 레디스를 플래그로 사용하기
  - 레디시는 인메모리 키/값 저장소 엔진 
  - 자체 락을 제공하며 각 연산은 원자적, 파이썬(또는 어떤 언어든) 안에서는 락 사용을 걱정할 필요가 없음 
  - 레디스를 사용하면 언어와 무관한 데이터 저장소를 만들 수 있음, 레디스와 인터페이스하는 언어나 도구라면 데이터를 서로 호환되는 방식으로 공유할 수 있다는 의미, 파이썬, 루비, C++, PHP 등의 언어 사이에서 데이터를 똑같이 쉽게 공유할 수 있음
  - 데이터를 한 컴퓨터에서 지역적으로 공유하거나 네트워크를 통해 공유할 수도 있음. 다른 컴퓨터와 공유하고 싶다면 레디스에서 지역적으로 공유하거나 네트워크를 통해 공유할 수도 있음, 다른 컴퓨터와 공유하고 싶다면 레디스에서 기본 제공하는 localhost의 공유 설정을 바꾸기만 하면 됨
  - 레디스 저장 내역
    - 문자열의 리스트
    - 문자열의 집합
    - 문자열을 정렬한 집합
    - 문자열의 해시 
  - 레디스는 모든 것을 RAM에 저장하고 디스크에 스냅샷을 저장하며(저널링 옵션 사용), 레디스 클러스터 사이에 마스터/슬레이브 복제를 지원함, 레디스를 사용하면 클러스터에서 부하를 공유할 수 있음 
  - 여러 컴퓨터가 상태를 읽거나 쓸 수 있고, 레디스는 고속 중앙 집중 데이터 리포지터리 역할을 함 
- RawValue를 플래그로 사용하기
  - multiprocessing.RawValue는 바이트의 ctypes 블록을 감싸는 얇은 래퍼, RawValue는 동기화 요소를 제공하지 않으므로 처리에 추가되는 부분이 거의 없어서, 검색 시 프로세스 사이에 플래그를 설정하는 가장 빠른 방법이 될 수 있음 
- mmap을 플래그로 사용하기
  - 바이트를 공유하는 가장 빠른 방식에 도달함 
  - mmap 모듈을 사용한 메모리 매핑(공유 메모리) 해법을 보여줌, 공유 메모리 블록의 바이트들은 동기화되지 않으며 부가비용도 매우 적음, 파일처럼 작동함(여기서는 파일과 유사한 인터페이스를 제공하는 메모리 블록) 
- $ps -A -o pid,size,vsize,cmd | grep np_shared(생략.py)
  - ps : 프로세스 정보를 표시함
  - -A : 모든 프로세스를 나열함
  - -o pid, size, vsize, cmd : PID, 크기 정보, 명령어 이름을 표시함
  - grep : 결과 중에서 우리 데모와 관련된 부분만 걸러내 표시함
- assert 검사 : 각 PID의 빈도가 예상과 일치하는지 확인하는 검사 
